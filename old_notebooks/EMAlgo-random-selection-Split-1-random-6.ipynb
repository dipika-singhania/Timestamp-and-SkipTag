{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from time import time\n",
    "from utils import get_all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utility.adaptive_data_loader import BreakfastWithWeights, collate_fn_override_wtd\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temp': 1, 'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 1, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select6-temp1-exp4/split1/', 'project_name': 'breakfast-split-1', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split1.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split1.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split1_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    temp=1,\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=1,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select6-temp1-exp4/\",\n",
    "    project_name=\"breakfast-split-1\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "config.output_dir = config.output_dir + f\"split{config.split}\"\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "config.output_dir = config.output_dir + \"/\"\n",
    "if not os.path.exists(os.path.join(config.output_dir, \"posterior_weights\")):\n",
    "    os.mkdir(os.path.join(config.output_dir, \"posterior_weights\"))\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1460\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 252\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = BreakfastWithWeights(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override_wtd(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "\n",
    "trainloder_expectation = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=20,\n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override_wtd(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_frames_dict = pickle.load(open(\"data/breakfast_len_assum_annotations.pkl\", 'rb'))\n",
    "# loaded_vidid_selected_frames\n",
    "boundary_frames_dict = pickle.load(open(\"data/breakfast_boundary_annotations.pkl\", \"rb\"))\n",
    "num_boundary = 0\n",
    "for key in boundary_frames_dict.keys():\n",
    "    num_boundary += len(boundary_frames_dict[key])\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frames_dict = pickle.load(open(\"data/breakfast_random6frame_selection.pkl\", \"rb\"))\n",
    "# print(selected_frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"data/breakfast_meanvar_actions.pkl\", \"rb\"))\n",
    "mat_poisson = pickle.load(open(\"data/breakfast_possion_class_dict.pkl\", \"rb\"))\n",
    "\n",
    "def get_possion_prob(minlen, maxlen, cur_class):\n",
    "    prob = mat_poisson[label_id_to_label_name[cur_class]][minlen:maxlen]\n",
    "    return torch.tensor(prob)\n",
    "\n",
    "def get_poisson_logcdf(minlen, cur_class):\n",
    "    return np.log(np.sum(np.exp(mat_poisson[label_id_to_label_name[cur_class]][minlen:])) + 1e-20)\n",
    "\n",
    "def get_possion_prob_for_all_class(minlen, maxlen):\n",
    "    ele_list = []\n",
    "    for i in range(config.num_class):\n",
    "        prob = mat_poisson[label_id_to_label_name[i]][minlen:maxlen]\n",
    "        ele_list.append(torch.tensor(prob))\n",
    "    return torch.stack(ele_list, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, best_val_acc=None):\n",
    "    model.eval()\n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    vidcount = 0\n",
    "    all_scores = []\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "            for p, l, c in zip(pred, item_2, item_1):\n",
    "                all_scores.append(get_all_scores(p[:c].detach().cpu().numpy(), \n",
    "                                                 l[:c].detach().cpu().numpy(), ['SIL']))\n",
    "            \n",
    "    final_scores = np.mean(np.array(all_scores), axis=0)\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if best_val_acc is not None and val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-last-model.wt\")\n",
    "    print(f\"Validation:: Probability Accuracy {val_acc}\")\n",
    "    print(f\"Other scores:: Edit {final_scores[3]}, F1@[10:25:50] {final_scores[:3]}\")\n",
    "    _ = model.train()\n",
    "    return val_acc, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels, first_ele_flag, last_ele_flag, vidid, gt_labels):\n",
    "    prob_each_segment = []\n",
    "    LOW_VAL = -10000000\n",
    "    num_frames = len(cur_vid_feat)\n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    prev_boundary = 0\n",
    "    per_frame_weights = torch.zeros((num_frames, config.num_class))\n",
    "    start_time = time()\n",
    "    boundary_error = 0\n",
    "    current_boundary = 0\n",
    "    labels = [config.num_class-1] + labels if selected_frames[0] != 0 else labels\n",
    "    labels = labels + [config.num_class-1] if selected_frames[-1] != num_frames-1 else labels\n",
    "    selected_frames = [0] + selected_frames if selected_frames[0] != 0 else selected_frames\n",
    "    selected_frames = selected_frames + [num_frames-1] if selected_frames[-1] != num_frames-1 else selected_frames\n",
    "\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[i]\n",
    "        label_next_ele = labels[i + 1]\n",
    "        if cur_ele == next_ele-1:\n",
    "            per_frame_weights[cur_ele, label_cur_ele] = 1.0\n",
    "            if label_cur_ele != label_next_ele:\n",
    "                prev_boundary = cur_ele\n",
    "            continue\n",
    "        \n",
    "        seg_len = next_ele - cur_ele\n",
    "        mat_b1_b2_c_prob = LOW_VAL * torch.ones((seg_len, seg_len, config.num_class), dtype=cumsum_feat.dtype)\n",
    "        b1_prior = get_possion_prob(cur_ele-prev_boundary, next_ele-prev_boundary, label_cur_ele)\n",
    "        \n",
    "        # find dummy label where we will keep the diagonal (b1=b2) probabilities, later we will distribute among\n",
    "        # rest of the classes after the softmax by dividing by (num_class - 2)\n",
    "        dummy_label = 0\n",
    "        while True:\n",
    "            if dummy_label != label_cur_ele and dummy_label != label_next_ele:\n",
    "                break\n",
    "            else:\n",
    "                dummy_label += 1\n",
    "        \n",
    "        for b1 in range(cur_ele, next_ele - 1):\n",
    "\n",
    "            cur_boundary_len = b1 - prev_boundary\n",
    "            strt_index = cumsum_feat[cur_ele - 1, label_cur_ele] if cur_ele > 0 else 0\n",
    "            left_sum = (cumsum_feat[b1, label_cur_ele] - strt_index)\n",
    "            right_sum = cumsum_feat[next_ele-1, label_next_ele] - cumsum_feat[b1+1:next_ele, label_next_ele] # mid_seg_len\n",
    "            mid_sum = (cumsum_feat[b1+1:next_ele, :] - cumsum_feat[b1, :])  # mid_seg_len\n",
    "            b2_prior = get_possion_prob_for_all_class(1, next_ele-b1)  # mid_seg_len x num_class\n",
    "            \n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1+1-cur_ele:next_ele-cur_ele] = (left_sum + right_sum[:,None] + mid_sum) / config.temp \\\n",
    "                                                                            + b1_prior[b1-cur_ele] + b2_prior\n",
    "            # when mid segment is absent but right and left is not the same\n",
    "            # we assign the probability to a dummy label for now and then later \n",
    "            # re-distribute among other classes after the softmax\n",
    "            if label_cur_ele != label_next_ele:\n",
    "                rightsum_wo_midseg = cumsum_feat[next_ele-1, label_next_ele] - cumsum_feat[b1, label_next_ele]\n",
    "                mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = (left_sum + rightsum_wo_midseg) / config.temp \\\n",
    "                                                                        + b1_prior[b1-cur_ele]\n",
    "        \n",
    "#         if vidid=='P39_cam02_P39_scrambledegg' and cur_ele==574:\n",
    "#             import pdb\n",
    "#             pdb.set_trace()\n",
    "        # when mid segment is absent b1 can also be next_ele-1\n",
    "        b1 = next_ele - 1\n",
    "        if label_cur_ele != label_next_ele:\n",
    "            left_sum = (cumsum_feat[b1, label_cur_ele] - strt_index)\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = left_sum / config.temp + b1_prior[b1-cur_ele]\n",
    "        else:\n",
    "            # returns prob that the left class length >= seg len\n",
    "            b1_prior_ = get_poisson_logcdf(next_ele - prev_boundary, label_cur_ele) \n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = left_sum  / config.temp + b1_prior_\n",
    "        \n",
    "        mat_b1_b2_c_prob[:, :, label_cur_ele] = LOW_VAL\n",
    "        mat_b1_b2_c_prob[:, :, label_next_ele] = LOW_VAL\n",
    "        mat_b1_b2_c_prob = torch.softmax(mat_b1_b2_c_prob.flatten(), dim=0).reshape((seg_len, seg_len, config.num_class))\n",
    "        \n",
    "        # re-distribute the dummy class probability among the left-over classes\n",
    "        left_over_classes = config.num_class - 2 + (label_cur_ele==label_next_ele)\n",
    "        for b1 in range(cur_ele, next_ele):\n",
    "            assigned_prob = mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label]\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, :] = assigned_prob/left_over_classes\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, label_cur_ele] = 0\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, label_next_ele] = 0\n",
    "        \n",
    "        marginal_b1 = torch.sum(mat_b1_b2_c_prob, axis=(1,2))\n",
    "        mean_b1 = round(torch.sum(marginal_b1.squeeze() * torch.arange(cur_ele, next_ele, 1)).item())\n",
    "        cumm_b1_prob = torch.cumsum(marginal_b1, dim=0)\n",
    "        cumm_b1_c_prob = torch.cumsum(torch.sum(mat_b1_b2_c_prob, dim=1), dim=0)\n",
    "        cumm_b2_c_prob = torch.cumsum(torch.sum(mat_b1_b2_c_prob, dim=0), dim=0)\n",
    "\n",
    "        per_frame_weights[cur_ele, label_cur_ele] = 1.0\n",
    "        per_frame_weights[cur_ele+1:next_ele, :] = cumm_b1_c_prob[:-1] - cumm_b2_c_prob[:-1]\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_cur_ele] = 1 - cumm_b1_prob[:-1]\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_next_ele] = 0\n",
    "        remaining_probability = 1 - torch.sum(per_frame_weights[cur_ele+1:next_ele, :], dim=-1)\n",
    "        # we use \"+=\" in the next line because left and right label might be the same\n",
    "        # in that case using \"=\" would just overwrite the previous probability\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_next_ele] += remaining_probability\n",
    "        \n",
    "        expected_boundary = round(torch.sum(torch.sum(mat_b1_b2_c_prob, axis=(0,2)).squeeze() * \\\n",
    "                            torch.arange(cur_ele, next_ele, 1)).item())\n",
    "        if not (label_cur_ele == label_next_ele and expected_boundary >= next_ele-2):\n",
    "            prev_boundary = expected_boundary\n",
    "        if expected_boundary == 0 and i > 0:\n",
    "            print(f'Estimated boundary has become zero! for {vidid} and cur_ele, next_ele {cur_ele, next_ele}')\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        # boundary_error += (boundary_frames_dict[vidid + '.txt'][current_boundary] - mean_b1)**2\n",
    "        # boundary_error += (boundary_frames_dict[vidid + '.txt'][current_boundary+1] - prev_boundary)**2\n",
    "        # current_boundary += 2\n",
    "        # prob_each_segment.append(mat_b1_b2_c_prob)\n",
    "        \n",
    "    posterior_prediction = torch.argmax(per_frame_weights, dim=1)\n",
    "    correct = torch.sum(posterior_prediction == gt_labels[:num_frames]).item()\n",
    "    \n",
    "    return (vidid, per_frame_weights, [correct, num_frames, boundary_error]) #, prob_each_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_acc_correct, posterior_acc_total = 0, 0\n",
    "posterior_boundary_total_mse = 0\n",
    "results = []\n",
    "\n",
    "# Step 2: Define callback function to collect the output in `results`\n",
    "def collect_result(result):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    fname = os.path.join(config.output_dir, 'posterior_weights', result[0] + '.wt')\n",
    "    torch.save(result[1], fname)\n",
    "    correct, total, boundary_err = result[2]\n",
    "    posterior_acc_correct += correct\n",
    "    posterior_acc_total += total\n",
    "    posterior_boundary_total_mse += boundary_err\n",
    "    # print(f'Dumped in file {fname} at time {time()}')\n",
    "    return\n",
    "\n",
    "def calculate_element_probb(data_feat, data_count, video_ids, gt_labels): # loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    pool = mp.Pool(20)\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "#         if cur_vidid!='P39_cam02_P39_scrambledegg':\n",
    "#             continue\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num][:cur_vid_count].detach().cpu()\n",
    "        cur_gt_labels = gt_labels[iter_num].detach().cpu()\n",
    "        \n",
    "        cur_video_select_frames = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices_and_labels = cur_video_select_frames\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "        with torch.no_grad():\n",
    "            # Multi-processing\n",
    "            pool.apply_async(prob_vals_per_segment,\n",
    "                             args=(selected_frames_indices, cur_vid_feat, selected_frames_labels,\n",
    "                                   cur_video_select_frames[1], cur_video_select_frames[2], cur_vidid, cur_gt_labels),\n",
    "                             callback=collect_result)\n",
    "#             results.append(prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels,\n",
    "#                                    cur_video_select_frames[1], cur_video_select_frames[2], cur_vidid, cur_gt_labels))\n",
    "    # Step 4: Close Pool and let all the processes complete\n",
    "    pool.close()\n",
    "    pool.join()  # postpones the execution of next line of code until all processes in the queue are done.\n",
    "    return results\n",
    "\n",
    "def perform_expectation(model, dataloader):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse = 0, 0, 0\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    curtime = time()\n",
    "    print(f'Calculating expectation')\n",
    "\n",
    "    for i, item in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device) # features\n",
    "            item_1 = item[1].to(device) # count\n",
    "            item_2 = item[2].to(device) # gt frame-wise labels\n",
    "            item_4 = item[4] # video-ids\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            prob = torch.softmax(predictions[-1], dim=1)\n",
    "            prob = prob.permute(0, 2, 1)\n",
    "            \n",
    "            calculate_element_probb(prob, item_1, item_4, item_2)\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(f\"iter {i+1} of Expectation completed in a total of {(time() - curtime)/60.: .1f} minutes\")\n",
    "    _ = model.train()\n",
    "    print(f'Expectation step finished, '\n",
    "          f'posterior frame-wise accuracy {100*posterior_acc_correct/posterior_acc_total: .2f}%, '\n",
    "          f'boundary mse {(posterior_boundary_total_mse/num_boundary)**0.5: .2f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_file = torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select6/split1/ms-tcn-initial-30-epochs.wt')\n",
    "model.load_state_dict(loaded_file)\n",
    "# # loaded_file=torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcnnew-full-supervised-split1/ms-tcn-best-model.wt')\n",
    "# # model.load_state_dict(loaded_file)\n",
    "# loaded_file=torch.load(os.path.join(config.output_dir, \"ms-tcn-emmax-best-model.wt\"))\n",
    "# loaded_file=torch.load(\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/ms-tcn-emmax-last-model.wt\")\n",
    "# model.load_state_dict(loaded_file)\n",
    "# _ = validate(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = next(iter(trainloader))\n",
    "    \n",
    "# with torch.no_grad():\n",
    "#     item_0 = item[0].to(device) # features\n",
    "#     item_1 = item[1].to(device) # count\n",
    "#     item_2 = item[2].to(device) # gt frame-wise labels\n",
    "#     item_4 = item[4] # video-ids\n",
    "#     src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "#     src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "#     middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "#     prob = torch.softmax(predictions[-1], dim=1)\n",
    "#     prob = prob.permute(0, 2, 1)\n",
    "\n",
    "#     res = calculate_element_probb(prob, item_1, item_4, item_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 2\n",
    "# vidid = res[idx][0]\n",
    "# mat = res[idx][1]\n",
    "# mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace(0, 5281, 4 + 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundary_frames_dict[f'{vidid}.txt'], selected_frames_dict[f'{vidid}.txt'], weakly_labels[f'{vidid}.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20, 5))\n",
    "# for i in range(48):\n",
    "#     plt.plot(mat[:,i])\n",
    "    \n",
    "# for bd in boundary_frames_dict[f'{vidid}.txt']:\n",
    "#     plt.plot([bd, bd], [0, 2])\n",
    "    \n",
    "# for bd in selected_frames_dict[f'{vidid}.txt']:\n",
    "#     plt.plot([bd[0], bd[0]], [0, 2], '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculating Expectation Step\n",
    "# perform_expectation(model, trainloder_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_random(video_ids, len_frames, device):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((len(video_ids), len_frames), dtype=torch.long, device=device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "\n",
    "        frame_idx_tensor = torch.from_numpy(np.array(selected_frames_indices))\n",
    "        frame_labels = torch.from_numpy(np.array(selected_frames_labels)).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = frame_labels\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labels = pickle.load(open(\"data/breakfast_weaklysupervised_labels.pkl\", \"rb\"))\n",
    "prior_probs = pickle.load(open('data/breakfast_lengthmodel_multinomial_prior.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Epoch 31: Iteration 20 with loss 1.9348218441009521\n",
      "Epoch 31: Iteration 40 with loss 0.8680094480514526\n",
      "Epoch 31: Iteration 60 with loss 0.703044593334198\n",
      "Epoch 31: Iteration 80 with loss 2.2023158073425293\n",
      "Epoch 31: Iteration 100 with loss 1.587623953819275\n",
      "Epoch 31: Iteration 120 with loss 1.3736432790756226\n",
      "Epoch 31: Iteration 140 with loss 0.7242828011512756\n",
      "Epoch 31: Iteration 160 with loss 1.138664722442627\n",
      "Epoch 31: Iteration 180 with loss 1.3904500007629395\n",
      "Epoch 31 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.88841403817008\n",
      "Other scores:: Edit 44.902570599741715, F1@[10:25:50] [48.27744596 43.15948885 34.33271482]\n",
      "Starting Training\n",
      "Epoch 32: Iteration 20 with loss 0.0\n",
      "Epoch 32: Iteration 40 with loss 0.0\n",
      "Epoch 32: Iteration 60 with loss 0.0\n",
      "Epoch 32: Iteration 80 with loss 0.0\n",
      "Epoch 32: Iteration 100 with loss 0.0\n",
      "Epoch 32: Iteration 120 with loss 0.0\n",
      "Epoch 32: Iteration 140 with loss 0.0\n",
      "Epoch 32: Iteration 160 with loss 0.0\n",
      "Epoch 32: Iteration 180 with loss 0.0\n",
      "Epoch 32 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.735053084353275\n",
      "Other scores:: Edit 41.42194254249416, F1@[10:25:50] [43.78675277 39.21299127 29.45635981]\n",
      "Starting Training\n",
      "Epoch 33: Iteration 20 with loss 0.0\n",
      "Epoch 33: Iteration 40 with loss 0.0\n",
      "Epoch 33: Iteration 60 with loss 0.0\n",
      "Epoch 33: Iteration 80 with loss 0.0\n",
      "Epoch 33: Iteration 100 with loss 0.0\n",
      "Epoch 33: Iteration 120 with loss 0.0\n",
      "Epoch 33: Iteration 140 with loss 0.0\n",
      "Epoch 33: Iteration 160 with loss 0.0\n",
      "Epoch 33: Iteration 180 with loss 0.0\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.3 minutes\n",
      "iter 20 of Expectation completed in a total of  7.0 minutes\n",
      "iter 30 of Expectation completed in a total of  9.8 minutes\n",
      "iter 40 of Expectation completed in a total of  13.1 minutes\n",
      "iter 50 of Expectation completed in a total of  16.8 minutes\n",
      "iter 60 of Expectation completed in a total of  19.7 minutes\n",
      "iter 70 of Expectation completed in a total of  23.0 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  74.75%, boundary mse  0.00\n",
      "Epoch 33 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.735053084353275\n",
      "Other scores:: Edit 41.42194254249416, F1@[10:25:50] [43.78675277 39.21299127 29.45635981]\n",
      "Starting Training\n",
      "Epoch 34: Iteration 20 with loss 7.9166154861450195\n",
      "Epoch 34: Iteration 40 with loss 2.942477226257324\n",
      "Epoch 34: Iteration 60 with loss 3.4530515670776367\n",
      "Epoch 34: Iteration 80 with loss 2.826751232147217\n",
      "Epoch 34: Iteration 100 with loss 2.238232135772705\n",
      "Epoch 34: Iteration 120 with loss 1.2526648044586182\n",
      "Epoch 34: Iteration 140 with loss 1.4416301250457764\n",
      "Epoch 34: Iteration 160 with loss 2.734518527984619\n",
      "Epoch 34: Iteration 180 with loss 2.119274616241455\n",
      "Epoch 34 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.1465705885379\n",
      "Other scores:: Edit 56.15955337847316, F1@[10:25:50] [55.25786601 51.62924175 42.64842016]\n",
      "Starting Training\n",
      "Epoch 35: Iteration 20 with loss 2.1179006099700928\n",
      "Epoch 35: Iteration 40 with loss 1.7560306787490845\n",
      "Epoch 35: Iteration 60 with loss 1.449641227722168\n",
      "Epoch 35: Iteration 80 with loss 3.5715408325195312\n",
      "Epoch 35: Iteration 100 with loss 2.1628293991088867\n",
      "Epoch 35: Iteration 120 with loss 2.1076929569244385\n",
      "Epoch 35: Iteration 140 with loss 2.9856481552124023\n",
      "Epoch 35: Iteration 160 with loss 1.9889163970947266\n",
      "Epoch 35: Iteration 180 with loss 2.1025547981262207\n",
      "Epoch 35 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 52.21161722283557\n",
      "Other scores:: Edit 53.63463169428186, F1@[10:25:50] [52.53762453 50.08619608 41.19799252]\n",
      "Starting Training\n",
      "Epoch 36: Iteration 20 with loss 2.0971601009368896\n",
      "Epoch 36: Iteration 40 with loss 1.6845899820327759\n",
      "Epoch 36: Iteration 60 with loss 1.6175882816314697\n",
      "Epoch 36: Iteration 80 with loss 3.5328469276428223\n",
      "Epoch 36: Iteration 100 with loss 1.6737306118011475\n",
      "Epoch 36: Iteration 120 with loss 2.1026129722595215\n",
      "Epoch 36: Iteration 140 with loss 1.1781001091003418\n",
      "Epoch 36: Iteration 160 with loss 2.8403546810150146\n",
      "Epoch 36: Iteration 180 with loss 1.4512053728103638\n",
      "Epoch 36 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.903209595150194\n",
      "Other scores:: Edit 58.918382289820194, F1@[10:25:50] [57.3049987  54.15318339 45.51199023]\n",
      "Starting Training\n",
      "Epoch 37: Iteration 20 with loss 0.9936349391937256\n",
      "Epoch 37: Iteration 40 with loss 0.9089445471763611\n",
      "Epoch 37: Iteration 60 with loss 2.964150905609131\n",
      "Epoch 37: Iteration 80 with loss 1.5357171297073364\n",
      "Epoch 37: Iteration 100 with loss 1.6828186511993408\n",
      "Epoch 37: Iteration 120 with loss 2.8123321533203125\n",
      "Epoch 37: Iteration 140 with loss 1.1950263977050781\n",
      "Epoch 37: Iteration 160 with loss 1.5378212928771973\n",
      "Epoch 37: Iteration 180 with loss 1.9071364402770996\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.5 minutes\n",
      "iter 20 of Expectation completed in a total of  6.4 minutes\n",
      "iter 30 of Expectation completed in a total of  10.4 minutes\n",
      "iter 40 of Expectation completed in a total of  13.3 minutes\n",
      "iter 50 of Expectation completed in a total of  16.4 minutes\n",
      "iter 60 of Expectation completed in a total of  20.0 minutes\n",
      "iter 70 of Expectation completed in a total of  23.0 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  75.73%, boundary mse  0.00\n",
      "Epoch 37 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.46100486326278\n",
      "Other scores:: Edit 58.242542873787045, F1@[10:25:50] [57.69233892 53.94815964 42.62742042]\n",
      "Starting Training\n",
      "Epoch 38: Iteration 20 with loss 0.9278465509414673\n",
      "Epoch 38: Iteration 40 with loss 1.4377596378326416\n",
      "Epoch 38: Iteration 60 with loss 1.4790928363800049\n",
      "Epoch 38: Iteration 80 with loss 1.152124285697937\n",
      "Epoch 38: Iteration 100 with loss 1.2241652011871338\n",
      "Epoch 38: Iteration 120 with loss 1.5423353910446167\n",
      "Epoch 38: Iteration 140 with loss 1.936051845550537\n",
      "Epoch 38: Iteration 160 with loss 1.624267578125\n",
      "Epoch 38: Iteration 180 with loss 3.85679030418396\n",
      "Epoch 38 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 56.70370502273348\n",
      "Other scores:: Edit 57.90168182416265, F1@[10:25:50] [56.30366869 52.668707   39.17393104]\n",
      "Starting Training\n",
      "Epoch 39: Iteration 20 with loss 0.9021427035331726\n",
      "Epoch 39: Iteration 40 with loss 1.4599796533584595\n",
      "Epoch 39: Iteration 60 with loss 1.1600487232208252\n",
      "Epoch 39: Iteration 80 with loss 0.6870311498641968\n",
      "Epoch 39: Iteration 100 with loss 1.2826597690582275\n",
      "Epoch 39: Iteration 120 with loss 1.688988447189331\n",
      "Epoch 39: Iteration 140 with loss 0.9181849956512451\n",
      "Epoch 39: Iteration 160 with loss 1.3040293455123901\n",
      "Epoch 39: Iteration 180 with loss 0.6690124273300171\n",
      "Epoch 39 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.70788370905896\n",
      "Other scores:: Edit 63.004300012307176, F1@[10:25:50] [60.2436953  56.92260777 45.22730658]\n",
      "Starting Training\n",
      "Epoch 40: Iteration 20 with loss 0.8118085861206055\n",
      "Epoch 40: Iteration 40 with loss 1.2241442203521729\n",
      "Epoch 40: Iteration 60 with loss 0.6130954027175903\n",
      "Epoch 40: Iteration 80 with loss 0.97059166431427\n",
      "Epoch 40: Iteration 100 with loss 0.8283126354217529\n",
      "Epoch 40: Iteration 120 with loss 1.0733972787857056\n",
      "Epoch 40: Iteration 140 with loss 6.368022441864014\n",
      "Epoch 40: Iteration 160 with loss 2.155426263809204\n",
      "Epoch 40: Iteration 180 with loss 1.9210572242736816\n",
      "Epoch 40 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.21313674513575\n",
      "Other scores:: Edit 57.08765003966381, F1@[10:25:50] [54.85170562 51.08153661 41.57960909]\n",
      "Starting Training\n",
      "Epoch 41: Iteration 20 with loss 1.2588398456573486\n",
      "Epoch 41: Iteration 40 with loss 0.9038819074630737\n",
      "Epoch 41: Iteration 60 with loss 0.8410177826881409\n",
      "Epoch 41: Iteration 80 with loss 1.4780046939849854\n",
      "Epoch 41: Iteration 100 with loss 1.964688777923584\n",
      "Epoch 41: Iteration 120 with loss 1.2124409675598145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Iteration 140 with loss 0.8416739106178284\n",
      "Epoch 41: Iteration 160 with loss 1.7861708402633667\n",
      "Epoch 41: Iteration 180 with loss 0.669053852558136\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.8 minutes\n",
      "iter 20 of Expectation completed in a total of  6.2 minutes\n",
      "iter 30 of Expectation completed in a total of  9.3 minutes\n",
      "iter 40 of Expectation completed in a total of  12.3 minutes\n",
      "iter 50 of Expectation completed in a total of  15.9 minutes\n",
      "iter 60 of Expectation completed in a total of  20.1 minutes\n",
      "iter 70 of Expectation completed in a total of  23.4 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  75.41%, boundary mse  0.00\n",
      "Epoch 41 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.09018206567977\n",
      "Other scores:: Edit 63.03104038832653, F1@[10:25:50] [61.68931256 58.2435453  47.8352055 ]\n",
      "Starting Training\n",
      "Epoch 42: Iteration 20 with loss 1.264890193939209\n",
      "Epoch 42: Iteration 40 with loss 0.5021525025367737\n",
      "Epoch 42: Iteration 60 with loss 0.4766331911087036\n",
      "Epoch 42: Iteration 80 with loss 0.7867478132247925\n",
      "Epoch 42: Iteration 100 with loss 1.1253416538238525\n",
      "Epoch 42: Iteration 120 with loss 0.8293213844299316\n",
      "Epoch 42: Iteration 140 with loss 0.7340607643127441\n",
      "Epoch 42: Iteration 160 with loss 1.853492021560669\n",
      "Epoch 42: Iteration 180 with loss 1.124427080154419\n",
      "Epoch 42 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.61785992695213\n",
      "Other scores:: Edit 62.9822418124355, F1@[10:25:50] [60.7251124  57.73497285 46.89674887]\n",
      "Starting Training\n",
      "Epoch 43: Iteration 20 with loss 0.6133399605751038\n",
      "Epoch 43: Iteration 40 with loss 0.5981724858283997\n",
      "Epoch 43: Iteration 60 with loss 0.6747944951057434\n",
      "Epoch 43: Iteration 80 with loss 0.5887830853462219\n",
      "Epoch 43: Iteration 100 with loss 1.4522886276245117\n",
      "Epoch 43: Iteration 120 with loss 0.9522406458854675\n",
      "Epoch 43: Iteration 140 with loss 0.8568664789199829\n",
      "Epoch 43: Iteration 160 with loss 1.0695589780807495\n",
      "Epoch 43: Iteration 180 with loss 0.9358701109886169\n",
      "Epoch 43 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.85172390596373\n",
      "Other scores:: Edit 62.68874907324118, F1@[10:25:50] [61.07027936 58.36525155 48.22131937]\n",
      "Starting Training\n",
      "Epoch 44: Iteration 20 with loss 1.012229561805725\n",
      "Epoch 44: Iteration 40 with loss 0.8063501119613647\n",
      "Epoch 44: Iteration 60 with loss 0.6139960289001465\n",
      "Epoch 44: Iteration 80 with loss 0.750756025314331\n",
      "Epoch 44: Iteration 100 with loss 0.8901346921920776\n",
      "Epoch 44: Iteration 120 with loss 0.9804550409317017\n",
      "Epoch 44: Iteration 140 with loss 0.593349814414978\n",
      "Epoch 44: Iteration 160 with loss 0.7638976573944092\n",
      "Epoch 44: Iteration 180 with loss 0.9610928893089294\n",
      "Epoch 44 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.28155086244762\n",
      "Other scores:: Edit 64.19094002350549, F1@[10:25:50] [61.1513088  58.03232997 47.50949754]\n",
      "Starting Training\n",
      "Epoch 45: Iteration 20 with loss 0.8145264387130737\n",
      "Epoch 45: Iteration 40 with loss 0.49792587757110596\n",
      "Epoch 45: Iteration 60 with loss 0.8327738642692566\n",
      "Epoch 45: Iteration 80 with loss 0.801609456539154\n",
      "Epoch 45: Iteration 100 with loss 1.0357666015625\n",
      "Epoch 45: Iteration 120 with loss 1.7338948249816895\n",
      "Epoch 45: Iteration 140 with loss 2.0714306831359863\n",
      "Epoch 45: Iteration 160 with loss 1.8291552066802979\n",
      "Epoch 45: Iteration 180 with loss 0.8704378008842468\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.4 minutes\n",
      "iter 20 of Expectation completed in a total of  6.4 minutes\n",
      "iter 30 of Expectation completed in a total of  9.5 minutes\n",
      "iter 40 of Expectation completed in a total of  12.3 minutes\n",
      "iter 50 of Expectation completed in a total of  15.7 minutes\n",
      "iter 60 of Expectation completed in a total of  19.4 minutes\n",
      "iter 70 of Expectation completed in a total of  23.0 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  75.45%, boundary mse  0.00\n",
      "Epoch 45 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.75545583690461\n",
      "Other scores:: Edit 61.87940904604048, F1@[10:25:50] [58.94438431 55.74762255 46.49129653]\n",
      "Starting Training\n",
      "Epoch 46: Iteration 20 with loss 0.7321257591247559\n",
      "Epoch 46: Iteration 40 with loss 0.5495806336402893\n",
      "Epoch 46: Iteration 60 with loss 0.8208122253417969\n",
      "Epoch 46: Iteration 80 with loss 0.9554839730262756\n",
      "Epoch 46: Iteration 100 with loss 1.3260164260864258\n",
      "Epoch 46: Iteration 120 with loss 0.7439552545547485\n",
      "Epoch 46: Iteration 140 with loss 1.4023456573486328\n",
      "Epoch 46: Iteration 160 with loss 0.5739266276359558\n",
      "Epoch 46: Iteration 180 with loss 0.6702179908752441\n",
      "Epoch 46 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.63340337381436\n",
      "Other scores:: Edit 64.63317829480864, F1@[10:25:50] [61.14568469 58.33179604 47.67398318]\n",
      "Starting Training\n",
      "Epoch 47: Iteration 20 with loss 1.0090703964233398\n",
      "Epoch 47: Iteration 40 with loss 0.6548938155174255\n",
      "Epoch 47: Iteration 60 with loss 0.7987729907035828\n",
      "Epoch 47: Iteration 80 with loss 2.29217529296875\n",
      "Epoch 47: Iteration 100 with loss 0.8034756779670715\n",
      "Epoch 47: Iteration 120 with loss 0.856269896030426\n",
      "Epoch 47: Iteration 140 with loss 1.6262590885162354\n",
      "Epoch 47: Iteration 160 with loss 1.0626252889633179\n",
      "Epoch 47: Iteration 180 with loss 0.9053784608840942\n",
      "Epoch 47 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.96228102456957\n",
      "Other scores:: Edit 65.82635639700894, F1@[10:25:50] [62.79705655 60.18331132 48.68434573]\n",
      "Starting Training\n",
      "Epoch 48: Iteration 20 with loss 1.4862432479858398\n",
      "Epoch 48: Iteration 40 with loss 1.2329158782958984\n",
      "Epoch 48: Iteration 60 with loss 1.0765138864517212\n",
      "Epoch 48: Iteration 80 with loss 0.9029529690742493\n",
      "Epoch 48: Iteration 100 with loss 0.7028882503509521\n",
      "Epoch 48: Iteration 120 with loss 0.44477733969688416\n",
      "Epoch 48: Iteration 140 with loss 1.0437126159667969\n",
      "Epoch 48: Iteration 160 with loss 0.9090560078620911\n",
      "Epoch 48: Iteration 180 with loss 0.7802179455757141\n",
      "Epoch 48 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.79153262026584\n",
      "Other scores:: Edit 64.03067241862261, F1@[10:25:50] [61.57574391 58.68282175 48.2337504 ]\n",
      "Starting Training\n",
      "Epoch 49: Iteration 20 with loss 0.42123568058013916\n",
      "Epoch 49: Iteration 40 with loss 0.6964241862297058\n",
      "Epoch 49: Iteration 60 with loss 0.5286080241203308\n",
      "Epoch 49: Iteration 80 with loss 1.0525851249694824\n",
      "Epoch 49: Iteration 100 with loss 0.6222377419471741\n",
      "Epoch 49: Iteration 120 with loss 0.538866400718689\n",
      "Epoch 49: Iteration 140 with loss 0.8953113555908203\n",
      "Epoch 49: Iteration 160 with loss 0.8911879062652588\n",
      "Epoch 49: Iteration 180 with loss 0.651203453540802\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.7 minutes\n",
      "iter 20 of Expectation completed in a total of  6.8 minutes\n",
      "iter 30 of Expectation completed in a total of  10.3 minutes\n",
      "iter 40 of Expectation completed in a total of  13.3 minutes\n",
      "iter 50 of Expectation completed in a total of  16.7 minutes\n",
      "iter 60 of Expectation completed in a total of  20.7 minutes\n",
      "iter 70 of Expectation completed in a total of  23.6 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  75.50%, boundary mse  0.00\n",
      "Epoch 49 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.602470806573514\n",
      "Other scores:: Edit 64.51140343561214, F1@[10:25:50] [60.34121151 57.39106795 47.54320688]\n",
      "Starting Training\n",
      "Epoch 50: Iteration 20 with loss 1.3721530437469482\n",
      "Epoch 50: Iteration 40 with loss 0.600517988204956\n",
      "Epoch 50: Iteration 60 with loss 1.2105579376220703\n",
      "Epoch 50: Iteration 80 with loss 1.7194461822509766\n",
      "Epoch 50: Iteration 100 with loss 0.6656320691108704\n",
      "Epoch 50: Iteration 120 with loss 0.6387333869934082\n",
      "Epoch 50: Iteration 140 with loss 0.9087671041488647\n",
      "Epoch 50: Iteration 160 with loss 1.0216559171676636\n",
      "Epoch 50: Iteration 180 with loss 1.4646966457366943\n",
      "Epoch 50 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Probability Accuracy 61.73751835100174\n",
      "Other scores:: Edit 63.40546297251721, F1@[10:25:50] [60.84857069 57.12163078 46.46461655]\n",
      "Starting Training\n",
      "Epoch 51: Iteration 20 with loss 0.636618435382843\n",
      "Epoch 51: Iteration 40 with loss 1.3805400133132935\n",
      "Epoch 51: Iteration 60 with loss 0.6697105765342712\n",
      "Epoch 51: Iteration 80 with loss 0.7442406415939331\n",
      "Epoch 51: Iteration 100 with loss 0.5393558144569397\n",
      "Epoch 51: Iteration 120 with loss 0.5489935874938965\n",
      "Epoch 51: Iteration 140 with loss 0.44547033309936523\n",
      "Epoch 51: Iteration 160 with loss 0.5937674641609192\n",
      "Epoch 51: Iteration 180 with loss 1.4772839546203613\n",
      "Epoch 51 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.92187518548856\n",
      "Other scores:: Edit 64.35844152415643, F1@[10:25:50] [62.28283686 59.40295099 48.64203642]\n",
      "Starting Training\n",
      "Epoch 52: Iteration 20 with loss 0.4600970447063446\n",
      "Epoch 52: Iteration 40 with loss 0.6563302278518677\n",
      "Epoch 52: Iteration 60 with loss 0.6683940887451172\n",
      "Epoch 52: Iteration 80 with loss 1.1778900623321533\n",
      "Epoch 52: Iteration 100 with loss 1.4898681640625\n",
      "Epoch 52: Iteration 120 with loss 0.9119818210601807\n",
      "Epoch 52: Iteration 140 with loss 0.6058515310287476\n",
      "Epoch 52: Iteration 160 with loss 0.9313230514526367\n",
      "Epoch 52: Iteration 180 with loss 0.4819440543651581\n",
      "Epoch 52 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.22646026488756\n",
      "Other scores:: Edit 65.28338128885146, F1@[10:25:50] [61.87761842 59.03443147 49.06413957]\n",
      "Starting Training\n",
      "Epoch 53: Iteration 20 with loss 0.8769288063049316\n",
      "Epoch 53: Iteration 40 with loss 0.44174468517303467\n",
      "Epoch 53: Iteration 60 with loss 0.4424101710319519\n",
      "Epoch 53: Iteration 80 with loss 0.643721878528595\n",
      "Epoch 53: Iteration 100 with loss 0.6031774878501892\n",
      "Epoch 53: Iteration 120 with loss 0.5663584470748901\n",
      "Epoch 53: Iteration 140 with loss 0.3523581027984619\n",
      "Epoch 53: Iteration 160 with loss 0.520095944404602\n",
      "Epoch 53: Iteration 180 with loss 0.4547517001628876\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.8 minutes\n",
      "iter 20 of Expectation completed in a total of  7.4 minutes\n",
      "iter 30 of Expectation completed in a total of  10.4 minutes\n",
      "iter 40 of Expectation completed in a total of  13.5 minutes\n",
      "iter 50 of Expectation completed in a total of  16.4 minutes\n",
      "iter 60 of Expectation completed in a total of  19.5 minutes\n",
      "iter 70 of Expectation completed in a total of  23.2 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  75.52%, boundary mse  0.00\n",
      "Epoch 53 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.46570984246827\n",
      "Other scores:: Edit 64.51306425981043, F1@[10:25:50] [60.62035587 57.59694511 46.69759569]\n",
      "Starting Training\n",
      "Epoch 54: Iteration 20 with loss 0.542481541633606\n",
      "Epoch 54: Iteration 40 with loss 0.9492700099945068\n",
      "Epoch 54: Iteration 60 with loss 0.5622349381446838\n",
      "Epoch 54: Iteration 80 with loss 0.5480657815933228\n",
      "Epoch 54: Iteration 100 with loss 0.37560486793518066\n",
      "Epoch 54: Iteration 120 with loss 0.5833874344825745\n",
      "Epoch 54: Iteration 140 with loss 1.1582809686660767\n",
      "Epoch 54: Iteration 160 with loss 0.6044433116912842\n",
      "Epoch 54: Iteration 180 with loss 0.45837604999542236\n",
      "Epoch 54 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.44528730447033\n",
      "Other scores:: Edit 65.65952802192177, F1@[10:25:50] [63.05799893 60.52584598 49.30955084]\n",
      "Starting Training\n",
      "Epoch 55: Iteration 20 with loss 0.4458999037742615\n",
      "Epoch 55: Iteration 40 with loss 0.5251109600067139\n",
      "Epoch 55: Iteration 60 with loss 0.3595712184906006\n",
      "Epoch 55: Iteration 80 with loss 0.4575415849685669\n",
      "Epoch 55: Iteration 100 with loss 0.43865036964416504\n",
      "Epoch 55: Iteration 120 with loss 0.5642303824424744\n",
      "Epoch 55: Iteration 140 with loss 0.6214609146118164\n",
      "Epoch 55: Iteration 160 with loss 0.7766773700714111\n",
      "Epoch 55: Iteration 180 with loss 0.8500889539718628\n",
      "Epoch 55 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.41110200980567\n",
      "Other scores:: Edit 65.50330443150605, F1@[10:25:50] [62.39270043 59.08466198 48.54033296]\n",
      "Starting Training\n",
      "Epoch 56: Iteration 20 with loss 0.6600111126899719\n",
      "Epoch 56: Iteration 40 with loss 0.30709999799728394\n",
      "Epoch 56: Iteration 60 with loss 0.34067100286483765\n",
      "Epoch 56: Iteration 80 with loss 0.33173978328704834\n",
      "Epoch 56: Iteration 100 with loss 0.4741402268409729\n",
      "Epoch 56: Iteration 120 with loss 0.19811484217643738\n",
      "Epoch 56: Iteration 140 with loss 0.41130927205085754\n",
      "Epoch 56: Iteration 160 with loss 0.4304083585739136\n",
      "Epoch 56: Iteration 180 with loss 0.412087619304657\n",
      "Epoch 56 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.20810332751641\n",
      "Other scores:: Edit 64.75542361336909, F1@[10:25:50] [61.84821531 58.55235339 48.10449061]\n",
      "Starting Training\n",
      "Epoch 57: Iteration 20 with loss 0.3455236554145813\n",
      "Epoch 57: Iteration 40 with loss 0.3977200984954834\n",
      "Epoch 57: Iteration 60 with loss 0.5787984132766724\n",
      "Epoch 57: Iteration 80 with loss 1.1571245193481445\n",
      "Epoch 57: Iteration 100 with loss 5.349865913391113\n",
      "Epoch 57: Iteration 120 with loss 4.457024574279785\n",
      "Epoch 57: Iteration 140 with loss 6.5785322189331055\n",
      "Epoch 57: Iteration 160 with loss 2.503511905670166\n",
      "Epoch 57: Iteration 180 with loss 3.289036750793457\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.5 minutes\n",
      "iter 20 of Expectation completed in a total of  7.0 minutes\n",
      "iter 30 of Expectation completed in a total of  9.6 minutes\n",
      "iter 40 of Expectation completed in a total of  13.1 minutes\n",
      "iter 50 of Expectation completed in a total of  15.5 minutes\n",
      "iter 60 of Expectation completed in a total of  19.3 minutes\n",
      "iter 70 of Expectation completed in a total of  22.6 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  70.48%, boundary mse  0.00\n",
      "Epoch 57 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 53.29724467870413\n",
      "Other scores:: Edit 54.0383013316884, F1@[10:25:50] [51.07926486 48.02676098 37.17982903]\n",
      "Starting Training\n",
      "Epoch 58: Iteration 20 with loss 2.901442289352417\n",
      "Epoch 58: Iteration 40 with loss 1.729027271270752\n",
      "Epoch 58: Iteration 60 with loss 3.217057228088379\n",
      "Epoch 58: Iteration 80 with loss 2.847604274749756\n",
      "Epoch 58: Iteration 100 with loss 4.777090072631836\n",
      "Epoch 58: Iteration 120 with loss 1.7510693073272705\n",
      "Epoch 58: Iteration 140 with loss 2.3187754154205322\n",
      "Epoch 58: Iteration 160 with loss 1.5523900985717773\n",
      "Epoch 58: Iteration 180 with loss 2.0610275268554688\n",
      "Epoch 58 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.04179477743351\n",
      "Other scores:: Edit 59.65879527154036, F1@[10:25:50] [56.98272964 53.64478843 42.10283695]\n",
      "Starting Training\n",
      "Epoch 59: Iteration 20 with loss 2.7679078578948975\n",
      "Epoch 59: Iteration 40 with loss 1.2854533195495605\n",
      "Epoch 59: Iteration 60 with loss 3.480262517929077\n",
      "Epoch 59: Iteration 80 with loss 1.3386025428771973\n",
      "Epoch 59: Iteration 100 with loss 1.5578818321228027\n",
      "Epoch 59: Iteration 120 with loss 2.6928699016571045\n",
      "Epoch 59: Iteration 140 with loss 1.2914742231369019\n",
      "Epoch 59: Iteration 160 with loss 4.154759407043457\n",
      "Epoch 59: Iteration 180 with loss 3.445549964904785\n",
      "Epoch 59 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.213928163000425\n",
      "Other scores:: Edit 60.20142363318229, F1@[10:25:50] [56.85169057 53.49537278 41.87352249]\n",
      "Starting Training\n",
      "Epoch 60: Iteration 20 with loss 1.7311103343963623\n",
      "Epoch 60: Iteration 40 with loss 2.7519094944000244\n",
      "Epoch 60: Iteration 60 with loss 2.1424355506896973\n",
      "Epoch 60: Iteration 80 with loss 1.3245755434036255\n",
      "Epoch 60: Iteration 100 with loss 0.8072249889373779\n",
      "Epoch 60: Iteration 120 with loss 3.2012033462524414\n",
      "Epoch 60: Iteration 140 with loss 2.949601650238037\n",
      "Epoch 60: Iteration 160 with loss 1.6539362668991089\n",
      "Epoch 60: Iteration 180 with loss 2.2347216606140137\n",
      "Epoch 60 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.994705414485324\n",
      "Other scores:: Edit 60.851579646875095, F1@[10:25:50] [57.58664118 54.43292292 43.96967795]\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Iteration 20 with loss 1.503791093826294\n",
      "Epoch 61: Iteration 40 with loss 1.749988079071045\n",
      "Epoch 61: Iteration 60 with loss 3.123542308807373\n",
      "Epoch 61: Iteration 80 with loss 2.593391180038452\n",
      "Epoch 61: Iteration 100 with loss 1.7336360216140747\n",
      "Epoch 61: Iteration 120 with loss 3.3829870223999023\n",
      "Epoch 61: Iteration 140 with loss 1.7996141910552979\n",
      "Epoch 61: Iteration 160 with loss 1.5684044361114502\n",
      "Epoch 61: Iteration 180 with loss 1.338841438293457\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.5 minutes\n",
      "iter 20 of Expectation completed in a total of  7.4 minutes\n",
      "iter 30 of Expectation completed in a total of  10.5 minutes\n",
      "iter 40 of Expectation completed in a total of  13.4 minutes\n",
      "iter 50 of Expectation completed in a total of  17.2 minutes\n",
      "iter 60 of Expectation completed in a total of  20.5 minutes\n",
      "iter 70 of Expectation completed in a total of  23.2 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  70.88%, boundary mse  0.00\n",
      "Epoch 61 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.24444127877299\n",
      "Other scores:: Edit 62.47431070414115, F1@[10:25:50] [58.93877556 55.25142099 45.16102271]\n",
      "Starting Training\n",
      "Epoch 62: Iteration 20 with loss 1.546614408493042\n",
      "Epoch 62: Iteration 40 with loss 1.9238262176513672\n",
      "Epoch 62: Iteration 60 with loss 1.6917613744735718\n",
      "Epoch 62: Iteration 80 with loss 3.0551767349243164\n",
      "Epoch 62: Iteration 100 with loss 1.30324387550354\n",
      "Epoch 62: Iteration 120 with loss 1.5931265354156494\n",
      "Epoch 62: Iteration 140 with loss 2.786729335784912\n",
      "Epoch 62: Iteration 160 with loss 2.148893117904663\n",
      "Epoch 62: Iteration 180 with loss 1.268581748008728\n",
      "Epoch 62 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.53159537970251\n",
      "Other scores:: Edit 61.28772236798053, F1@[10:25:50] [57.74889901 53.4223505  42.3416501 ]\n",
      "Starting Training\n",
      "Epoch 63: Iteration 20 with loss 2.047539234161377\n",
      "Epoch 63: Iteration 40 with loss 2.5695228576660156\n",
      "Epoch 63: Iteration 60 with loss 2.3581924438476562\n",
      "Epoch 63: Iteration 80 with loss 0.9241836667060852\n",
      "Epoch 63: Iteration 100 with loss 1.6803172826766968\n",
      "Epoch 63: Iteration 120 with loss 1.110478401184082\n",
      "Epoch 63: Iteration 140 with loss 2.418002128601074\n",
      "Epoch 63: Iteration 160 with loss 1.2784876823425293\n",
      "Epoch 63: Iteration 180 with loss 2.142042636871338\n",
      "Epoch 63 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 63.55402020489809\n",
      "Other scores:: Edit 64.72906276953364, F1@[10:25:50] [61.80056131 58.92097605 48.41190511]\n",
      "Starting Training\n",
      "Epoch 64: Iteration 20 with loss 1.1262922286987305\n",
      "Epoch 64: Iteration 40 with loss 0.7009312510490417\n",
      "Epoch 64: Iteration 60 with loss 1.0207555294036865\n",
      "Epoch 64: Iteration 80 with loss 1.295852780342102\n",
      "Epoch 64: Iteration 100 with loss 1.2769145965576172\n",
      "Epoch 64: Iteration 120 with loss 1.8563761711120605\n",
      "Epoch 64: Iteration 140 with loss 0.9885222911834717\n",
      "Epoch 64: Iteration 160 with loss 2.8626465797424316\n",
      "Epoch 64: Iteration 180 with loss 1.2102431058883667\n",
      "Epoch 64 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.583828958771086\n",
      "Other scores:: Edit 63.480023667826934, F1@[10:25:50] [60.15518612 56.97447661 46.37148062]\n",
      "Starting Training\n",
      "Epoch 65: Iteration 20 with loss 0.7121173143386841\n",
      "Epoch 65: Iteration 40 with loss 1.491876244544983\n",
      "Epoch 65: Iteration 60 with loss 1.58247709274292\n",
      "Epoch 65: Iteration 80 with loss 1.1957249641418457\n",
      "Epoch 65: Iteration 100 with loss 1.4634519815444946\n",
      "Epoch 65: Iteration 120 with loss 1.8418786525726318\n",
      "Epoch 65: Iteration 140 with loss 1.6160004138946533\n",
      "Epoch 65: Iteration 160 with loss 0.8683472871780396\n",
      "Epoch 65: Iteration 180 with loss 1.2190625667572021\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.6 minutes\n",
      "iter 20 of Expectation completed in a total of  6.7 minutes\n",
      "iter 30 of Expectation completed in a total of  9.5 minutes\n",
      "iter 40 of Expectation completed in a total of  13.5 minutes\n",
      "iter 50 of Expectation completed in a total of  16.4 minutes\n",
      "iter 60 of Expectation completed in a total of  19.2 minutes\n",
      "iter 70 of Expectation completed in a total of  22.8 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  71.59%, boundary mse  0.00\n",
      "Epoch 65 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.850932488099055\n",
      "Other scores:: Edit 62.0289718328232, F1@[10:25:50] [58.52306875 54.87479039 44.22451012]\n",
      "Starting Training\n",
      "Epoch 66: Iteration 20 with loss 0.5779674053192139\n",
      "Epoch 66: Iteration 40 with loss 0.6177864670753479\n",
      "Epoch 66: Iteration 60 with loss 0.9189107418060303\n",
      "Epoch 66: Iteration 80 with loss 1.15651535987854\n",
      "Epoch 66: Iteration 100 with loss 1.2314329147338867\n",
      "Epoch 66: Iteration 120 with loss 1.4435145854949951\n",
      "Epoch 66: Iteration 140 with loss 3.3251051902770996\n",
      "Epoch 66: Iteration 160 with loss 1.647998332977295\n",
      "Epoch 66: Iteration 180 with loss 0.752927303314209\n",
      "Epoch 66 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.298720673021755\n",
      "Other scores:: Edit 63.19984355620039, F1@[10:25:50] [59.64502197 56.19929201 45.5502129 ]\n",
      "Starting Training\n",
      "Epoch 67: Iteration 20 with loss 0.7395452260971069\n",
      "Epoch 67: Iteration 40 with loss 1.931911826133728\n",
      "Epoch 67: Iteration 60 with loss 0.7842465043067932\n",
      "Epoch 67: Iteration 80 with loss 1.1044020652770996\n",
      "Epoch 67: Iteration 100 with loss 1.010297179222107\n",
      "Epoch 67: Iteration 120 with loss 1.2250195741653442\n",
      "Epoch 67: Iteration 140 with loss 1.6272577047348022\n",
      "Epoch 67: Iteration 160 with loss 1.066589117050171\n",
      "Epoch 67: Iteration 180 with loss 2.4686617851257324\n",
      "Epoch 67 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.93739488981485\n",
      "Other scores:: Edit 64.22839089550284, F1@[10:25:50] [60.28117736 57.11182164 45.7800341 ]\n",
      "Starting Training\n",
      "Epoch 68: Iteration 20 with loss 1.372756004333496\n",
      "Epoch 68: Iteration 40 with loss 1.1229703426361084\n",
      "Epoch 68: Iteration 60 with loss 0.7428566813468933\n",
      "Epoch 68: Iteration 80 with loss 0.9901877045631409\n",
      "Epoch 68: Iteration 100 with loss 0.7347989678382874\n",
      "Epoch 68: Iteration 120 with loss 1.0950523614883423\n",
      "Epoch 68: Iteration 140 with loss 0.6493087410926819\n",
      "Epoch 68: Iteration 160 with loss 0.7764413952827454\n",
      "Epoch 68: Iteration 180 with loss 0.7354523539543152\n",
      "Epoch 68 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.48402325185686\n",
      "Other scores:: Edit 66.03203878666592, F1@[10:25:50] [62.40691153 59.55802968 49.52503181]\n",
      "Starting Training\n",
      "Epoch 69: Iteration 20 with loss 0.9371618628501892\n",
      "Epoch 69: Iteration 40 with loss 0.8477400541305542\n",
      "Epoch 69: Iteration 60 with loss 0.713142991065979\n",
      "Epoch 69: Iteration 80 with loss 0.7753922939300537\n",
      "Epoch 69: Iteration 100 with loss 0.6078498959541321\n",
      "Epoch 69: Iteration 120 with loss 0.9992057085037231\n",
      "Epoch 69: Iteration 140 with loss 0.6988299489021301\n",
      "Epoch 69: Iteration 160 with loss 0.5653465390205383\n",
      "Epoch 69: Iteration 180 with loss 3.1163907051086426\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  4.0 minutes\n",
      "iter 20 of Expectation completed in a total of  6.9 minutes\n",
      "iter 30 of Expectation completed in a total of  10.3 minutes\n",
      "iter 40 of Expectation completed in a total of  13.1 minutes\n",
      "iter 50 of Expectation completed in a total of  16.4 minutes\n",
      "iter 60 of Expectation completed in a total of  19.6 minutes\n",
      "iter 70 of Expectation completed in a total of  22.7 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  72.28%, boundary mse  0.00\n",
      "Epoch 69 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.135051501517545\n",
      "Other scores:: Edit 65.1524632287108, F1@[10:25:50] [62.12881947 59.22954056 47.30911522]\n",
      "Starting Training\n",
      "Epoch 70: Iteration 20 with loss 0.6880055069923401\n",
      "Epoch 70: Iteration 40 with loss 0.8684566020965576\n",
      "Epoch 70: Iteration 60 with loss 0.8615381717681885\n",
      "Epoch 70: Iteration 80 with loss 0.6261575818061829\n",
      "Epoch 70: Iteration 100 with loss 1.7941690683364868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Iteration 120 with loss 1.0938249826431274\n",
      "Epoch 70: Iteration 140 with loss 0.5899152755737305\n",
      "Epoch 70: Iteration 160 with loss 1.001709222793579\n",
      "Epoch 70: Iteration 180 with loss 1.3695642948150635\n",
      "Epoch 70 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.68493259098338\n",
      "Other scores:: Edit 63.344819026271445, F1@[10:25:50] [59.82127195 56.87371951 44.91941411]\n",
      "Starting Training\n",
      "Epoch 71: Iteration 20 with loss 1.351090669631958\n",
      "Epoch 71: Iteration 40 with loss 0.5859665870666504\n",
      "Epoch 71: Iteration 60 with loss 0.9913274645805359\n",
      "Epoch 71: Iteration 80 with loss 4.356311321258545\n",
      "Epoch 71: Iteration 100 with loss 0.8294530510902405\n",
      "Epoch 71: Iteration 120 with loss 1.234480381011963\n",
      "Epoch 71: Iteration 140 with loss 1.068010687828064\n",
      "Epoch 71: Iteration 160 with loss 0.424634724855423\n",
      "Epoch 71: Iteration 180 with loss 1.2988369464874268\n",
      "Epoch 71 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.489298051924926\n",
      "Other scores:: Edit 63.22852150465518, F1@[10:25:50] [59.40007838 55.62184214 45.37007185]\n",
      "Starting Training\n",
      "Epoch 72: Iteration 20 with loss 1.4919755458831787\n",
      "Epoch 72: Iteration 40 with loss 0.5037453770637512\n",
      "Epoch 72: Iteration 60 with loss 0.45627033710479736\n",
      "Epoch 72: Iteration 80 with loss 1.1450163125991821\n",
      "Epoch 72: Iteration 100 with loss 0.46466338634490967\n",
      "Epoch 72: Iteration 120 with loss 0.9391295909881592\n",
      "Epoch 72: Iteration 140 with loss 0.5317628383636475\n",
      "Epoch 72: Iteration 160 with loss 1.3144077062606812\n",
      "Epoch 72: Iteration 180 with loss 0.9687433838844299\n",
      "Epoch 72 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.2189853231557\n",
      "Other scores:: Edit 64.01538358916414, F1@[10:25:50] [60.76907385 57.46900862 46.22521332]\n",
      "Starting Training\n",
      "Epoch 73: Iteration 20 with loss 0.8718956708908081\n",
      "Epoch 73: Iteration 40 with loss 0.7468248009681702\n",
      "Epoch 73: Iteration 60 with loss 0.5801523327827454\n",
      "Epoch 73: Iteration 80 with loss 0.6950443387031555\n",
      "Epoch 73: Iteration 100 with loss 0.4070519804954529\n",
      "Epoch 73: Iteration 120 with loss 1.0228058099746704\n",
      "Epoch 73: Iteration 140 with loss 0.716215968132019\n",
      "Epoch 73: Iteration 160 with loss 1.792630910873413\n",
      "Epoch 73: Iteration 180 with loss 1.910010576248169\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.5 minutes\n",
      "iter 20 of Expectation completed in a total of  6.3 minutes\n",
      "iter 30 of Expectation completed in a total of  10.1 minutes\n",
      "iter 40 of Expectation completed in a total of  13.5 minutes\n",
      "iter 50 of Expectation completed in a total of  16.6 minutes\n",
      "iter 60 of Expectation completed in a total of  19.9 minutes\n",
      "iter 70 of Expectation completed in a total of  22.8 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  69.78%, boundary mse  0.00\n",
      "Epoch 73 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.731119737565834\n",
      "Other scores:: Edit 62.99334255352518, F1@[10:25:50] [58.44117234 55.81819649 45.21853968]\n",
      "Starting Training\n",
      "Epoch 74: Iteration 20 with loss 0.7393724322319031\n",
      "Epoch 74: Iteration 40 with loss 1.825151801109314\n",
      "Epoch 74: Iteration 60 with loss 0.9157199263572693\n",
      "Epoch 74: Iteration 80 with loss 1.149559497833252\n",
      "Epoch 74: Iteration 100 with loss 0.4998511075973511\n",
      "Epoch 74: Iteration 120 with loss 1.1941187381744385\n",
      "Epoch 74: Iteration 140 with loss 0.9326774477958679\n",
      "Epoch 74: Iteration 160 with loss 1.8561689853668213\n",
      "Epoch 74: Iteration 180 with loss 1.8646894693374634\n",
      "Epoch 74 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.6663342711635\n",
      "Other scores:: Edit 63.72742539935954, F1@[10:25:50] [58.73701867 55.97411261 46.82716687]\n",
      "Starting Training\n",
      "Epoch 75: Iteration 20 with loss 0.9925290942192078\n",
      "Epoch 75: Iteration 40 with loss 1.5288887023925781\n",
      "Epoch 75: Iteration 60 with loss 0.7804913520812988\n",
      "Epoch 75: Iteration 80 with loss 1.0219457149505615\n",
      "Epoch 75: Iteration 100 with loss 1.4339659214019775\n",
      "Epoch 75: Iteration 120 with loss 1.8466198444366455\n",
      "Epoch 75: Iteration 140 with loss 0.6342403888702393\n",
      "Epoch 75: Iteration 160 with loss 1.340616226196289\n",
      "Epoch 75: Iteration 180 with loss 0.7861486673355103\n",
      "Epoch 75 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.96839077048486\n",
      "Other scores:: Edit 64.11298984587903, F1@[10:25:50] [58.51292542 55.87639591 44.5640468 ]\n",
      "Starting Training\n",
      "Epoch 76: Iteration 20 with loss 1.0396018028259277\n",
      "Epoch 76: Iteration 40 with loss 4.932240962982178\n",
      "Epoch 76: Iteration 60 with loss 1.1037836074829102\n",
      "Epoch 76: Iteration 80 with loss 1.5457484722137451\n",
      "Epoch 76: Iteration 100 with loss 0.7926744222640991\n",
      "Epoch 76: Iteration 120 with loss 1.0001901388168335\n",
      "Epoch 76: Iteration 140 with loss 1.1186529397964478\n",
      "Epoch 76: Iteration 160 with loss 1.0174262523651123\n",
      "Epoch 76: Iteration 180 with loss 1.5377094745635986\n",
      "Epoch 76 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.60262513305713\n",
      "Other scores:: Edit 64.46891115638323, F1@[10:25:50] [60.08303657 57.57435529 47.71956666]\n",
      "Starting Training\n",
      "Epoch 77: Iteration 20 with loss 0.8284188508987427\n",
      "Epoch 77: Iteration 40 with loss 0.6486969590187073\n",
      "Epoch 77: Iteration 60 with loss 1.183923602104187\n",
      "Epoch 77: Iteration 80 with loss 1.0216742753982544\n",
      "Epoch 77: Iteration 100 with loss 1.723618507385254\n",
      "Epoch 77: Iteration 120 with loss 1.48610520362854\n",
      "Epoch 77: Iteration 140 with loss 1.218668818473816\n",
      "Epoch 77: Iteration 160 with loss 0.4995383024215698\n",
      "Epoch 77: Iteration 180 with loss 0.7587237358093262\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.5 minutes\n",
      "iter 20 of Expectation completed in a total of  6.7 minutes\n",
      "iter 30 of Expectation completed in a total of  10.1 minutes\n",
      "iter 40 of Expectation completed in a total of  13.2 minutes\n",
      "iter 50 of Expectation completed in a total of  16.5 minutes\n",
      "iter 60 of Expectation completed in a total of  20.0 minutes\n",
      "iter 70 of Expectation completed in a total of  22.9 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  70.32%, boundary mse  0.00\n",
      "Epoch 77 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.247674220750184\n",
      "Other scores:: Edit 65.01503608794489, F1@[10:25:50] [60.63396374 58.46128155 48.83416867]\n",
      "Starting Training\n",
      "Epoch 78: Iteration 20 with loss 0.7949989438056946\n",
      "Epoch 78: Iteration 40 with loss 0.38947173953056335\n",
      "Epoch 78: Iteration 60 with loss 0.9970578551292419\n",
      "Epoch 78: Iteration 80 with loss 0.9235371351242065\n",
      "Epoch 78: Iteration 100 with loss 0.5825402736663818\n",
      "Epoch 78: Iteration 120 with loss 1.4567009210586548\n",
      "Epoch 78: Iteration 140 with loss 1.0095369815826416\n",
      "Epoch 78: Iteration 160 with loss 0.7941455245018005\n",
      "Epoch 78: Iteration 180 with loss 0.5507887601852417\n",
      "Epoch 78 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.86946353740043\n",
      "Other scores:: Edit 63.409696942061686, F1@[10:25:50] [58.20198556 56.00041306 44.7535916 ]\n",
      "Starting Training\n",
      "Epoch 79: Iteration 20 with loss 1.2343227863311768\n",
      "Epoch 79: Iteration 40 with loss 0.6017481088638306\n",
      "Epoch 79: Iteration 60 with loss 0.8741686344146729\n",
      "Epoch 79: Iteration 80 with loss 0.999694287776947\n",
      "Epoch 79: Iteration 100 with loss 0.646759033203125\n",
      "Epoch 79: Iteration 120 with loss 0.6517033576965332\n",
      "Epoch 79: Iteration 140 with loss 0.6421448588371277\n",
      "Epoch 79: Iteration 160 with loss 2.1783618927001953\n",
      "Epoch 79: Iteration 180 with loss 1.335418701171875\n",
      "Epoch 79 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.38874445512859\n",
      "Other scores:: Edit 64.6673001591631, F1@[10:25:50] [60.5201861  57.34367264 47.21705679]\n",
      "Starting Training\n",
      "Epoch 80: Iteration 20 with loss 0.6703800559043884\n",
      "Epoch 80: Iteration 40 with loss 0.7014118432998657\n",
      "Epoch 80: Iteration 60 with loss 0.44245100021362305\n",
      "Epoch 80: Iteration 80 with loss 0.7227792739868164\n",
      "Epoch 80: Iteration 100 with loss 1.0853431224822998\n",
      "Epoch 80: Iteration 120 with loss 0.9809951186180115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Iteration 140 with loss 0.77043616771698\n",
      "Epoch 80: Iteration 160 with loss 0.9213445782661438\n",
      "Epoch 80: Iteration 180 with loss 0.5722818970680237\n",
      "Epoch 80 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.2771980641919\n",
      "Other scores:: Edit 64.62668810998274, F1@[10:25:50] [60.99020992 58.82560459 48.28639575]\n",
      "Starting Training\n",
      "Epoch 81: Iteration 20 with loss 1.167665719985962\n",
      "Epoch 81: Iteration 40 with loss 0.5194901823997498\n",
      "Epoch 81: Iteration 60 with loss 3.8171637058258057\n",
      "Epoch 81: Iteration 80 with loss 2.507784366607666\n",
      "Epoch 81: Iteration 100 with loss 1.148696780204773\n",
      "Epoch 81: Iteration 120 with loss 0.8049187064170837\n",
      "Epoch 81: Iteration 140 with loss 0.7336041331291199\n",
      "Epoch 81: Iteration 160 with loss 0.9677023887634277\n",
      "Epoch 81: Iteration 180 with loss 0.5703545808792114\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.4 minutes\n",
      "iter 20 of Expectation completed in a total of  6.9 minutes\n",
      "iter 30 of Expectation completed in a total of  10.3 minutes\n",
      "iter 40 of Expectation completed in a total of  14.0 minutes\n",
      "iter 50 of Expectation completed in a total of  17.3 minutes\n",
      "iter 60 of Expectation completed in a total of  20.6 minutes\n",
      "iter 70 of Expectation completed in a total of  23.8 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  70.87%, boundary mse  0.00\n",
      "Epoch 81 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.15622192939761\n",
      "Other scores:: Edit 64.22490351326786, F1@[10:25:50] [59.78218034 57.20189129 46.75977439]\n",
      "Starting Training\n",
      "Epoch 82: Iteration 20 with loss 0.46611201763153076\n",
      "Epoch 82: Iteration 40 with loss 0.8890520334243774\n",
      "Epoch 82: Iteration 60 with loss 0.5281313061714172\n",
      "Epoch 82: Iteration 80 with loss 0.3237156569957733\n",
      "Epoch 82: Iteration 100 with loss 0.8355004787445068\n",
      "Epoch 82: Iteration 120 with loss 0.6680675745010376\n",
      "Epoch 82: Iteration 140 with loss 0.765180766582489\n",
      "Epoch 82: Iteration 160 with loss 0.7399485111236572\n",
      "Epoch 82: Iteration 180 with loss 0.6146638989448547\n",
      "Epoch 82 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.029440744565925\n",
      "Other scores:: Edit 64.84797448858274, F1@[10:25:50] [61.22488379 58.6118432  48.15079262]\n",
      "Starting Training\n",
      "Epoch 83: Iteration 20 with loss 0.4236651062965393\n",
      "Epoch 83: Iteration 40 with loss 0.42976248264312744\n",
      "Epoch 83: Iteration 60 with loss 1.0241929292678833\n",
      "Epoch 83: Iteration 80 with loss 0.4090437591075897\n",
      "Epoch 83: Iteration 100 with loss 0.807788074016571\n",
      "Epoch 83: Iteration 120 with loss 0.6836047172546387\n",
      "Epoch 83: Iteration 140 with loss 0.5073792338371277\n",
      "Epoch 83: Iteration 160 with loss 0.5828763842582703\n",
      "Epoch 83: Iteration 180 with loss 0.8246020078659058\n",
      "Epoch 83 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.76510717776432\n",
      "Other scores:: Edit 65.40452211275436, F1@[10:25:50] [62.0707666  59.04737916 48.0594989 ]\n",
      "Starting Training\n",
      "Epoch 84: Iteration 20 with loss 1.2788708209991455\n",
      "Epoch 84: Iteration 40 with loss 0.40898609161376953\n",
      "Epoch 84: Iteration 60 with loss 0.47392386198043823\n",
      "Epoch 84: Iteration 80 with loss 0.3288203477859497\n",
      "Epoch 84: Iteration 100 with loss 0.6687570810317993\n",
      "Epoch 84: Iteration 120 with loss 0.5175586342811584\n",
      "Epoch 84: Iteration 140 with loss 0.31736570596694946\n",
      "Epoch 84: Iteration 160 with loss 0.39279597997665405\n",
      "Epoch 84: Iteration 180 with loss 0.585550844669342\n",
      "Epoch 84 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.152308368056794\n",
      "Other scores:: Edit 65.14802231546534, F1@[10:25:50] [61.02044249 58.23917784 48.16137332]\n",
      "Starting Training\n",
      "Epoch 85: Iteration 20 with loss 0.2803908586502075\n",
      "Epoch 85: Iteration 40 with loss 0.5281753540039062\n",
      "Epoch 85: Iteration 60 with loss 0.3473460376262665\n",
      "Epoch 85: Iteration 80 with loss 0.4966379702091217\n",
      "Epoch 85: Iteration 100 with loss 0.6773260831832886\n",
      "Epoch 85: Iteration 120 with loss 0.37847796082496643\n",
      "Epoch 85: Iteration 140 with loss 0.6467782258987427\n",
      "Epoch 85: Iteration 160 with loss 0.8809601068496704\n",
      "Epoch 85: Iteration 180 with loss 0.5103068947792053\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.8 minutes\n",
      "iter 20 of Expectation completed in a total of  6.9 minutes\n",
      "iter 30 of Expectation completed in a total of  10.2 minutes\n",
      "iter 40 of Expectation completed in a total of  13.8 minutes\n",
      "iter 50 of Expectation completed in a total of  17.1 minutes\n",
      "iter 60 of Expectation completed in a total of  20.2 minutes\n",
      "iter 70 of Expectation completed in a total of  23.3 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  70.84%, boundary mse  0.00\n",
      "Epoch 85 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.312174776721236\n",
      "Other scores:: Edit 65.38125127480745, F1@[10:25:50] [62.57457317 60.3974791  47.23039504]\n",
      "Starting Training\n",
      "Epoch 86: Iteration 20 with loss 0.43452751636505127\n",
      "Epoch 86: Iteration 40 with loss 0.5158082246780396\n",
      "Epoch 86: Iteration 60 with loss 0.3451216518878937\n",
      "Epoch 86: Iteration 80 with loss 1.4259541034698486\n",
      "Epoch 86: Iteration 100 with loss 0.8485503792762756\n",
      "Epoch 86: Iteration 120 with loss 0.5148829221725464\n",
      "Epoch 86: Iteration 140 with loss 0.575496256351471\n",
      "Epoch 86: Iteration 160 with loss 0.6085926294326782\n",
      "Epoch 86: Iteration 180 with loss 1.3095061779022217\n",
      "Epoch 86 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.732615517330075\n",
      "Other scores:: Edit 66.38158085455393, F1@[10:25:50] [62.05153064 59.0996214  47.68137605]\n",
      "Starting Training\n",
      "Epoch 87: Iteration 20 with loss 3.745880603790283\n",
      "Epoch 87: Iteration 40 with loss 0.9146740436553955\n",
      "Epoch 87: Iteration 60 with loss 0.7635908722877502\n",
      "Epoch 87: Iteration 80 with loss 0.6799439787864685\n",
      "Epoch 87: Iteration 100 with loss 0.4228716492652893\n",
      "Epoch 87: Iteration 120 with loss 0.46357524394989014\n",
      "Epoch 87: Iteration 140 with loss 0.4778968095779419\n",
      "Epoch 87: Iteration 160 with loss 0.49769365787506104\n",
      "Epoch 87: Iteration 180 with loss 0.924645721912384\n",
      "Epoch 87 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.26394181495859\n",
      "Other scores:: Edit 65.32926487788424, F1@[10:25:50] [61.95571901 59.02588476 48.56446658]\n",
      "Starting Training\n",
      "Epoch 88: Iteration 20 with loss 0.4849708676338196\n",
      "Epoch 88: Iteration 40 with loss 0.3052728772163391\n",
      "Epoch 88: Iteration 60 with loss 0.9425435066223145\n",
      "Epoch 88: Iteration 80 with loss 0.4695534408092499\n",
      "Epoch 88: Iteration 100 with loss 0.7897363305091858\n",
      "Epoch 88: Iteration 120 with loss 0.7486853003501892\n",
      "Epoch 88: Iteration 140 with loss 1.9623605012893677\n",
      "Epoch 88: Iteration 160 with loss 0.5063564777374268\n",
      "Epoch 88: Iteration 180 with loss 0.8357479572296143\n",
      "Epoch 88 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.834839005820875\n",
      "Other scores:: Edit 64.01023680664967, F1@[10:25:50] [59.93915576 57.16382396 46.60047667]\n",
      "Starting Training\n",
      "Epoch 89: Iteration 20 with loss 0.4505564570426941\n",
      "Epoch 89: Iteration 40 with loss 0.47693851590156555\n",
      "Epoch 89: Iteration 60 with loss 0.6472046971321106\n",
      "Epoch 89: Iteration 80 with loss 0.5000939965248108\n",
      "Epoch 89: Iteration 100 with loss 0.770767092704773\n",
      "Epoch 89: Iteration 120 with loss 0.4514062702655792\n",
      "Epoch 89: Iteration 140 with loss 0.6678768992424011\n",
      "Epoch 89: Iteration 160 with loss 0.7677202224731445\n",
      "Epoch 89: Iteration 180 with loss 0.5340977907180786\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.1 minutes\n",
      "iter 20 of Expectation completed in a total of  6.7 minutes\n",
      "iter 30 of Expectation completed in a total of  9.9 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-21599:\n",
      "Process ForkPoolWorker-21605:\n",
      "Process ForkPoolWorker-21601:\n",
      "Process ForkPoolWorker-21606:\n",
      "Process ForkPoolWorker-21596:\n",
      "Process ForkPoolWorker-21604:\n",
      "Process ForkPoolWorker-21607:\n",
      "Process ForkPoolWorker-21602:\n",
      "Process ForkPoolWorker-21600:\n",
      "Process ForkPoolWorker-21597:\n",
      "Process ForkPoolWorker-21590:\n",
      "Process ForkPoolWorker-21594:\n",
      "Process ForkPoolWorker-21589:\n",
      "Process ForkPoolWorker-21595:\n",
      "Process ForkPoolWorker-21592:\n",
      "Process ForkPoolWorker-21603:\n",
      "Process ForkPoolWorker-21598:\n",
      "Process ForkPoolWorker-21608:\n",
      "Process ForkPoolWorker-21593:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "initialize_epoch = 30\n",
    "expectation_cal_gap = 4\n",
    "best_val_acc = 0\n",
    "for epoch in range(30, 150):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)  # features\n",
    "        item_1 = item[1].to(device)  # count\n",
    "        item_2 = item[2].to(device)  # target\n",
    "        weights = item[5].to(device)  # posterior weight\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        boundary_target_tensor = get_single_random(item[4], item_2.shape[1], item_2.device)\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, boundary_target_tensor)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                            max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                total_count = torch.sum(src_mask)\n",
    "                weighted_loss_sum = -torch.sum(torch.sum(torch.log(prob + 1e-8) * weights, dim=-1) * src_mask)\n",
    "                loss += weighted_loss_sum/total_count\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1)%20 == 0:\n",
    "            print(f'Epoch {epoch+1}: Iteration {i+1} with loss {loss.item()}')\n",
    "\n",
    "    if (epoch >= initialize_epoch) and ((epoch % (3 * expectation_cal_gap)) == 0):\n",
    "        torch.save(model.state_dict(), config.output_dir + f\"ms-tcn-initial-{epoch}-epochs.wt\")\n",
    "\n",
    "    if epoch >= initialize_epoch and (epoch % expectation_cal_gap == 0):\n",
    "        perform_expectation(model, trainloder_expectation)\n",
    "    \n",
    "    print(f'Epoch {epoch+1} finished, starting validation')\n",
    "    val_acc, best_val_acc = validate(model, testloader, best_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 105, Probability Accuracy 61.02425300046298\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 60, Probability Accuracy 65.1877045320544\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {best_val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-emmax-best-model.wt\"))\n",
    "# model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-initial-15-epochs.wt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
