{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from time import time\n",
    "from utils import get_all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utility.adaptive_data_loader import BreakfastWithWeights, collate_fn_override_wtd\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='6'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temp': 1, 'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 2, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select6-temp1-exp4/split2/', 'project_name': 'breakfast-split-1', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split2.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split2.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split2_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    temp=1,\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=2,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select6-temp1-exp4/\",\n",
    "    project_name=\"breakfast-split-1\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "config.output_dir = config.output_dir + f\"split{config.split}\"\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "config.output_dir = config.output_dir + \"/\"\n",
    "if not os.path.exists(os.path.join(config.output_dir, \"posterior_weights\")):\n",
    "    os.mkdir(os.path.join(config.output_dir, \"posterior_weights\"))\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1261\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 451\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = BreakfastWithWeights(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override_wtd(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "\n",
    "trainloder_expectation = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=20,\n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override_wtd(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_frames_dict = pickle.load(open(\"data/breakfast_len_assum_annotations.pkl\", 'rb'))\n",
    "# loaded_vidid_selected_frames\n",
    "boundary_frames_dict = pickle.load(open(\"data/breakfast_boundary_annotations.pkl\", \"rb\"))\n",
    "num_boundary = 0\n",
    "for key in boundary_frames_dict.keys():\n",
    "    num_boundary += len(boundary_frames_dict[key])\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frames_dict = pickle.load(open(\"data/breakfast_random6frame_selection.pkl\", \"rb\"))\n",
    "# print(selected_frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"data/breakfast_meanvar_actions.pkl\", \"rb\"))\n",
    "mat_poisson = pickle.load(open(\"data/breakfast_possion_class_dict.pkl\", \"rb\"))\n",
    "\n",
    "def get_possion_prob(minlen, maxlen, cur_class):\n",
    "    prob = mat_poisson[label_id_to_label_name[cur_class]][minlen:maxlen]\n",
    "    return torch.tensor(prob)\n",
    "\n",
    "def get_poisson_logcdf(minlen, cur_class):\n",
    "    return np.log(np.sum(np.exp(mat_poisson[label_id_to_label_name[cur_class]][minlen:])) + 1e-20)\n",
    "\n",
    "def get_possion_prob_for_all_class(minlen, maxlen):\n",
    "    ele_list = []\n",
    "    for i in range(config.num_class):\n",
    "        prob = mat_poisson[label_id_to_label_name[i]][minlen:maxlen]\n",
    "        ele_list.append(torch.tensor(prob))\n",
    "    return torch.stack(ele_list, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, best_val_acc=None):\n",
    "    model.eval()\n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    vidcount = 0\n",
    "    all_scores = []\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "            for p, l, c in zip(pred, item_2, item_1):\n",
    "                all_scores.append(get_all_scores(p[:c].detach().cpu().numpy(), \n",
    "                                                 l[:c].detach().cpu().numpy(), ['SIL']))\n",
    "            \n",
    "    final_scores = np.mean(np.array(all_scores), axis=0)\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if best_val_acc is not None and val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-last-model.wt\")\n",
    "    print(f\"Validation:: Probability Accuracy {val_acc}\")\n",
    "    print(f\"Other scores:: Edit {final_scores[3]}, F1@[10:25:50] {final_scores[:3]}\")\n",
    "    _ = model.train()\n",
    "    return val_acc, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels, first_ele_flag, last_ele_flag, vidid, gt_labels):\n",
    "    prob_each_segment = []\n",
    "    LOW_VAL = -10000000\n",
    "    num_frames = len(cur_vid_feat)\n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    prev_boundary = 0\n",
    "    per_frame_weights = torch.zeros((num_frames, config.num_class))\n",
    "    start_time = time()\n",
    "    boundary_error = 0\n",
    "    current_boundary = 0\n",
    "    labels = [config.num_class-1] + labels if selected_frames[0] != 0 else labels\n",
    "    labels = labels + [config.num_class-1] if selected_frames[-1] != num_frames-1 else labels\n",
    "    selected_frames = [0] + selected_frames if selected_frames[0] != 0 else selected_frames\n",
    "    selected_frames = selected_frames + [num_frames-1] if selected_frames[-1] != num_frames-1 else selected_frames\n",
    "\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[i]\n",
    "        label_next_ele = labels[i + 1]\n",
    "        if cur_ele == next_ele-1:\n",
    "            per_frame_weights[cur_ele, label_cur_ele] = 1.0\n",
    "            if label_cur_ele != label_next_ele:\n",
    "                prev_boundary = cur_ele\n",
    "            continue\n",
    "        \n",
    "        seg_len = next_ele - cur_ele\n",
    "        mat_b1_b2_c_prob = LOW_VAL * torch.ones((seg_len, seg_len, config.num_class), dtype=cumsum_feat.dtype)\n",
    "        b1_prior = get_possion_prob(cur_ele-prev_boundary, next_ele-prev_boundary, label_cur_ele)\n",
    "        \n",
    "        # find dummy label where we will keep the diagonal (b1=b2) probabilities, later we will distribute among\n",
    "        # rest of the classes after the softmax by dividing by (num_class - 2)\n",
    "        dummy_label = 0\n",
    "        while True:\n",
    "            if dummy_label != label_cur_ele and dummy_label != label_next_ele:\n",
    "                break\n",
    "            else:\n",
    "                dummy_label += 1\n",
    "        \n",
    "        for b1 in range(cur_ele, next_ele - 1):\n",
    "\n",
    "            cur_boundary_len = b1 - prev_boundary\n",
    "            strt_index = cumsum_feat[cur_ele - 1, label_cur_ele] if cur_ele > 0 else 0\n",
    "            left_sum = (cumsum_feat[b1, label_cur_ele] - strt_index)\n",
    "            right_sum = cumsum_feat[next_ele-1, label_next_ele] - cumsum_feat[b1+1:next_ele, label_next_ele] # mid_seg_len\n",
    "            mid_sum = (cumsum_feat[b1+1:next_ele, :] - cumsum_feat[b1, :])  # mid_seg_len\n",
    "            b2_prior = get_possion_prob_for_all_class(1, next_ele-b1)  # mid_seg_len x num_class\n",
    "            \n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1+1-cur_ele:next_ele-cur_ele] = (left_sum + right_sum[:,None] + mid_sum) / config.temp \\\n",
    "                                                                            + b1_prior[b1-cur_ele] + b2_prior\n",
    "            # when mid segment is absent but right and left is not the same\n",
    "            # we assign the probability to a dummy label for now and then later \n",
    "            # re-distribute among other classes after the softmax\n",
    "            if label_cur_ele != label_next_ele:\n",
    "                rightsum_wo_midseg = cumsum_feat[next_ele-1, label_next_ele] - cumsum_feat[b1, label_next_ele]\n",
    "                mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = (left_sum + rightsum_wo_midseg) / config.temp \\\n",
    "                                                                        + b1_prior[b1-cur_ele]\n",
    "        \n",
    "#         if vidid=='P39_cam02_P39_scrambledegg' and cur_ele==574:\n",
    "#             import pdb\n",
    "#             pdb.set_trace()\n",
    "        # when mid segment is absent b1 can also be next_ele-1\n",
    "        b1 = next_ele - 1\n",
    "        if label_cur_ele != label_next_ele:\n",
    "            left_sum = (cumsum_feat[b1, label_cur_ele] - strt_index)\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = left_sum / config.temp + b1_prior[b1-cur_ele]\n",
    "        else:\n",
    "            # returns prob that the left class length >= seg len\n",
    "            b1_prior_ = get_poisson_logcdf(next_ele - prev_boundary, label_cur_ele) \n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = left_sum  / config.temp + b1_prior_\n",
    "        \n",
    "        mat_b1_b2_c_prob[:, :, label_cur_ele] = LOW_VAL\n",
    "        mat_b1_b2_c_prob[:, :, label_next_ele] = LOW_VAL\n",
    "        mat_b1_b2_c_prob = torch.softmax(mat_b1_b2_c_prob.flatten(), dim=0).reshape((seg_len, seg_len, config.num_class))\n",
    "        \n",
    "        # re-distribute the dummy class probability among the left-over classes\n",
    "        left_over_classes = config.num_class - 2 + (label_cur_ele==label_next_ele)\n",
    "        for b1 in range(cur_ele, next_ele):\n",
    "            assigned_prob = mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label]\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, :] = assigned_prob/left_over_classes\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, label_cur_ele] = 0\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, label_next_ele] = 0\n",
    "        \n",
    "        marginal_b1 = torch.sum(mat_b1_b2_c_prob, axis=(1,2))\n",
    "        mean_b1 = round(torch.sum(marginal_b1.squeeze() * torch.arange(cur_ele, next_ele, 1)).item())\n",
    "        cumm_b1_prob = torch.cumsum(marginal_b1, dim=0)\n",
    "        cumm_b1_c_prob = torch.cumsum(torch.sum(mat_b1_b2_c_prob, dim=1), dim=0)\n",
    "        cumm_b2_c_prob = torch.cumsum(torch.sum(mat_b1_b2_c_prob, dim=0), dim=0)\n",
    "\n",
    "        per_frame_weights[cur_ele, label_cur_ele] = 1.0\n",
    "        per_frame_weights[cur_ele+1:next_ele, :] = cumm_b1_c_prob[:-1] - cumm_b2_c_prob[:-1]\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_cur_ele] = 1 - cumm_b1_prob[:-1]\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_next_ele] = 0\n",
    "        remaining_probability = 1 - torch.sum(per_frame_weights[cur_ele+1:next_ele, :], dim=-1)\n",
    "        # we use \"+=\" in the next line because left and right label might be the same\n",
    "        # in that case using \"=\" would just overwrite the previous probability\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_next_ele] += remaining_probability\n",
    "        \n",
    "        expected_boundary = round(torch.sum(torch.sum(mat_b1_b2_c_prob, axis=(0,2)).squeeze() * \\\n",
    "                            torch.arange(cur_ele, next_ele, 1)).item())\n",
    "        if not (label_cur_ele == label_next_ele and expected_boundary >= next_ele-2):\n",
    "            prev_boundary = expected_boundary\n",
    "        if expected_boundary == 0 and i > 0:\n",
    "            print(f'Estimated boundary has become zero! for {vidid} and cur_ele, next_ele {cur_ele, next_ele}')\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        # boundary_error += (boundary_frames_dict[vidid + '.txt'][current_boundary] - mean_b1)**2\n",
    "        # boundary_error += (boundary_frames_dict[vidid + '.txt'][current_boundary+1] - prev_boundary)**2\n",
    "        # current_boundary += 2\n",
    "        # prob_each_segment.append(mat_b1_b2_c_prob)\n",
    "        \n",
    "    posterior_prediction = torch.argmax(per_frame_weights, dim=1)\n",
    "    correct = torch.sum(posterior_prediction == gt_labels[:num_frames]).item()\n",
    "    \n",
    "    return (vidid, per_frame_weights, [correct, num_frames, boundary_error]) #, prob_each_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_acc_correct, posterior_acc_total = 0, 0\n",
    "posterior_boundary_total_mse = 0\n",
    "results = []\n",
    "\n",
    "# Step 2: Define callback function to collect the output in `results`\n",
    "def collect_result(result):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    fname = os.path.join(config.output_dir, 'posterior_weights', result[0] + '.wt')\n",
    "    torch.save(result[1], fname)\n",
    "    correct, total, boundary_err = result[2]\n",
    "    posterior_acc_correct += correct\n",
    "    posterior_acc_total += total\n",
    "    posterior_boundary_total_mse += boundary_err\n",
    "    # print(f'Dumped in file {fname} at time {time()}')\n",
    "    return\n",
    "\n",
    "def calculate_element_probb(data_feat, data_count, video_ids, gt_labels): # loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    pool = mp.Pool(20)\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "#         if cur_vidid!='P39_cam02_P39_scrambledegg':\n",
    "#             continue\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num][:cur_vid_count].detach().cpu()\n",
    "        cur_gt_labels = gt_labels[iter_num].detach().cpu()\n",
    "        \n",
    "        cur_video_select_frames = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices_and_labels = cur_video_select_frames\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "        with torch.no_grad():\n",
    "            # Multi-processing\n",
    "            pool.apply_async(prob_vals_per_segment,\n",
    "                             args=(selected_frames_indices, cur_vid_feat, selected_frames_labels,\n",
    "                                   cur_video_select_frames[1], cur_video_select_frames[2], cur_vidid, cur_gt_labels),\n",
    "                             callback=collect_result)\n",
    "#             results.append(prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels,\n",
    "#                                    cur_video_select_frames[1], cur_video_select_frames[2], cur_vidid, cur_gt_labels))\n",
    "    # Step 4: Close Pool and let all the processes complete\n",
    "    pool.close()\n",
    "    pool.join()  # postpones the execution of next line of code until all processes in the queue are done.\n",
    "    return results\n",
    "\n",
    "def perform_expectation(model, dataloader):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse = 0, 0, 0\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    curtime = time()\n",
    "    print(f'Calculating expectation')\n",
    "\n",
    "    for i, item in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device) # features\n",
    "            item_1 = item[1].to(device) # count\n",
    "            item_2 = item[2].to(device) # gt frame-wise labels\n",
    "            item_4 = item[4] # video-ids\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            prob = torch.softmax(predictions[-1], dim=1)\n",
    "            prob = prob.permute(0, 2, 1)\n",
    "            \n",
    "            calculate_element_probb(prob, item_1, item_4, item_2)\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(f\"iter {i+1} of Expectation completed in a total of {(time() - curtime)/60.: .1f} minutes\")\n",
    "    _ = model.train()\n",
    "    print(f'Expectation step finished, '\n",
    "          f'posterior frame-wise accuracy {100*posterior_acc_correct/posterior_acc_total: .2f}%, '\n",
    "          f'boundary mse {(posterior_boundary_total_mse/num_boundary)**0.5: .2f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loaded_file=torch.load(os.path.join(config.output_dir, \"ms-tcn-initial-30-epochs.wt\"))\n",
    "# model.load_state_dict(loaded_file)\n",
    "# # loaded_file=torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcnnew-full-supervised-split1/ms-tcn-best-model.wt')\n",
    "# # model.load_state_dict(loaded_file)\n",
    "# loaded_file=torch.load(os.path.join(config.output_dir, \"ms-tcn-emmax-best-model.wt\"))\n",
    "# loaded_file=torch.load(\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/ms-tcn-emmax-last-model.wt\")\n",
    "# model.load_state_dict(loaded_file)\n",
    "# _ = validate(model, testloader)\n",
    "loaded_file = torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select6/split2/ms-tcn-initial-30-epochs.wt')\n",
    "model.load_state_dict(loaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = next(iter(trainloader))\n",
    "    \n",
    "# with torch.no_grad():\n",
    "#     item_0 = item[0].to(device) # features\n",
    "#     item_1 = item[1].to(device) # count\n",
    "#     item_2 = item[2].to(device) # gt frame-wise labels\n",
    "#     item_4 = item[4] # video-ids\n",
    "#     src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "#     src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "#     middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "#     prob = torch.softmax(predictions[-1], dim=1)\n",
    "#     prob = prob.permute(0, 2, 1)\n",
    "\n",
    "#     res = calculate_element_probb(prob, item_1, item_4, item_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 2\n",
    "# vidid = res[idx][0]\n",
    "# mat = res[idx][1]\n",
    "# mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace(0, 5281, 4 + 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundary_frames_dict[f'{vidid}.txt'], selected_frames_dict[f'{vidid}.txt'], weakly_labels[f'{vidid}.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20, 5))\n",
    "# for i in range(48):\n",
    "#     plt.plot(mat[:,i])\n",
    "    \n",
    "# for bd in boundary_frames_dict[f'{vidid}.txt']:\n",
    "#     plt.plot([bd, bd], [0, 2])\n",
    "    \n",
    "# for bd in selected_frames_dict[f'{vidid}.txt']:\n",
    "#     plt.plot([bd[0], bd[0]], [0, 2], '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculating Expectation Step\n",
    "# perform_expectation(model, trainloder_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_random(video_ids, len_frames, device):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((len(video_ids), len_frames), dtype=torch.long, device=device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "\n",
    "        frame_idx_tensor = torch.from_numpy(np.array(selected_frames_indices))\n",
    "        frame_labels = torch.from_numpy(np.array(selected_frames_labels)).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = frame_labels\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labels = pickle.load(open(\"data/breakfast_weaklysupervised_labels.pkl\", \"rb\"))\n",
    "prior_probs = pickle.load(open('data/breakfast_lengthmodel_multinomial_prior.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Epoch 31: Iteration 20 with loss 1.2574782371520996\n",
      "Epoch 31: Iteration 40 with loss 1.0708187818527222\n",
      "Epoch 31: Iteration 60 with loss 1.005059838294983\n",
      "Epoch 31: Iteration 80 with loss 0.738014817237854\n",
      "Epoch 31: Iteration 100 with loss 0.8339711427688599\n",
      "Epoch 31: Iteration 120 with loss 0.8635150790214539\n",
      "Epoch 31: Iteration 140 with loss 0.555597186088562\n",
      "Epoch 31 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.26821891701537\n",
      "Other scores:: Edit 42.974029232267256, F1@[10:25:50] [43.82067289 39.52503825 31.03352285]\n",
      "Starting Training\n",
      "Epoch 32: Iteration 20 with loss 0.0\n",
      "Epoch 32: Iteration 40 with loss 0.0\n",
      "Epoch 32: Iteration 60 with loss 0.0\n",
      "Epoch 32: Iteration 80 with loss 0.0\n",
      "Epoch 32: Iteration 100 with loss 0.0\n",
      "Epoch 32: Iteration 120 with loss 0.0\n",
      "Epoch 32: Iteration 140 with loss 0.0\n",
      "Epoch 32 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.548887599950284\n",
      "Other scores:: Edit 40.93011720371917, F1@[10:25:50] [41.72978158 37.67998796 29.90488218]\n",
      "Starting Training\n",
      "Epoch 33: Iteration 20 with loss 0.0\n",
      "Epoch 33: Iteration 40 with loss 0.0\n",
      "Epoch 33: Iteration 60 with loss 0.0\n",
      "Epoch 33: Iteration 80 with loss 0.0\n",
      "Epoch 33: Iteration 100 with loss 0.0\n",
      "Epoch 33: Iteration 120 with loss 0.0\n",
      "Epoch 33: Iteration 140 with loss 0.0\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  2.7 minutes\n",
      "iter 20 of Expectation completed in a total of  5.9 minutes\n",
      "iter 30 of Expectation completed in a total of  9.4 minutes\n",
      "iter 40 of Expectation completed in a total of  12.4 minutes\n",
      "iter 50 of Expectation completed in a total of  15.6 minutes\n",
      "iter 60 of Expectation completed in a total of  18.7 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  82.40%, boundary mse  0.00\n",
      "Epoch 33 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.548887599950284\n",
      "Other scores:: Edit 40.93011720371917, F1@[10:25:50] [41.72978158 37.67998796 29.90488218]\n",
      "Starting Training\n",
      "Epoch 34: Iteration 20 with loss 5.265589714050293\n",
      "Epoch 34: Iteration 40 with loss 5.872620582580566\n",
      "Epoch 34: Iteration 60 with loss 4.334425449371338\n",
      "Epoch 34: Iteration 80 with loss 3.056239128112793\n",
      "Epoch 34: Iteration 100 with loss 2.8175766468048096\n",
      "Epoch 34: Iteration 120 with loss 3.534688711166382\n",
      "Epoch 34: Iteration 140 with loss 3.20678973197937\n",
      "Epoch 34 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.24787670381572\n",
      "Other scores:: Edit 53.43900980979534, F1@[10:25:50] [51.03049224 47.04855857 37.22320377]\n",
      "Starting Training\n",
      "Epoch 35: Iteration 20 with loss 2.433018207550049\n",
      "Epoch 35: Iteration 40 with loss 2.5647521018981934\n",
      "Epoch 35: Iteration 60 with loss 1.4619083404541016\n",
      "Epoch 35: Iteration 80 with loss 2.633749485015869\n",
      "Epoch 35: Iteration 100 with loss 1.2022907733917236\n",
      "Epoch 35: Iteration 120 with loss 2.5571963787078857\n",
      "Epoch 35: Iteration 140 with loss 1.3871452808380127\n",
      "Epoch 35 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.93352529311845\n",
      "Other scores:: Edit 55.696102963680126, F1@[10:25:50] [52.55629753 48.63870534 38.9696425 ]\n",
      "Starting Training\n",
      "Epoch 36: Iteration 20 with loss 1.4930111169815063\n",
      "Epoch 36: Iteration 40 with loss 1.6970585584640503\n",
      "Epoch 36: Iteration 60 with loss 1.8498035669326782\n",
      "Epoch 36: Iteration 80 with loss 2.567891836166382\n",
      "Epoch 36: Iteration 100 with loss 1.8670918941497803\n",
      "Epoch 36: Iteration 120 with loss 2.5214757919311523\n",
      "Epoch 36: Iteration 140 with loss 1.4245001077651978\n",
      "Epoch 36 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.78197373327257\n",
      "Other scores:: Edit 58.54309751009917, F1@[10:25:50] [55.28456482 51.8183749  40.81543692]\n",
      "Starting Training\n",
      "Epoch 37: Iteration 20 with loss 1.1894965171813965\n",
      "Epoch 37: Iteration 40 with loss 1.0287539958953857\n",
      "Epoch 37: Iteration 60 with loss 2.638364315032959\n",
      "Epoch 37: Iteration 80 with loss 2.046149253845215\n",
      "Epoch 37: Iteration 100 with loss 1.8577680587768555\n",
      "Epoch 37: Iteration 120 with loss 1.964380145072937\n",
      "Epoch 37: Iteration 140 with loss 1.8174573183059692\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  2.9 minutes\n",
      "iter 20 of Expectation completed in a total of  6.1 minutes\n",
      "iter 30 of Expectation completed in a total of  9.3 minutes\n",
      "iter 40 of Expectation completed in a total of  12.4 minutes\n",
      "iter 50 of Expectation completed in a total of  16.1 minutes\n",
      "iter 60 of Expectation completed in a total of  18.6 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  81.90%, boundary mse  0.00\n",
      "Epoch 37 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 63.163400588308406\n",
      "Other scores:: Edit 59.84114803770302, F1@[10:25:50] [56.24305765 52.38095737 43.29429439]\n",
      "Starting Training\n",
      "Epoch 38: Iteration 20 with loss 1.5111180543899536\n",
      "Epoch 38: Iteration 40 with loss 1.9312794208526611\n",
      "Epoch 38: Iteration 60 with loss 0.9139147996902466\n",
      "Epoch 38: Iteration 80 with loss 1.3076661825180054\n",
      "Epoch 38: Iteration 100 with loss 1.4377100467681885\n",
      "Epoch 38: Iteration 120 with loss 1.6492668390274048\n",
      "Epoch 38: Iteration 140 with loss 2.279348611831665\n",
      "Epoch 38 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 63.07743298670091\n",
      "Other scores:: Edit 60.643054708106, F1@[10:25:50] [56.01041377 51.37512596 40.5942897 ]\n",
      "Starting Training\n",
      "Epoch 39: Iteration 20 with loss 1.5151900053024292\n",
      "Epoch 39: Iteration 40 with loss 1.1595375537872314\n",
      "Epoch 39: Iteration 60 with loss 1.236263394355774\n",
      "Epoch 39: Iteration 80 with loss 0.8723794221878052\n",
      "Epoch 39: Iteration 100 with loss 2.029022216796875\n",
      "Epoch 39: Iteration 120 with loss 5.258296012878418\n",
      "Epoch 39: Iteration 140 with loss 1.8581355810165405\n",
      "Epoch 39 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 56.59102208228032\n",
      "Other scores:: Edit 59.692744295477, F1@[10:25:50] [55.74473339 51.55490623 41.39797824]\n",
      "Starting Training\n",
      "Epoch 40: Iteration 20 with loss 1.4282798767089844\n",
      "Epoch 40: Iteration 40 with loss 2.329678773880005\n",
      "Epoch 40: Iteration 60 with loss 2.267897605895996\n",
      "Epoch 40: Iteration 80 with loss 1.864793062210083\n",
      "Epoch 40: Iteration 100 with loss 1.2178337574005127\n",
      "Epoch 40: Iteration 120 with loss 1.3468321561813354\n",
      "Epoch 40: Iteration 140 with loss 1.0919770002365112\n",
      "Epoch 40 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 63.149107179848365\n",
      "Other scores:: Edit 61.04557075169882, F1@[10:25:50] [57.73016332 53.83883216 43.54087639]\n",
      "Starting Training\n",
      "Epoch 41: Iteration 20 with loss 1.1725714206695557\n",
      "Epoch 41: Iteration 40 with loss 0.7639418840408325\n",
      "Epoch 41: Iteration 60 with loss 0.7448874711990356\n",
      "Epoch 41: Iteration 80 with loss 0.6401589512825012\n",
      "Epoch 41: Iteration 100 with loss 0.9131341576576233\n",
      "Epoch 41: Iteration 120 with loss 0.7713444232940674\n",
      "Epoch 41: Iteration 140 with loss 0.7364639043807983\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.6 minutes\n",
      "iter 20 of Expectation completed in a total of  6.7 minutes\n",
      "iter 30 of Expectation completed in a total of  9.8 minutes\n",
      "iter 40 of Expectation completed in a total of  12.8 minutes\n",
      "iter 50 of Expectation completed in a total of  16.1 minutes\n",
      "iter 60 of Expectation completed in a total of  19.0 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  78.29%, boundary mse  0.00\n",
      "Epoch 41 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.08283962381406\n",
      "Other scores:: Edit 62.436616441663205, F1@[10:25:50] [57.6034958  54.84047171 43.78481108]\n",
      "Starting Training\n",
      "Epoch 42: Iteration 20 with loss 3.9641671180725098\n",
      "Epoch 42: Iteration 40 with loss 1.7468329668045044\n",
      "Epoch 42: Iteration 60 with loss 0.8440765142440796\n",
      "Epoch 42: Iteration 80 with loss 0.9891281127929688\n",
      "Epoch 42: Iteration 100 with loss 1.4742473363876343\n",
      "Epoch 42: Iteration 120 with loss 1.3390744924545288\n",
      "Epoch 42: Iteration 140 with loss 2.2108354568481445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.44931018767867\n",
      "Other scores:: Edit 61.6046511170398, F1@[10:25:50] [57.24580522 54.35535222 43.03272674]\n",
      "Starting Training\n",
      "Epoch 43: Iteration 20 with loss 2.074800491333008\n",
      "Epoch 43: Iteration 40 with loss 1.2217682600021362\n",
      "Epoch 43: Iteration 60 with loss 5.3713836669921875\n",
      "Epoch 43: Iteration 80 with loss 2.0834789276123047\n",
      "Epoch 43: Iteration 100 with loss 1.378605842590332\n",
      "Epoch 43: Iteration 120 with loss 2.1211655139923096\n",
      "Epoch 43: Iteration 140 with loss 1.3211874961853027\n",
      "Epoch 43 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.876869536396406\n",
      "Other scores:: Edit 63.41914022683899, F1@[10:25:50] [58.17440155 54.58506978 44.01323329]\n",
      "Starting Training\n",
      "Epoch 44: Iteration 20 with loss 1.453108787536621\n",
      "Epoch 44: Iteration 40 with loss 1.1679092645645142\n",
      "Epoch 44: Iteration 60 with loss 1.3362265825271606\n",
      "Epoch 44: Iteration 80 with loss 1.0895155668258667\n",
      "Epoch 44: Iteration 100 with loss 1.282563328742981\n",
      "Epoch 44: Iteration 120 with loss 2.1231589317321777\n",
      "Epoch 44: Iteration 140 with loss 1.4766123294830322\n",
      "Epoch 44 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.46582011020425\n",
      "Other scores:: Edit 64.60984723662777, F1@[10:25:50] [59.92821658 56.90945307 45.2863279 ]\n",
      "Starting Training\n",
      "Epoch 45: Iteration 20 with loss 1.192060947418213\n",
      "Epoch 45: Iteration 40 with loss 4.049312591552734\n",
      "Epoch 45: Iteration 60 with loss 1.61517333984375\n",
      "Epoch 45: Iteration 80 with loss 1.3074064254760742\n",
      "Epoch 45: Iteration 100 with loss 1.0523515939712524\n",
      "Epoch 45: Iteration 120 with loss 1.8510565757751465\n",
      "Epoch 45: Iteration 140 with loss 1.4856703281402588\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.8 minutes\n",
      "iter 20 of Expectation completed in a total of  7.0 minutes\n",
      "iter 30 of Expectation completed in a total of  10.1 minutes\n",
      "iter 40 of Expectation completed in a total of  13.2 minutes\n",
      "iter 50 of Expectation completed in a total of  16.3 minutes\n",
      "iter 60 of Expectation completed in a total of  19.5 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  76.35%, boundary mse  0.00\n",
      "Epoch 45 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 56.220429216555495\n",
      "Other scores:: Edit 61.35291942270632, F1@[10:25:50] [55.78859678 52.64820801 43.33492881]\n",
      "Starting Training\n",
      "Epoch 46: Iteration 20 with loss 1.1018179655075073\n",
      "Epoch 46: Iteration 40 with loss 1.0117701292037964\n",
      "Epoch 46: Iteration 60 with loss 0.747663676738739\n",
      "Epoch 46: Iteration 80 with loss 1.8698351383209229\n",
      "Epoch 46: Iteration 100 with loss 1.3657782077789307\n",
      "Epoch 46: Iteration 120 with loss 1.1206575632095337\n",
      "Epoch 46: Iteration 140 with loss 1.0683132410049438\n",
      "Epoch 46 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.54426813605668\n",
      "Other scores:: Edit 64.15903180088168, F1@[10:25:50] [58.04000599 55.20979068 43.91969113]\n",
      "Starting Training\n",
      "Epoch 47: Iteration 20 with loss 1.43936288356781\n",
      "Epoch 47: Iteration 40 with loss 2.6616873741149902\n",
      "Epoch 47: Iteration 60 with loss 1.889156699180603\n",
      "Epoch 47: Iteration 80 with loss 0.9304655194282532\n",
      "Epoch 47: Iteration 100 with loss 0.8460694551467896\n",
      "Epoch 47: Iteration 120 with loss 1.0562931299209595\n",
      "Epoch 47: Iteration 140 with loss 1.2950111627578735\n",
      "Epoch 47 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.90168620789659\n",
      "Other scores:: Edit 64.11212175861418, F1@[10:25:50] [57.3292616  54.36195046 44.24530145]\n",
      "Starting Training\n",
      "Epoch 48: Iteration 20 with loss 0.9471654891967773\n",
      "Epoch 48: Iteration 40 with loss 1.7884823083877563\n",
      "Epoch 48: Iteration 60 with loss 0.8274836540222168\n",
      "Epoch 48: Iteration 80 with loss 1.7294723987579346\n",
      "Epoch 48: Iteration 100 with loss 0.6917523145675659\n",
      "Epoch 48: Iteration 120 with loss 1.0205738544464111\n",
      "Epoch 48: Iteration 140 with loss 1.6602556705474854\n",
      "Epoch 48 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.06171023739487\n",
      "Other scores:: Edit 63.6322133602769, F1@[10:25:50] [58.80968105 55.83075999 43.76237854]\n",
      "Starting Training\n",
      "Epoch 49: Iteration 20 with loss 1.2688043117523193\n",
      "Epoch 49: Iteration 40 with loss 2.893333911895752\n",
      "Epoch 49: Iteration 60 with loss 0.7617035508155823\n",
      "Epoch 49: Iteration 80 with loss 0.9495710134506226\n",
      "Epoch 49: Iteration 100 with loss 0.9222621321678162\n",
      "Epoch 49: Iteration 120 with loss 0.5964934825897217\n",
      "Epoch 49: Iteration 140 with loss 0.4588854908943176\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.2 minutes\n",
      "iter 20 of Expectation completed in a total of  6.7 minutes\n",
      "iter 30 of Expectation completed in a total of  10.0 minutes\n",
      "iter 40 of Expectation completed in a total of  12.9 minutes\n",
      "iter 50 of Expectation completed in a total of  16.2 minutes\n",
      "iter 60 of Expectation completed in a total of  19.4 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  76.75%, boundary mse  0.00\n",
      "Epoch 49 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.02661888387124\n",
      "Other scores:: Edit 64.13344524590002, F1@[10:25:50] [58.95655805 55.98736709 44.81562849]\n",
      "Starting Training\n",
      "Epoch 50: Iteration 20 with loss 0.6971184611320496\n",
      "Epoch 50: Iteration 40 with loss 0.9170932173728943\n",
      "Epoch 50: Iteration 60 with loss 0.8650262355804443\n",
      "Epoch 50: Iteration 80 with loss 0.9344820976257324\n",
      "Epoch 50: Iteration 100 with loss 1.3550856113433838\n",
      "Epoch 50: Iteration 120 with loss 1.009368658065796\n",
      "Epoch 50: Iteration 140 with loss 0.9112497568130493\n",
      "Epoch 50 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.896486721630694\n",
      "Other scores:: Edit 62.452453385169655, F1@[10:25:50] [57.45847194 54.38371221 42.54098308]\n",
      "Starting Training\n",
      "Epoch 51: Iteration 20 with loss 1.5670629739761353\n",
      "Epoch 51: Iteration 40 with loss 0.7647643089294434\n",
      "Epoch 51: Iteration 60 with loss 0.8909732103347778\n",
      "Epoch 51: Iteration 80 with loss 0.9158580303192139\n",
      "Epoch 51: Iteration 100 with loss 1.754943609237671\n",
      "Epoch 51: Iteration 120 with loss 0.7409082055091858\n",
      "Epoch 51: Iteration 140 with loss 1.1634981632232666\n",
      "Epoch 51 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 55.174006711687454\n",
      "Other scores:: Edit 61.66238247073727, F1@[10:25:50] [55.32347456 52.9362295  41.92438882]\n",
      "Starting Training\n",
      "Epoch 52: Iteration 20 with loss 4.419462203979492\n",
      "Epoch 52: Iteration 40 with loss 5.003056526184082\n",
      "Epoch 52: Iteration 60 with loss 1.1316421031951904\n",
      "Epoch 52: Iteration 80 with loss 1.0523624420166016\n",
      "Epoch 52: Iteration 100 with loss 1.2256064414978027\n",
      "Epoch 52: Iteration 120 with loss 1.30709969997406\n",
      "Epoch 52: Iteration 140 with loss 3.141265392303467\n",
      "Epoch 52 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 56.34751626134151\n",
      "Other scores:: Edit 61.97817678308374, F1@[10:25:50] [56.75868124 54.02504246 42.44146559]\n",
      "Starting Training\n",
      "Epoch 53: Iteration 20 with loss 0.8976254463195801\n",
      "Epoch 53: Iteration 40 with loss 0.7474887371063232\n",
      "Epoch 53: Iteration 60 with loss 0.8601378202438354\n",
      "Epoch 53: Iteration 80 with loss 0.776755690574646\n",
      "Epoch 53: Iteration 100 with loss 1.4195243120193481\n",
      "Epoch 53: Iteration 120 with loss 0.6572339534759521\n",
      "Epoch 53: Iteration 140 with loss 1.524430513381958\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.3 minutes\n",
      "iter 20 of Expectation completed in a total of  6.0 minutes\n",
      "iter 30 of Expectation completed in a total of  9.3 minutes\n",
      "iter 40 of Expectation completed in a total of  11.7 minutes\n",
      "iter 50 of Expectation completed in a total of  15.2 minutes\n",
      "iter 60 of Expectation completed in a total of  18.4 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.32%, boundary mse  0.00\n",
      "Epoch 53 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.22446865807681\n",
      "Other scores:: Edit 65.49676770315193, F1@[10:25:50] [61.28456296 57.85582263 47.06501126]\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Iteration 20 with loss 0.7668478488922119\n",
      "Epoch 54: Iteration 40 with loss 0.6426512598991394\n",
      "Epoch 54: Iteration 60 with loss 1.283782958984375\n",
      "Epoch 54: Iteration 80 with loss 0.9775731563568115\n",
      "Epoch 54: Iteration 100 with loss 1.1546767950057983\n",
      "Epoch 54: Iteration 120 with loss 0.9989784955978394\n",
      "Epoch 54: Iteration 140 with loss 0.33656299114227295\n",
      "Epoch 54 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.60717984836558\n",
      "Other scores:: Edit 65.15046445730383, F1@[10:25:50] [61.32469488 58.24499372 46.45097808]\n",
      "Starting Training\n",
      "Epoch 55: Iteration 20 with loss 0.5449814796447754\n",
      "Epoch 55: Iteration 40 with loss 0.5643701553344727\n",
      "Epoch 55: Iteration 60 with loss 0.4652245044708252\n",
      "Epoch 55: Iteration 80 with loss 0.6582809686660767\n",
      "Epoch 55: Iteration 100 with loss 0.5138751268386841\n",
      "Epoch 55: Iteration 120 with loss 0.5655753016471863\n",
      "Epoch 55: Iteration 140 with loss 1.0304491519927979\n",
      "Epoch 55 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.56233168993661\n",
      "Other scores:: Edit 64.85730549152585, F1@[10:25:50] [61.14977258 57.78376719 47.0171161 ]\n",
      "Starting Training\n",
      "Epoch 56: Iteration 20 with loss 0.4783916473388672\n",
      "Epoch 56: Iteration 40 with loss 0.6266682147979736\n",
      "Epoch 56: Iteration 60 with loss 0.5562387704849243\n",
      "Epoch 56: Iteration 80 with loss 1.0904289484024048\n",
      "Epoch 56: Iteration 100 with loss 0.5543610453605652\n",
      "Epoch 56: Iteration 120 with loss 0.5980538129806519\n",
      "Epoch 56: Iteration 140 with loss 0.7200740575790405\n",
      "Epoch 56 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.30763972324647\n",
      "Other scores:: Edit 65.03074000884652, F1@[10:25:50] [60.51027142 57.24498592 45.43304748]\n",
      "Starting Training\n",
      "Epoch 57: Iteration 20 with loss 0.49685853719711304\n",
      "Epoch 57: Iteration 40 with loss 0.6126164197921753\n",
      "Epoch 57: Iteration 60 with loss 0.6693407893180847\n",
      "Epoch 57: Iteration 80 with loss 0.2993043065071106\n",
      "Epoch 57: Iteration 100 with loss 0.4611758291721344\n",
      "Epoch 57: Iteration 120 with loss 0.5343411564826965\n",
      "Epoch 57: Iteration 140 with loss 0.6598559021949768\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.6 minutes\n",
      "iter 20 of Expectation completed in a total of  6.5 minutes\n",
      "iter 30 of Expectation completed in a total of  9.6 minutes\n",
      "iter 40 of Expectation completed in a total of  12.7 minutes\n",
      "iter 50 of Expectation completed in a total of  15.8 minutes\n",
      "iter 60 of Expectation completed in a total of  19.1 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.96%, boundary mse  0.00\n",
      "Epoch 57 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.14784355968016\n",
      "Other scores:: Edit 65.883501729109, F1@[10:25:50] [62.7648588  59.06825597 47.61083136]\n",
      "Starting Training\n",
      "Epoch 58: Iteration 20 with loss 0.37770143151283264\n",
      "Epoch 58: Iteration 40 with loss 0.4697762429714203\n",
      "Epoch 58: Iteration 60 with loss 0.3677294850349426\n",
      "Epoch 58: Iteration 80 with loss 0.9266367554664612\n",
      "Epoch 58: Iteration 100 with loss 0.5570593476295471\n",
      "Epoch 58: Iteration 120 with loss 0.5256104469299316\n",
      "Epoch 58: Iteration 140 with loss 2.1930272579193115\n",
      "Epoch 58 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.15641960475618\n",
      "Other scores:: Edit 65.14485160048562, F1@[10:25:50] [61.3844276  58.13775918 44.96568831]\n",
      "Starting Training\n",
      "Epoch 59: Iteration 20 with loss 0.38582274317741394\n",
      "Epoch 59: Iteration 40 with loss 0.445529580116272\n",
      "Epoch 59: Iteration 60 with loss 0.5716663002967834\n",
      "Epoch 59: Iteration 80 with loss 0.6460088491439819\n",
      "Epoch 59: Iteration 100 with loss 0.8060671091079712\n",
      "Epoch 59: Iteration 120 with loss 0.4025195240974426\n",
      "Epoch 59: Iteration 140 with loss 0.4121701419353485\n",
      "Epoch 59 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.144922732733974\n",
      "Other scores:: Edit 65.99153165364642, F1@[10:25:50] [61.7955806  58.4843641  46.65367362]\n",
      "Starting Training\n",
      "Epoch 60: Iteration 20 with loss 0.4086865186691284\n",
      "Epoch 60: Iteration 40 with loss 0.4305417835712433\n",
      "Epoch 60: Iteration 60 with loss 0.42476558685302734\n",
      "Epoch 60: Iteration 80 with loss 0.7389679551124573\n",
      "Epoch 60: Iteration 100 with loss 0.4419621229171753\n",
      "Epoch 60: Iteration 120 with loss 0.3753388524055481\n",
      "Epoch 60: Iteration 140 with loss 0.3137781620025635\n",
      "Epoch 60 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.59464722210714\n",
      "Other scores:: Edit 66.00798281617786, F1@[10:25:50] [62.12058106 59.02370007 47.56948078]\n",
      "Starting Training\n",
      "Epoch 61: Iteration 20 with loss 0.6094858050346375\n",
      "Epoch 61: Iteration 40 with loss 0.9013992547988892\n",
      "Epoch 61: Iteration 60 with loss 0.5222786068916321\n",
      "Epoch 61: Iteration 80 with loss 0.5190534591674805\n",
      "Epoch 61: Iteration 100 with loss 0.41351965069770813\n",
      "Epoch 61: Iteration 120 with loss 0.7747600078582764\n",
      "Epoch 61: Iteration 140 with loss 0.46525537967681885\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.4 minutes\n",
      "iter 20 of Expectation completed in a total of  6.4 minutes\n",
      "iter 30 of Expectation completed in a total of  9.6 minutes\n",
      "iter 40 of Expectation completed in a total of  12.8 minutes\n",
      "iter 50 of Expectation completed in a total of  15.7 minutes\n",
      "iter 60 of Expectation completed in a total of  18.7 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.70%, boundary mse  0.00\n",
      "Epoch 61 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.656792476281225\n",
      "Other scores:: Edit 65.21010080303454, F1@[10:25:50] [61.13984166 57.65889031 44.9215352 ]\n",
      "Starting Training\n",
      "Epoch 62: Iteration 20 with loss 0.723688542842865\n",
      "Epoch 62: Iteration 40 with loss 0.43107208609580994\n",
      "Epoch 62: Iteration 60 with loss 0.522972822189331\n",
      "Epoch 62: Iteration 80 with loss 1.0670820474624634\n",
      "Epoch 62: Iteration 100 with loss 0.6161526441574097\n",
      "Epoch 62: Iteration 120 with loss 0.41709429025650024\n",
      "Epoch 62: Iteration 140 with loss 0.5064569711685181\n",
      "Epoch 62 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.54648465012222\n",
      "Other scores:: Edit 66.74877331401703, F1@[10:25:50] [63.2445504  59.71249042 47.26974994]\n",
      "Starting Training\n",
      "Epoch 63: Iteration 20 with loss 0.7374616861343384\n",
      "Epoch 63: Iteration 40 with loss 0.8060861825942993\n",
      "Epoch 63: Iteration 60 with loss 1.1746336221694946\n",
      "Epoch 63: Iteration 80 with loss 1.9162774085998535\n",
      "Epoch 63: Iteration 100 with loss 0.8325124382972717\n",
      "Epoch 63: Iteration 120 with loss 1.140824317932129\n",
      "Epoch 63: Iteration 140 with loss 1.7631855010986328\n",
      "Epoch 63 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.67286738202759\n",
      "Other scores:: Edit 62.50976844880497, F1@[10:25:50] [56.94884756 53.99683373 42.17383413]\n",
      "Starting Training\n",
      "Epoch 64: Iteration 20 with loss 0.7318898439407349\n",
      "Epoch 64: Iteration 40 with loss 0.8520530462265015\n",
      "Epoch 64: Iteration 60 with loss 1.1503410339355469\n",
      "Epoch 64: Iteration 80 with loss 0.8825035095214844\n",
      "Epoch 64: Iteration 100 with loss 0.8986981511116028\n",
      "Epoch 64: Iteration 120 with loss 1.046004056930542\n",
      "Epoch 64: Iteration 140 with loss 0.4115230441093445\n",
      "Epoch 64 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.22291502672246\n",
      "Other scores:: Edit 63.65282012435825, F1@[10:25:50] [59.26455014 55.95828177 43.40951401]\n",
      "Starting Training\n",
      "Epoch 65: Iteration 20 with loss 0.5099289417266846\n",
      "Epoch 65: Iteration 40 with loss 0.6448469758033752\n",
      "Epoch 65: Iteration 60 with loss 0.5380092263221741\n",
      "Epoch 65: Iteration 80 with loss 0.3948257863521576\n",
      "Epoch 65: Iteration 100 with loss 0.6995106935501099\n",
      "Epoch 65: Iteration 120 with loss 0.34826910495758057\n",
      "Epoch 65: Iteration 140 with loss 0.47347429394721985\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  2.7 minutes\n",
      "iter 20 of Expectation completed in a total of  5.8 minutes\n",
      "iter 30 of Expectation completed in a total of  8.6 minutes\n",
      "iter 40 of Expectation completed in a total of  11.9 minutes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 50 of Expectation completed in a total of  14.4 minutes\n",
      "iter 60 of Expectation completed in a total of  18.2 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.72%, boundary mse  0.00\n",
      "Epoch 65 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.01692422422008\n",
      "Other scores:: Edit 66.17419319677718, F1@[10:25:50] [61.895852   58.48518092 47.46878506]\n",
      "Starting Training\n",
      "Epoch 66: Iteration 20 with loss 0.5619697570800781\n",
      "Epoch 66: Iteration 40 with loss 0.28654026985168457\n",
      "Epoch 66: Iteration 60 with loss 0.29388266801834106\n",
      "Epoch 66: Iteration 80 with loss 0.6260179281234741\n",
      "Epoch 66: Iteration 100 with loss 0.7525129318237305\n",
      "Epoch 66: Iteration 120 with loss 0.8450700640678406\n",
      "Epoch 66: Iteration 140 with loss 0.8310724496841431\n",
      "Epoch 66 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.91055226415876\n",
      "Other scores:: Edit 65.37469389277628, F1@[10:25:50] [61.8201161  59.24507242 47.51805137]\n",
      "Starting Training\n",
      "Epoch 67: Iteration 20 with loss 0.5855384469032288\n",
      "Epoch 67: Iteration 40 with loss 0.5265037417411804\n",
      "Epoch 67: Iteration 60 with loss 0.6962682008743286\n",
      "Epoch 67: Iteration 80 with loss 0.7787387371063232\n",
      "Epoch 67: Iteration 100 with loss 0.5315730571746826\n",
      "Epoch 67: Iteration 120 with loss 0.5115047693252563\n",
      "Epoch 67: Iteration 140 with loss 1.0580155849456787\n",
      "Epoch 67 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.555495711977464\n",
      "Other scores:: Edit 65.36801603291006, F1@[10:25:50] [61.62052765 58.93566356 46.71394901]\n",
      "Starting Training\n",
      "Epoch 68: Iteration 20 with loss 0.4693117141723633\n",
      "Epoch 68: Iteration 40 with loss 0.5839062333106995\n",
      "Epoch 68: Iteration 60 with loss 0.5503697395324707\n",
      "Epoch 68: Iteration 80 with loss 0.40824195742607117\n",
      "Epoch 68: Iteration 100 with loss 0.5083534717559814\n",
      "Epoch 68: Iteration 120 with loss 0.5238585472106934\n",
      "Epoch 68: Iteration 140 with loss 0.35452088713645935\n",
      "Epoch 68 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.0324605377636\n",
      "Other scores:: Edit 66.1661411925028, F1@[10:25:50] [62.62875837 59.51779525 47.50094511]\n",
      "Starting Training\n",
      "Epoch 69: Iteration 20 with loss 0.3485545814037323\n",
      "Epoch 69: Iteration 40 with loss 0.3674944043159485\n",
      "Epoch 69: Iteration 60 with loss 0.24190926551818848\n",
      "Epoch 69: Iteration 80 with loss 0.5823167562484741\n",
      "Epoch 69: Iteration 100 with loss 0.3721429109573364\n",
      "Epoch 69: Iteration 120 with loss 0.5401089787483215\n",
      "Epoch 69: Iteration 140 with loss 0.6031955480575562\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.3 minutes\n",
      "iter 20 of Expectation completed in a total of  6.7 minutes\n",
      "iter 30 of Expectation completed in a total of  9.7 minutes\n",
      "iter 40 of Expectation completed in a total of  11.9 minutes\n",
      "iter 50 of Expectation completed in a total of  15.8 minutes\n",
      "iter 60 of Expectation completed in a total of  18.6 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.87%, boundary mse  0.00\n",
      "Epoch 69 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.77381198989104\n",
      "Other scores:: Edit 65.78330664348525, F1@[10:25:50] [61.4336195  57.93282765 47.32679789]\n",
      "Starting Training\n",
      "Epoch 70: Iteration 20 with loss 0.250499963760376\n",
      "Epoch 70: Iteration 40 with loss 1.1889500617980957\n",
      "Epoch 70: Iteration 60 with loss 1.5853897333145142\n",
      "Epoch 70: Iteration 80 with loss 0.4681141972541809\n",
      "Epoch 70: Iteration 100 with loss 0.752772331237793\n",
      "Epoch 70: Iteration 120 with loss 0.4224395751953125\n",
      "Epoch 70: Iteration 140 with loss 0.37339481711387634\n",
      "Epoch 70 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.521895844554\n",
      "Other scores:: Edit 61.845872195231806, F1@[10:25:50] [56.4516796  52.45929917 42.4475065 ]\n",
      "Starting Training\n",
      "Epoch 71: Iteration 20 with loss 1.089216709136963\n",
      "Epoch 71: Iteration 40 with loss 0.5765808820724487\n",
      "Epoch 71: Iteration 60 with loss 1.6261087656021118\n",
      "Epoch 71: Iteration 80 with loss 1.517075538635254\n",
      "Epoch 71: Iteration 100 with loss 0.590660572052002\n",
      "Epoch 71: Iteration 120 with loss 2.815709114074707\n",
      "Epoch 71: Iteration 140 with loss 0.8671423196792603\n",
      "Epoch 71 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.66721216389775\n",
      "Other scores:: Edit 64.44382410089844, F1@[10:25:50] [59.93119849 57.07581428 45.23863996]\n",
      "Starting Training\n",
      "Epoch 72: Iteration 20 with loss 0.5706186890602112\n",
      "Epoch 72: Iteration 40 with loss 0.8029208183288574\n",
      "Epoch 72: Iteration 60 with loss 0.44641876220703125\n",
      "Epoch 72: Iteration 80 with loss 0.5858662724494934\n",
      "Epoch 72: Iteration 100 with loss 0.32553625106811523\n",
      "Epoch 72: Iteration 120 with loss 0.46757879853248596\n",
      "Epoch 72: Iteration 140 with loss 0.3586203455924988\n",
      "Epoch 72 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.55936943282098\n",
      "Other scores:: Edit 64.59197293675743, F1@[10:25:50] [61.29623994 58.01761226 46.07901597]\n",
      "Starting Training\n",
      "Epoch 73: Iteration 20 with loss 0.4619429111480713\n",
      "Epoch 73: Iteration 40 with loss 0.8941469788551331\n",
      "Epoch 73: Iteration 60 with loss 0.40805599093437195\n",
      "Epoch 73: Iteration 80 with loss 0.6124269962310791\n",
      "Epoch 73: Iteration 100 with loss 0.5082948207855225\n",
      "Epoch 73: Iteration 120 with loss 0.2542732059955597\n",
      "Epoch 73: Iteration 140 with loss 0.5968542695045471\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  2.9 minutes\n",
      "iter 20 of Expectation completed in a total of  5.7 minutes\n",
      "iter 30 of Expectation completed in a total of  8.2 minutes\n",
      "iter 40 of Expectation completed in a total of  10.8 minutes\n",
      "iter 50 of Expectation completed in a total of  14.2 minutes\n",
      "iter 60 of Expectation completed in a total of  17.6 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.72%, boundary mse  0.00\n",
      "Epoch 73 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.83421717694825\n",
      "Other scores:: Edit 65.6322864869657, F1@[10:25:50] [61.29632485 58.48951386 46.26274388]\n",
      "Starting Training\n",
      "Epoch 74: Iteration 20 with loss 0.3595328629016876\n",
      "Epoch 74: Iteration 40 with loss 0.26823270320892334\n",
      "Epoch 74: Iteration 60 with loss 0.32191479206085205\n",
      "Epoch 74: Iteration 80 with loss 0.39338773488998413\n",
      "Epoch 74: Iteration 100 with loss 0.2783845365047455\n",
      "Epoch 74: Iteration 120 with loss 0.27476003766059875\n",
      "Epoch 74: Iteration 140 with loss 0.4615044891834259\n",
      "Epoch 74 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.38438911215147\n",
      "Other scores:: Edit 65.59812535280092, F1@[10:25:50] [60.9678744 57.7173537 46.3428434]\n",
      "Starting Training\n",
      "Epoch 75: Iteration 20 with loss 0.24337582290172577\n",
      "Epoch 75: Iteration 40 with loss 0.23331916332244873\n",
      "Epoch 75: Iteration 60 with loss 0.45427852869033813\n",
      "Epoch 75: Iteration 80 with loss 1.5306999683380127\n",
      "Epoch 75: Iteration 100 with loss 0.32541513442993164\n",
      "Epoch 75: Iteration 120 with loss 0.288836270570755\n",
      "Epoch 75: Iteration 140 with loss 0.49313461780548096\n",
      "Epoch 75 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.99154824543233\n",
      "Other scores:: Edit 66.14565351114281, F1@[10:25:50] [62.53419026 59.54155295 46.69008739]\n",
      "Starting Training\n",
      "Epoch 76: Iteration 20 with loss 0.3791313171386719\n",
      "Epoch 76: Iteration 40 with loss 0.24855883419513702\n",
      "Epoch 76: Iteration 60 with loss 0.24409857392311096\n",
      "Epoch 76: Iteration 80 with loss 0.35889655351638794\n",
      "Epoch 76: Iteration 100 with loss 0.22822648286819458\n",
      "Epoch 76: Iteration 120 with loss 0.2420988529920578\n",
      "Epoch 76: Iteration 140 with loss 0.1985223889350891\n",
      "Epoch 76 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.690454488958856\n",
      "Other scores:: Edit 65.91040101031655, F1@[10:25:50] [62.31452644 59.09504477 46.98586461]\n",
      "Starting Training\n",
      "Epoch 77: Iteration 20 with loss 0.3292038142681122\n",
      "Epoch 77: Iteration 40 with loss 0.3492977023124695\n",
      "Epoch 77: Iteration 60 with loss 0.20839126408100128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Iteration 80 with loss 0.3858333230018616\n",
      "Epoch 77: Iteration 100 with loss 0.46621453762054443\n",
      "Epoch 77: Iteration 120 with loss 0.3166162073612213\n",
      "Epoch 77: Iteration 140 with loss 0.5315820574760437\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.5 minutes\n",
      "iter 20 of Expectation completed in a total of  6.2 minutes\n",
      "iter 30 of Expectation completed in a total of  9.0 minutes\n",
      "iter 40 of Expectation completed in a total of  12.4 minutes\n",
      "iter 50 of Expectation completed in a total of  15.5 minutes\n",
      "iter 60 of Expectation completed in a total of  18.4 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.73%, boundary mse  0.00\n",
      "Epoch 77 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.46134565190371\n",
      "Other scores:: Edit 66.28218071818311, F1@[10:25:50] [62.37876909 58.97992041 47.09255832]\n",
      "Starting Training\n",
      "Epoch 78: Iteration 20 with loss 0.46046918630599976\n",
      "Epoch 78: Iteration 40 with loss 0.2664321959018707\n",
      "Epoch 78: Iteration 60 with loss 0.22033554315567017\n",
      "Epoch 78: Iteration 80 with loss 0.2650725841522217\n",
      "Epoch 78: Iteration 100 with loss 0.24186432361602783\n",
      "Epoch 78: Iteration 120 with loss 0.3841605484485626\n",
      "Epoch 78: Iteration 140 with loss 0.20421454310417175\n",
      "Epoch 78 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.28135228073083\n",
      "Other scores:: Edit 66.46857264641248, F1@[10:25:50] [62.90256503 59.9408174  48.257642  ]\n",
      "Starting Training\n",
      "Epoch 79: Iteration 20 with loss 0.2837395668029785\n",
      "Epoch 79: Iteration 40 with loss 0.3440086245536804\n",
      "Epoch 79: Iteration 60 with loss 0.220159113407135\n",
      "Epoch 79: Iteration 80 with loss 0.439240038394928\n",
      "Epoch 79: Iteration 100 with loss 0.38894569873809814\n",
      "Epoch 79: Iteration 120 with loss 0.34312450885772705\n",
      "Epoch 79: Iteration 140 with loss 0.3817313015460968\n",
      "Epoch 79 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.08557401499772\n",
      "Other scores:: Edit 66.11764398308574, F1@[10:25:50] [62.32917087 58.93679132 45.56485008]\n",
      "Starting Training\n",
      "Epoch 80: Iteration 20 with loss 0.34373602271080017\n",
      "Epoch 80: Iteration 40 with loss 0.41166171431541443\n",
      "Epoch 80: Iteration 60 with loss 0.4589436650276184\n",
      "Epoch 80: Iteration 80 with loss 0.40936794877052307\n",
      "Epoch 80: Iteration 100 with loss 0.4283340275287628\n",
      "Epoch 80: Iteration 120 with loss 0.2773113548755646\n",
      "Epoch 80: Iteration 140 with loss 0.45231741666793823\n",
      "Epoch 80 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.79523138749637\n",
      "Other scores:: Edit 62.88380208907906, F1@[10:25:50] [59.09419992 55.7970652  42.25731065]\n",
      "Starting Training\n",
      "Epoch 81: Iteration 20 with loss 0.9803488254547119\n",
      "Epoch 81: Iteration 40 with loss 0.7565851211547852\n",
      "Epoch 81: Iteration 60 with loss 1.1697874069213867\n",
      "Epoch 81: Iteration 80 with loss 1.0186374187469482\n",
      "Epoch 81: Iteration 100 with loss 0.4788902997970581\n",
      "Epoch 81: Iteration 120 with loss 0.5145691633224487\n",
      "Epoch 81: Iteration 140 with loss 0.4562089741230011\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.4 minutes\n",
      "iter 20 of Expectation completed in a total of  6.2 minutes\n",
      "iter 30 of Expectation completed in a total of  9.0 minutes\n",
      "iter 40 of Expectation completed in a total of  12.0 minutes\n",
      "iter 50 of Expectation completed in a total of  15.2 minutes\n",
      "iter 60 of Expectation completed in a total of  18.9 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.56%, boundary mse  0.00\n",
      "Epoch 81 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.11706094377926\n",
      "Other scores:: Edit 65.3262921762598, F1@[10:25:50] [61.11149498 57.64819397 45.61259878]\n",
      "Starting Training\n",
      "Epoch 82: Iteration 20 with loss 0.2816770076751709\n",
      "Epoch 82: Iteration 40 with loss 0.3502810001373291\n",
      "Epoch 82: Iteration 60 with loss 0.7709752917289734\n",
      "Epoch 82: Iteration 80 with loss 0.7543136477470398\n",
      "Epoch 82: Iteration 100 with loss 0.48150280117988586\n",
      "Epoch 82: Iteration 120 with loss 0.39823246002197266\n",
      "Epoch 82: Iteration 140 with loss 0.38666999340057373\n",
      "Epoch 82 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.201474914032396\n",
      "Other scores:: Edit 65.0967383460447, F1@[10:25:50] [60.75259422 57.67541592 44.76046895]\n",
      "Starting Training\n",
      "Epoch 83: Iteration 20 with loss 0.3421909809112549\n",
      "Epoch 83: Iteration 40 with loss 0.3211672604084015\n",
      "Epoch 83: Iteration 60 with loss 0.3752948045730591\n",
      "Epoch 83: Iteration 80 with loss 0.3779776692390442\n",
      "Epoch 83: Iteration 100 with loss 0.24370506405830383\n",
      "Epoch 83: Iteration 120 with loss 0.23051691055297852\n",
      "Epoch 83: Iteration 140 with loss 0.48701754212379456\n",
      "Epoch 83 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.853896507436716\n",
      "Other scores:: Edit 66.64883784985791, F1@[10:25:50] [62.11057119 58.67693445 46.72785636]\n",
      "Starting Training\n",
      "Epoch 84: Iteration 20 with loss 0.41115307807922363\n",
      "Epoch 84: Iteration 40 with loss 0.29510828852653503\n",
      "Epoch 84: Iteration 60 with loss 0.3536856174468994\n",
      "Epoch 84: Iteration 80 with loss 0.3963776230812073\n",
      "Epoch 84: Iteration 100 with loss 0.42790937423706055\n",
      "Epoch 84: Iteration 120 with loss 0.4124574363231659\n",
      "Epoch 84: Iteration 140 with loss 0.3472272455692291\n",
      "Epoch 84 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.08627832787836\n",
      "Other scores:: Edit 65.19601160401585, F1@[10:25:50] [61.00830944 57.53786754 46.09970049]\n",
      "Starting Training\n",
      "Epoch 85: Iteration 20 with loss 0.3103373050689697\n",
      "Epoch 85: Iteration 40 with loss 0.32099103927612305\n",
      "Epoch 85: Iteration 60 with loss 0.30253997445106506\n",
      "Epoch 85: Iteration 80 with loss 0.2837614417076111\n",
      "Epoch 85: Iteration 100 with loss 0.3564612567424774\n",
      "Epoch 85: Iteration 120 with loss 0.4403931200504303\n",
      "Epoch 85: Iteration 140 with loss 0.3275544345378876\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.2 minutes\n",
      "iter 20 of Expectation completed in a total of  6.2 minutes\n",
      "iter 30 of Expectation completed in a total of  9.2 minutes\n",
      "iter 40 of Expectation completed in a total of  12.3 minutes\n",
      "iter 50 of Expectation completed in a total of  15.3 minutes\n",
      "iter 60 of Expectation completed in a total of  18.3 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.53%, boundary mse  0.00\n",
      "Epoch 85 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.75889712888926\n",
      "Other scores:: Edit 65.54834907269522, F1@[10:25:50] [62.0568917  58.26983302 46.50829071]\n",
      "Starting Training\n",
      "Epoch 86: Iteration 20 with loss 0.24667277932167053\n",
      "Epoch 86: Iteration 40 with loss 0.2671889662742615\n",
      "Epoch 86: Iteration 60 with loss 0.199188694357872\n",
      "Epoch 86: Iteration 80 with loss 0.24583402276039124\n",
      "Epoch 86: Iteration 100 with loss 0.2945045828819275\n",
      "Epoch 86: Iteration 120 with loss 0.28661972284317017\n",
      "Epoch 86: Iteration 140 with loss 0.2929270565509796\n",
      "Epoch 86 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.46070348427725\n",
      "Other scores:: Edit 65.693204612436, F1@[10:25:50] [61.52271558 57.48942876 45.38550051]\n",
      "Starting Training\n",
      "Epoch 87: Iteration 20 with loss 0.2296941578388214\n",
      "Epoch 87: Iteration 40 with loss 0.3271479904651642\n",
      "Epoch 87: Iteration 60 with loss 0.22863741219043732\n",
      "Epoch 87: Iteration 80 with loss 0.27759575843811035\n",
      "Epoch 87: Iteration 100 with loss 0.3217932879924774\n",
      "Epoch 87: Iteration 120 with loss 0.26090726256370544\n",
      "Epoch 87: Iteration 140 with loss 0.29175007343292236\n",
      "Epoch 87 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.452106724116504\n",
      "Other scores:: Edit 66.29627637302353, F1@[10:25:50] [62.83288834 59.05354079 46.57309314]\n",
      "Starting Training\n",
      "Epoch 88: Iteration 20 with loss 0.4495196044445038\n",
      "Epoch 88: Iteration 40 with loss 0.32994508743286133\n",
      "Epoch 88: Iteration 60 with loss 0.29102614521980286\n",
      "Epoch 88: Iteration 80 with loss 0.3757491409778595\n",
      "Epoch 88: Iteration 100 with loss 0.41884374618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Iteration 120 with loss 2.0710532665252686\n",
      "Epoch 88: Iteration 140 with loss 1.6069703102111816\n",
      "Epoch 88 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 55.45241745038737\n",
      "Other scores:: Edit 60.41844867407689, F1@[10:25:50] [54.00753041 50.86053354 38.72729606]\n",
      "Starting Training\n",
      "Epoch 89: Iteration 20 with loss 0.9140113592147827\n",
      "Epoch 89: Iteration 40 with loss 2.9257595539093018\n",
      "Epoch 89: Iteration 60 with loss 1.7159864902496338\n",
      "Epoch 89: Iteration 80 with loss 0.7840824127197266\n",
      "Epoch 89: Iteration 100 with loss 0.5761829018592834\n",
      "Epoch 89: Iteration 120 with loss 0.9038782715797424\n",
      "Epoch 89: Iteration 140 with loss 0.8083029985427856\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  2.8 minutes\n",
      "iter 20 of Expectation completed in a total of  5.7 minutes\n",
      "iter 30 of Expectation completed in a total of  9.0 minutes\n",
      "iter 40 of Expectation completed in a total of  12.3 minutes\n",
      "iter 50 of Expectation completed in a total of  15.0 minutes\n",
      "iter 60 of Expectation completed in a total of  18.0 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.67%, boundary mse  0.00\n",
      "Epoch 89 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.634337324439656\n",
      "Other scores:: Edit 66.23131361507416, F1@[10:25:50] [62.02541576 59.31140011 46.46922705]\n",
      "Starting Training\n",
      "Epoch 90: Iteration 20 with loss 0.263187050819397\n",
      "Epoch 90: Iteration 40 with loss 0.4059210419654846\n",
      "Epoch 90: Iteration 60 with loss 0.9930368661880493\n",
      "Epoch 90: Iteration 80 with loss 0.4937346577644348\n",
      "Epoch 90: Iteration 100 with loss 1.6277520656585693\n",
      "Epoch 90: Iteration 120 with loss 3.1040451526641846\n",
      "Epoch 90: Iteration 140 with loss 1.5607917308807373\n",
      "Epoch 90 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.798442225628705\n",
      "Other scores:: Edit 59.24893844700611, F1@[10:25:50] [52.70076071 49.42016867 36.04977358]\n",
      "Starting Training\n",
      "Epoch 91: Iteration 20 with loss 0.6741576790809631\n",
      "Epoch 91: Iteration 40 with loss 1.3302226066589355\n",
      "Epoch 91: Iteration 60 with loss 0.42827272415161133\n",
      "Epoch 91: Iteration 80 with loss 0.6764279007911682\n",
      "Epoch 91: Iteration 100 with loss 0.4367007315158844\n",
      "Epoch 91: Iteration 120 with loss 0.27533891797065735\n",
      "Epoch 91: Iteration 140 with loss 0.5177170634269714\n",
      "Epoch 91 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.10278825040395\n",
      "Other scores:: Edit 65.7099770000864, F1@[10:25:50] [60.60415571 57.13195132 44.65232824]\n",
      "Starting Training\n",
      "Epoch 92: Iteration 20 with loss 0.3658619225025177\n",
      "Epoch 92: Iteration 40 with loss 0.33886775374412537\n",
      "Epoch 92: Iteration 60 with loss 0.38660290837287903\n",
      "Epoch 92: Iteration 80 with loss 0.3249718248844147\n",
      "Epoch 92: Iteration 100 with loss 0.2794182002544403\n",
      "Epoch 92: Iteration 120 with loss 0.3234676718711853\n",
      "Epoch 92: Iteration 140 with loss 0.41131505370140076\n",
      "Epoch 92 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 55.09995028379666\n",
      "Other scores:: Edit 62.251196516534065, F1@[10:25:50] [56.50700917 53.02359434 42.45917974]\n",
      "Starting Training\n",
      "Epoch 93: Iteration 20 with loss 1.6374106407165527\n",
      "Epoch 93: Iteration 40 with loss 1.7423784732818604\n",
      "Epoch 93: Iteration 60 with loss 0.9571552872657776\n",
      "Epoch 93: Iteration 80 with loss 0.7573326826095581\n",
      "Epoch 93: Iteration 100 with loss 0.5257233381271362\n",
      "Epoch 93: Iteration 120 with loss 0.49134135246276855\n",
      "Epoch 93: Iteration 140 with loss 0.24470482766628265\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.0 minutes\n",
      "iter 20 of Expectation completed in a total of  6.7 minutes\n",
      "iter 30 of Expectation completed in a total of  9.8 minutes\n",
      "iter 40 of Expectation completed in a total of  13.0 minutes\n",
      "iter 50 of Expectation completed in a total of  16.1 minutes\n",
      "iter 60 of Expectation completed in a total of  18.8 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  78.05%, boundary mse  0.00\n",
      "Epoch 93 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.24116501636492\n",
      "Other scores:: Edit 65.16197065314637, F1@[10:25:50] [61.12234074 58.07169935 46.57970705]\n",
      "Starting Training\n",
      "Epoch 94: Iteration 20 with loss 0.41241341829299927\n",
      "Epoch 94: Iteration 40 with loss 0.34594327211380005\n",
      "Epoch 94: Iteration 60 with loss 0.6889572739601135\n",
      "Epoch 94: Iteration 80 with loss 1.1032330989837646\n",
      "Epoch 94: Iteration 100 with loss 0.7866092324256897\n",
      "Epoch 94: Iteration 120 with loss 0.30055153369903564\n",
      "Epoch 94: Iteration 140 with loss 0.38145074248313904\n",
      "Epoch 94 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.84001740067117\n",
      "Other scores:: Edit 65.71719197758121, F1@[10:25:50] [61.72972476 58.61877178 46.88638034]\n",
      "Starting Training\n",
      "Epoch 95: Iteration 20 with loss 0.4895474910736084\n",
      "Epoch 95: Iteration 40 with loss 0.3519245684146881\n",
      "Epoch 95: Iteration 60 with loss 0.37800419330596924\n",
      "Epoch 95: Iteration 80 with loss 0.5046043992042542\n",
      "Epoch 95: Iteration 100 with loss 0.33048465847969055\n",
      "Epoch 95: Iteration 120 with loss 0.26716458797454834\n",
      "Epoch 95: Iteration 140 with loss 0.45974934101104736\n",
      "Epoch 95 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.22013920536935\n",
      "Other scores:: Edit 66.37186473653252, F1@[10:25:50] [62.26515368 59.12478757 46.7928574 ]\n",
      "Starting Training\n",
      "Epoch 96: Iteration 20 with loss 0.8453496694564819\n",
      "Epoch 96: Iteration 40 with loss 0.3369276523590088\n",
      "Epoch 96: Iteration 60 with loss 0.33477461338043213\n",
      "Epoch 96: Iteration 80 with loss 0.7004529237747192\n",
      "Epoch 96: Iteration 100 with loss 0.2200549989938736\n",
      "Epoch 96: Iteration 120 with loss 0.3819054663181305\n",
      "Epoch 96: Iteration 140 with loss 0.6108208894729614\n",
      "Epoch 96 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.935410365828396\n",
      "Other scores:: Edit 66.16130704817485, F1@[10:25:50] [61.85080595 58.99645418 46.84226893]\n",
      "Starting Training\n",
      "Epoch 97: Iteration 20 with loss 0.3294392228126526\n",
      "Epoch 97: Iteration 40 with loss 0.3218283951282501\n",
      "Epoch 97: Iteration 60 with loss 0.2771151065826416\n",
      "Epoch 97: Iteration 80 with loss 0.22703324258327484\n",
      "Epoch 97: Iteration 100 with loss 0.26257088780403137\n",
      "Epoch 97: Iteration 120 with loss 0.35692209005355835\n",
      "Epoch 97: Iteration 140 with loss 0.3060019910335541\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.3 minutes\n",
      "iter 20 of Expectation completed in a total of  6.5 minutes\n",
      "iter 30 of Expectation completed in a total of  9.9 minutes\n",
      "iter 40 of Expectation completed in a total of  12.4 minutes\n",
      "iter 50 of Expectation completed in a total of  15.5 minutes\n",
      "iter 60 of Expectation completed in a total of  18.9 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-22286:\n",
      "Process ForkPoolWorker-22287:\n",
      "Process ForkPoolWorker-22293:\n",
      "Process ForkPoolWorker-22288:\n",
      "Process ForkPoolWorker-22297:\n",
      "Process ForkPoolWorker-22283:\n",
      "Process ForkPoolWorker-22299:\n",
      "Process ForkPoolWorker-22298:\n",
      "Process ForkPoolWorker-22282:\n",
      "Process ForkPoolWorker-22284:\n",
      "Process ForkPoolWorker-22295:\n",
      "Process ForkPoolWorker-22292:\n",
      "Process ForkPoolWorker-22290:\n",
      "Process ForkPoolWorker-22294:\n",
      "Process ForkPoolWorker-22296:\n",
      "Process ForkPoolWorker-22291:\n",
      "Process ForkPoolWorker-22285:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-22300:\n",
      "Process ForkPoolWorker-22289:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-22281:\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-8ffe18a7b6ba>\", line 42, in <module>\n",
      "    perform_expectation(model, trainloder_expectation)\n",
      "  File \"<ipython-input-15-e151fbc59213>\", line 66, in perform_expectation\n",
      "    calculate_element_probb(prob, item_1, item_4, item_2)\n",
      "  File \"<ipython-input-15-e151fbc59213>\", line 42, in calculate_element_probb\n",
      "    pool.join()  # postpones the execution of next line of code until all processes in the queue are done.\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 556, in join\n",
      "    self._worker_handler.join()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/threading.py\", line 1032, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "initialize_epoch = 30\n",
    "expectation_cal_gap = 4\n",
    "best_val_acc = 0\n",
    "for epoch in range(30, 150):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)  # features\n",
    "        item_1 = item[1].to(device)  # count\n",
    "        item_2 = item[2].to(device)  # target\n",
    "        weights = item[5].to(device)  # posterior weight\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        boundary_target_tensor = get_single_random(item[4], item_2.shape[1], item_2.device)\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, boundary_target_tensor)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                            max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                total_count = torch.sum(src_mask)\n",
    "                weighted_loss_sum = -torch.sum(torch.sum(torch.log(prob + 1e-8) * weights, dim=-1) * src_mask)\n",
    "                loss += weighted_loss_sum/total_count\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1)%20 == 0:\n",
    "            print(f'Epoch {epoch+1}: Iteration {i+1} with loss {loss.item()}')\n",
    "\n",
    "    if (epoch >= initialize_epoch) and ((epoch % (3 * expectation_cal_gap)) == 0):\n",
    "        torch.save(model.state_dict(), config.output_dir + f\"ms-tcn-initial-{epoch}-epochs.wt\")\n",
    "\n",
    "    if epoch >= initialize_epoch and (epoch % expectation_cal_gap == 0):\n",
    "        perform_expectation(model, trainloder_expectation)\n",
    "    \n",
    "    print(f'Epoch {epoch+1} finished, starting validation')\n",
    "    val_acc, best_val_acc = validate(model, testloader, best_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 105, Probability Accuracy 61.02425300046298\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 66, Probability Accuracy 63.79697145461325\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {best_val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-emmax-best-model.wt\"))\n",
    "# model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-initial-15-epochs.wt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
