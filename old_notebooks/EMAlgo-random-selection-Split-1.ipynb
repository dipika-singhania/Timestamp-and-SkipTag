{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utility.adaptive_data_loader import BreakfastWithWeights, collate_fn_override_wtd\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 1, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select4/split1/', 'project_name': 'breakfast-split-1', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split1.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split1.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split1_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=1,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select4/\",\n",
    "    project_name=\"breakfast-split-1\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "config.output_dir = config.output_dir + f\"split{config.split}\"\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "config.output_dir = config.output_dir + \"/\"\n",
    "if not os.path.exists(os.path.join(config.output_dir, \"posterior_weights\")):\n",
    "    os.mkdir(os.path.join(config.output_dir, \"posterior_weights\"))\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1460\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 252\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = BreakfastWithWeights(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override_wtd(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "\n",
    "trainloder_expectation = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=20,\n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override_wtd(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_frames_dict = pickle.load(open(\"data/breakfast_len_assum_annotations.pkl\", 'rb'))\n",
    "# loaded_vidid_selected_frames\n",
    "boundary_frames_dict = pickle.load(open(\"data/breakfast_boundary_annotations.pkl\", \"rb\"))\n",
    "num_boundary = 0\n",
    "for key in boundary_frames_dict.keys():\n",
    "    num_boundary += len(boundary_frames_dict[key])\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frames_dict = pickle.load(open(\"data/breakfast_random4frame_selection.pkl\", \"rb\"))\n",
    "# print(selected_frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"data/breakfast_meanvar_actions.pkl\", \"rb\"))\n",
    "mat_poisson = pickle.load(open(\"data/breakfast_possion_class_dict.pkl\", \"rb\"))\n",
    "\n",
    "def get_possion_prob(minlen, maxlen, cur_class):\n",
    "    prob = mat_poisson[label_id_to_label_name[cur_class]][minlen:maxlen]\n",
    "    return torch.tensor(prob)\n",
    "\n",
    "def get_poisson_logcdf(minlen, cur_class):\n",
    "    return np.log(np.sum(np.exp(mat_poisson[label_id_to_label_name[cur_class]][minlen:])) + 1e-20)\n",
    "\n",
    "def get_possion_prob_for_all_class(minlen, maxlen):\n",
    "    ele_list = []\n",
    "    for i in range(config.num_class):\n",
    "        prob = mat_poisson[label_id_to_label_name[i]][minlen:maxlen]\n",
    "        ele_list.append(torch.tensor(prob))\n",
    "    return torch.stack(ele_list, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, best_val_acc=None):\n",
    "    model.eval()\n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if best_val_acc is not None and val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-last-model.wt\")\n",
    "    print(f\"Validation:: Probability Accuracy {val_acc}\")\n",
    "    _ = model.train()\n",
    "    return val_acc, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels, first_ele_flag, last_ele_flag, vidid, gt_labels):\n",
    "    prob_each_segment = []\n",
    "    LOW_VAL = -10000000\n",
    "    num_frames = len(cur_vid_feat)\n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    prev_boundary = 0\n",
    "    per_frame_weights = torch.zeros((num_frames, config.num_class))\n",
    "    start_time = time()\n",
    "    boundary_error = 0\n",
    "    current_boundary = 0\n",
    "    labels = [config.num_class-1] + labels if selected_frames[0] != 0 else labels\n",
    "    labels = labels + [config.num_class-1] if selected_frames[-1] != num_frames-1 else labels\n",
    "    selected_frames = [0] + selected_frames if selected_frames[0] != 0 else selected_frames\n",
    "    selected_frames = selected_frames + [num_frames-1] if selected_frames[-1] != num_frames-1 else selected_frames\n",
    "\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[i]\n",
    "        label_next_ele = labels[i + 1]\n",
    "        if cur_ele == next_ele-1:\n",
    "            per_frame_weights[cur_ele, label_cur_ele] = 1.0\n",
    "            if label_cur_ele != label_next_ele:\n",
    "                prev_boundary = cur_ele\n",
    "            continue\n",
    "        \n",
    "        seg_len = next_ele - cur_ele\n",
    "        mat_b1_b2_c_prob = LOW_VAL * torch.ones((seg_len, seg_len, config.num_class), dtype=cumsum_feat.dtype)\n",
    "        b1_prior = get_possion_prob(cur_ele-prev_boundary, next_ele-prev_boundary, label_cur_ele)\n",
    "        \n",
    "        # find dummy label where we will keep the diagonal (b1=b2) probabilities, later we will distribute among\n",
    "        # rest of the classes after the softmax by dividing by (num_class - 2)\n",
    "        dummy_label = 0\n",
    "        while True:\n",
    "            if dummy_label != label_cur_ele and dummy_label != label_next_ele:\n",
    "                break\n",
    "            else:\n",
    "                dummy_label += 1\n",
    "        \n",
    "        for b1 in range(cur_ele, next_ele - 1):\n",
    "\n",
    "            cur_boundary_len = b1 - prev_boundary\n",
    "            strt_index = cumsum_feat[cur_ele - 1, label_cur_ele] if cur_ele > 0 else 0\n",
    "            left_sum = (cumsum_feat[b1, label_cur_ele] - strt_index)\n",
    "            right_sum = cumsum_feat[next_ele-1, label_next_ele] - cumsum_feat[b1+1:next_ele, label_next_ele] # mid_seg_len\n",
    "            mid_sum = (cumsum_feat[b1+1:next_ele, :] - cumsum_feat[b1, :])  # mid_seg_len\n",
    "            b2_prior = get_possion_prob_for_all_class(1, next_ele-b1)  # mid_seg_len x num_class\n",
    "            \n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1+1-cur_ele:next_ele-cur_ele] = (left_sum + right_sum[:,None] + mid_sum) \\\n",
    "                                                                            + b1_prior[b1-cur_ele] + b2_prior\n",
    "            # when mid segment is absent but right and left is not the same\n",
    "            # we assign the probability to a dummy label for now and then later \n",
    "            # re-distribute among other classes after the softmax\n",
    "            if label_cur_ele != label_next_ele:\n",
    "                rightsum_wo_midseg = cumsum_feat[next_ele-1, label_next_ele] - cumsum_feat[b1, label_next_ele]\n",
    "                mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = left_sum + rightsum_wo_midseg + b1_prior[b1-cur_ele]\n",
    "        \n",
    "#         if vidid=='P39_cam02_P39_scrambledegg' and cur_ele==574:\n",
    "#             import pdb\n",
    "#             pdb.set_trace()\n",
    "        # when mid segment is absent b1 can also be next_ele-1\n",
    "        b1 = next_ele - 1\n",
    "        if label_cur_ele != label_next_ele:\n",
    "            left_sum = (cumsum_feat[b1, label_cur_ele] - strt_index)\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = left_sum + b1_prior[b1-cur_ele]\n",
    "        else:\n",
    "            # returns prob that the left class length >= seg len\n",
    "            b1_prior_ = get_poisson_logcdf(next_ele - prev_boundary, label_cur_ele) \n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = left_sum + b1_prior_\n",
    "        \n",
    "        mat_b1_b2_c_prob[:, :, label_cur_ele] = LOW_VAL\n",
    "        mat_b1_b2_c_prob[:, :, label_next_ele] = LOW_VAL\n",
    "        mat_b1_b2_c_prob = torch.softmax(mat_b1_b2_c_prob.flatten(), dim=0).reshape((seg_len, seg_len, config.num_class))\n",
    "        \n",
    "        # re-distribute the dummy class probability among the left-over classes\n",
    "        left_over_classes = config.num_class - 2 + (label_cur_ele==label_next_ele)\n",
    "        for b1 in range(cur_ele, next_ele):\n",
    "            assigned_prob = mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label]\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, :] = assigned_prob/left_over_classes\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, label_cur_ele] = 0\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, label_next_ele] = 0\n",
    "        \n",
    "        marginal_b1 = torch.sum(mat_b1_b2_c_prob, axis=(1,2))\n",
    "        mean_b1 = round(torch.sum(marginal_b1.squeeze() * torch.arange(cur_ele, next_ele, 1)).item())\n",
    "        cumm_b1_prob = torch.cumsum(marginal_b1, dim=0)\n",
    "        cumm_b1_c_prob = torch.cumsum(torch.sum(mat_b1_b2_c_prob, dim=1), dim=0)\n",
    "        cumm_b2_c_prob = torch.cumsum(torch.sum(mat_b1_b2_c_prob, dim=0), dim=0)\n",
    "\n",
    "        per_frame_weights[cur_ele, label_cur_ele] = 1.0\n",
    "        per_frame_weights[cur_ele+1:next_ele, :] = cumm_b1_c_prob[:-1] - cumm_b2_c_prob[:-1]\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_cur_ele] = 1 - cumm_b1_prob[:-1]\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_next_ele] = 0\n",
    "        remaining_probability = 1 - torch.sum(per_frame_weights[cur_ele+1:next_ele, :], dim=-1)\n",
    "        # we use \"+=\" in the next line because left and right label might be the same\n",
    "        # in that case using \"=\" would just overwrite the previous probability\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_next_ele] += remaining_probability\n",
    "        \n",
    "        expected_boundary = round(torch.sum(torch.sum(mat_b1_b2_c_prob, axis=(0,2)).squeeze() * \\\n",
    "                            torch.arange(cur_ele, next_ele, 1)).item())\n",
    "        if not (label_cur_ele == label_next_ele and expected_boundary >= next_ele-2):\n",
    "            prev_boundary = expected_boundary\n",
    "        if expected_boundary == 0 and i > 0:\n",
    "            print(f'Estimated boundary has become zero! for {vidid} and cur_ele, next_ele {cur_ele, next_ele}')\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        # boundary_error += (boundary_frames_dict[vidid + '.txt'][current_boundary] - mean_b1)**2\n",
    "        # boundary_error += (boundary_frames_dict[vidid + '.txt'][current_boundary+1] - prev_boundary)**2\n",
    "        # current_boundary += 2\n",
    "        # prob_each_segment.append(mat_b1_b2_c_prob)\n",
    "        \n",
    "    posterior_prediction = torch.argmax(per_frame_weights, dim=1)\n",
    "    correct = torch.sum(posterior_prediction == gt_labels[:num_frames]).item()\n",
    "    \n",
    "    return (vidid, per_frame_weights, [correct, num_frames, boundary_error]) #, prob_each_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_acc_correct, posterior_acc_total = 0, 0\n",
    "posterior_boundary_total_mse = 0\n",
    "results = []\n",
    "\n",
    "# Step 2: Define callback function to collect the output in `results`\n",
    "def collect_result(result):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    fname = os.path.join(config.output_dir, 'posterior_weights', result[0] + '.wt')\n",
    "    torch.save(result[1], fname)\n",
    "    correct, total, boundary_err = result[2]\n",
    "    posterior_acc_correct += correct\n",
    "    posterior_acc_total += total\n",
    "    posterior_boundary_total_mse += boundary_err\n",
    "    # print(f'Dumped in file {fname} at time {time()}')\n",
    "    return\n",
    "\n",
    "def calculate_element_probb(data_feat, data_count, video_ids, gt_labels): # loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    pool = mp.Pool(20)\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "#         if cur_vidid!='P39_cam02_P39_scrambledegg':\n",
    "#             continue\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num][:cur_vid_count].detach().cpu()\n",
    "        cur_gt_labels = gt_labels[iter_num].detach().cpu()\n",
    "        \n",
    "        cur_video_select_frames = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices_and_labels = cur_video_select_frames\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "        with torch.no_grad():\n",
    "            # Multi-processing\n",
    "            pool.apply_async(prob_vals_per_segment,\n",
    "                             args=(selected_frames_indices, cur_vid_feat, selected_frames_labels,\n",
    "                                   cur_video_select_frames[1], cur_video_select_frames[2], cur_vidid, cur_gt_labels),\n",
    "                             callback=collect_result)\n",
    "#             results.append(prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels,\n",
    "#                                    cur_video_select_frames[1], cur_video_select_frames[2], cur_vidid, cur_gt_labels))\n",
    "    # Step 4: Close Pool and let all the processes complete\n",
    "    pool.close()\n",
    "    pool.join()  # postpones the execution of next line of code until all processes in the queue are done.\n",
    "    return results\n",
    "\n",
    "def perform_expectation(model, dataloader):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse = 0, 0, 0\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    curtime = time()\n",
    "    print(f'Calculating expectation')\n",
    "\n",
    "    for i, item in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device) # features\n",
    "            item_1 = item[1].to(device) # count\n",
    "            item_2 = item[2].to(device) # gt frame-wise labels\n",
    "            item_4 = item[4] # video-ids\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            prob = torch.softmax(predictions[-1], dim=1)\n",
    "            prob = prob.permute(0, 2, 1)\n",
    "            \n",
    "            calculate_element_probb(prob, item_1, item_4, item_2)\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(f\"iter {i+1} of Expectation completed in a total of {(time() - curtime)/60.: .1f} minutes\")\n",
    "    _ = model.train()\n",
    "    print(f'Expectation step finished, '\n",
    "          f'posterior frame-wise accuracy {100*posterior_acc_correct/posterior_acc_total: .2f}%, '\n",
    "          f'boundary mse {(posterior_boundary_total_mse/num_boundary)**0.5: .2f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 55.835123916252165\n"
     ]
    }
   ],
   "source": [
    "loaded_file=torch.load(os.path.join(config.output_dir, \"ms-tcn-initial-30-epochs.wt\"))\n",
    "model.load_state_dict(loaded_file)\n",
    "# loaded_file=torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcnnew-full-supervised-split1/ms-tcn-best-model.wt')\n",
    "# model.load_state_dict(loaded_file)\n",
    "_ = validate(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = next(iter(trainloader))\n",
    "    \n",
    "# with torch.no_grad():\n",
    "#     item_0 = item[0].to(device) # features\n",
    "#     item_1 = item[1].to(device) # count\n",
    "#     item_2 = item[2].to(device) # gt frame-wise labels\n",
    "#     item_4 = item[4] # video-ids\n",
    "#     src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "#     src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "#     middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "#     prob = torch.softmax(predictions[-1], dim=1)\n",
    "#     prob = prob.permute(0, 2, 1)\n",
    "\n",
    "#     res = calculate_element_probb(prob, item_1, item_4, item_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 2\n",
    "# vidid = res[idx][0]\n",
    "# mat = res[idx][1]\n",
    "# mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace(0, 5281, 4 + 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundary_frames_dict[f'{vidid}.txt'], selected_frames_dict[f'{vidid}.txt'], weakly_labels[f'{vidid}.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20, 5))\n",
    "# for i in range(48):\n",
    "#     plt.plot(mat[:,i])\n",
    "    \n",
    "# for bd in boundary_frames_dict[f'{vidid}.txt']:\n",
    "#     plt.plot([bd, bd], [0, 2])\n",
    "    \n",
    "# for bd in selected_frames_dict[f'{vidid}.txt']:\n",
    "#     plt.plot([bd[0], bd[0]], [0, 2], '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculating Expectation Step\n",
    "# perform_expectation(model, trainloder_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_random(video_ids, len_frames, device):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((len(video_ids), len_frames), dtype=torch.long, device=device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "\n",
    "        frame_idx_tensor = torch.from_numpy(np.array(selected_frames_indices))\n",
    "        frame_labels = torch.from_numpy(np.array(selected_frames_labels)).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = frame_labels\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labels = pickle.load(open(\"data/breakfast_weaklysupervised_labels.pkl\", \"rb\"))\n",
    "prior_probs = pickle.load(open('data/breakfast_lengthmodel_multinomial_prior.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Epoch 31: Iteration 20 with loss 1.2421857118606567\n",
      "Epoch 31: Iteration 40 with loss 1.193537712097168\n",
      "Epoch 31: Iteration 60 with loss 0.6960170269012451\n",
      "Epoch 31: Iteration 80 with loss 1.0945032835006714\n",
      "Epoch 31: Iteration 100 with loss 0.7095000147819519\n",
      "Epoch 31: Iteration 120 with loss 0.6708444952964783\n",
      "Epoch 31: Iteration 140 with loss 2.113300323486328\n",
      "Epoch 31: Iteration 160 with loss 1.212669849395752\n",
      "Epoch 31: Iteration 180 with loss 0.5667948126792908\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  6.8 minutes\n",
      "iter 20 of Expectation completed in a total of  13.7 minutes\n",
      "iter 30 of Expectation completed in a total of  18.8 minutes\n",
      "iter 40 of Expectation completed in a total of  24.1 minutes\n",
      "iter 50 of Expectation completed in a total of  31.1 minutes\n",
      "iter 60 of Expectation completed in a total of  34.3 minutes\n",
      "iter 70 of Expectation completed in a total of  38.0 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.17%, boundary mse  0.00\n",
      "Epoch 31 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 56.691833754763344\n",
      "Starting Training\n",
      "Epoch 32: Iteration 20 with loss 4.271744728088379\n",
      "Epoch 32: Iteration 40 with loss 1.8881276845932007\n",
      "Epoch 32: Iteration 60 with loss 3.328526496887207\n",
      "Epoch 32: Iteration 80 with loss 2.473923683166504\n",
      "Epoch 32: Iteration 100 with loss 3.052426815032959\n",
      "Epoch 32: Iteration 120 with loss 5.121852874755859\n",
      "Epoch 32: Iteration 140 with loss 2.2498438358306885\n",
      "Epoch 32: Iteration 160 with loss 2.4442782402038574\n",
      "Epoch 32: Iteration 180 with loss 1.2782737016677856\n",
      "Epoch 32 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.26077614349989\n",
      "Starting Training\n",
      "Epoch 33: Iteration 20 with loss 2.676449775695801\n",
      "Epoch 33: Iteration 40 with loss 2.535750150680542\n",
      "Epoch 33: Iteration 60 with loss 0.963762104511261\n",
      "Epoch 33: Iteration 80 with loss 1.5878382921218872\n",
      "Epoch 33: Iteration 100 with loss 3.2432289123535156\n",
      "Epoch 33: Iteration 120 with loss 2.32792592048645\n",
      "Epoch 33: Iteration 140 with loss 1.7797608375549316\n",
      "Epoch 33: Iteration 160 with loss 1.6164641380310059\n",
      "Epoch 33: Iteration 180 with loss 1.8232262134552002\n",
      "Epoch 33 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.406860010051005\n",
      "Starting Training\n",
      "Epoch 34: Iteration 20 with loss 4.844557762145996\n",
      "Epoch 34: Iteration 40 with loss 2.140885353088379\n",
      "Epoch 34: Iteration 60 with loss 1.4426848888397217\n",
      "Epoch 34: Iteration 80 with loss 1.5901557207107544\n",
      "Epoch 34: Iteration 100 with loss 4.552931308746338\n",
      "Epoch 34: Iteration 120 with loss 1.8198109865188599\n",
      "Epoch 34: Iteration 140 with loss 1.355088710784912\n",
      "Epoch 34: Iteration 160 with loss 1.6288188695907593\n",
      "Epoch 34: Iteration 180 with loss 1.3273375034332275\n",
      "Epoch 34 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 63.59062328113932\n",
      "Starting Training\n",
      "Epoch 35: Iteration 20 with loss 1.384353518486023\n",
      "Epoch 35: Iteration 40 with loss 2.373213291168213\n",
      "Epoch 35: Iteration 60 with loss 3.9748339653015137\n",
      "Epoch 35: Iteration 80 with loss 1.810727834701538\n",
      "Epoch 35: Iteration 100 with loss 2.579393148422241\n",
      "Epoch 35: Iteration 120 with loss 2.968019485473633\n",
      "Epoch 35: Iteration 140 with loss 2.0847015380859375\n",
      "Epoch 35: Iteration 160 with loss 1.2191840410232544\n",
      "Epoch 35: Iteration 180 with loss 1.9241180419921875\n",
      "Epoch 35 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.02889070914998\n",
      "Starting Training\n",
      "Epoch 36: Iteration 20 with loss 2.483595132827759\n",
      "Epoch 36: Iteration 40 with loss 2.9766907691955566\n",
      "Epoch 36: Iteration 60 with loss 2.4805798530578613\n",
      "Epoch 36: Iteration 80 with loss 2.131185293197632\n",
      "Epoch 36: Iteration 100 with loss 1.8313877582550049\n",
      "Epoch 36: Iteration 120 with loss 1.5821125507354736\n",
      "Epoch 36: Iteration 140 with loss 2.487384080886841\n",
      "Epoch 36: Iteration 160 with loss 1.7411361932754517\n",
      "Epoch 36: Iteration 180 with loss 1.7213293313980103\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  4.1 minutes\n",
      "iter 20 of Expectation completed in a total of  8.1 minutes\n",
      "iter 30 of Expectation completed in a total of  12.0 minutes\n",
      "iter 40 of Expectation completed in a total of  16.1 minutes\n",
      "iter 50 of Expectation completed in a total of  19.2 minutes\n",
      "iter 60 of Expectation completed in a total of  22.3 minutes\n",
      "iter 70 of Expectation completed in a total of  25.7 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  77.78%, boundary mse  0.00\n",
      "Epoch 36 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.838467656730415\n",
      "Starting Training\n",
      "Epoch 37: Iteration 20 with loss 0.8370974063873291\n",
      "Epoch 37: Iteration 40 with loss 0.8729639649391174\n",
      "Validation:: Probability Accuracy 63.48180332474645\n",
      "Starting Training\n",
      "Epoch 38: Iteration 20 with loss 0.6881101131439209\n",
      "Epoch 38: Iteration 40 with loss 1.0239152908325195\n",
      "Epoch 38: Iteration 60 with loss 0.8919458389282227\n",
      "Epoch 38: Iteration 80 with loss 1.3428704738616943\n",
      "Epoch 38: Iteration 100 with loss 0.9304941296577454\n",
      "Epoch 38: Iteration 120 with loss 1.2323577404022217\n",
      "Epoch 38: Iteration 140 with loss 1.5989806652069092\n",
      "Epoch 38: Iteration 160 with loss 1.3104512691497803\n",
      "Epoch 38: Iteration 180 with loss 1.0515711307525635\n",
      "Epoch 38 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.46942554934292\n",
      "Starting Training\n",
      "Epoch 39: Iteration 20 with loss 0.9670054912567139\n",
      "Epoch 39: Iteration 40 with loss 1.6197597980499268\n",
      "Epoch 39: Iteration 60 with loss 1.1849488019943237\n",
      "Epoch 39: Iteration 80 with loss 1.151381254196167\n",
      "Epoch 39: Iteration 100 with loss 1.1998056173324585\n",
      "Epoch 39: Iteration 120 with loss 1.1663070917129517\n",
      "Epoch 39: Iteration 140 with loss 0.9322479963302612\n",
      "Epoch 39: Iteration 160 with loss 1.2329137325286865\n",
      "Epoch 39: Iteration 180 with loss 0.7790216207504272\n",
      "Epoch 39 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.56241714844229\n",
      "Starting Training\n",
      "Epoch 40: Iteration 20 with loss 1.2529269456863403\n",
      "Epoch 40: Iteration 40 with loss 0.8487215042114258\n",
      "Epoch 40: Iteration 60 with loss 1.5872455835342407\n",
      "Epoch 40: Iteration 80 with loss 0.9926963448524475\n",
      "Epoch 40: Iteration 100 with loss 0.8909633159637451\n",
      "Epoch 40: Iteration 120 with loss 0.9494686722755432\n",
      "Epoch 40: Iteration 140 with loss 0.9744817614555359\n",
      "Epoch 40: Iteration 160 with loss 1.1381409168243408\n",
      "Epoch 40: Iteration 180 with loss 0.9574337005615234\n",
      "Epoch 40 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.00462188032971\n",
      "Starting Training\n",
      "Epoch 41: Iteration 20 with loss 0.4517194628715515\n",
      "Epoch 41: Iteration 40 with loss 0.9535969495773315\n",
      "Epoch 41: Iteration 60 with loss 1.0373119115829468\n",
      "Epoch 41: Iteration 80 with loss 1.1733005046844482\n",
      "Epoch 41: Iteration 100 with loss 1.4921963214874268\n",
      "Epoch 41: Iteration 120 with loss 0.7146793603897095\n",
      "Epoch 41: Iteration 140 with loss 1.0451040267944336\n",
      "Epoch 41: Iteration 160 with loss 1.1638820171356201\n",
      "Epoch 41: Iteration 180 with loss 1.2577993869781494\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  4.1 minutes\n",
      "iter 20 of Expectation completed in a total of  8.0 minutes\n",
      "iter 30 of Expectation completed in a total of  11.6 minutes\n",
      "iter 40 of Expectation completed in a total of  14.6 minutes\n",
      "iter 50 of Expectation completed in a total of  18.3 minutes\n",
      "iter 60 of Expectation completed in a total of  22.2 minutes\n",
      "iter 70 of Expectation completed in a total of  26.2 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  76.99%, boundary mse  0.00\n",
      "Epoch 41 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.772142882581285\n",
      "Starting Training\n",
      "Epoch 42: Iteration 20 with loss 1.3107839822769165\n",
      "Epoch 42: Iteration 40 with loss 0.914339005947113\n",
      "Epoch 42: Iteration 60 with loss 0.5766425728797913\n",
      "Epoch 42: Iteration 80 with loss 0.8279110193252563\n",
      "Epoch 42: Iteration 100 with loss 0.8174561858177185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Iteration 120 with loss 1.8190981149673462\n",
      "Epoch 42: Iteration 140 with loss 1.5592681169509888\n",
      "Epoch 42: Iteration 160 with loss 1.3646129369735718\n",
      "Epoch 42: Iteration 180 with loss 0.9108996391296387\n",
      "Epoch 42 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.21456525438149\n",
      "Starting Training\n",
      "Epoch 43: Iteration 20 with loss 1.6122702360153198\n",
      "Epoch 43: Iteration 40 with loss 1.283385992050171\n",
      "Epoch 43: Iteration 60 with loss 2.1941707134246826\n",
      "Epoch 43: Iteration 80 with loss 1.3589376211166382\n",
      "Epoch 43: Iteration 100 with loss 1.0183168649673462\n",
      "Epoch 43: Iteration 120 with loss 1.3828750848770142\n",
      "Epoch 43: Iteration 140 with loss 2.1910760402679443\n",
      "Epoch 43: Iteration 160 with loss 0.6894497275352478\n",
      "Epoch 43: Iteration 180 with loss 0.6364771723747253\n",
      "Epoch 43 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.613550656678974\n",
      "Starting Training\n",
      "Epoch 44: Iteration 20 with loss 0.6851882934570312\n",
      "Epoch 44: Iteration 40 with loss 0.6839818358421326\n",
      "Epoch 44: Iteration 60 with loss 0.4988902807235718\n",
      "Epoch 44: Iteration 80 with loss 0.8931723833084106\n",
      "Epoch 44: Iteration 100 with loss 0.723241925239563\n",
      "Epoch 44: Iteration 120 with loss 4.149567604064941\n",
      "Epoch 44: Iteration 140 with loss 0.9233999252319336\n",
      "Epoch 44: Iteration 160 with loss 0.6135876178741455\n",
      "Epoch 44: Iteration 180 with loss 0.8282483220100403\n",
      "Epoch 44 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.25059850976016\n",
      "Starting Training\n",
      "Epoch 45: Iteration 20 with loss 1.1619834899902344\n",
      "Epoch 45: Iteration 40 with loss 0.6527969241142273\n",
      "Epoch 45: Iteration 60 with loss 2.3537373542785645\n",
      "Epoch 45: Iteration 80 with loss 0.8033056855201721\n",
      "Epoch 45: Iteration 100 with loss 1.0127651691436768\n",
      "Epoch 45: Iteration 120 with loss 2.5495927333831787\n",
      "Epoch 45: Iteration 140 with loss 0.575915515422821\n",
      "Epoch 45: Iteration 160 with loss 1.0140116214752197\n",
      "Epoch 45: Iteration 180 with loss 0.8893660306930542\n",
      "Epoch 45 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.76090870599222\n",
      "Starting Training\n",
      "Epoch 46: Iteration 20 with loss 0.9228450655937195\n",
      "Epoch 46: Iteration 40 with loss 4.026547431945801\n",
      "Epoch 46: Iteration 60 with loss 1.2553341388702393\n",
      "Epoch 46: Iteration 80 with loss 0.7962309122085571\n",
      "Epoch 46: Iteration 100 with loss 1.0664265155792236\n",
      "Epoch 46: Iteration 120 with loss 3.3030056953430176\n",
      "Epoch 46: Iteration 140 with loss 1.0530723333358765\n",
      "Epoch 46: Iteration 160 with loss 0.8135628700256348\n",
      "Epoch 46: Iteration 180 with loss 0.8805476427078247\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  4.0 minutes\n",
      "iter 20 of Expectation completed in a total of  8.0 minutes\n",
      "iter 30 of Expectation completed in a total of  11.4 minutes\n",
      "iter 40 of Expectation completed in a total of  14.7 minutes\n",
      "iter 50 of Expectation completed in a total of  18.6 minutes\n",
      "iter 60 of Expectation completed in a total of  22.5 minutes\n",
      "iter 70 of Expectation completed in a total of  26.7 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  76.92%, boundary mse  0.00\n",
      "Epoch 46 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.821606499123504\n",
      "Starting Training\n",
      "Epoch 47: Iteration 20 with loss 0.6684931516647339\n",
      "Epoch 47: Iteration 40 with loss 1.2288333177566528\n",
      "Epoch 47: Iteration 60 with loss 6.396254062652588\n",
      "Epoch 47: Iteration 80 with loss 3.4928910732269287\n",
      "Epoch 47: Iteration 100 with loss 1.1640881299972534\n",
      "Epoch 47: Iteration 120 with loss 1.2285583019256592\n",
      "Epoch 47: Iteration 140 with loss 1.1905783414840698\n",
      "Epoch 47: Iteration 160 with loss 0.5702733993530273\n",
      "Epoch 47: Iteration 180 with loss 0.9043039083480835\n",
      "Epoch 47 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.37197035348679\n",
      "Starting Training\n",
      "Epoch 48: Iteration 20 with loss 0.6160733699798584\n",
      "Epoch 48: Iteration 40 with loss 0.9597960114479065\n",
      "Epoch 48: Iteration 60 with loss 0.8911241292953491\n",
      "Epoch 48: Iteration 80 with loss 1.98468816280365\n",
      "Epoch 48: Iteration 100 with loss 1.1381860971450806\n",
      "Epoch 48: Iteration 120 with loss 1.0667238235473633\n",
      "Epoch 48: Iteration 140 with loss 1.5662343502044678\n",
      "Epoch 48: Iteration 160 with loss 0.838031530380249\n",
      "Epoch 48: Iteration 180 with loss 1.3184688091278076\n",
      "Epoch 48 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.88491992829754\n",
      "Starting Training\n",
      "Epoch 49: Iteration 20 with loss 0.4970019459724426\n",
      "Epoch 49: Iteration 40 with loss 0.8275209665298462\n",
      "Epoch 49: Iteration 60 with loss 0.647920548915863\n",
      "Epoch 49: Iteration 80 with loss 0.8206266164779663\n",
      "Epoch 49: Iteration 100 with loss 0.4990958273410797\n",
      "Epoch 49: Iteration 120 with loss 1.5109515190124512\n",
      "Epoch 49: Iteration 140 with loss 0.8324620723724365\n",
      "Epoch 49: Iteration 160 with loss 0.8768680095672607\n",
      "Epoch 49: Iteration 180 with loss 1.9468655586242676\n",
      "Epoch 49 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.02983645349826\n",
      "Starting Training\n",
      "Epoch 50: Iteration 20 with loss 0.5217430591583252\n",
      "Epoch 50: Iteration 40 with loss 0.5254329442977905\n",
      "Epoch 50: Iteration 60 with loss 0.5441291332244873\n",
      "Epoch 50: Iteration 80 with loss 0.7885727286338806\n",
      "Epoch 50: Iteration 100 with loss 0.42774277925491333\n",
      "Epoch 50: Iteration 120 with loss 0.6334847807884216\n",
      "Epoch 50: Iteration 140 with loss 0.5907528400421143\n",
      "Epoch 50: Iteration 160 with loss 0.4047252833843231\n",
      "Epoch 50: Iteration 180 with loss 0.8674601316452026\n",
      "Epoch 50 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.86830015313936\n",
      "Starting Training\n",
      "Epoch 51: Iteration 20 with loss 0.7111923694610596\n",
      "Epoch 51: Iteration 40 with loss 0.6462697982788086\n",
      "Epoch 51: Iteration 60 with loss 1.2043102979660034\n",
      "Epoch 51: Iteration 80 with loss 0.5535525679588318\n",
      "Epoch 51: Iteration 100 with loss 0.6657440662384033\n",
      "Epoch 51: Iteration 120 with loss 0.4384545385837555\n",
      "Epoch 51: Iteration 140 with loss 0.4338815212249756\n",
      "Epoch 51: Iteration 160 with loss 0.47152799367904663\n",
      "Epoch 51: Iteration 180 with loss 0.5771915316581726\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.4 minutes\n",
      "iter 20 of Expectation completed in a total of  7.4 minutes\n",
      "iter 30 of Expectation completed in a total of  10.8 minutes\n",
      "iter 40 of Expectation completed in a total of  14.9 minutes\n",
      "iter 50 of Expectation completed in a total of  19.1 minutes\n",
      "iter 60 of Expectation completed in a total of  22.2 minutes\n",
      "iter 70 of Expectation completed in a total of  25.8 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  76.58%, boundary mse  0.00\n",
      "Epoch 51 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.568946345825864\n",
      "Starting Training\n",
      "Epoch 52: Iteration 20 with loss 0.44113847613334656\n",
      "Epoch 52: Iteration 40 with loss 0.7468592524528503\n",
      "Epoch 52: Iteration 60 with loss 0.4455019533634186\n",
      "Epoch 52: Iteration 80 with loss 0.6266238689422607\n",
      "Epoch 52: Iteration 100 with loss 0.7466531991958618\n",
      "Epoch 52: Iteration 120 with loss 0.6144755482673645\n",
      "Epoch 52: Iteration 140 with loss 0.4536803364753723\n",
      "Epoch 52: Iteration 160 with loss 0.6250961422920227\n",
      "Epoch 52: Iteration 180 with loss 0.9389309883117676\n",
      "Epoch 52 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.156859020778676\n",
      "Starting Training\n",
      "Epoch 53: Iteration 20 with loss 0.4628126919269562\n",
      "Epoch 53: Iteration 40 with loss 0.32179945707321167\n",
      "Epoch 53: Iteration 60 with loss 0.5607276558876038\n",
      "Epoch 53: Iteration 80 with loss 0.40908777713775635\n",
      "Epoch 53: Iteration 100 with loss 0.6532255411148071\n",
      "Epoch 53: Iteration 120 with loss 1.0176796913146973\n",
      "Epoch 53: Iteration 140 with loss 1.4259215593338013\n",
      "Epoch 53: Iteration 160 with loss 2.0019311904907227\n",
      "Epoch 53: Iteration 180 with loss 1.1985818147659302\n",
      "Epoch 53 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.46357697132297\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Iteration 20 with loss 0.9988481998443604\n",
      "Epoch 54: Iteration 40 with loss 0.41554734110832214\n",
      "Epoch 54: Iteration 60 with loss 0.5077337026596069\n",
      "Epoch 54: Iteration 80 with loss 1.5505235195159912\n",
      "Epoch 54: Iteration 100 with loss 1.484798550605774\n",
      "Epoch 54: Iteration 120 with loss 1.523590326309204\n",
      "Epoch 54: Iteration 140 with loss 1.6119850873947144\n",
      "Epoch 54: Iteration 160 with loss 0.7083007097244263\n",
      "Epoch 54: Iteration 180 with loss 1.0229507684707642\n",
      "Epoch 54 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.51482127806071\n",
      "Starting Training\n",
      "Epoch 55: Iteration 20 with loss 2.3743484020233154\n",
      "Epoch 55: Iteration 40 with loss 0.5011219382286072\n",
      "Epoch 55: Iteration 60 with loss 1.2677690982818604\n",
      "Epoch 55: Iteration 80 with loss 0.40027517080307007\n",
      "Epoch 55: Iteration 100 with loss 0.4590405821800232\n",
      "Epoch 55: Iteration 120 with loss 0.9679972529411316\n",
      "Epoch 55: Iteration 140 with loss 0.7717399001121521\n",
      "Epoch 55: Iteration 160 with loss 0.6388688683509827\n",
      "Epoch 55: Iteration 180 with loss 0.6475412249565125\n",
      "Epoch 55 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 50.98768949511497\n",
      "Starting Training\n",
      "Epoch 56: Iteration 20 with loss 1.1080610752105713\n",
      "Epoch 56: Iteration 40 with loss 0.47512316703796387\n",
      "Epoch 56: Iteration 60 with loss 0.8042462468147278\n",
      "Epoch 56: Iteration 80 with loss 0.5597962141036987\n",
      "Epoch 56: Iteration 100 with loss 1.6494169235229492\n",
      "Epoch 56: Iteration 120 with loss 0.7953364849090576\n",
      "Epoch 56: Iteration 140 with loss 0.6983609199523926\n",
      "Epoch 56: Iteration 160 with loss 0.9241713881492615\n",
      "Epoch 56: Iteration 180 with loss 0.48025357723236084\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.5 minutes\n",
      "iter 20 of Expectation completed in a total of  7.3 minutes\n",
      "iter 30 of Expectation completed in a total of  11.8 minutes\n",
      "iter 40 of Expectation completed in a total of  14.9 minutes\n",
      "iter 50 of Expectation completed in a total of  18.6 minutes\n",
      "iter 60 of Expectation completed in a total of  22.5 minutes\n",
      "iter 70 of Expectation completed in a total of  26.5 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  76.64%, boundary mse  0.00\n",
      "Epoch 56 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.125598015124\n",
      "Starting Training\n",
      "Epoch 57: Iteration 20 with loss 0.37682652473449707\n",
      "Epoch 57: Iteration 40 with loss 0.625244140625\n",
      "Epoch 57: Iteration 60 with loss 0.7441921234130859\n",
      "Epoch 57: Iteration 80 with loss 0.8383644819259644\n",
      "Epoch 57: Iteration 100 with loss 4.728555679321289\n",
      "Epoch 57: Iteration 120 with loss 1.1184179782867432\n",
      "Epoch 57: Iteration 140 with loss 0.7753407955169678\n",
      "Epoch 57: Iteration 160 with loss 0.7784674167633057\n",
      "Epoch 57: Iteration 180 with loss 2.155621290206909\n",
      "Epoch 57 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.06125178563656\n",
      "Starting Training\n",
      "Epoch 58: Iteration 20 with loss 1.4547487497329712\n",
      "Epoch 58: Iteration 40 with loss 0.8069683909416199\n",
      "Epoch 58: Iteration 60 with loss 0.6190987825393677\n",
      "Epoch 58: Iteration 80 with loss 0.8049765825271606\n",
      "Epoch 58: Iteration 100 with loss 0.8244355916976929\n",
      "Epoch 58: Iteration 120 with loss 2.5348997116088867\n",
      "Epoch 58: Iteration 140 with loss 0.7756691575050354\n",
      "Epoch 58: Iteration 160 with loss 0.5671553015708923\n",
      "Epoch 58: Iteration 180 with loss 0.5010988116264343\n",
      "Epoch 58 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 63.82567438694794\n",
      "Starting Training\n",
      "Epoch 59: Iteration 20 with loss 0.5533028244972229\n",
      "Epoch 59: Iteration 40 with loss 0.5873054265975952\n",
      "Epoch 59: Iteration 60 with loss 0.9835872650146484\n",
      "Epoch 59: Iteration 80 with loss 0.9289120435714722\n",
      "Epoch 59: Iteration 100 with loss 0.4218705892562866\n",
      "Epoch 59: Iteration 120 with loss 0.3905509114265442\n",
      "Epoch 59: Iteration 140 with loss 0.47737419605255127\n",
      "Epoch 59: Iteration 160 with loss 0.7736514806747437\n",
      "Epoch 59: Iteration 180 with loss 0.9016553163528442\n",
      "Epoch 59 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 56.49556212432383\n",
      "Starting Training\n",
      "Epoch 60: Iteration 20 with loss 0.5706325769424438\n",
      "Epoch 60: Iteration 40 with loss 0.5358771681785583\n",
      "Epoch 60: Iteration 60 with loss 0.4789038896560669\n",
      "Epoch 60: Iteration 80 with loss 0.6062580347061157\n",
      "Epoch 60: Iteration 100 with loss 0.5998514890670776\n",
      "Epoch 60: Iteration 120 with loss 0.563727617263794\n",
      "Epoch 60: Iteration 140 with loss 0.4918396770954132\n",
      "Epoch 60: Iteration 160 with loss 0.456831693649292\n",
      "Epoch 60: Iteration 180 with loss 0.5180416107177734\n",
      "Epoch 60 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.976328691667554\n",
      "Starting Training\n",
      "Epoch 61: Iteration 20 with loss 0.43832725286483765\n",
      "Epoch 61: Iteration 40 with loss 1.120642900466919\n",
      "Epoch 61: Iteration 60 with loss 0.4428521394729614\n",
      "Epoch 61: Iteration 80 with loss 0.41734617948532104\n",
      "Epoch 61: Iteration 100 with loss 0.44969820976257324\n",
      "Epoch 61: Iteration 120 with loss 0.35944896936416626\n",
      "Epoch 61: Iteration 140 with loss 1.0039982795715332\n",
      "Epoch 61: Iteration 160 with loss 0.3400726318359375\n",
      "Epoch 61: Iteration 180 with loss 0.6026854515075684\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.6 minutes\n",
      "iter 20 of Expectation completed in a total of  7.2 minutes\n",
      "iter 30 of Expectation completed in a total of  11.8 minutes\n",
      "iter 40 of Expectation completed in a total of  15.9 minutes\n",
      "iter 50 of Expectation completed in a total of  20.0 minutes\n",
      "iter 60 of Expectation completed in a total of  23.5 minutes\n",
      "iter 70 of Expectation completed in a total of  27.2 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  76.59%, boundary mse  0.00\n",
      "Epoch 61 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.48105543486433\n",
      "Starting Training\n",
      "Epoch 62: Iteration 20 with loss 0.3093107342720032\n",
      "Epoch 62: Iteration 40 with loss 0.32470858097076416\n",
      "Epoch 62: Iteration 60 with loss 0.32780271768569946\n",
      "Epoch 62: Iteration 80 with loss 0.30006515979766846\n",
      "Epoch 62: Iteration 100 with loss 0.38962459564208984\n",
      "Epoch 62: Iteration 120 with loss 0.45394444465637207\n",
      "Epoch 62: Iteration 140 with loss 0.5555410981178284\n",
      "Epoch 62: Iteration 160 with loss 0.38224753737449646\n",
      "Epoch 62: Iteration 180 with loss 0.5481932163238525\n",
      "Epoch 62 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.378610349371414\n",
      "Starting Training\n",
      "Epoch 63: Iteration 20 with loss 0.3252263069152832\n",
      "Epoch 63: Iteration 40 with loss 0.41602030396461487\n",
      "Epoch 63: Iteration 60 with loss 0.39675164222717285\n",
      "Epoch 63: Iteration 80 with loss 0.5522692799568176\n",
      "Epoch 63: Iteration 100 with loss 0.5793994665145874\n",
      "Epoch 63: Iteration 120 with loss 0.47194987535476685\n",
      "Epoch 63: Iteration 140 with loss 0.3704867660999298\n",
      "Epoch 63: Iteration 160 with loss 0.31982651352882385\n",
      "Epoch 63: Iteration 180 with loss 0.5665411949157715\n",
      "Epoch 63 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.70847727245747\n",
      "Starting Training\n",
      "Epoch 64: Iteration 20 with loss 0.5825901627540588\n",
      "Epoch 64: Iteration 40 with loss 2.076871871948242\n",
      "Epoch 64: Iteration 60 with loss 1.384484052658081\n",
      "Epoch 64: Iteration 80 with loss 0.5194716453552246\n",
      "Epoch 64: Iteration 100 with loss 0.5914479494094849\n",
      "Epoch 64: Iteration 120 with loss 0.39551985263824463\n",
      "Epoch 64: Iteration 140 with loss 0.42953938245773315\n",
      "Epoch 64: Iteration 160 with loss 0.6395514607429504\n",
      "Epoch 64: Iteration 180 with loss 0.4569990932941437\n",
      "Epoch 64 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.66534499883266\n",
      "Starting Training\n",
      "Epoch 65: Iteration 20 with loss 0.6420931816101074\n",
      "Epoch 65: Iteration 40 with loss 1.8869928121566772\n",
      "Epoch 65: Iteration 60 with loss 3.4837605953216553\n",
      "Epoch 65: Iteration 80 with loss 1.2147722244262695\n",
      "Epoch 65: Iteration 100 with loss 0.5731233358383179\n",
      "Epoch 65: Iteration 120 with loss 0.7985560297966003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Iteration 140 with loss 0.4508247673511505\n",
      "Epoch 65: Iteration 160 with loss 0.8115043640136719\n",
      "Epoch 65: Iteration 180 with loss 0.42172250151634216\n",
      "Epoch 65 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.31940833600437\n",
      "Starting Training\n",
      "Epoch 66: Iteration 20 with loss 0.6926485300064087\n",
      "Epoch 66: Iteration 40 with loss 0.3721248209476471\n",
      "Epoch 66: Iteration 60 with loss 0.458239883184433\n",
      "Epoch 66: Iteration 80 with loss 0.721886396408081\n",
      "Epoch 66: Iteration 100 with loss 0.28227171301841736\n",
      "Epoch 66: Iteration 120 with loss 0.2464321106672287\n",
      "Epoch 66: Iteration 140 with loss 0.6153993606567383\n",
      "Epoch 66: Iteration 160 with loss 0.4452989399433136\n",
      "Epoch 66: Iteration 180 with loss 0.3143503665924072\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  4.0 minutes\n",
      "iter 20 of Expectation completed in a total of  7.9 minutes\n",
      "iter 30 of Expectation completed in a total of  11.5 minutes\n",
      "iter 40 of Expectation completed in a total of  15.9 minutes\n",
      "iter 50 of Expectation completed in a total of  20.4 minutes\n",
      "iter 60 of Expectation completed in a total of  23.9 minutes\n",
      "iter 70 of Expectation completed in a total of  27.1 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  76.57%, boundary mse  0.00\n",
      "Epoch 66 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.43159181832211\n",
      "Starting Training\n",
      "Epoch 67: Iteration 20 with loss 0.21026824414730072\n",
      "Epoch 67: Iteration 40 with loss 0.26179561018943787\n",
      "Epoch 67: Iteration 60 with loss 0.364468514919281\n",
      "Epoch 67: Iteration 80 with loss 0.440067857503891\n",
      "Epoch 67: Iteration 100 with loss 0.5552178621292114\n",
      "Epoch 67: Iteration 120 with loss 0.4576127529144287\n",
      "Epoch 67: Iteration 140 with loss 0.7141801118850708\n",
      "Epoch 67: Iteration 160 with loss 0.29273736476898193\n",
      "Epoch 67: Iteration 180 with loss 0.22756338119506836\n",
      "Epoch 67 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.55762511327168\n",
      "Starting Training\n",
      "Epoch 68: Iteration 20 with loss 0.34029096364974976\n",
      "Epoch 68: Iteration 40 with loss 0.7161837816238403\n",
      "Epoch 68: Iteration 60 with loss 0.29788321256637573\n",
      "Epoch 68: Iteration 80 with loss 0.3082427978515625\n",
      "Epoch 68: Iteration 100 with loss 0.2981545329093933\n",
      "Epoch 68: Iteration 120 with loss 0.4659770429134369\n",
      "Epoch 68: Iteration 140 with loss 0.38417375087738037\n",
      "Epoch 68: Iteration 160 with loss 0.3460138440132141\n",
      "Epoch 68: Iteration 180 with loss 0.6990603804588318\n",
      "Epoch 68 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 63.11913608825892\n",
      "Starting Training\n",
      "Epoch 69: Iteration 20 with loss 0.5362733006477356\n",
      "Epoch 69: Iteration 40 with loss 0.35199594497680664\n",
      "Epoch 69: Iteration 60 with loss 0.46444836258888245\n",
      "Epoch 69: Iteration 80 with loss 0.3521995544433594\n",
      "Epoch 69: Iteration 100 with loss 0.25254908204078674\n",
      "Epoch 69: Iteration 120 with loss 0.3675091862678528\n",
      "Epoch 69: Iteration 140 with loss 0.2529294192790985\n",
      "Epoch 69: Iteration 160 with loss 0.3362099826335907\n",
      "Epoch 69: Iteration 180 with loss 0.25539329648017883\n",
      "Epoch 69 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.63720613665412\n",
      "Starting Training\n",
      "Epoch 70: Iteration 20 with loss 0.27583053708076477\n",
      "Epoch 70: Iteration 40 with loss 0.3126070201396942\n",
      "Epoch 70: Iteration 60 with loss 0.2614768147468567\n",
      "Epoch 70: Iteration 80 with loss 0.3635229766368866\n",
      "Epoch 70: Iteration 100 with loss 0.22093461453914642\n",
      "Epoch 70: Iteration 120 with loss 0.33380457758903503\n",
      "Epoch 70: Iteration 140 with loss 0.4500720798969269\n",
      "Epoch 70: Iteration 160 with loss 0.2076810598373413\n",
      "Epoch 70: Iteration 180 with loss 0.19127608835697174\n",
      "Epoch 70 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.43772530677335\n",
      "Starting Training\n",
      "Epoch 71: Iteration 20 with loss 0.26664748787879944\n",
      "Epoch 71: Iteration 40 with loss 0.32325756549835205\n",
      "Epoch 71: Iteration 60 with loss 0.2392674684524536\n",
      "Epoch 71: Iteration 80 with loss 0.22097517549991608\n",
      "Epoch 71: Iteration 100 with loss 0.3333180844783783\n",
      "Epoch 71: Iteration 120 with loss 0.24399298429489136\n",
      "Epoch 71: Iteration 140 with loss 0.23508191108703613\n",
      "Epoch 71: Iteration 160 with loss 0.21666915714740753\n",
      "Epoch 71: Iteration 180 with loss 0.295940637588501\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  4.4 minutes\n",
      "iter 20 of Expectation completed in a total of  8.2 minutes\n",
      "iter 30 of Expectation completed in a total of  12.2 minutes\n",
      "iter 40 of Expectation completed in a total of  16.5 minutes\n",
      "iter 50 of Expectation completed in a total of  21.0 minutes\n",
      "iter 60 of Expectation completed in a total of  25.3 minutes\n",
      "iter 70 of Expectation completed in a total of  28.7 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  76.50%, boundary mse  0.00\n",
      "Epoch 71 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 62.361947046230675\n",
      "Starting Training\n",
      "Epoch 72: Iteration 20 with loss 0.24113331735134125\n",
      "Epoch 72: Iteration 40 with loss 0.2413043975830078\n",
      "Epoch 72: Iteration 60 with loss 0.26899999380111694\n",
      "Epoch 72: Iteration 80 with loss 0.31730857491493225\n",
      "Epoch 72: Iteration 100 with loss 0.24452023208141327\n",
      "Epoch 72: Iteration 120 with loss 0.2606376111507416\n",
      "Epoch 72: Iteration 140 with loss 0.3207017481327057\n",
      "Epoch 72: Iteration 160 with loss 0.19822202622890472\n",
      "Epoch 72: Iteration 180 with loss 0.6866476535797119\n",
      "Epoch 72 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.120608125487216\n",
      "Starting Training\n",
      "Epoch 73: Iteration 20 with loss 0.38248929381370544\n",
      "Epoch 73: Iteration 40 with loss 0.30436602234840393\n",
      "Epoch 73: Iteration 60 with loss 0.2805110812187195\n",
      "Epoch 73: Iteration 80 with loss 0.2050284892320633\n",
      "Epoch 73: Iteration 100 with loss 0.3481573164463043\n",
      "Epoch 73: Iteration 120 with loss 0.25884655117988586\n",
      "Epoch 73: Iteration 140 with loss 0.22777047753334045\n",
      "Epoch 73: Iteration 160 with loss 0.7765212655067444\n",
      "Epoch 73: Iteration 180 with loss 2.6614668369293213\n",
      "Epoch 73 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 51.46451875858194\n",
      "Starting Training\n",
      "Epoch 74: Iteration 20 with loss 1.1780692338943481\n",
      "Epoch 74: Iteration 40 with loss 2.876964807510376\n",
      "Epoch 74: Iteration 60 with loss 1.6026962995529175\n",
      "Epoch 74: Iteration 80 with loss 1.411255121231079\n",
      "Epoch 74: Iteration 100 with loss 0.7531852722167969\n",
      "Epoch 74: Iteration 120 with loss 0.7749125957489014\n",
      "Epoch 74: Iteration 140 with loss 0.4653356373310089\n",
      "Epoch 74: Iteration 160 with loss 3.0970938205718994\n",
      "Epoch 74: Iteration 180 with loss 5.262307167053223\n",
      "Epoch 74 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 49.071468990269516\n",
      "Starting Training\n",
      "Epoch 75: Iteration 20 with loss 1.2669432163238525\n",
      "Epoch 75: Iteration 40 with loss 1.0278531312942505\n",
      "Epoch 75: Iteration 60 with loss 0.7126323580741882\n",
      "Epoch 75: Iteration 80 with loss 0.9224419593811035\n",
      "Epoch 75: Iteration 100 with loss 1.7902941703796387\n",
      "Epoch 75: Iteration 120 with loss 1.8204963207244873\n",
      "Epoch 75: Iteration 140 with loss 1.3412890434265137\n",
      "Epoch 75: Iteration 160 with loss 1.1942262649536133\n",
      "Epoch 75: Iteration 180 with loss 1.1471644639968872\n",
      "Epoch 75 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 55.35849250725136\n",
      "Starting Training\n",
      "Epoch 76: Iteration 20 with loss 1.7465596199035645\n",
      "Epoch 76: Iteration 40 with loss 0.6687715649604797\n",
      "Epoch 76: Iteration 60 with loss 0.4511881470680237\n",
      "Epoch 76: Iteration 80 with loss 0.38093113899230957\n",
      "Epoch 76: Iteration 100 with loss 0.4253126382827759\n",
      "Epoch 76: Iteration 120 with loss 1.1005624532699585\n",
      "Epoch 76: Iteration 140 with loss 0.48074862360954285\n",
      "Epoch 76: Iteration 160 with loss 0.8386852741241455\n",
      "Epoch 76: Iteration 180 with loss 0.486708402633667\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.4 minutes\n",
      "iter 20 of Expectation completed in a total of  6.6 minutes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 30 of Expectation completed in a total of  9.9 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-14343:\n",
      "Process ForkPoolWorker-14335:\n",
      "Process ForkPoolWorker-14337:\n",
      "Process ForkPoolWorker-14334:\n",
      "Process ForkPoolWorker-14346:\n",
      "Process ForkPoolWorker-14329:\n",
      "Process ForkPoolWorker-14347:\n",
      "Process ForkPoolWorker-14333:\n",
      "Process ForkPoolWorker-14345:\n",
      "Process ForkPoolWorker-14348:\n",
      "Process ForkPoolWorker-14340:\n",
      "Process ForkPoolWorker-14330:\n",
      "Process ForkPoolWorker-14342:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-14336:\n",
      "Process ForkPoolWorker-14338:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-14331:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"<ipython-input-14-ff1e769c794e>\", line 47, in prob_vals_per_segment\n",
      "    b2_prior = get_possion_prob_for_all_class(1, next_ele-b1)  # mid_seg_len x num_class\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-14-ff1e769c794e>\", line 47, in prob_vals_per_segment\n",
      "    b2_prior = get_possion_prob_for_all_class(1, next_ele-b1)  # mid_seg_len x num_class\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"<ipython-input-12-748e515e4c49>\", line 15, in get_possion_prob_for_all_class\n",
      "    ele_list.append(torch.tensor(prob))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"<ipython-input-14-ff1e769c794e>\", line 98, in prob_vals_per_segment\n",
      "    expected_boundary = round(torch.sum(torch.sum(mat_b1_b2_c_prob, axis=(0,2)).squeeze() * \\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-12-748e515e4c49>\", line 15, in get_possion_prob_for_all_class\n",
      "    ele_list.append(torch.tensor(prob))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-14-ff1e769c794e>\", line 71, in prob_vals_per_segment\n",
      "    mat_b1_b2_c_prob[:, :, label_cur_ele] = LOW_VAL\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-14344:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-14-ff1e769c794e>\", line 76, in prob_vals_per_segment\n",
      "    left_over_classes = config.num_class - 2 + (label_cur_ele==label_next_ele)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-14332:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-14-ff1e769c794e>\", line 73, in prob_vals_per_segment\n",
      "    mat_b1_b2_c_prob = torch.softmax(mat_b1_b2_c_prob.flatten(), dim=0).reshape((seg_len, seg_len, config.num_class))\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-14341:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-14-ff1e769c794e>\", line 73, in prob_vals_per_segment\n",
      "    mat_b1_b2_c_prob = torch.softmax(mat_b1_b2_c_prob.flatten(), dim=0).reshape((seg_len, seg_len, config.num_class))\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-14339:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-14-ff1e769c794e>\", line 73, in prob_vals_per_segment\n",
      "    mat_b1_b2_c_prob = torch.softmax(mat_b1_b2_c_prob.flatten(), dim=0).reshape((seg_len, seg_len, config.num_class))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-547e90c7ceda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0minitialize_epoch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexpectation_cal_gap\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mperform_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloder_expectation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1} finished, starting validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e151fbc59213>\u001b[0m in \u001b[0;36mperform_expectation\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mcalculate_element_probb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"iter {i+1} of Expectation completed in a total of {(time() - curtime)/60.: .1f} minutes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e151fbc59213>\u001b[0m in \u001b[0;36mcalculate_element_probb\u001b[0;34m(data_feat, data_count, video_ids, gt_labels)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Step 4: Close Pool and let all the processes complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# postpones the execution of next line of code until all processes in the queue are done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"In unknown state\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initialize_epoch = 30\n",
    "expectation_cal_gap = 5\n",
    "best_val_acc = 0\n",
    "for epoch in range(30, 150):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)  # features\n",
    "        item_1 = item[1].to(device)  # count\n",
    "        item_2 = item[2].to(device)  # target\n",
    "        weights = item[5].to(device)  # posterior weight\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        boundary_target_tensor = get_single_random(item[4], item_2.shape[1], item_2.device)\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, boundary_target_tensor)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                            max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                total_count = torch.sum(src_mask)\n",
    "                weighted_loss_sum = -torch.sum(torch.sum(torch.log(prob + 1e-8) * weights, dim=-1) * src_mask)\n",
    "                loss += weighted_loss_sum/total_count\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1)%20 == 0:\n",
    "            print(f'Epoch {epoch+1}: Iteration {i+1} with loss {loss.item()}')\n",
    "\n",
    "    if (epoch >= initialize_epoch) and ((epoch % (3 * expectation_cal_gap)) == 0):\n",
    "        torch.save(model.state_dict(), config.output_dir + f\"ms-tcn-initial-{epoch}-epochs.wt\")\n",
    "\n",
    "    if epoch >= initialize_epoch and (epoch % expectation_cal_gap == 0):\n",
    "        perform_expectation(model, trainloder_expectation)\n",
    "    \n",
    "    print(f'Epoch {epoch+1} finished, starting validation')\n",
    "    val_acc, best_val_acc = validate(model, testloader, best_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 105, Probability Accuracy 61.02425300046298\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 105, Probability Accuracy 63.70656599831428\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {best_val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-emmax-best-model.wt\"))\n",
    "# model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-initial-15-epochs.wt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
