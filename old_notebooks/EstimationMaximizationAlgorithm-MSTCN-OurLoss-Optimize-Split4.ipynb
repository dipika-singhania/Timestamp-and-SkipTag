{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 4, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split4/', 'project_name': 'breakfast-split-4', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split4.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split4.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split4_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=4,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split4/\",\n",
    "    project_name=\"breakfast-split-4\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1136\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 576\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = Breakfast(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = iter(trainloader).next()\n",
    "# print(item[0]) # -- data feature\n",
    "# print(item[1]) # -- valid count\n",
    "# item[2] # -- Actual labels\n",
    "# print(item[5]) # video names\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vidid_selected_frames = np.load(\"/home/dipika16/ar/TimestampActionSeg/data/breakfast_annotation_all.npy\", allow_pickle=True).item()\n",
    "# loaded_vidid_selected_frames\n",
    "video_id_boundary_frames = pickle.load(open(\"dump_dir/chunk_1_video_id_boundary_frames_dict.pkl\", \"rb\"))\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"dump_dir/mean_var_actions.pkl\", \"rb\"))\n",
    "def get_possion_prob(cur_len, cur_class):\n",
    "    mean_class, std_class = loaded_mean_var_actions[cur_class]\n",
    "    mean_class = mean_class * 10\n",
    "    prob = cur_len * torch.log(torch.tensor(mean_class, device=device) + 1e-5)\n",
    "    prob = prob - mean_class\n",
    "    factorials = torch.cumsum(torch.log(torch.arange(1, torch.max(cur_len)+1, 1).type(torch.float).to(device)), \n",
    "                              dim=0)[min(cur_len)-1:]\n",
    "    prob = prob - factorials\n",
    "    return prob\n",
    "\n",
    "# get_possion_prob(torch.arange(10, 21), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_video_each_segment_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels):\n",
    "    prob_each_segment = []\n",
    "    \n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    cur_boundary = 0\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[cur_ele]\n",
    "        label_next_ele = labels[next_ele]\n",
    "\n",
    "        indices = torch.arange(cur_ele, next_ele).to(cumsum_feat.device)\n",
    "        strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "        end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "        left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "        right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "\n",
    "        cur_boundary_len = indices - cur_boundary\n",
    "        len_prob = get_possion_prob(cur_boundary_len, label_cur_ele.item())\n",
    "\n",
    "        prob = torch.softmax((left_sum + right_sum + len_prob), dim=0)\n",
    "#         prob = torch.softmax((left_sum + right_sum), dim=0)\n",
    "\n",
    "        cur_boundary = round(np.sum(np.arange(cur_ele, next_ele, 1) * prob.detach().cpu().numpy()).item())\n",
    "        prob_each_segment.append(prob)\n",
    "    \n",
    "    return prob_each_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_element_probb(data_feat, data_count, video_ids, labels_all): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        labels = labels_all[iter_num]\n",
    "        \n",
    "        selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "        prob_video = prob_vals_per_segment(selected_frames, cur_vid_feat, labels)\n",
    "        prob_video_each_segment_dict[cur_vidid] = prob_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_loss(data_feat, data_count, video_ids, labels_all): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    loss_arr = []\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        labels = labels_all[iter_num]\n",
    "        \n",
    "        selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "        prob_each_video = prob_video_each_segment_dict[cur_vidid]\n",
    "        \n",
    "        log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "        cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "        \n",
    "        \n",
    "        current_vid_prob_arr = []\n",
    "        # Start segment log probability\n",
    "        start_ele_idx = selected_frames[0]\n",
    "        if start_ele_idx > 0:\n",
    "            start_ele_label_idx = labels[selected_frames[0]]\n",
    "            first_segment_prob = (cumsum_feat[start_ele_idx - 1, :])[start_ele_label_idx]\n",
    "            current_vid_prob_arr.append(first_segment_prob.unsqueeze(0))\n",
    "        \n",
    "        for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "            next_ele = selected_frames[i + 1]\n",
    "            label_cur_ele = labels[cur_ele]\n",
    "            label_next_ele = labels[next_ele]\n",
    "\n",
    "            indices = torch.arange(cur_ele, next_ele)\n",
    "            strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "            end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "            left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "            right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "            current_vid_prob_arr.append((left_sum + right_sum)  * (prob_each_video[i]))\n",
    "        \n",
    "        # End segment log probability\n",
    "        end_index = cur_vid_count.item() - 1\n",
    "        last_ele_label_idx = labels[selected_frames[-1]]\n",
    "        last_segment_sum_prob = (cumsum_feat[end_index, :] - cumsum_feat[selected_frames[-1] - 1, :])[last_ele_label_idx]\n",
    "        current_vid_prob_arr.append(last_segment_sum_prob.unsqueeze(0))\n",
    "            \n",
    "        loss_arr.append(torch.cat(current_vid_prob_arr))\n",
    "    return -torch.mean(torch.cat(loss_arr)), loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_file_list = set(open(config.train_split_file).read().split(\"\\n\")[0:-1])\n",
    "\n",
    "def get_estimated_boundaries():\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames, video_id_boundary_frames\n",
    "    estimated_boundary_dict = {}\n",
    "    for ele in video_id_boundary_frames.keys():\n",
    "        if (ele + \".txt\") not in train_split_file_list:\n",
    "            continue\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        selected_ele_list = loaded_vidid_selected_frames[ele + \".txt\"]\n",
    "        boundary_list = []\n",
    "        for i, segment in enumerate(estimated_boundary_probs):\n",
    "            estimated_boundary = np.sum(np.arange(selected_ele_list[i], selected_ele_list[i + 1], 1) \\\n",
    "                                        * segment.detach().cpu().numpy())\n",
    "            estimated_boundary = round(estimated_boundary.item())\n",
    "            \n",
    "            if (estimated_boundary < selected_ele_list[i]) or (estimated_boundary > selected_ele_list[i + 1]):\n",
    "                print(\"Estimated value wrong\")\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "            boundary_list.append(estimated_boundary)\n",
    "\n",
    "        estimated_boundary_dict[ele] = boundary_list\n",
    "    return estimated_boundary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_file_list = set(open(config.train_split_file).read().split(\"\\n\")[0:-1])\n",
    "\n",
    "def get_boundary_err():\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    err_list = []\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    estimated_boundar_dict = get_estimated_boundaries()\n",
    "    for ele in video_id_boundary_frames.keys():\n",
    "        if ele + \".txt\" not in train_split_file_list:\n",
    "            continue\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        estimated_boundary_list = estimated_boundar_dict[ele]\n",
    "        \n",
    "        estimated = np.array(estimated_boundary_list) #.detach().cpu().numpy()\n",
    "        actual = np.array(video_id_boundary_frames[ele][:-1])\n",
    "        if len(actual) != len(estimated):\n",
    "            print(ele)\n",
    "            continue\n",
    "        \n",
    "        mse_err = (actual - estimated)**2\n",
    "        err_list.append(mse_err)\n",
    "        \n",
    "        estimated_labels = []\n",
    "        actual_labels = []\n",
    "        start_v1 = 0\n",
    "        start_v2 = 0\n",
    "        for i, v1 in enumerate(estimated):\n",
    "            estimated_labels.extend([i] * (v1 - start_v1))\n",
    "            start_v1 = v1\n",
    "            v2 = actual[i]\n",
    "            actual_labels.extend([i] * (v2 - start_v2))\n",
    "            start_v2 = v2\n",
    "            \n",
    "        last_ele = video_id_boundary_frames[ele][-1]\n",
    "        estimated_labels.extend([i+1] * (last_ele - start_v1))\n",
    "        actual_labels.extend([i+1] * (last_ele - start_v2))\n",
    "        \n",
    "        correct += np.sum(np.array(actual_labels) == np.array(estimated_labels))\n",
    "        total += len(actual_labels)\n",
    "        \n",
    "    print(f\"Train Boundary avergage error = {np.sqrt(np.mean(np.concatenate(err_list))):.3f}\")\n",
    "    print(f\"Train From boundary avergage accuracy = {correct * 100.0 / total:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Boundary avergage error = 84.449\n",
      "Train From boundary avergage accuracy = 89.000\n"
     ]
    }
   ],
   "source": [
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_random(labels_all, video_ids):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((labels_all.shape[0], labels_all.shape[1]), dtype=torch.long, device=labels_all.device) * (-100)\n",
    "    for iter_num, labels in enumerate(labels_all):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        frame_idx_tensor = torch.from_numpy(np.array(loaded_vidid_selected_frames[cur_vidid + \".txt\"]))\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = labels[frame_idx_tensor]\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split4/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Training:: Epoch 15, Iteration 0, Current loss 1.8556843996047974 Accuracy 71.94321352371574\n",
      "Training:: Epoch 15, Iteration 10, Current loss 1.4181013107299805 Accuracy 80.85716561778061\n",
      "Training:: Epoch 15, Iteration 20, Current loss 1.330886960029602 Accuracy 62.76542467948718\n",
      "Training:: Epoch 15, Iteration 30, Current loss 1.2861876487731934 Accuracy 69.17018605182056\n",
      "Training:: Epoch 15, Iteration 40, Current loss 2.0291144847869873 Accuracy 71.45560637123482\n",
      "Training:: Epoch 15, Iteration 50, Current loss 1.2951205968856812 Accuracy 80.90161182001343\n",
      "Training:: Epoch 15, Iteration 60, Current loss 0.8947985172271729 Accuracy 68.93127186547794\n",
      "Training:: Epoch 15, Iteration 70, Current loss 1.6893976926803589 Accuracy 65.86749162155195\n",
      "Training:: Epoch 15, Iteration 80, Current loss 2.151519775390625 Accuracy 81.5013582455443\n",
      "Training:: Epoch 15, Iteration 90, Current loss 1.4900544881820679 Accuracy 77.8420666612338\n",
      "Training:: Epoch 15, Iteration 100, Current loss 2.4255142211914062 Accuracy 74.96155029221778\n",
      "Training:: Epoch 15, Iteration 110, Current loss 1.8158520460128784 Accuracy 73.84359195756754\n",
      "Training:: Epoch 15, Iteration 120, Current loss 2.5469086170196533 Accuracy 75.60171447411804\n",
      "Training:: Epoch 15, Iteration 130, Current loss 3.2285315990448 Accuracy 58.297144361100145\n",
      "Training:: Epoch 15, Iteration 140, Current loss 1.425101637840271 Accuracy 67.19465158138338\n",
      "Calculating Expectation\n",
      "Epoch 15 iter 0\n",
      "Epoch 15 iter 10\n",
      "Epoch 15 iter 20\n",
      "Epoch 15 iter 30\n",
      "Epoch 15 iter 40\n",
      "Epoch 15 iter 50\n",
      "Epoch 15 iter 60\n",
      "Epoch 15 iter 70\n",
      "Epoch 15 iter 80\n",
      "Epoch 15 iter 90\n",
      "Epoch 15 iter 100\n",
      "Epoch 15 iter 110\n",
      "Epoch 15 iter 120\n",
      "Epoch 15 iter 130\n",
      "Epoch 15 iter 140\n",
      "Train Boundary avergage error = 87.772\n",
      "Train From boundary avergage accuracy = 88.003\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 15, Probability Accuracy 55.105262125896246\n",
      "Starting Training\n",
      "Training:: Epoch 16, Iteration 0, Current loss 3.8229539104102104 Accuracy 67.95149415331312\n",
      "Training:: Epoch 16, Iteration 10, Current loss 4.271855196300814 Accuracy 67.29071944370152\n",
      "Training:: Epoch 16, Iteration 20, Current loss 4.050331724231612 Accuracy 63.69507230099677\n",
      "Training:: Epoch 16, Iteration 30, Current loss 3.9230010935640665 Accuracy 65.73735199138859\n",
      "Training:: Epoch 16, Iteration 40, Current loss 8.612939710117656 Accuracy 48.73185297044994\n",
      "Training:: Epoch 16, Iteration 50, Current loss 5.283512060859293 Accuracy 52.00338123415047\n",
      "Training:: Epoch 16, Iteration 60, Current loss 4.231719505180276 Accuracy 62.351387054161165\n",
      "Training:: Epoch 16, Iteration 70, Current loss 4.111939719989788 Accuracy 68.03584764749813\n",
      "Training:: Epoch 16, Iteration 80, Current loss 4.073682086075623 Accuracy 64.01195977167708\n",
      "Training:: Epoch 16, Iteration 90, Current loss 4.591585685945721 Accuracy 58.123396314439\n",
      "Training:: Epoch 16, Iteration 100, Current loss 6.1991616949522435 Accuracy 44.67209742450424\n",
      "Training:: Epoch 16, Iteration 110, Current loss 2.5186095327938585 Accuracy 75.04614510861849\n",
      "Training:: Epoch 16, Iteration 120, Current loss 5.126671388042346 Accuracy 57.8718609143593\n",
      "Training:: Epoch 16, Iteration 130, Current loss 5.996800712007872 Accuracy 54.399301004805594\n",
      "Training:: Epoch 16, Iteration 140, Current loss 5.5857697028897135 Accuracy 58.01716350496838\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 16, Probability Accuracy 53.85125066176903\n",
      "Starting Training\n",
      "Training:: Epoch 17, Iteration 0, Current loss 5.372621304596768 Accuracy 51.42767912911573\n",
      "Training:: Epoch 17, Iteration 10, Current loss 2.99782115682612 Accuracy 80.4624394184168\n",
      "Training:: Epoch 17, Iteration 20, Current loss 3.2643767153480825 Accuracy 75.61177670150396\n",
      "Training:: Epoch 17, Iteration 30, Current loss 4.876196147951697 Accuracy 61.158542183053335\n",
      "Training:: Epoch 17, Iteration 40, Current loss 3.5705105941916075 Accuracy 70.84511308562197\n",
      "Training:: Epoch 17, Iteration 50, Current loss 3.2241020688017232 Accuracy 73.87132811986594\n",
      "Training:: Epoch 17, Iteration 60, Current loss 2.479714556199686 Accuracy 67.27423650261129\n",
      "Training:: Epoch 17, Iteration 70, Current loss 3.516815287616373 Accuracy 69.21094085636545\n",
      "Training:: Epoch 17, Iteration 80, Current loss 2.3822240317605736 Accuracy 81.9979060171214\n",
      "Training:: Epoch 17, Iteration 90, Current loss 2.396062195031281 Accuracy 81.62636479335521\n",
      "Training:: Epoch 17, Iteration 100, Current loss 2.8178438351464403 Accuracy 80.30597806862399\n",
      "Training:: Epoch 17, Iteration 110, Current loss 5.770402301657764 Accuracy 65.18691588785046\n",
      "Training:: Epoch 17, Iteration 120, Current loss 4.869111905336977 Accuracy 63.36322869955157\n",
      "Training:: Epoch 17, Iteration 130, Current loss 6.965607563537698 Accuracy 45.528012729252154\n",
      "Training:: Epoch 17, Iteration 140, Current loss 4.975888908370242 Accuracy 64.4870349492672\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 17, Probability Accuracy 47.346796384290094\n",
      "Starting Training\n",
      "Training:: Epoch 18, Iteration 0, Current loss 3.5093983937796644 Accuracy 75.12833489986262\n",
      "Training:: Epoch 18, Iteration 10, Current loss 2.732915821128118 Accuracy 81.33659331703342\n",
      "Training:: Epoch 18, Iteration 20, Current loss 3.3618570760354927 Accuracy 74.38956714761376\n",
      "Training:: Epoch 18, Iteration 30, Current loss 3.4615906581601505 Accuracy 71.32452574525745\n",
      "Training:: Epoch 18, Iteration 40, Current loss 2.279229906423469 Accuracy 83.69643039787256\n",
      "Training:: Epoch 18, Iteration 50, Current loss 2.5185293941725067 Accuracy 78.36988191995093\n",
      "Training:: Epoch 18, Iteration 60, Current loss 2.88293551167913 Accuracy 76.316734191497\n",
      "Training:: Epoch 18, Iteration 70, Current loss 4.679006189478352 Accuracy 68.35539071061282\n",
      "Training:: Epoch 18, Iteration 80, Current loss 2.7936779550456183 Accuracy 81.39704731597892\n",
      "Training:: Epoch 18, Iteration 90, Current loss 3.7082001724516136 Accuracy 72.89380877742947\n",
      "Training:: Epoch 18, Iteration 100, Current loss 5.7086254227915605 Accuracy 57.74669457348512\n",
      "Training:: Epoch 18, Iteration 110, Current loss 2.7611580692240567 Accuracy 73.95119936676188\n",
      "Training:: Epoch 18, Iteration 120, Current loss 2.4699136416569 Accuracy 63.25107296137339\n",
      "Training:: Epoch 18, Iteration 130, Current loss 3.4554545221887216 Accuracy 69.41919191919192\n",
      "Training:: Epoch 18, Iteration 140, Current loss 2.234904488139394 Accuracy 85.84230218485843\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 18, Probability Accuracy 62.68456002980412\n",
      "Starting Training\n",
      "Training:: Epoch 19, Iteration 0, Current loss 1.992414831075632 Accuracy 80.0454345595779\n",
      "Training:: Epoch 19, Iteration 10, Current loss 1.8607669357117735 Accuracy 82.6116578349735\n",
      "Training:: Epoch 19, Iteration 20, Current loss 1.952742791883639 Accuracy 81.61827864628071\n",
      "Training:: Epoch 19, Iteration 30, Current loss 1.7765782419971856 Accuracy 82.69099201824402\n",
      "Training:: Epoch 19, Iteration 40, Current loss 2.0237756352902583 Accuracy 82.386749568943\n",
      "Training:: Epoch 19, Iteration 50, Current loss 1.1489204900341776 Accuracy 90.35659663527328\n",
      "Training:: Epoch 19, Iteration 60, Current loss 2.3427467871488297 Accuracy 75.65491997416206\n",
      "Training:: Epoch 19, Iteration 70, Current loss 1.8994831375643508 Accuracy 80.24584594477732\n",
      "Training:: Epoch 19, Iteration 80, Current loss 3.0360519524496836 Accuracy 72.46264144424289\n",
      "Training:: Epoch 19, Iteration 90, Current loss 2.2029191348196573 Accuracy 83.47721098702083\n",
      "Training:: Epoch 19, Iteration 100, Current loss 4.073692709158334 Accuracy 68.51479961582118\n",
      "Training:: Epoch 19, Iteration 110, Current loss 2.105729367795745 Accuracy 85.1520572450805\n",
      "Training:: Epoch 19, Iteration 120, Current loss 1.6508203015466691 Accuracy 85.67924677585252\n",
      "Training:: Epoch 19, Iteration 130, Current loss 2.021792543702225 Accuracy 81.80347225259106\n",
      "Training:: Epoch 19, Iteration 140, Current loss 2.6571046390046558 Accuracy 79.17079616782293\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 19, Probability Accuracy 62.14779181563278\n",
      "Starting Training\n",
      "Training:: Epoch 20, Iteration 0, Current loss 2.249281560886877 Accuracy 71.35852052491477\n",
      "Training:: Epoch 20, Iteration 10, Current loss 1.8719683630293935 Accuracy 80.20536651176735\n",
      "Training:: Epoch 20, Iteration 20, Current loss 1.9259833071231407 Accuracy 80.05809406770193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 20, Iteration 30, Current loss 1.708415991407148 Accuracy 87.51558603491272\n",
      "Training:: Epoch 20, Iteration 40, Current loss 1.8237482708133728 Accuracy 81.64462191165461\n",
      "Training:: Epoch 20, Iteration 50, Current loss 2.772337122916954 Accuracy 78.36148041681639\n",
      "Training:: Epoch 20, Iteration 60, Current loss 3.670781148245705 Accuracy 69.35190449118818\n",
      "Training:: Epoch 20, Iteration 70, Current loss 1.7826626465789985 Accuracy 86.00746268656717\n",
      "Training:: Epoch 20, Iteration 80, Current loss 3.478642447049301 Accuracy 73.5360324656796\n",
      "Training:: Epoch 20, Iteration 90, Current loss 1.7740410474433908 Accuracy 81.7632241813602\n",
      "Training:: Epoch 20, Iteration 100, Current loss 1.9707998470944488 Accuracy 81.97882197220383\n",
      "Training:: Epoch 20, Iteration 110, Current loss 1.6678847773083456 Accuracy 86.96003805899144\n",
      "Training:: Epoch 20, Iteration 120, Current loss 2.6124297487862607 Accuracy 77.31218470208609\n",
      "Training:: Epoch 20, Iteration 130, Current loss 2.1437064156392935 Accuracy 76.60041215183142\n",
      "Training:: Epoch 20, Iteration 140, Current loss 1.530428180785484 Accuracy 84.74325107918304\n",
      "Calculating Expectation\n",
      "Epoch 20 iter 0\n",
      "Epoch 20 iter 10\n",
      "Epoch 20 iter 20\n",
      "Epoch 20 iter 30\n",
      "Epoch 20 iter 40\n",
      "Epoch 20 iter 50\n",
      "Epoch 20 iter 60\n",
      "Epoch 20 iter 70\n",
      "Epoch 20 iter 80\n",
      "Epoch 20 iter 90\n",
      "Epoch 20 iter 100\n",
      "Epoch 20 iter 110\n",
      "Epoch 20 iter 120\n",
      "Epoch 20 iter 130\n",
      "Epoch 20 iter 140\n",
      "Train Boundary avergage error = 87.753\n",
      "Train From boundary avergage accuracy = 87.754\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 20, Probability Accuracy 60.350149347381354\n",
      "Starting Training\n",
      "Training:: Epoch 21, Iteration 0, Current loss 1.3599008686142144 Accuracy 81.0450250138966\n",
      "Training:: Epoch 21, Iteration 70, Current loss 1.6218349083713284 Accuracy 82.5091575091575\n",
      "Training:: Epoch 21, Iteration 80, Current loss 2.094979223634027 Accuracy 83.46731628095819\n",
      "Training:: Epoch 21, Iteration 90, Current loss 1.9264056797631084 Accuracy 79.94782608695652\n",
      "Training:: Epoch 21, Iteration 100, Current loss 1.2996186465860498 Accuracy 86.88776521911561\n",
      "Training:: Epoch 21, Iteration 110, Current loss 1.831316746991066 Accuracy 79.06645978794931\n",
      "Training:: Epoch 21, Iteration 120, Current loss 1.645182356662311 Accuracy 87.09193757241191\n",
      "Training:: Epoch 21, Iteration 130, Current loss 1.5688102927731287 Accuracy 81.11696339180777\n",
      "Training:: Epoch 21, Iteration 140, Current loss 1.1080657897221107 Accuracy 88.88540031397174\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 21, Probability Accuracy 63.38897639853855\n",
      "Starting Training\n",
      "Training:: Epoch 22, Iteration 0, Current loss 1.6836595085471528 Accuracy 81.64556962025317\n",
      "Training:: Epoch 22, Iteration 10, Current loss 1.6498191625830596 Accuracy 89.15921536008872\n",
      "Training:: Epoch 22, Iteration 20, Current loss 1.0206245044341093 Accuracy 87.70602998032965\n",
      "Training:: Epoch 22, Iteration 30, Current loss 1.7132094072158388 Accuracy 84.63289081549715\n",
      "Training:: Epoch 22, Iteration 40, Current loss 1.4122132688261966 Accuracy 83.73836608066183\n",
      "Training:: Epoch 22, Iteration 50, Current loss 5.509567366987598 Accuracy 72.83905779806994\n",
      "Training:: Epoch 22, Iteration 60, Current loss 2.2359433718703086 Accuracy 79.53594656354367\n",
      "Training:: Epoch 22, Iteration 70, Current loss 1.5465984607755714 Accuracy 89.38543067309973\n",
      "Training:: Epoch 22, Iteration 80, Current loss 1.596274418042105 Accuracy 81.76714343002273\n",
      "Training:: Epoch 22, Iteration 90, Current loss 1.6036043067770651 Accuracy 80.59353117705902\n",
      "Training:: Epoch 22, Iteration 100, Current loss 2.455965754827526 Accuracy 72.48478786363258\n",
      "Training:: Epoch 22, Iteration 110, Current loss 2.5550091051103654 Accuracy 78.35675675675675\n",
      "Training:: Epoch 22, Iteration 120, Current loss 1.7237975807917834 Accuracy 85.05088210460828\n",
      "Training:: Epoch 22, Iteration 130, Current loss 2.217760670492169 Accuracy 83.56481481481481\n",
      "Training:: Epoch 22, Iteration 140, Current loss 1.7149706831045564 Accuracy 82.30992498774926\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 22, Probability Accuracy 64.30810005294153\n",
      "Starting Training\n",
      "Training:: Epoch 23, Iteration 0, Current loss 1.7404961910248125 Accuracy 84.02606551602678\n",
      "Training:: Epoch 23, Iteration 10, Current loss 1.1557649138652781 Accuracy 85.16463978379916\n",
      "Training:: Epoch 23, Iteration 20, Current loss 1.3608224177958568 Accuracy 83.59599749843652\n",
      "Training:: Epoch 23, Iteration 30, Current loss 1.1630579553756903 Accuracy 87.56366723259762\n",
      "Training:: Epoch 23, Iteration 40, Current loss 1.771527748041049 Accuracy 83.31887578070784\n",
      "Training:: Epoch 23, Iteration 50, Current loss 1.3472309181000377 Accuracy 80.74162679425838\n",
      "Training:: Epoch 23, Iteration 60, Current loss 1.4026550311107813 Accuracy 85.02487562189054\n",
      "Training:: Epoch 23, Iteration 70, Current loss 0.8741822972172728 Accuracy 88.49291541434091\n",
      "Training:: Epoch 23, Iteration 80, Current loss 4.617643598720881 Accuracy 64.0854407070955\n",
      "Training:: Epoch 23, Iteration 90, Current loss 1.9412487813136279 Accuracy 86.52561247216036\n",
      "Training:: Epoch 23, Iteration 100, Current loss 2.2493865551593553 Accuracy 76.56536547026461\n",
      "Training:: Epoch 23, Iteration 110, Current loss 2.1021756625655508 Accuracy 80.9692223485327\n",
      "Training:: Epoch 23, Iteration 120, Current loss 1.6443196575940289 Accuracy 82.88279682873245\n",
      "Training:: Epoch 23, Iteration 130, Current loss 1.5975716527319714 Accuracy 87.03313675933727\n",
      "Training:: Epoch 23, Iteration 140, Current loss 1.090522122882933 Accuracy 87.05423873585309\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 23, Probability Accuracy 62.335864940293725\n",
      "Starting Training\n",
      "Training:: Epoch 24, Iteration 0, Current loss 0.9786882917157019 Accuracy 86.92274258394002\n",
      "Training:: Epoch 24, Iteration 10, Current loss 1.8125802002236222 Accuracy 82.29533881707795\n",
      "Training:: Epoch 24, Iteration 20, Current loss 1.3820428246490402 Accuracy 85.17551494052799\n",
      "Training:: Epoch 24, Iteration 30, Current loss 1.0965329211340378 Accuracy 88.85021398002853\n",
      "Training:: Epoch 24, Iteration 40, Current loss 1.251216481069599 Accuracy 80.36416872540946\n",
      "Training:: Epoch 24, Iteration 50, Current loss 1.2375443778024464 Accuracy 85.34560368110434\n",
      "Training:: Epoch 24, Iteration 60, Current loss 0.8637632901872287 Accuracy 81.45481814773153\n",
      "Training:: Epoch 24, Iteration 70, Current loss 1.2255204135329656 Accuracy 87.48568947139869\n",
      "Training:: Epoch 24, Iteration 80, Current loss 3.340011608898313 Accuracy 80.45956694653115\n",
      "Training:: Epoch 24, Iteration 90, Current loss 2.2360587764139135 Accuracy 84.32753383043358\n",
      "Training:: Epoch 24, Iteration 100, Current loss 1.8662462724610518 Accuracy 87.29678036340452\n",
      "Training:: Epoch 24, Iteration 110, Current loss 1.7449164700661846 Accuracy 86.04961434229728\n",
      "Training:: Epoch 24, Iteration 120, Current loss 1.256683543200908 Accuracy 87.04663212435233\n",
      "Training:: Epoch 24, Iteration 130, Current loss 2.678853717213045 Accuracy 72.85970653436081\n",
      "Training:: Epoch 24, Iteration 140, Current loss 4.105421642631768 Accuracy 69.14094324250928\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 24, Probability Accuracy 60.00864384734541\n",
      "Starting Training\n",
      "Training:: Epoch 25, Iteration 0, Current loss 2.0841386839377365 Accuracy 80.67115708443589\n",
      "Training:: Epoch 25, Iteration 10, Current loss 1.5078257407311937 Accuracy 84.72541507024266\n",
      "Training:: Epoch 25, Iteration 20, Current loss 1.6005314132865434 Accuracy 78.57976426654218\n",
      "Training:: Epoch 25, Iteration 30, Current loss 0.9775513222550108 Accuracy 88.28838867840427\n",
      "Training:: Epoch 25, Iteration 40, Current loss 2.92867309538063 Accuracy 83.00962675223779\n",
      "Training:: Epoch 25, Iteration 50, Current loss 1.0006622133152085 Accuracy 88.14360641205585\n",
      "Training:: Epoch 25, Iteration 60, Current loss 1.6051132116734403 Accuracy 78.90639832921967\n",
      "Training:: Epoch 25, Iteration 70, Current loss 1.0399453746334553 Accuracy 87.12602762946013\n",
      "Training:: Epoch 25, Iteration 80, Current loss 0.9580036920381371 Accuracy 89.15940881499077\n",
      "Training:: Epoch 25, Iteration 90, Current loss 3.757412721798465 Accuracy 73.75881572515885\n",
      "Training:: Epoch 25, Iteration 100, Current loss 1.5682976956315628 Accuracy 81.49502013138377\n",
      "Training:: Epoch 25, Iteration 110, Current loss 1.3977385406718421 Accuracy 87.1205973056322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 25, Iteration 120, Current loss 1.0509257626096835 Accuracy 88.22977556469654\n",
      "Training:: Epoch 25, Iteration 130, Current loss 1.385312951866557 Accuracy 85.83347238444853\n",
      "Training:: Epoch 25, Iteration 140, Current loss 1.1184941635853198 Accuracy 85.53598737112131\n",
      "Calculating Expectation\n",
      "Epoch 25 iter 0\n",
      "Epoch 25 iter 10\n",
      "Epoch 25 iter 20\n",
      "Epoch 25 iter 30\n",
      "Epoch 25 iter 40\n",
      "Epoch 25 iter 50\n",
      "Epoch 25 iter 60\n",
      "Epoch 25 iter 70\n",
      "Epoch 25 iter 80\n",
      "Epoch 25 iter 90\n",
      "Epoch 25 iter 100\n",
      "Epoch 25 iter 110\n",
      "Epoch 25 iter 120\n",
      "Epoch 25 iter 130\n",
      "Epoch 25 iter 140\n",
      "Train Boundary avergage error = 86.473\n",
      "Train From boundary avergage accuracy = 87.778\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 25, Probability Accuracy 63.2057235668207\n",
      "Starting Training\n",
      "Training:: Epoch 26, Iteration 0, Current loss 1.0592093790267907 Accuracy 84.29200257183837\n",
      "Training:: Epoch 26, Iteration 10, Current loss 1.2576144873180584 Accuracy 86.45848119233499\n",
      "Training:: Epoch 26, Iteration 20, Current loss 0.8994909804619147 Accuracy 78.15342837746097\n",
      "Training:: Epoch 26, Iteration 30, Current loss 0.9035280921525365 Accuracy 84.81417789242381\n",
      "Training:: Epoch 26, Iteration 40, Current loss 2.624581319390309 Accuracy 76.56374685409122\n",
      "Training:: Epoch 26, Iteration 50, Current loss 0.8062709164383455 Accuracy 89.81193543610247\n",
      "Training:: Epoch 26, Iteration 60, Current loss 1.526046600790744 Accuracy 88.4563420994753\n",
      "Training:: Epoch 26, Iteration 70, Current loss 2.6616168436740093 Accuracy 71.56961515212573\n",
      "Training:: Epoch 26, Iteration 80, Current loss 1.2216750418809685 Accuracy 83.97137150466045\n",
      "Training:: Epoch 26, Iteration 90, Current loss 1.08283978237505 Accuracy 82.378053047799\n",
      "Training:: Epoch 26, Iteration 100, Current loss 1.0545113618173496 Accuracy 82.47100802854594\n",
      "Training:: Epoch 26, Iteration 110, Current loss 1.2927152529666277 Accuracy 85.42465247309842\n",
      "Training:: Epoch 26, Iteration 120, Current loss 0.9608612408016969 Accuracy 81.67603895213277\n",
      "Training:: Epoch 26, Iteration 130, Current loss 0.8935239580043676 Accuracy 87.35383536014967\n",
      "Training:: Epoch 26, Iteration 140, Current loss 1.2050689413997258 Accuracy 88.69231720895706\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 26, Probability Accuracy 62.63243550611442\n",
      "Starting Training\n",
      "Training:: Epoch 27, Iteration 0, Current loss 0.8816851644892553 Accuracy 88.65835411471322\n",
      "Training:: Epoch 27, Iteration 10, Current loss 1.7001803298023126 Accuracy 77.0528061929776\n",
      "Training:: Epoch 27, Iteration 20, Current loss 1.144714265624468 Accuracy 88.01585754208098\n",
      "Training:: Epoch 27, Iteration 30, Current loss 0.9614905383903884 Accuracy 87.57961783439491\n",
      "Training:: Epoch 27, Iteration 40, Current loss 2.3026865473726454 Accuracy 76.18911665619825\n",
      "Training:: Epoch 27, Iteration 50, Current loss 1.0171214230654844 Accuracy 87.68094878204755\n",
      "Training:: Epoch 27, Iteration 60, Current loss 2.0213080958038314 Accuracy 76.02735978112175\n",
      "Training:: Epoch 27, Iteration 70, Current loss 0.8454901336368923 Accuracy 86.1297101803431\n",
      "Training:: Epoch 27, Iteration 80, Current loss 1.2399456748915272 Accuracy 84.74691537938405\n",
      "Training:: Epoch 27, Iteration 90, Current loss 1.462897179097705 Accuracy 84.82450711696579\n",
      "Training:: Epoch 27, Iteration 100, Current loss 0.7801556785627664 Accuracy 86.69846316905141\n",
      "Training:: Epoch 27, Iteration 110, Current loss 1.403174742237451 Accuracy 84.33566433566433\n",
      "Training:: Epoch 27, Iteration 120, Current loss 1.6060650599580901 Accuracy 77.48670079293386\n",
      "Training:: Epoch 27, Iteration 130, Current loss 1.2565372900910061 Accuracy 86.11218818663565\n",
      "Training:: Epoch 27, Iteration 140, Current loss 0.8528632545107573 Accuracy 88.77606527651858\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 27, Probability Accuracy 64.93972182824724\n",
      "Starting Training\n",
      "Training:: Epoch 28, Iteration 0, Current loss 1.174453438033897 Accuracy 84.6103375373624\n",
      "Training:: Epoch 28, Iteration 10, Current loss 1.1785417044534774 Accuracy 82.69467393214977\n",
      "Training:: Epoch 28, Iteration 20, Current loss 1.182584715285632 Accuracy 87.75165319617928\n",
      "Training:: Epoch 28, Iteration 30, Current loss 0.7847723702867258 Accuracy 87.55012589760328\n",
      "Training:: Epoch 28, Iteration 40, Current loss 0.9145832922287267 Accuracy 87.54520652242878\n",
      "Training:: Epoch 28, Iteration 50, Current loss 1.1182358921635684 Accuracy 91.40660928979699\n",
      "Training:: Epoch 28, Iteration 60, Current loss 1.2814004498548233 Accuracy 85.16589506172839\n",
      "Training:: Epoch 28, Iteration 70, Current loss 0.6262723126258888 Accuracy 87.3338069623465\n",
      "Training:: Epoch 28, Iteration 80, Current loss 1.5687903051128649 Accuracy 79.16582406471183\n",
      "Training:: Epoch 28, Iteration 90, Current loss 1.1042058854457248 Accuracy 84.11677817360327\n",
      "Training:: Epoch 28, Iteration 100, Current loss 1.2216757828176976 Accuracy 87.94109069699621\n",
      "Training:: Epoch 28, Iteration 110, Current loss 1.3249963888190648 Accuracy 84.66108452950559\n",
      "Training:: Epoch 28, Iteration 120, Current loss 1.2169273183870084 Accuracy 85.41055718475073\n",
      "Training:: Epoch 28, Iteration 130, Current loss 1.1236189442378204 Accuracy 87.98202528999896\n",
      "Training:: Epoch 28, Iteration 140, Current loss 0.9553206006974958 Accuracy 88.97009624787688\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 28, Probability Accuracy 64.6692952241518\n",
      "Starting Training\n",
      "Training:: Epoch 29, Iteration 0, Current loss 1.5950026935531916 Accuracy 86.14600720372485\n",
      "Training:: Epoch 29, Iteration 10, Current loss 1.1408864529002658 Accuracy 82.63529152430287\n",
      "Training:: Epoch 29, Iteration 20, Current loss 0.8470165826648127 Accuracy 87.83500524030543\n",
      "Training:: Epoch 29, Iteration 30, Current loss 0.7524876067021812 Accuracy 90.06294747969824\n",
      "Training:: Epoch 29, Iteration 40, Current loss 0.5627717015168787 Accuracy 90.62190381830654\n",
      "Training:: Epoch 29, Iteration 50, Current loss 0.9251413601356865 Accuracy 87.25932697251899\n",
      "Training:: Epoch 29, Iteration 60, Current loss 0.8911148446262424 Accuracy 85.03789491612024\n",
      "Training:: Epoch 29, Iteration 70, Current loss 0.7614220442236371 Accuracy 84.87861947937994\n",
      "Training:: Epoch 29, Iteration 80, Current loss 0.6489879190361425 Accuracy 91.40488067952002\n",
      "Training:: Epoch 29, Iteration 90, Current loss 0.7631570494849637 Accuracy 89.17625759731023\n",
      "Training:: Epoch 29, Iteration 100, Current loss 0.9495126973543884 Accuracy 84.52326468344775\n",
      "Training:: Epoch 29, Iteration 110, Current loss 0.658811500259922 Accuracy 91.4057998847705\n",
      "Training:: Epoch 29, Iteration 120, Current loss 0.6917908056924854 Accuracy 87.46608088900375\n",
      "Training:: Epoch 29, Iteration 130, Current loss 0.9486199085783095 Accuracy 87.82249742002064\n",
      "Training:: Epoch 29, Iteration 140, Current loss 0.9846809684817354 Accuracy 87.23141951391335\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 29, Probability Accuracy 64.01643147994432\n",
      "Starting Training\n",
      "Training:: Epoch 30, Iteration 0, Current loss 1.2931411173185108 Accuracy 82.99128030625266\n",
      "Training:: Epoch 30, Iteration 10, Current loss 0.7316610321021157 Accuracy 85.2515243902439\n",
      "Training:: Epoch 30, Iteration 20, Current loss 1.0772410580747183 Accuracy 80.46971569839307\n",
      "Training:: Epoch 30, Iteration 30, Current loss 0.7609275860385678 Accuracy 87.71324365661398\n",
      "Training:: Epoch 30, Iteration 40, Current loss 0.6554476248476486 Accuracy 87.21055465805063\n",
      "Training:: Epoch 30, Iteration 50, Current loss 0.46638062653381207 Accuracy 87.09320889107208\n",
      "Training:: Epoch 30, Iteration 60, Current loss 0.6020176541859725 Accuracy 89.01278710381189\n",
      "Training:: Epoch 30, Iteration 70, Current loss 0.6246692572474422 Accuracy 77.22047177041642\n",
      "Training:: Epoch 30, Iteration 80, Current loss 0.8417131835833491 Accuracy 76.55345259700977\n",
      "Training:: Epoch 30, Iteration 90, Current loss 3.618690699534656 Accuracy 80.6725475890429\n",
      "Training:: Epoch 30, Iteration 100, Current loss 1.3902730099381218 Accuracy 79.15267785771383\n",
      "Training:: Epoch 30, Iteration 110, Current loss 1.150576170880517 Accuracy 88.73158499634312\n",
      "Training:: Epoch 30, Iteration 120, Current loss 1.35964591993566 Accuracy 86.9594108200897\n",
      "Training:: Epoch 30, Iteration 130, Current loss 1.3422928554433842 Accuracy 85.26214393835146\n",
      "Training:: Epoch 30, Iteration 140, Current loss 1.3212582377054733 Accuracy 85.39195576562918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Expectation\n",
      "Epoch 30 iter 0\n",
      "Epoch 30 iter 10\n",
      "Epoch 30 iter 20\n",
      "Epoch 30 iter 30\n",
      "Epoch 30 iter 40\n",
      "Epoch 30 iter 50\n",
      "Epoch 30 iter 60\n",
      "Epoch 30 iter 70\n",
      "Epoch 30 iter 80\n",
      "Epoch 30 iter 90\n",
      "Epoch 30 iter 100\n",
      "Epoch 30 iter 110\n",
      "Epoch 30 iter 120\n",
      "Epoch 30 iter 130\n",
      "Epoch 30 iter 140\n",
      "Train Boundary avergage error = 89.456\n",
      "Train From boundary avergage accuracy = 87.100\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 30, Probability Accuracy 62.801064059242215\n",
      "Starting Training\n",
      "Training:: Epoch 31, Iteration 0, Current loss 1.3611515759945576 Accuracy 79.0379567938623\n",
      "Training:: Epoch 31, Iteration 10, Current loss 1.136381931018063 Accuracy 84.18867924528301\n",
      "Training:: Epoch 31, Iteration 20, Current loss 1.0240495131145668 Accuracy 85.40748898678414\n",
      "Training:: Epoch 31, Iteration 30, Current loss 1.1373213464637146 Accuracy 88.5356928286635\n",
      "Training:: Epoch 31, Iteration 40, Current loss 1.0210399906740844 Accuracy 82.20176797594094\n",
      "Training:: Epoch 31, Iteration 50, Current loss 1.1174306637891314 Accuracy 85.61989895064127\n",
      "Training:: Epoch 31, Iteration 60, Current loss 1.755801677397988 Accuracy 79.16758666372267\n",
      "Training:: Epoch 31, Iteration 70, Current loss 1.6612418746892212 Accuracy 85.44088369404662\n",
      "Training:: Epoch 31, Iteration 80, Current loss 1.534926582283484 Accuracy 81.96152441251674\n",
      "Training:: Epoch 31, Iteration 90, Current loss 0.8385486667004959 Accuracy 90.29582526956041\n",
      "Training:: Epoch 31, Iteration 100, Current loss 1.0798077890042872 Accuracy 90.19518461729726\n",
      "Training:: Epoch 31, Iteration 110, Current loss 1.0173476997552862 Accuracy 85.11422254974208\n",
      "Training:: Epoch 31, Iteration 120, Current loss 0.9760726018019714 Accuracy 81.73798935627323\n",
      "Training:: Epoch 31, Iteration 130, Current loss 1.5504314583814072 Accuracy 86.2281795511222\n",
      "Training:: Epoch 31, Iteration 140, Current loss 0.974578470769526 Accuracy 83.27971233913702\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 31, Probability Accuracy 63.83440414643233\n",
      "Starting Training\n",
      "Training:: Epoch 32, Iteration 0, Current loss 1.0275260198280094 Accuracy 85.97419081870108\n",
      "Training:: Epoch 32, Iteration 10, Current loss 0.6874163289750856 Accuracy 88.39766081871345\n",
      "Training:: Epoch 32, Iteration 20, Current loss 0.9174619583814198 Accuracy 84.00749476468643\n",
      "Training:: Epoch 32, Iteration 30, Current loss 0.7264662320645399 Accuracy 87.31845554374779\n",
      "Training:: Epoch 32, Iteration 40, Current loss 0.9518183297927529 Accuracy 83.47419381307951\n",
      "Training:: Epoch 32, Iteration 50, Current loss 0.7481797552614387 Accuracy 85.70501905456904\n",
      "Training:: Epoch 32, Iteration 60, Current loss 0.8657887793048635 Accuracy 82.91958847315351\n",
      "Training:: Epoch 32, Iteration 70, Current loss 0.7716239125785355 Accuracy 88.71011175440958\n",
      "Training:: Epoch 32, Iteration 80, Current loss 0.6856260102334347 Accuracy 84.8993288590604\n",
      "Training:: Epoch 32, Iteration 90, Current loss 1.0048077356641634 Accuracy 86.75347106888992\n",
      "Training:: Epoch 32, Iteration 100, Current loss 1.5160584527112706 Accuracy 83.08593296996405\n",
      "Training:: Epoch 32, Iteration 110, Current loss 1.2096229275132087 Accuracy 87.80473372781066\n",
      "Training:: Epoch 32, Iteration 120, Current loss 0.8826225701010327 Accuracy 83.18125259228536\n",
      "Training:: Epoch 32, Iteration 130, Current loss 2.1477633628410047 Accuracy 83.21330699126888\n",
      "Training:: Epoch 32, Iteration 140, Current loss 0.8632988563555255 Accuracy 85.22310513447432\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 32, Probability Accuracy 64.92199295420231\n",
      "Starting Training\n",
      "Training:: Epoch 33, Iteration 0, Current loss 1.2836271091097957 Accuracy 76.86054660126139\n",
      "Training:: Epoch 33, Iteration 10, Current loss 1.337420252651829 Accuracy 85.61084720748974\n",
      "Training:: Epoch 33, Iteration 20, Current loss 0.7639122677286069 Accuracy 85.42183343103216\n",
      "Training:: Epoch 33, Iteration 30, Current loss 0.7621518994779233 Accuracy 90.1001068333795\n",
      "Training:: Epoch 33, Iteration 40, Current loss 0.8142308956033788 Accuracy 88.14308258811153\n",
      "Training:: Epoch 33, Iteration 50, Current loss 1.0183165610651228 Accuracy 81.7967460504598\n",
      "Training:: Epoch 33, Iteration 60, Current loss 0.6948010934668765 Accuracy 90.63611031036803\n",
      "Training:: Epoch 33, Iteration 70, Current loss 0.5106928961100989 Accuracy 83.81334541453627\n",
      "Training:: Epoch 33, Iteration 80, Current loss 1.1129906476446334 Accuracy 81.72006537358537\n",
      "Training:: Epoch 33, Iteration 90, Current loss 0.6683117134755672 Accuracy 88.42741488299878\n",
      "Training:: Epoch 33, Iteration 100, Current loss 0.9692379069683805 Accuracy 81.30411255411255\n",
      "Training:: Epoch 33, Iteration 110, Current loss 0.5337396803781824 Accuracy 85.27287571437543\n",
      "Training:: Epoch 33, Iteration 120, Current loss 1.4685506424592438 Accuracy 80.88797580323003\n",
      "Training:: Epoch 33, Iteration 130, Current loss 0.8142443247458683 Accuracy 84.89494605337876\n",
      "Training:: Epoch 33, Iteration 140, Current loss 0.9039274366586012 Accuracy 84.69527059970746\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 33, Probability Accuracy 65.2347400963405\n",
      "Starting Training\n",
      "Training:: Epoch 34, Iteration 0, Current loss 0.7264234273959786 Accuracy 86.09600501987032\n",
      "Training:: Epoch 34, Iteration 10, Current loss 0.9346449347686675 Accuracy 83.11908195898916\n",
      "Training:: Epoch 34, Iteration 20, Current loss 0.6882105294301984 Accuracy 84.27016645326505\n",
      "Training:: Epoch 34, Iteration 30, Current loss 0.7666301174707987 Accuracy 89.21091086215294\n",
      "Training:: Epoch 34, Iteration 40, Current loss 0.7537396927128696 Accuracy 78.846241406001\n",
      "Training:: Epoch 34, Iteration 50, Current loss 0.8374008612644501 Accuracy 86.99222126188418\n",
      "Training:: Epoch 34, Iteration 60, Current loss 1.053238817078597 Accuracy 87.10446719404374\n",
      "Training:: Epoch 34, Iteration 70, Current loss 0.918412462302575 Accuracy 88.1708572268784\n",
      "Training:: Epoch 34, Iteration 80, Current loss 0.9244479584512875 Accuracy 85.99241609598732\n",
      "Training:: Epoch 34, Iteration 90, Current loss 0.8875104968673673 Accuracy 90.12000950570342\n",
      "Training:: Epoch 34, Iteration 100, Current loss 0.9245318643285103 Accuracy 83.09794524040177\n",
      "Training:: Epoch 34, Iteration 110, Current loss 0.5805951000206423 Accuracy 84.27621980872102\n",
      "Training:: Epoch 34, Iteration 120, Current loss 0.9732343450114246 Accuracy 85.31585047812229\n",
      "Training:: Epoch 34, Iteration 130, Current loss 0.7350154120579216 Accuracy 85.09485094850949\n",
      "Training:: Epoch 34, Iteration 140, Current loss 1.0899657862960215 Accuracy 82.72859216255442\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 34, Probability Accuracy 64.93808783063942\n",
      "Starting Training\n",
      "Training:: Epoch 35, Iteration 0, Current loss 0.9534239560869564 Accuracy 83.71056852610943\n",
      "Training:: Epoch 35, Iteration 10, Current loss 0.7937518198682781 Accuracy 85.32651218778213\n",
      "Training:: Epoch 35, Iteration 20, Current loss 0.7170304890209845 Accuracy 89.94897959183673\n",
      "Training:: Epoch 35, Iteration 30, Current loss 0.8790829426871843 Accuracy 86.41982681397432\n",
      "Training:: Epoch 35, Iteration 40, Current loss 1.2859579667487928 Accuracy 83.9483849757541\n",
      "Training:: Epoch 35, Iteration 50, Current loss 0.7229575024962785 Accuracy 87.49147339699863\n",
      "Training:: Epoch 35, Iteration 60, Current loss 0.5551463064645391 Accuracy 90.11853136744723\n",
      "Training:: Epoch 35, Iteration 70, Current loss 1.085136561797699 Accuracy 83.63903154805575\n",
      "Training:: Epoch 35, Iteration 80, Current loss 0.7328247494888601 Accuracy 88.4046915228378\n",
      "Training:: Epoch 35, Iteration 90, Current loss 0.853177204891898 Accuracy 85.9797410612464\n",
      "Training:: Epoch 35, Iteration 100, Current loss 0.4832728388085933 Accuracy 87.56845829496437\n",
      "Training:: Epoch 35, Iteration 110, Current loss 0.5646773851115626 Accuracy 89.23423987968417\n",
      "Training:: Epoch 35, Iteration 120, Current loss 0.7086219822527631 Accuracy 83.66866050389704\n",
      "Training:: Epoch 35, Iteration 130, Current loss 0.7203686683450764 Accuracy 87.14561855670104\n",
      "Training:: Epoch 35, Iteration 140, Current loss 0.9005918667010332 Accuracy 82.86103670285257\n",
      "Calculating Expectation\n",
      "Epoch 35 iter 0\n",
      "Epoch 35 iter 10\n",
      "Epoch 35 iter 20\n",
      "Epoch 35 iter 30\n",
      "Epoch 35 iter 40\n",
      "Epoch 35 iter 50\n",
      "Epoch 35 iter 60\n",
      "Epoch 35 iter 70\n",
      "Epoch 35 iter 80\n",
      "Epoch 35 iter 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 iter 100\n",
      "Epoch 35 iter 110\n",
      "Epoch 35 iter 120\n",
      "Epoch 35 iter 130\n",
      "Epoch 35 iter 140\n",
      "Train Boundary avergage error = 83.947\n",
      "Train From boundary avergage accuracy = 87.601\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 35, Probability Accuracy 63.73064529833528\n",
      "Starting Training\n",
      "Training:: Epoch 36, Iteration 0, Current loss 2.073209094847968 Accuracy 89.20977153595095\n",
      "Training:: Epoch 36, Iteration 10, Current loss 1.465784879713677 Accuracy 77.49129256965944\n",
      "Training:: Epoch 36, Iteration 20, Current loss 0.9004424373195352 Accuracy 83.0796721917555\n",
      "Training:: Epoch 36, Iteration 30, Current loss 1.0556056273119254 Accuracy 87.16550319953461\n",
      "Training:: Epoch 36, Iteration 40, Current loss 0.7337957745337411 Accuracy 78.68277072365025\n",
      "Training:: Epoch 36, Iteration 50, Current loss 0.6379597241566372 Accuracy 87.26482458863707\n",
      "Training:: Epoch 36, Iteration 60, Current loss 0.7494418367072104 Accuracy 82.71788927526633\n",
      "Training:: Epoch 36, Iteration 70, Current loss 0.7691947850099132 Accuracy 83.8944572946115\n",
      "Training:: Epoch 36, Iteration 80, Current loss 0.8043404143573931 Accuracy 84.15285577318176\n",
      "Training:: Epoch 36, Iteration 90, Current loss 0.6292915349649099 Accuracy 83.633853151397\n",
      "Training:: Epoch 36, Iteration 100, Current loss 1.0013469131411175 Accuracy 87.02420909805042\n",
      "Training:: Epoch 36, Iteration 110, Current loss 0.9588913726984184 Accuracy 78.72280701754386\n",
      "Training:: Epoch 36, Iteration 120, Current loss 0.8627332136942778 Accuracy 83.49506075705918\n",
      "Training:: Epoch 36, Iteration 130, Current loss 0.5211281695284231 Accuracy 87.89598509232593\n",
      "Training:: Epoch 36, Iteration 140, Current loss 1.2507230146265933 Accuracy 81.06197144045474\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 36, Probability Accuracy 65.52943156491219\n",
      "Starting Training\n",
      "Training:: Epoch 37, Iteration 0, Current loss 0.7207394627905352 Accuracy 88.62506902263942\n",
      "Training:: Epoch 37, Iteration 10, Current loss 0.5884960032974044 Accuracy 91.41976605729495\n",
      "Training:: Epoch 37, Iteration 20, Current loss 0.6586725125200118 Accuracy 82.8453214513049\n",
      "Training:: Epoch 37, Iteration 30, Current loss 0.7450439769902543 Accuracy 81.64237123420797\n",
      "Training:: Epoch 37, Iteration 40, Current loss 0.6180927099345672 Accuracy 88.89536012424772\n",
      "Training:: Epoch 37, Iteration 50, Current loss 0.8147698745245315 Accuracy 89.69653524492234\n",
      "Training:: Epoch 37, Iteration 60, Current loss 0.46023097819373804 Accuracy 90.34754185844841\n",
      "Training:: Epoch 37, Iteration 70, Current loss 0.6703888225046002 Accuracy 89.18250515227845\n",
      "Training:: Epoch 37, Iteration 80, Current loss 0.568392202995985 Accuracy 88.37966640190628\n",
      "Training:: Epoch 37, Iteration 90, Current loss 0.7400761596161344 Accuracy 84.7313760734971\n",
      "Training:: Epoch 37, Iteration 100, Current loss 0.6198731611565228 Accuracy 82.70239614348505\n",
      "Training:: Epoch 37, Iteration 110, Current loss 0.6518206281940873 Accuracy 86.50093771198276\n",
      "Training:: Epoch 37, Iteration 120, Current loss 0.5339327583652779 Accuracy 80.40295695028264\n",
      "Training:: Epoch 37, Iteration 130, Current loss 0.5546040770006716 Accuracy 87.3070987654321\n",
      "Training:: Epoch 37, Iteration 140, Current loss 0.46806261508347435 Accuracy 89.60049062554758\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 37, Probability Accuracy 65.17656978150184\n",
      "Starting Training\n",
      "Training:: Epoch 38, Iteration 0, Current loss 0.47383741775867055 Accuracy 92.33075435203095\n",
      "Training:: Epoch 38, Iteration 10, Current loss 0.47849029745572097 Accuracy 90.321577684996\n",
      "Training:: Epoch 38, Iteration 20, Current loss 0.3845727080490096 Accuracy 86.99873131446853\n",
      "Training:: Epoch 38, Iteration 30, Current loss 0.532647117464062 Accuracy 87.32099581405596\n",
      "Training:: Epoch 38, Iteration 40, Current loss 0.5777607607049866 Accuracy 86.43347050754458\n",
      "Training:: Epoch 38, Iteration 50, Current loss 0.5145840917370974 Accuracy 88.98274130216419\n",
      "Training:: Epoch 38, Iteration 60, Current loss 0.5849599863947361 Accuracy 81.24865330747684\n",
      "Training:: Epoch 38, Iteration 70, Current loss 0.7024409779117202 Accuracy 89.95934959349593\n",
      "Training:: Epoch 38, Iteration 80, Current loss 0.42105200405830634 Accuracy 88.13641730916163\n",
      "Training:: Epoch 38, Iteration 90, Current loss 0.3997947594536656 Accuracy 91.598554590037\n",
      "Training:: Epoch 38, Iteration 100, Current loss 0.423896241511716 Accuracy 89.58672171483381\n",
      "Training:: Epoch 38, Iteration 110, Current loss 0.6982285154331638 Accuracy 86.57930201217529\n",
      "Training:: Epoch 38, Iteration 120, Current loss 0.7511813636059197 Accuracy 85.51845342706503\n",
      "Training:: Epoch 38, Iteration 130, Current loss 0.7579583482412833 Accuracy 89.70362935178827\n",
      "Training:: Epoch 38, Iteration 140, Current loss 0.7050938513525076 Accuracy 83.73789914752203\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 38, Probability Accuracy 64.08448748031033\n",
      "Starting Training\n",
      "Training:: Epoch 39, Iteration 0, Current loss 0.7234127446508722 Accuracy 85.04627374573795\n",
      "Training:: Epoch 39, Iteration 10, Current loss 0.8711925262492254 Accuracy 85.4248468666562\n",
      "Training:: Epoch 39, Iteration 20, Current loss 0.6252021064536866 Accuracy 83.27391102154705\n",
      "Training:: Epoch 39, Iteration 30, Current loss 0.6081046877776054 Accuracy 86.4645516131196\n",
      "Training:: Epoch 39, Iteration 40, Current loss 0.6166715017779872 Accuracy 83.56340092841437\n",
      "Training:: Epoch 39, Iteration 50, Current loss 0.6525004714402186 Accuracy 88.44440139480821\n",
      "Training:: Epoch 39, Iteration 60, Current loss 0.5675827207453544 Accuracy 86.70103092783505\n",
      "Training:: Epoch 39, Iteration 70, Current loss 0.5857965878359492 Accuracy 88.23586649800525\n",
      "Training:: Epoch 39, Iteration 80, Current loss 0.7095736538412637 Accuracy 78.56602822580645\n",
      "Training:: Epoch 39, Iteration 90, Current loss 0.5383518694080528 Accuracy 85.94798164057903\n",
      "Training:: Epoch 39, Iteration 100, Current loss 0.9608478318885209 Accuracy 84.33927147035362\n",
      "Training:: Epoch 39, Iteration 110, Current loss 0.3851058540019572 Accuracy 89.99397681072128\n",
      "Training:: Epoch 39, Iteration 120, Current loss 0.45604819263434715 Accuracy 84.75446257565311\n",
      "Training:: Epoch 39, Iteration 130, Current loss 0.5369539742081278 Accuracy 82.05159856807802\n",
      "Training:: Epoch 39, Iteration 140, Current loss 0.616907362027293 Accuracy 87.0479308404522\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 39, Probability Accuracy 65.04102967993255\n",
      "Starting Training\n",
      "Training:: Epoch 40, Iteration 0, Current loss 0.36575377938311704 Accuracy 92.024111991232\n",
      "Training:: Epoch 40, Iteration 10, Current loss 0.5541426786408911 Accuracy 85.7416923603974\n",
      "Training:: Epoch 40, Iteration 20, Current loss 0.566377163287884 Accuracy 85.86211994283744\n",
      "Training:: Epoch 40, Iteration 30, Current loss 0.5053139810835314 Accuracy 82.49947000211999\n",
      "Training:: Epoch 40, Iteration 40, Current loss 0.5057635631642373 Accuracy 93.08078273958856\n",
      "Training:: Epoch 40, Iteration 50, Current loss 0.46175647208242543 Accuracy 87.09105242412298\n",
      "Training:: Epoch 40, Iteration 60, Current loss 0.4853388768584447 Accuracy 84.49065914698625\n",
      "Training:: Epoch 40, Iteration 70, Current loss 0.4737110942039578 Accuracy 83.68140155470472\n",
      "Training:: Epoch 40, Iteration 80, Current loss 0.41272041942545445 Accuracy 87.54341648247554\n",
      "Training:: Epoch 40, Iteration 90, Current loss 0.45817810064808295 Accuracy 84.16921064108155\n",
      "Training:: Epoch 40, Iteration 100, Current loss 0.5342763033983972 Accuracy 88.18197817669835\n",
      "Training:: Epoch 40, Iteration 110, Current loss 0.5516043136994564 Accuracy 89.80706648070665\n",
      "Training:: Epoch 40, Iteration 120, Current loss 0.6434697692405195 Accuracy 85.46511627906976\n",
      "Training:: Epoch 40, Iteration 130, Current loss 0.5572356354288316 Accuracy 89.85752714954668\n",
      "Training:: Epoch 40, Iteration 140, Current loss 0.6262749896955616 Accuracy 83.1049517284335\n",
      "Calculating Expectation\n",
      "Epoch 40 iter 0\n",
      "Epoch 40 iter 10\n",
      "Epoch 40 iter 20\n",
      "Epoch 40 iter 30\n",
      "Epoch 40 iter 40\n",
      "Epoch 40 iter 50\n",
      "Epoch 40 iter 60\n",
      "Epoch 40 iter 70\n",
      "Epoch 40 iter 80\n",
      "Epoch 40 iter 90\n",
      "Epoch 40 iter 100\n",
      "Epoch 40 iter 110\n",
      "Epoch 40 iter 120\n",
      "Epoch 40 iter 130\n",
      "Epoch 40 iter 140\n",
      "Train Boundary avergage error = 82.445\n",
      "Train From boundary avergage accuracy = 87.780\n",
      "Calculating Validation Data Accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 40, Probability Accuracy 65.06308864763822\n",
      "Starting Training\n",
      "Training:: Epoch 41, Iteration 0, Current loss 0.40734903190962124 Accuracy 88.36284560422492\n",
      "Training:: Epoch 41, Iteration 10, Current loss 0.9147332756886107 Accuracy 78.30381881701\n",
      "Training:: Epoch 41, Iteration 20, Current loss 0.5051849820207027 Accuracy 86.9837296620776\n",
      "Training:: Epoch 41, Iteration 30, Current loss 0.4127926116859051 Accuracy 85.33021210186564\n",
      "Training:: Epoch 41, Iteration 40, Current loss 0.5042227840838841 Accuracy 85.56298773690078\n",
      "Training:: Epoch 41, Iteration 50, Current loss 0.3831133439187121 Accuracy 88.79855465221318\n",
      "Training:: Epoch 41, Iteration 60, Current loss 0.3761551645338624 Accuracy 89.79477402713917\n",
      "Training:: Epoch 41, Iteration 70, Current loss 0.6021401265997114 Accuracy 87.21435006962078\n",
      "Training:: Epoch 41, Iteration 80, Current loss 0.4721830521324605 Accuracy 88.07105571966171\n",
      "Training:: Epoch 41, Iteration 90, Current loss 0.4385665022962484 Accuracy 90.56248246000882\n",
      "Training:: Epoch 41, Iteration 100, Current loss 0.45511788614108395 Accuracy 85.02533308313005\n",
      "Training:: Epoch 41, Iteration 110, Current loss 0.4578318798284634 Accuracy 88.41890001076311\n",
      "Training:: Epoch 41, Iteration 120, Current loss 0.5899291708497969 Accuracy 87.82677092490631\n",
      "Training:: Epoch 41, Iteration 130, Current loss 0.6050839289746278 Accuracy 87.08094283541854\n",
      "Training:: Epoch 41, Iteration 140, Current loss 0.38963988914881603 Accuracy 89.17113037716052\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 41, Probability Accuracy 64.92722174654736\n",
      "Starting Training\n",
      "Training:: Epoch 42, Iteration 0, Current loss 0.6954928271007289 Accuracy 83.67045750499176\n",
      "Training:: Epoch 42, Iteration 10, Current loss 0.5196348473814182 Accuracy 86.7491383554899\n",
      "Training:: Epoch 42, Iteration 20, Current loss 0.37859664933104065 Accuracy 86.69570628500311\n",
      "Training:: Epoch 42, Iteration 30, Current loss 0.33002264660440644 Accuracy 89.8964306351958\n",
      "Training:: Epoch 42, Iteration 40, Current loss 0.47720429559214866 Accuracy 89.53336596508403\n",
      "Training:: Epoch 42, Iteration 50, Current loss 0.6554991194111668 Accuracy 83.5506220666021\n",
      "Training:: Epoch 42, Iteration 60, Current loss 0.4971655770405325 Accuracy 82.02301246842802\n",
      "Training:: Epoch 42, Iteration 70, Current loss 0.45792515145683815 Accuracy 90.54527263631816\n",
      "Training:: Epoch 42, Iteration 80, Current loss 0.41995011294131884 Accuracy 89.36214767349333\n",
      "Training:: Epoch 42, Iteration 90, Current loss 0.401610012231789 Accuracy 86.98336763642432\n",
      "Training:: Epoch 42, Iteration 100, Current loss 5.441013747488801 Accuracy 66.38697349838\n",
      "Training:: Epoch 42, Iteration 110, Current loss 3.052039222569273 Accuracy 77.13400642496558\n",
      "Training:: Epoch 42, Iteration 120, Current loss 2.013627023738114 Accuracy 82.13214132631192\n",
      "Training:: Epoch 42, Iteration 130, Current loss 3.105755069925551 Accuracy 75.10777720296603\n",
      "Training:: Epoch 42, Iteration 140, Current loss 6.893068024687417 Accuracy 44.66106986748075\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 42, Probability Accuracy 54.43466950764384\n",
      "Starting Training\n",
      "Training:: Epoch 43, Iteration 0, Current loss 2.191433927284389 Accuracy 82.00122025625382\n",
      "Training:: Epoch 43, Iteration 10, Current loss 5.399878744151796 Accuracy 64.16348639665148\n",
      "Training:: Epoch 43, Iteration 20, Current loss 3.5302182384445002 Accuracy 65.74029041895366\n",
      "Training:: Epoch 43, Iteration 30, Current loss 2.895866166524736 Accuracy 75.6154879140555\n",
      "Training:: Epoch 43, Iteration 40, Current loss 2.81457309012708 Accuracy 71.31228765571915\n",
      "Training:: Epoch 43, Iteration 50, Current loss 2.3716825784545468 Accuracy 80.75492748233545\n",
      "Training:: Epoch 43, Iteration 60, Current loss 4.001494579587062 Accuracy 68.76886950687688\n",
      "Training:: Epoch 43, Iteration 70, Current loss 3.388364672167117 Accuracy 70.22544853635505\n",
      "Training:: Epoch 43, Iteration 80, Current loss 2.7860444428858884 Accuracy 80.73261941186469\n",
      "Training:: Epoch 43, Iteration 90, Current loss 2.272769958945889 Accuracy 73.61608775137111\n",
      "Training:: Epoch 43, Iteration 100, Current loss 2.105279452338009 Accuracy 67.95762992386626\n",
      "Training:: Epoch 43, Iteration 110, Current loss 1.5897750382624265 Accuracy 85.16083587696643\n",
      "Training:: Epoch 43, Iteration 120, Current loss 1.4667538848638682 Accuracy 79.57995058242146\n",
      "Training:: Epoch 43, Iteration 130, Current loss 2.8794980937043047 Accuracy 78.422037978069\n",
      "Training:: Epoch 43, Iteration 140, Current loss 1.3760672532558034 Accuracy 81.00749704064185\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 43, Probability Accuracy 64.16847495735266\n",
      "Starting Training\n",
      "Training:: Epoch 44, Iteration 0, Current loss 1.0091951582262169 Accuracy 90.72268067016755\n",
      "Training:: Epoch 44, Iteration 10, Current loss 1.0680370261258465 Accuracy 85.73367457732279\n",
      "Training:: Epoch 44, Iteration 20, Current loss 1.354698948651717 Accuracy 84.66242459300884\n",
      "Training:: Epoch 44, Iteration 30, Current loss 1.1726928627404782 Accuracy 90.72027544843672\n",
      "Training:: Epoch 44, Iteration 40, Current loss 1.035458904025462 Accuracy 82.54573764110549\n",
      "Training:: Epoch 44, Iteration 50, Current loss 0.7813738361135529 Accuracy 87.80089759281925\n",
      "Training:: Epoch 44, Iteration 60, Current loss 0.6142835142848999 Accuracy 86.37889313870892\n",
      "Training:: Epoch 44, Iteration 70, Current loss 0.7231655928191238 Accuracy 87.17629601263702\n",
      "Training:: Epoch 44, Iteration 80, Current loss 0.7323989307091312 Accuracy 87.37037916567719\n",
      "Training:: Epoch 44, Iteration 90, Current loss 0.865736379784297 Accuracy 86.35512618887141\n",
      "Training:: Epoch 44, Iteration 100, Current loss 0.7300563040817287 Accuracy 83.22133408785457\n",
      "Training:: Epoch 44, Iteration 110, Current loss 0.7027534867950694 Accuracy 84.40152801358234\n",
      "Training:: Epoch 44, Iteration 120, Current loss 0.7154782243274592 Accuracy 88.01944728761515\n",
      "Training:: Epoch 44, Iteration 130, Current loss 0.8079998588778696 Accuracy 88.73888353155469\n",
      "Training:: Epoch 44, Iteration 140, Current loss 0.8306431243681336 Accuracy 89.90978256350559\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 44, Probability Accuracy 65.0594121530206\n",
      "Starting Training\n",
      "Training:: Epoch 45, Iteration 0, Current loss 0.5529402051169876 Accuracy 88.01373719175768\n",
      "Training:: Epoch 45, Iteration 10, Current loss 0.6354467161331241 Accuracy 83.42466728346737\n",
      "Training:: Epoch 45, Iteration 20, Current loss 0.6538699218575044 Accuracy 86.83074956049225\n",
      "Training:: Epoch 45, Iteration 30, Current loss 0.8967194257721921 Accuracy 88.16014321751159\n",
      "Training:: Epoch 45, Iteration 40, Current loss 0.4510201720081786 Accuracy 88.95291405992756\n",
      "Training:: Epoch 45, Iteration 50, Current loss 0.4556009984765598 Accuracy 86.60526315789474\n",
      "Training:: Epoch 45, Iteration 60, Current loss 0.7083817335886684 Accuracy 81.84804928131418\n",
      "Training:: Epoch 45, Iteration 70, Current loss 0.5062161024044329 Accuracy 86.74085349850401\n",
      "Training:: Epoch 45, Iteration 80, Current loss 2.2537355674778023 Accuracy 79.59364938381259\n",
      "Training:: Epoch 45, Iteration 90, Current loss 0.7870289682382144 Accuracy 87.75386742718867\n",
      "Training:: Epoch 45, Iteration 100, Current loss 0.5935979613773199 Accuracy 86.29375591296122\n",
      "Training:: Epoch 45, Iteration 110, Current loss 0.7378673526035149 Accuracy 91.79563530932884\n",
      "Training:: Epoch 45, Iteration 120, Current loss 0.6325579643790558 Accuracy 89.82475207172938\n",
      "Training:: Epoch 45, Iteration 130, Current loss 0.4095736403568345 Accuracy 93.11700706241649\n",
      "Training:: Epoch 45, Iteration 140, Current loss 0.4321981901037965 Accuracy 88.9182678183207\n",
      "Calculating Expectation\n",
      "Epoch 45 iter 0\n",
      "Epoch 45 iter 10\n",
      "Epoch 45 iter 20\n",
      "Epoch 45 iter 30\n",
      "Epoch 45 iter 40\n",
      "Epoch 45 iter 50\n",
      "Epoch 45 iter 60\n",
      "Epoch 45 iter 70\n",
      "Epoch 45 iter 80\n",
      "Epoch 45 iter 90\n",
      "Epoch 45 iter 100\n",
      "Epoch 45 iter 110\n",
      "Epoch 45 iter 120\n",
      "Epoch 45 iter 130\n",
      "Epoch 45 iter 140\n",
      "Train Boundary avergage error = 82.212\n",
      "Train From boundary avergage accuracy = 87.811\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 45, Probability Accuracy 66.38335871476284\n",
      "Starting Training\n",
      "Training:: Epoch 46, Iteration 0, Current loss 0.4180419640225068 Accuracy 88.54365230651925\n",
      "Training:: Epoch 46, Iteration 10, Current loss 0.34157757775836173 Accuracy 89.14328419050207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 46, Iteration 20, Current loss 0.40172782740416435 Accuracy 88.55116934815061\n",
      "Training:: Epoch 46, Iteration 30, Current loss 0.4288736589310698 Accuracy 91.9994986631016\n",
      "Training:: Epoch 46, Iteration 40, Current loss 0.5978105013005827 Accuracy 79.17876399834094\n",
      "Training:: Epoch 46, Iteration 50, Current loss 0.5435002439833422 Accuracy 80.18021691266411\n",
      "Training:: Epoch 46, Iteration 60, Current loss 0.44555304675373175 Accuracy 90.18360444516026\n",
      "Training:: Epoch 46, Iteration 70, Current loss 0.5596945418445295 Accuracy 91.5614478114478\n",
      "Training:: Epoch 46, Iteration 80, Current loss 0.35242536004940317 Accuracy 91.29268386157207\n",
      "Training:: Epoch 46, Iteration 90, Current loss 0.34987923668106735 Accuracy 91.92923459317201\n",
      "Training:: Epoch 46, Iteration 100, Current loss 0.5633921469913205 Accuracy 86.80134283526709\n",
      "Training:: Epoch 46, Iteration 110, Current loss 0.4381263782117122 Accuracy 83.05408970976254\n",
      "Training:: Epoch 46, Iteration 120, Current loss 0.37401249975234113 Accuracy 88.00687285223368\n",
      "Training:: Epoch 46, Iteration 130, Current loss 0.7543537047813824 Accuracy 84.11036316795479\n",
      "Training:: Epoch 46, Iteration 140, Current loss 0.4803080619655774 Accuracy 91.42857142857143\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 46, Probability Accuracy 65.67256975535788\n",
      "Starting Training\n",
      "Training:: Epoch 47, Iteration 0, Current loss 0.4742716544121063 Accuracy 89.65331417280403\n",
      "Training:: Epoch 47, Iteration 10, Current loss 0.3224082972536944 Accuracy 88.53397886284466\n",
      "Training:: Epoch 47, Iteration 20, Current loss 0.41409163660549075 Accuracy 85.52423414353517\n",
      "Training:: Epoch 47, Iteration 30, Current loss 0.35852525912510613 Accuracy 90.25058507905702\n",
      "Training:: Epoch 47, Iteration 40, Current loss 0.37598684365239204 Accuracy 83.74679213002567\n",
      "Training:: Epoch 47, Iteration 50, Current loss 0.5556127263016658 Accuracy 89.12650028576871\n",
      "Training:: Epoch 47, Iteration 60, Current loss 0.32320914080520063 Accuracy 90.05536274995869\n",
      "Training:: Epoch 47, Iteration 70, Current loss 0.3992975210454719 Accuracy 84.10899770673142\n",
      "Training:: Epoch 47, Iteration 80, Current loss 0.33407335649798814 Accuracy 88.56682769726248\n",
      "Training:: Epoch 47, Iteration 90, Current loss 0.26628709609782575 Accuracy 92.88144001133867\n",
      "Training:: Epoch 47, Iteration 100, Current loss 0.35280626238007334 Accuracy 89.31904963937208\n",
      "Training:: Epoch 47, Iteration 110, Current loss 0.3588179557199035 Accuracy 87.53840094525404\n",
      "Training:: Epoch 47, Iteration 120, Current loss 0.35084618847882526 Accuracy 89.17015776807202\n",
      "Training:: Epoch 47, Iteration 130, Current loss 1.284487444771199 Accuracy 82.4897171157559\n",
      "Training:: Epoch 47, Iteration 140, Current loss 0.5803543897390251 Accuracy 88.04106724127004\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 47, Probability Accuracy 66.07273576951484\n",
      "Starting Training\n",
      "Training:: Epoch 48, Iteration 0, Current loss 0.6387710752047857 Accuracy 87.31841170773701\n",
      "Training:: Epoch 48, Iteration 10, Current loss 0.837842736095161 Accuracy 85.14303877940242\n",
      "Training:: Epoch 48, Iteration 20, Current loss 0.7471667969208038 Accuracy 85.32313373780005\n",
      "Training:: Epoch 48, Iteration 30, Current loss 0.9902513014938032 Accuracy 88.39621418384546\n",
      "Training:: Epoch 48, Iteration 40, Current loss 0.5544004391330805 Accuracy 90.25504377617054\n",
      "Training:: Epoch 48, Iteration 50, Current loss 0.775570320612121 Accuracy 83.67747564344918\n",
      "Training:: Epoch 48, Iteration 60, Current loss 0.6811071092392277 Accuracy 83.42262454584642\n",
      "Training:: Epoch 48, Iteration 70, Current loss 1.748005695297346 Accuracy 88.9708528247571\n",
      "Training:: Epoch 48, Iteration 80, Current loss 1.0195261941814597 Accuracy 86.72088840228356\n",
      "Training:: Epoch 48, Iteration 90, Current loss 0.6543002078253447 Accuracy 79.79193247619982\n",
      "Training:: Epoch 48, Iteration 100, Current loss 0.7499717238372283 Accuracy 93.22000395335047\n",
      "Training:: Epoch 48, Iteration 110, Current loss 0.6781274793311828 Accuracy 87.21268465179946\n",
      "Training:: Epoch 48, Iteration 120, Current loss 0.7575762186118632 Accuracy 90.82804472650348\n",
      "Training:: Epoch 48, Iteration 130, Current loss 0.46382627826152106 Accuracy 91.39516552811351\n",
      "Training:: Epoch 48, Iteration 140, Current loss 3.727501650292247 Accuracy 77.98572711375773\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 48, Probability Accuracy 65.69005352976163\n",
      "Starting Training\n",
      "Training:: Epoch 49, Iteration 0, Current loss 3.5301129023295807 Accuracy 72.65339292970337\n",
      "Training:: Epoch 49, Iteration 10, Current loss 1.2648641375583791 Accuracy 84.75233503051557\n",
      "Training:: Epoch 49, Iteration 20, Current loss 8.215911232360227 Accuracy 62.68789264217347\n",
      "Training:: Epoch 49, Iteration 30, Current loss 1.3729174263657755 Accuracy 80.98765432098766\n",
      "Training:: Epoch 49, Iteration 40, Current loss 1.1612432862380682 Accuracy 81.14307682450183\n",
      "Training:: Epoch 49, Iteration 50, Current loss 0.7574221374701867 Accuracy 92.24337110793266\n",
      "Training:: Epoch 49, Iteration 60, Current loss 0.632061429115633 Accuracy 89.45252874732878\n",
      "Training:: Epoch 49, Iteration 70, Current loss 0.9034182543605022 Accuracy 84.85592453805401\n",
      "Training:: Epoch 49, Iteration 80, Current loss 0.6676348176492025 Accuracy 87.31158038637263\n",
      "Training:: Epoch 49, Iteration 90, Current loss 0.4833414568403029 Accuracy 86.43274289299677\n",
      "Training:: Epoch 49, Iteration 100, Current loss 0.5159042885231712 Accuracy 88.15561742794793\n",
      "Training:: Epoch 49, Iteration 110, Current loss 0.9259121207556482 Accuracy 85.99254623444202\n",
      "Training:: Epoch 49, Iteration 120, Current loss 0.6023988231520119 Accuracy 91.11627906976744\n",
      "Training:: Epoch 49, Iteration 130, Current loss 0.5335098547573578 Accuracy 82.91280366154207\n",
      "Training:: Epoch 49, Iteration 140, Current loss 0.4084501015806345 Accuracy 87.53139864250976\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 49, Probability Accuracy 65.2868646200302\n",
      "Starting Training\n",
      "Training:: Epoch 50, Iteration 0, Current loss 0.41838854120388996 Accuracy 89.20087317553397\n",
      "Training:: Epoch 50, Iteration 10, Current loss 0.6476716333317265 Accuracy 81.95121951219512\n",
      "Training:: Epoch 50, Iteration 20, Current loss 0.4113808466393209 Accuracy 89.87919463087249\n",
      "Training:: Epoch 50, Iteration 30, Current loss 0.48922617053554873 Accuracy 87.74599842561008\n",
      "Training:: Epoch 50, Iteration 40, Current loss 0.4209236932787509 Accuracy 90.56308980688706\n",
      "Training:: Epoch 50, Iteration 50, Current loss 0.4089705481391137 Accuracy 92.10000832015974\n",
      "Training:: Epoch 50, Iteration 60, Current loss 0.32796882493408885 Accuracy 90.51039865194448\n",
      "Training:: Epoch 50, Iteration 70, Current loss 0.44876017576353755 Accuracy 81.16461366181412\n",
      "Training:: Epoch 50, Iteration 80, Current loss 1.3138966208859846 Accuracy 83.00401184807468\n",
      "Training:: Epoch 50, Iteration 90, Current loss 0.588315850870495 Accuracy 90.33887105909005\n",
      "Training:: Epoch 50, Iteration 100, Current loss 0.7364789314769642 Accuracy 88.1654712597232\n",
      "Training:: Epoch 50, Iteration 110, Current loss 0.4904668355260409 Accuracy 88.94477978985022\n",
      "Training:: Epoch 50, Iteration 120, Current loss 0.34832962609495594 Accuracy 88.29787234042553\n",
      "Training:: Epoch 50, Iteration 130, Current loss 0.32155374888858984 Accuracy 92.13512455980175\n",
      "Training:: Epoch 50, Iteration 140, Current loss 0.5446775125286489 Accuracy 87.08042600073449\n",
      "Calculating Expectation\n",
      "Epoch 50 iter 0\n",
      "Epoch 50 iter 10\n",
      "Epoch 50 iter 20\n",
      "Epoch 50 iter 30\n",
      "Epoch 50 iter 40\n",
      "Epoch 50 iter 50\n",
      "Epoch 50 iter 60\n",
      "Epoch 50 iter 70\n",
      "Epoch 50 iter 80\n",
      "Epoch 50 iter 90\n",
      "Epoch 50 iter 100\n",
      "Epoch 50 iter 110\n",
      "Epoch 50 iter 120\n",
      "Epoch 50 iter 130\n",
      "Epoch 50 iter 140\n",
      "Train Boundary avergage error = 83.599\n",
      "Train From boundary avergage accuracy = 87.614\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 50, Probability Accuracy 65.33106425532193\n",
      "Starting Training\n",
      "Training:: Epoch 51, Iteration 0, Current loss 0.45777017032697875 Accuracy 86.64255716285581\n",
      "Training:: Epoch 51, Iteration 10, Current loss 0.5573390252338808 Accuracy 85.57869580061454\n",
      "Training:: Epoch 51, Iteration 20, Current loss 0.34222509389471495 Accuracy 88.46442572357995\n",
      "Training:: Epoch 51, Iteration 30, Current loss 0.45598757271266627 Accuracy 90.43416185346226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 51, Iteration 40, Current loss 0.3161944675400019 Accuracy 91.58594491927825\n",
      "Training:: Epoch 51, Iteration 50, Current loss 0.3691043604240503 Accuracy 89.39381374906709\n",
      "Training:: Epoch 51, Iteration 60, Current loss 0.26644665051306754 Accuracy 91.02757839063091\n",
      "Training:: Epoch 51, Iteration 70, Current loss 0.32504380058096655 Accuracy 90.59192929410396\n",
      "Training:: Epoch 51, Iteration 80, Current loss 0.30461275777049934 Accuracy 91.56034302447186\n",
      "Training:: Epoch 51, Iteration 90, Current loss 0.3284516188700133 Accuracy 89.00438525255807\n",
      "Training:: Epoch 51, Iteration 100, Current loss 0.3099760034189155 Accuracy 83.83450272858893\n",
      "Training:: Epoch 51, Iteration 110, Current loss 0.39376971512539327 Accuracy 88.53895018388499\n",
      "Training:: Epoch 51, Iteration 120, Current loss 0.4165233919314221 Accuracy 88.82888963887952\n",
      "Training:: Epoch 51, Iteration 130, Current loss 0.3865130164923014 Accuracy 88.2765623557648\n",
      "Training:: Epoch 51, Iteration 140, Current loss 0.4724928239880743 Accuracy 89.38633732149749\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 51, Probability Accuracy 65.91979359342218\n",
      "Starting Training\n",
      "Training:: Epoch 52, Iteration 0, Current loss 0.3136085285407996 Accuracy 86.8481227410194\n",
      "Training:: Epoch 52, Iteration 10, Current loss 0.4564448559130301 Accuracy 86.08586856315027\n",
      "Training:: Epoch 52, Iteration 20, Current loss 0.5780126991427998 Accuracy 82.70578270578271\n",
      "Training:: Epoch 52, Iteration 30, Current loss 0.30502867641254966 Accuracy 90.55185375021357\n",
      "Training:: Epoch 52, Iteration 40, Current loss 0.3206254112199823 Accuracy 88.82371491643015\n",
      "Training:: Epoch 52, Iteration 50, Current loss 0.41998393344583607 Accuracy 93.02098217643078\n",
      "Training:: Epoch 52, Iteration 60, Current loss 0.439998619813671 Accuracy 84.7523772879679\n",
      "Training:: Epoch 52, Iteration 70, Current loss 0.4671554557547987 Accuracy 89.0228426395939\n",
      "Training:: Epoch 52, Iteration 80, Current loss 0.3701747065152942 Accuracy 88.10032968012118\n",
      "Training:: Epoch 52, Iteration 90, Current loss 0.3508812585968361 Accuracy 88.31243861574903\n",
      "Training:: Epoch 52, Iteration 100, Current loss 0.48481802931432744 Accuracy 83.59708615925646\n",
      "Training:: Epoch 52, Iteration 110, Current loss 0.4231856873049658 Accuracy 89.73808146740478\n",
      "Training:: Epoch 52, Iteration 120, Current loss 0.3059967948297331 Accuracy 88.20149751649492\n",
      "Training:: Epoch 52, Iteration 130, Current loss 0.3197516389599885 Accuracy 88.97298627776752\n",
      "Training:: Epoch 52, Iteration 140, Current loss 0.3199080638378506 Accuracy 89.92905613818631\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 52, Probability Accuracy 65.63760220655037\n",
      "Starting Training\n",
      "Training:: Epoch 53, Iteration 0, Current loss 0.40865018554822985 Accuracy 87.17447067518803\n",
      "Training:: Epoch 53, Iteration 10, Current loss 0.41300050347665435 Accuracy 84.69448289499704\n",
      "Training:: Epoch 53, Iteration 20, Current loss 0.28271044605105716 Accuracy 89.24965893587995\n",
      "Training:: Epoch 53, Iteration 30, Current loss 0.2638804771245048 Accuracy 92.41309025025478\n",
      "Training:: Epoch 53, Iteration 40, Current loss 0.31968361800767314 Accuracy 82.59507346585998\n",
      "Training:: Epoch 53, Iteration 50, Current loss 0.29847650218775107 Accuracy 85.39382802103796\n",
      "Training:: Epoch 53, Iteration 60, Current loss 0.38430497864735913 Accuracy 83.6107398857976\n",
      "Training:: Epoch 53, Iteration 70, Current loss 0.6373479220428327 Accuracy 85.74911347517731\n",
      "Training:: Epoch 53, Iteration 80, Current loss 0.2798173646660735 Accuracy 90.18740893332664\n",
      "Training:: Epoch 53, Iteration 90, Current loss 0.43000426426503535 Accuracy 89.19179402450779\n",
      "Training:: Epoch 53, Iteration 100, Current loss 0.26761665999369555 Accuracy 85.30633194904577\n",
      "Training:: Epoch 53, Iteration 110, Current loss 0.21611306370390346 Accuracy 90.35298836742881\n",
      "Training:: Epoch 53, Iteration 120, Current loss 0.383820590410938 Accuracy 88.02078129683285\n",
      "Training:: Epoch 53, Iteration 130, Current loss 0.3291452330464481 Accuracy 90.56603773584905\n",
      "Training:: Epoch 53, Iteration 140, Current loss 0.34996371774337703 Accuracy 88.6010773130545\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 53, Probability Accuracy 66.06407558219335\n",
      "Starting Training\n",
      "Training:: Epoch 54, Iteration 0, Current loss 0.3245540267246264 Accuracy 83.68033311979501\n",
      "Training:: Epoch 54, Iteration 10, Current loss 0.26441783218719267 Accuracy 78.47829201891389\n",
      "Training:: Epoch 54, Iteration 20, Current loss 0.3204983576287184 Accuracy 89.9524118537746\n",
      "Training:: Epoch 54, Iteration 30, Current loss 0.27035602273719567 Accuracy 90.60066740823137\n",
      "Training:: Epoch 54, Iteration 40, Current loss 0.2882565707759419 Accuracy 90.93580325774514\n",
      "Training:: Epoch 54, Iteration 50, Current loss 0.21380770084718784 Accuracy 89.4667447992968\n",
      "Training:: Epoch 54, Iteration 60, Current loss 0.20713747499802443 Accuracy 91.00422168328393\n",
      "Training:: Epoch 54, Iteration 70, Current loss 0.35110897567621735 Accuracy 86.8370551290998\n",
      "Training:: Epoch 54, Iteration 80, Current loss 0.29960953944258734 Accuracy 85.8804756267051\n",
      "Training:: Epoch 54, Iteration 90, Current loss 0.43342228384861153 Accuracy 87.00403896412449\n",
      "Training:: Epoch 54, Iteration 100, Current loss 0.34460064562410087 Accuracy 86.62194993134045\n",
      "Training:: Epoch 54, Iteration 110, Current loss 0.28136429765003146 Accuracy 90.81447659974485\n",
      "Training:: Epoch 54, Iteration 120, Current loss 0.46022278216209234 Accuracy 86.84681231634087\n",
      "Training:: Epoch 54, Iteration 130, Current loss 0.3990910395586353 Accuracy 81.85331738290236\n",
      "Training:: Epoch 54, Iteration 140, Current loss 0.28418438371927013 Accuracy 85.94495845365077\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 54, Probability Accuracy 65.83196622200145\n",
      "Starting Training\n",
      "Training:: Epoch 55, Iteration 0, Current loss 0.34351382039366546 Accuracy 87.41248850859203\n",
      "Training:: Epoch 55, Iteration 10, Current loss 0.3352830193298524 Accuracy 90.66390041493776\n",
      "Training:: Epoch 55, Iteration 20, Current loss 0.26872764741523697 Accuracy 87.88485434212343\n",
      "Training:: Epoch 55, Iteration 30, Current loss 0.3456438089533911 Accuracy 83.37453646477132\n",
      "Training:: Epoch 55, Iteration 40, Current loss 0.2835890970182667 Accuracy 87.98659251923516\n",
      "Training:: Epoch 55, Iteration 50, Current loss 0.36804436853474876 Accuracy 83.72145096283027\n",
      "Training:: Epoch 55, Iteration 60, Current loss 0.18332229733206976 Accuracy 89.4233849439402\n",
      "Training:: Epoch 55, Iteration 70, Current loss 0.22643386653793882 Accuracy 85.75501425498925\n",
      "Training:: Epoch 55, Iteration 80, Current loss 0.27853223824813295 Accuracy 88.34328688343287\n",
      "Training:: Epoch 55, Iteration 90, Current loss 0.3614579496010535 Accuracy 86.01341736125228\n",
      "Training:: Epoch 55, Iteration 100, Current loss 0.39320702939116975 Accuracy 84.83095452605623\n",
      "Training:: Epoch 55, Iteration 110, Current loss 0.2642899634301027 Accuracy 92.02316360601002\n",
      "Training:: Epoch 55, Iteration 120, Current loss 0.2634894608086349 Accuracy 88.39690047297977\n",
      "Training:: Epoch 55, Iteration 130, Current loss 0.3712935740672742 Accuracy 86.12729234088458\n",
      "Training:: Epoch 55, Iteration 140, Current loss 0.2651579037493485 Accuracy 87.8233135267389\n",
      "Calculating Expectation\n",
      "Epoch 55 iter 0\n",
      "Epoch 55 iter 10\n",
      "Epoch 55 iter 20\n",
      "Epoch 55 iter 30\n",
      "Epoch 55 iter 40\n",
      "Epoch 55 iter 50\n",
      "Epoch 55 iter 60\n",
      "Epoch 55 iter 70\n",
      "Epoch 55 iter 80\n",
      "Epoch 55 iter 90\n",
      "Epoch 55 iter 100\n",
      "Epoch 55 iter 110\n",
      "Epoch 55 iter 120\n",
      "Epoch 55 iter 130\n",
      "Epoch 55 iter 140\n",
      "Train Boundary avergage error = 84.130\n",
      "Train From boundary avergage accuracy = 87.512\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 55, Probability Accuracy 65.64609899411107\n",
      "Starting Training\n",
      "Training:: Epoch 56, Iteration 0, Current loss 0.22483308603733645 Accuracy 88.58104096576291\n",
      "Training:: Epoch 56, Iteration 10, Current loss 0.273791484161221 Accuracy 87.02645018675204\n",
      "Training:: Epoch 56, Iteration 20, Current loss 0.21420961492378202 Accuracy 92.57704306247996\n",
      "Training:: Epoch 56, Iteration 30, Current loss 0.3484728922402434 Accuracy 85.45110410094637\n",
      "Training:: Epoch 56, Iteration 40, Current loss 0.4086761586940445 Accuracy 88.24671313862173\n",
      "Training:: Epoch 56, Iteration 50, Current loss 0.3961371226735361 Accuracy 90.02120001972095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 56, Iteration 60, Current loss 0.3764832582731947 Accuracy 81.65303611493088\n",
      "Training:: Epoch 56, Iteration 70, Current loss 0.2768430068505099 Accuracy 86.59351145038168\n",
      "Training:: Epoch 56, Iteration 80, Current loss 0.30572230903101183 Accuracy 86.93798902253883\n",
      "Training:: Epoch 56, Iteration 90, Current loss 0.23534494758982782 Accuracy 87.40649711476811\n",
      "Training:: Epoch 56, Iteration 100, Current loss 0.26824423853026014 Accuracy 87.48908932208322\n",
      "Training:: Epoch 56, Iteration 110, Current loss 0.4049795796622098 Accuracy 86.73887321379813\n",
      "Training:: Epoch 56, Iteration 120, Current loss 0.3438943991234672 Accuracy 88.58737123235406\n",
      "Training:: Epoch 56, Iteration 130, Current loss 0.2625591576695111 Accuracy 90.60504339282791\n",
      "Training:: Epoch 56, Iteration 140, Current loss 0.39099057404028353 Accuracy 85.44231319782422\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 56, Probability Accuracy 65.61619683788783\n",
      "Starting Training\n",
      "Training:: Epoch 57, Iteration 0, Current loss 0.291755742639821 Accuracy 90.19527595884004\n",
      "Training:: Epoch 57, Iteration 10, Current loss 0.5015067902855226 Accuracy 86.98045692265346\n",
      "Training:: Epoch 57, Iteration 20, Current loss 0.35620688499338726 Accuracy 84.1714538223597\n",
      "Training:: Epoch 57, Iteration 30, Current loss 0.328284230237096 Accuracy 87.70700352631344\n",
      "Training:: Epoch 57, Iteration 40, Current loss 0.4010449165894619 Accuracy 87.27516566740297\n",
      "Training:: Epoch 57, Iteration 50, Current loss 0.34166159311246225 Accuracy 86.5437741724848\n",
      "Training:: Epoch 57, Iteration 60, Current loss 0.23268978594711862 Accuracy 91.65825919471705\n",
      "Training:: Epoch 57, Iteration 70, Current loss 0.2487848923990981 Accuracy 88.60759493670886\n",
      "Training:: Epoch 57, Iteration 80, Current loss 0.2348565561800866 Accuracy 87.6526236538021\n",
      "Training:: Epoch 57, Iteration 90, Current loss 0.3761564856710574 Accuracy 87.37544198007072\n",
      "Training:: Epoch 57, Iteration 100, Current loss 0.2501626943894233 Accuracy 90.09586692908387\n",
      "Training:: Epoch 57, Iteration 110, Current loss 0.31875813406218256 Accuracy 87.94779597815955\n",
      "Training:: Epoch 57, Iteration 120, Current loss 0.5534976585740012 Accuracy 80.60323925904375\n",
      "Training:: Epoch 57, Iteration 130, Current loss 0.7016123172368872 Accuracy 85.00963391136801\n",
      "Training:: Epoch 57, Iteration 140, Current loss 0.3604269820913997 Accuracy 91.02763807913125\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 57, Probability Accuracy 65.25884156105596\n",
      "Starting Training\n",
      "Training:: Epoch 58, Iteration 0, Current loss 0.41937354855971615 Accuracy 87.92358229598894\n",
      "Training:: Epoch 58, Iteration 10, Current loss 0.3885314562877704 Accuracy 90.47327734831211\n",
      "Training:: Epoch 58, Iteration 20, Current loss 0.3441575249582535 Accuracy 81.67357512953367\n",
      "Training:: Epoch 58, Iteration 30, Current loss 0.3541187065366162 Accuracy 86.86009671502418\n",
      "Training:: Epoch 58, Iteration 40, Current loss 0.30443945923220594 Accuracy 87.65397536394177\n",
      "Training:: Epoch 58, Iteration 50, Current loss 0.3274353691590643 Accuracy 85.88598901098901\n",
      "Training:: Epoch 58, Iteration 60, Current loss 0.30235813499595326 Accuracy 90.03117925938581\n",
      "Training:: Epoch 58, Iteration 70, Current loss 0.3258485384863926 Accuracy 86.67017913593256\n",
      "Training:: Epoch 58, Iteration 80, Current loss 0.29960078726009765 Accuracy 86.70778526024293\n",
      "Training:: Epoch 58, Iteration 90, Current loss 0.49563830920362406 Accuracy 88.2412204951065\n",
      "Training:: Epoch 58, Iteration 100, Current loss 0.267495462706108 Accuracy 89.26918970221853\n",
      "Training:: Epoch 58, Iteration 110, Current loss 0.3787954033233329 Accuracy 83.69599830166649\n",
      "Training:: Epoch 58, Iteration 120, Current loss 0.32519569879087207 Accuracy 87.73824650571791\n",
      "Training:: Epoch 58, Iteration 130, Current loss 0.23126106134994767 Accuracy 90.01494526800501\n",
      "Training:: Epoch 58, Iteration 140, Current loss 0.40719594526415226 Accuracy 86.2297053517739\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 58, Probability Accuracy 64.83490088170511\n",
      "Starting Training\n",
      "Training:: Epoch 59, Iteration 0, Current loss 0.30072802119534287 Accuracy 86.05617910802304\n",
      "Training:: Epoch 59, Iteration 10, Current loss 0.2640974409945347 Accuracy 87.61626361945257\n",
      "Training:: Epoch 59, Iteration 20, Current loss 0.3284681159696111 Accuracy 87.71701035129188\n",
      "Training:: Epoch 59, Iteration 30, Current loss 0.3215894848208383 Accuracy 85.50096621186391\n",
      "Training:: Epoch 59, Iteration 40, Current loss 0.32028497105911047 Accuracy 89.82702126038254\n",
      "Training:: Epoch 59, Iteration 50, Current loss 0.44772953489201683 Accuracy 85.88607039410164\n",
      "Training:: Epoch 59, Iteration 60, Current loss 0.22752758868744014 Accuracy 90.00460231789465\n",
      "Training:: Epoch 59, Iteration 70, Current loss 0.4091961448833563 Accuracy 89.05224787363305\n",
      "Training:: Epoch 59, Iteration 80, Current loss 0.49900041005501 Accuracy 88.81832006440648\n",
      "Training:: Epoch 59, Iteration 90, Current loss 0.3578680318802376 Accuracy 80.47674569244721\n",
      "Training:: Epoch 59, Iteration 100, Current loss 0.3933114857667359 Accuracy 83.45527265632622\n",
      "Training:: Epoch 59, Iteration 110, Current loss 0.30131833143981757 Accuracy 91.20018428933426\n",
      "Training:: Epoch 59, Iteration 120, Current loss 3.71539078071349 Accuracy 83.3076966900245\n",
      "Training:: Epoch 59, Iteration 130, Current loss 1.396789860249537 Accuracy 82.64658100723675\n",
      "Training:: Epoch 59, Iteration 140, Current loss 0.7914387311140691 Accuracy 85.13349514563107\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 59, Probability Accuracy 60.53928457048739\n",
      "Starting Training\n",
      "Training:: Epoch 60, Iteration 0, Current loss 1.6690547614041384 Accuracy 83.89191889753945\n",
      "Training:: Epoch 60, Iteration 10, Current loss 1.3184141625998302 Accuracy 84.61538461538461\n",
      "Training:: Epoch 60, Iteration 20, Current loss 1.2142330580470515 Accuracy 79.27876029725215\n",
      "Training:: Epoch 60, Iteration 30, Current loss 2.2077406867990352 Accuracy 76.97232657812583\n",
      "Training:: Epoch 60, Iteration 40, Current loss 2.680822274985434 Accuracy 79.23054671680649\n",
      "Training:: Epoch 60, Iteration 50, Current loss 2.3459569629866657 Accuracy 74.78131397729388\n",
      "Training:: Epoch 60, Iteration 60, Current loss 4.642453532631125 Accuracy 56.61149071311712\n",
      "Training:: Epoch 60, Iteration 70, Current loss 2.7797080848609204 Accuracy 66.11707841031149\n",
      "Training:: Epoch 60, Iteration 80, Current loss 5.379842536987914 Accuracy 51.656729547453814\n",
      "Training:: Epoch 60, Iteration 90, Current loss 2.3375849578743457 Accuracy 70.28123309897242\n",
      "Training:: Epoch 60, Iteration 100, Current loss 2.182785766562051 Accuracy 71.72715053763442\n",
      "Training:: Epoch 60, Iteration 110, Current loss 1.1185656878912333 Accuracy 77.95923379174853\n",
      "Training:: Epoch 60, Iteration 120, Current loss 1.9594401242827872 Accuracy 70.32001833040556\n",
      "Training:: Epoch 60, Iteration 130, Current loss 0.7024419625486975 Accuracy 87.61467889908256\n",
      "Training:: Epoch 60, Iteration 140, Current loss 0.7167896130221099 Accuracy 85.64803208824267\n",
      "Calculating Expectation\n",
      "Epoch 60 iter 0\n",
      "Epoch 60 iter 10\n",
      "Epoch 60 iter 20\n",
      "Epoch 60 iter 30\n",
      "Epoch 60 iter 40\n",
      "Epoch 60 iter 50\n",
      "Epoch 60 iter 60\n",
      "Epoch 60 iter 70\n",
      "Epoch 60 iter 80\n",
      "Epoch 60 iter 90\n",
      "Epoch 60 iter 100\n",
      "Epoch 60 iter 110\n",
      "Epoch 60 iter 120\n",
      "Epoch 60 iter 130\n",
      "Epoch 60 iter 140\n",
      "Train Boundary avergage error = 82.358\n",
      "Train From boundary avergage accuracy = 87.473\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 60, Probability Accuracy 63.4813789632612\n",
      "Starting Training\n",
      "Training:: Epoch 61, Iteration 0, Current loss 0.7327720249295262 Accuracy 79.96175603537567\n",
      "Training:: Epoch 61, Iteration 10, Current loss 0.665382641309378 Accuracy 86.40108998897036\n",
      "Training:: Epoch 61, Iteration 20, Current loss 1.1800505234091543 Accuracy 87.68818644521832\n",
      "Training:: Epoch 61, Iteration 30, Current loss 1.07236410575985 Accuracy 86.63018989378823\n",
      "Training:: Epoch 61, Iteration 40, Current loss 0.9554807325925186 Accuracy 85.99194000918227\n",
      "Training:: Epoch 61, Iteration 50, Current loss 0.9586861035889116 Accuracy 86.4695215511229\n",
      "Training:: Epoch 61, Iteration 60, Current loss 1.7137153536516898 Accuracy 85.44509421702404\n",
      "Training:: Epoch 61, Iteration 70, Current loss 1.0563815515369752 Accuracy 83.93221402793033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 61, Iteration 80, Current loss 0.9850010570021257 Accuracy 84.57423094070441\n",
      "Training:: Epoch 61, Iteration 90, Current loss 0.8642312277705559 Accuracy 86.88274087180312\n",
      "Training:: Epoch 61, Iteration 100, Current loss 0.6212537778957227 Accuracy 85.88046695166064\n",
      "Training:: Epoch 61, Iteration 110, Current loss 0.6852303233429617 Accuracy 82.63452914798206\n",
      "Training:: Epoch 61, Iteration 120, Current loss 0.9991747887791484 Accuracy 84.58767013610888\n",
      "Training:: Epoch 61, Iteration 130, Current loss 0.48637782254446216 Accuracy 90.32056293979672\n",
      "Training:: Epoch 61, Iteration 140, Current loss 0.7762422962274276 Accuracy 87.28005087979648\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 61, Probability Accuracy 64.7506683050216\n",
      "Starting Training\n",
      "Training:: Epoch 62, Iteration 0, Current loss 0.6353740568318589 Accuracy 83.73379326751517\n",
      "Training:: Epoch 62, Iteration 10, Current loss 0.4260926235731201 Accuracy 88.04429755899577\n",
      "Training:: Epoch 62, Iteration 20, Current loss 0.35538126707582524 Accuracy 91.03895616962244\n",
      "Training:: Epoch 62, Iteration 30, Current loss 0.5147171639128408 Accuracy 87.81631950421759\n",
      "Training:: Epoch 62, Iteration 40, Current loss 0.6795691638883079 Accuracy 84.06085430076068\n",
      "Training:: Epoch 62, Iteration 50, Current loss 0.5751890798795194 Accuracy 82.18538287825909\n",
      "Training:: Epoch 62, Iteration 60, Current loss 0.402946437341924 Accuracy 89.7738764613082\n",
      "Training:: Epoch 62, Iteration 70, Current loss 0.4962228126945918 Accuracy 87.22160898642946\n",
      "Training:: Epoch 62, Iteration 80, Current loss 0.5718986785928974 Accuracy 87.03556344494093\n",
      "Training:: Epoch 62, Iteration 90, Current loss 0.626240167597099 Accuracy 87.02975081107199\n",
      "Training:: Epoch 62, Iteration 100, Current loss 0.6585947090761333 Accuracy 88.90488377052677\n",
      "Training:: Epoch 62, Iteration 110, Current loss 0.5647762991378861 Accuracy 86.05917691314356\n",
      "Training:: Epoch 62, Iteration 120, Current loss 0.6824452653201758 Accuracy 82.97437001938403\n",
      "Training:: Epoch 62, Iteration 130, Current loss 0.649931626712229 Accuracy 84.0209641050643\n",
      "Training:: Epoch 62, Iteration 140, Current loss 0.3462178583665529 Accuracy 83.18042813455658\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 62, Probability Accuracy 65.9546794423493\n",
      "Starting Training\n",
      "Training:: Epoch 63, Iteration 0, Current loss 0.5450988581426721 Accuracy 83.36692479049539\n",
      "Training:: Epoch 63, Iteration 10, Current loss 0.517458428231459 Accuracy 84.55068078668684\n",
      "Training:: Epoch 63, Iteration 20, Current loss 0.4183344037611475 Accuracy 87.80530817388238\n",
      "Training:: Epoch 63, Iteration 30, Current loss 0.722699148691528 Accuracy 86.90981963927855\n",
      "Training:: Epoch 63, Iteration 40, Current loss 0.5728332228451908 Accuracy 87.81013193830057\n",
      "Training:: Epoch 63, Iteration 50, Current loss 0.5996889881409702 Accuracy 86.64231414749729\n",
      "Training:: Epoch 63, Iteration 60, Current loss 0.5904804482718865 Accuracy 85.91758708581139\n",
      "Training:: Epoch 63, Iteration 70, Current loss 0.8678517213963778 Accuracy 88.63202545068928\n",
      "Training:: Epoch 63, Iteration 80, Current loss 0.31667514952331405 Accuracy 90.36912260143548\n",
      "Training:: Epoch 63, Iteration 90, Current loss 0.4898083036892901 Accuracy 85.93894542090656\n",
      "Training:: Epoch 63, Iteration 100, Current loss 0.5466450748156885 Accuracy 87.6554636432001\n",
      "Training:: Epoch 63, Iteration 110, Current loss 0.3586344566748712 Accuracy 87.56436520679918\n",
      "Training:: Epoch 63, Iteration 120, Current loss 0.523985970213487 Accuracy 83.60287185437667\n",
      "Training:: Epoch 63, Iteration 130, Current loss 0.39934791758541766 Accuracy 87.5936108929039\n",
      "Training:: Epoch 63, Iteration 140, Current loss 0.39783167485011184 Accuracy 91.8764178459544\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 63, Probability Accuracy 65.1465859253982\n",
      "Starting Training\n",
      "Training:: Epoch 64, Iteration 0, Current loss 0.5895039254090929 Accuracy 88.89249580695774\n",
      "Training:: Epoch 64, Iteration 10, Current loss 0.2755520788091337 Accuracy 86.0237646717867\n",
      "Training:: Epoch 64, Iteration 20, Current loss 0.45924523442402054 Accuracy 83.3367326126861\n",
      "Training:: Epoch 64, Iteration 30, Current loss 0.4830366632280819 Accuracy 81.24873507387169\n",
      "Training:: Epoch 64, Iteration 40, Current loss 0.3077638943530223 Accuracy 92.63697675714843\n",
      "Training:: Epoch 64, Iteration 50, Current loss 0.36295602411495864 Accuracy 91.42653859836358\n",
      "Training:: Epoch 64, Iteration 60, Current loss 0.30228693536603707 Accuracy 91.879321950921\n",
      "Training:: Epoch 64, Iteration 70, Current loss 0.5066586876935972 Accuracy 87.78668805132318\n",
      "Training:: Epoch 64, Iteration 80, Current loss 0.492067951205937 Accuracy 85.01271026015469\n",
      "Training:: Epoch 64, Iteration 90, Current loss 0.356388777330483 Accuracy 81.82566541662855\n",
      "Training:: Epoch 64, Iteration 100, Current loss 0.32156182418268237 Accuracy 89.09351829705813\n",
      "Training:: Epoch 64, Iteration 110, Current loss 0.5618171298349559 Accuracy 81.8117694478033\n",
      "Training:: Epoch 64, Iteration 120, Current loss 0.29883741205221453 Accuracy 87.2706535753248\n",
      "Training:: Epoch 64, Iteration 130, Current loss 0.5096915609818843 Accuracy 87.5054704595186\n",
      "Training:: Epoch 64, Iteration 140, Current loss 0.49920156581783215 Accuracy 88.76600698486612\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 64, Probability Accuracy 66.43482963940941\n",
      "Starting Training\n",
      "Training:: Epoch 65, Iteration 0, Current loss 0.3498051870507492 Accuracy 85.21231144825181\n",
      "Training:: Epoch 65, Iteration 10, Current loss 0.39690513044392667 Accuracy 86.92777971072121\n",
      "Training:: Epoch 65, Iteration 20, Current loss 0.5344280864671249 Accuracy 87.49738803371177\n",
      "Training:: Epoch 65, Iteration 30, Current loss 0.37211795324273617 Accuracy 85.38630580615313\n",
      "Training:: Epoch 65, Iteration 40, Current loss 0.5477594721717978 Accuracy 86.5126050420168\n",
      "Training:: Epoch 65, Iteration 50, Current loss 0.5736301223766915 Accuracy 88.40081623885726\n",
      "Training:: Epoch 65, Iteration 60, Current loss 0.3449870993630089 Accuracy 92.46978335233752\n",
      "Training:: Epoch 65, Iteration 70, Current loss 0.2865235882734952 Accuracy 89.4382240317968\n",
      "Training:: Epoch 65, Iteration 80, Current loss 0.3509481985554559 Accuracy 87.77878239903556\n",
      "Training:: Epoch 65, Iteration 90, Current loss 0.451539811665976 Accuracy 82.7748294162244\n",
      "Training:: Epoch 65, Iteration 100, Current loss 0.31101812166101356 Accuracy 92.01882537503677\n",
      "Training:: Epoch 65, Iteration 110, Current loss 0.32497914121113614 Accuracy 87.05662361947057\n",
      "Training:: Epoch 65, Iteration 120, Current loss 0.3087084928577086 Accuracy 91.60965794768612\n",
      "Training:: Epoch 65, Iteration 130, Current loss 0.4513113265885028 Accuracy 89.1942859836877\n",
      "Training:: Epoch 65, Iteration 140, Current loss 0.378414893733665 Accuracy 87.97130097371696\n",
      "Calculating Expectation\n",
      "Epoch 65 iter 0\n",
      "Epoch 65 iter 10\n",
      "Epoch 65 iter 20\n",
      "Epoch 65 iter 30\n",
      "Epoch 65 iter 40\n",
      "Epoch 65 iter 50\n",
      "Epoch 65 iter 60\n",
      "Epoch 65 iter 70\n",
      "Epoch 65 iter 80\n",
      "Epoch 65 iter 90\n",
      "Epoch 65 iter 100\n",
      "Epoch 65 iter 110\n",
      "Epoch 65 iter 120\n",
      "Epoch 65 iter 130\n",
      "Epoch 65 iter 140\n",
      "Train Boundary avergage error = 82.737\n",
      "Train From boundary avergage accuracy = 87.477\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 65, Probability Accuracy 66.51146412721651\n",
      "Starting Training\n",
      "Training:: Epoch 66, Iteration 0, Current loss 0.3683096591996011 Accuracy 87.87209926624112\n",
      "Training:: Epoch 66, Iteration 10, Current loss 0.30656493549069797 Accuracy 90.11714016426552\n",
      "Training:: Epoch 66, Iteration 20, Current loss 0.3648930572801438 Accuracy 85.06366307541626\n",
      "Training:: Epoch 66, Iteration 30, Current loss 0.3601894410397315 Accuracy 88.92560769626202\n",
      "Training:: Epoch 66, Iteration 40, Current loss 0.22235530852645896 Accuracy 90.49288513095483\n",
      "Training:: Epoch 66, Iteration 50, Current loss 0.31365148788306024 Accuracy 89.41043772504446\n",
      "Training:: Epoch 66, Iteration 60, Current loss 0.34520204724891035 Accuracy 87.58653454594814\n",
      "Training:: Epoch 66, Iteration 70, Current loss 0.20950308491719571 Accuracy 91.88873934499776\n",
      "Training:: Epoch 66, Iteration 80, Current loss 0.3647306109847694 Accuracy 86.93829720106369\n",
      "Training:: Epoch 66, Iteration 90, Current loss 0.2808092180764229 Accuracy 90.1113089937667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 66, Iteration 100, Current loss 0.34190299984984246 Accuracy 84.246707356248\n",
      "Training:: Epoch 66, Iteration 110, Current loss 0.2592112062649825 Accuracy 86.60139251523063\n",
      "Training:: Epoch 66, Iteration 120, Current loss 0.30667458736572467 Accuracy 89.23939869867624\n",
      "Training:: Epoch 66, Iteration 130, Current loss 0.4233429737241124 Accuracy 88.32590802688213\n",
      "Training:: Epoch 66, Iteration 140, Current loss 0.23705175955731822 Accuracy 92.39894150926179\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 66, Probability Accuracy 66.2434885195328\n",
      "Starting Training\n",
      "Training:: Epoch 67, Iteration 0, Current loss 0.31572636717879665 Accuracy 80.45170485692358\n",
      "Training:: Epoch 67, Iteration 10, Current loss 0.26745049141048594 Accuracy 91.4131254714609\n",
      "Training:: Epoch 67, Iteration 20, Current loss 0.309748468404792 Accuracy 89.77749113189294\n",
      "Training:: Epoch 67, Iteration 30, Current loss 0.4596784032996849 Accuracy 88.03276412605858\n",
      "Training:: Epoch 67, Iteration 40, Current loss 0.33379098250651806 Accuracy 88.61660079051383\n",
      "Training:: Epoch 67, Iteration 50, Current loss 0.2821983333656182 Accuracy 89.82760656511985\n",
      "Training:: Epoch 67, Iteration 60, Current loss 0.21148191643851535 Accuracy 85.74100283057015\n",
      "Training:: Epoch 67, Iteration 70, Current loss 0.2842483992810079 Accuracy 89.52082831687936\n",
      "Training:: Epoch 67, Iteration 80, Current loss 0.3156716435633712 Accuracy 86.33532787886189\n",
      "Training:: Epoch 67, Iteration 90, Current loss 0.20895698190154668 Accuracy 83.38856277220223\n",
      "Training:: Epoch 67, Iteration 100, Current loss 0.3573397072004456 Accuracy 84.16538726242787\n",
      "Training:: Epoch 67, Iteration 110, Current loss 0.2350259088009316 Accuracy 83.76014663524482\n",
      "Training:: Epoch 67, Iteration 120, Current loss 0.2559579338434228 Accuracy 85.24898214844973\n",
      "Training:: Epoch 67, Iteration 130, Current loss 0.3239877865915663 Accuracy 93.7276374281687\n",
      "Training:: Epoch 67, Iteration 140, Current loss 0.310688049750088 Accuracy 87.68876489083743\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 67, Probability Accuracy 66.53899698690842\n",
      "Starting Training\n",
      "Training:: Epoch 68, Iteration 0, Current loss 0.42662133952527476 Accuracy 85.57643473844591\n",
      "Training:: Epoch 68, Iteration 10, Current loss 0.30311926543499484 Accuracy 85.87852078942326\n",
      "Training:: Epoch 68, Iteration 20, Current loss 0.25234097958957596 Accuracy 89.59861632969523\n",
      "Training:: Epoch 68, Iteration 30, Current loss 0.2458347523017808 Accuracy 80.44738406658739\n",
      "Training:: Epoch 68, Iteration 40, Current loss 0.19308043641093084 Accuracy 88.33007357734935\n",
      "Training:: Epoch 68, Iteration 50, Current loss 0.26559363606318703 Accuracy 90.8781226343679\n",
      "Training:: Epoch 68, Iteration 60, Current loss 0.2814339097710145 Accuracy 89.26180568120138\n",
      "Training:: Epoch 68, Iteration 70, Current loss 0.22435636358705904 Accuracy 88.84495566738558\n",
      "Training:: Epoch 68, Iteration 80, Current loss 0.33095468288718904 Accuracy 86.6362763915547\n",
      "Training:: Epoch 68, Iteration 90, Current loss 0.18302166014350232 Accuracy 91.24504103037879\n",
      "Training:: Epoch 68, Iteration 100, Current loss 0.4404745892767832 Accuracy 83.24847814056447\n",
      "Training:: Epoch 68, Iteration 110, Current loss 0.4078238322839225 Accuracy 81.95493534758674\n",
      "Training:: Epoch 68, Iteration 120, Current loss 0.31460329730612635 Accuracy 87.65759787657598\n",
      "Training:: Epoch 68, Iteration 130, Current loss 0.26685975634033876 Accuracy 87.85600636435959\n",
      "Training:: Epoch 68, Iteration 140, Current loss 0.3192661597902413 Accuracy 86.58987176700717\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 68, Probability Accuracy 66.47976457362466\n",
      "Starting Training\n",
      "Training:: Epoch 69, Iteration 0, Current loss 0.29575047977174485 Accuracy 89.38078291814946\n",
      "Training:: Epoch 69, Iteration 10, Current loss 0.26205275631785496 Accuracy 89.61560527825588\n",
      "Training:: Epoch 69, Iteration 20, Current loss 0.28632070806003673 Accuracy 87.4784821495397\n",
      "Training:: Epoch 69, Iteration 30, Current loss 0.34300178682266247 Accuracy 86.29765512840963\n",
      "Training:: Epoch 69, Iteration 40, Current loss 0.2784131745142582 Accuracy 89.44773643043375\n",
      "Training:: Epoch 69, Iteration 50, Current loss 0.3177362881518889 Accuracy 85.8196159122085\n",
      "Training:: Epoch 69, Iteration 60, Current loss 0.2891212460392373 Accuracy 84.95138515659355\n",
      "Training:: Epoch 69, Iteration 70, Current loss 0.26032674012535006 Accuracy 85.15781563126252\n",
      "Training:: Epoch 69, Iteration 80, Current loss 0.3006570302569927 Accuracy 87.70719654071863\n",
      "Training:: Epoch 69, Iteration 90, Current loss 0.2939688372310648 Accuracy 88.4136360401395\n",
      "Training:: Epoch 69, Iteration 100, Current loss 0.279662488009046 Accuracy 90.78439283038442\n",
      "Training:: Epoch 69, Iteration 110, Current loss 0.23982693267358288 Accuracy 81.22414441519368\n",
      "Training:: Epoch 69, Iteration 120, Current loss 0.2806415109718385 Accuracy 84.11719352351581\n",
      "Training:: Epoch 69, Iteration 130, Current loss 0.27353383591598773 Accuracy 91.74288998850402\n",
      "Training:: Epoch 69, Iteration 140, Current loss 0.19975888713602016 Accuracy 92.36904761904762\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 69, Probability Accuracy 66.59300060784712\n",
      "Starting Training\n",
      "Training:: Epoch 70, Iteration 0, Current loss 0.21495279997017003 Accuracy 89.73051092408399\n",
      "Training:: Epoch 70, Iteration 10, Current loss 0.22821500902087927 Accuracy 89.20657026993815\n",
      "Training:: Epoch 70, Iteration 20, Current loss 0.2903815480664676 Accuracy 87.75947403412869\n",
      "Training:: Epoch 70, Iteration 30, Current loss 0.25935304121402714 Accuracy 87.07430340557275\n",
      "Training:: Epoch 70, Iteration 40, Current loss 0.3445536358434649 Accuracy 84.14047700004858\n",
      "Training:: Epoch 70, Iteration 50, Current loss 0.24871996136933966 Accuracy 87.8635966190615\n",
      "Training:: Epoch 70, Iteration 60, Current loss 0.34647129974342394 Accuracy 85.66260322453795\n",
      "Training:: Epoch 70, Iteration 70, Current loss 0.3309828650412357 Accuracy 87.13820438763597\n",
      "Training:: Epoch 70, Iteration 80, Current loss 0.22571059875477487 Accuracy 88.09483488569009\n",
      "Training:: Epoch 70, Iteration 90, Current loss 0.31781155761222746 Accuracy 84.63081861958267\n",
      "Training:: Epoch 70, Iteration 100, Current loss 0.20573211162422408 Accuracy 86.84783284621604\n",
      "Training:: Epoch 70, Iteration 110, Current loss 0.29327480618484764 Accuracy 87.39124333426888\n",
      "Training:: Epoch 70, Iteration 120, Current loss 0.26325257538030017 Accuracy 84.32432432432432\n",
      "Training:: Epoch 70, Iteration 130, Current loss 0.2760799728551319 Accuracy 87.7434135166094\n",
      "Training:: Epoch 70, Iteration 140, Current loss 0.2219829588997292 Accuracy 84.01385613207547\n",
      "Calculating Expectation\n",
      "Epoch 70 iter 0\n",
      "Epoch 70 iter 10\n",
      "Epoch 70 iter 20\n",
      "Epoch 70 iter 30\n",
      "Epoch 70 iter 40\n",
      "Epoch 70 iter 50\n",
      "Epoch 70 iter 60\n",
      "Epoch 70 iter 70\n",
      "Epoch 70 iter 80\n",
      "Epoch 70 iter 90\n",
      "Epoch 70 iter 100\n",
      "Epoch 70 iter 110\n",
      "Epoch 70 iter 120\n",
      "Epoch 70 iter 130\n",
      "Epoch 70 iter 140\n",
      "Train Boundary avergage error = 82.688\n",
      "Train From boundary avergage accuracy = 87.484\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 70, Probability Accuracy 66.50247714037347\n",
      "Starting Training\n",
      "Training:: Epoch 71, Iteration 0, Current loss 0.21968587612615675 Accuracy 87.34278833288734\n",
      "Training:: Epoch 71, Iteration 10, Current loss 0.3075477426033334 Accuracy 84.78649453823238\n",
      "Training:: Epoch 71, Iteration 20, Current loss 0.2691497121288734 Accuracy 86.50829676703485\n",
      "Training:: Epoch 71, Iteration 30, Current loss 0.32736075754604343 Accuracy 85.79684088866058\n",
      "Training:: Epoch 71, Iteration 40, Current loss 0.3281982880004711 Accuracy 78.86647454370798\n",
      "Training:: Epoch 71, Iteration 50, Current loss 0.2778482805032746 Accuracy 87.3565965583174\n",
      "Training:: Epoch 71, Iteration 60, Current loss 0.2556867631106363 Accuracy 88.70250726098038\n",
      "Training:: Epoch 71, Iteration 70, Current loss 0.3747314994979709 Accuracy 89.54491237728232\n",
      "Training:: Epoch 71, Iteration 80, Current loss 0.3060869099681636 Accuracy 85.15406162464986\n",
      "Training:: Epoch 71, Iteration 90, Current loss 0.25517737270239077 Accuracy 90.93951985226224\n",
      "Training:: Epoch 71, Iteration 100, Current loss 0.32978480492209167 Accuracy 87.82310177705978\n",
      "Training:: Epoch 71, Iteration 110, Current loss 0.3348060054288011 Accuracy 82.61147236414305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 71, Iteration 120, Current loss 0.6094458080686026 Accuracy 84.34579439252336\n",
      "Training:: Epoch 71, Iteration 130, Current loss 0.3272621192563475 Accuracy 90.26543285035919\n",
      "Training:: Epoch 71, Iteration 140, Current loss 0.49984937759561243 Accuracy 85.24915624379591\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 71, Probability Accuracy 65.54201334649247\n",
      "Starting Training\n",
      "Training:: Epoch 72, Iteration 0, Current loss 0.3946254667046988 Accuracy 85.32058248206911\n",
      "Training:: Epoch 72, Iteration 10, Current loss 0.31394290010167 Accuracy 87.02424800491099\n",
      "Training:: Epoch 72, Iteration 20, Current loss 0.5072028993859055 Accuracy 89.94950709305121\n",
      "Training:: Epoch 72, Iteration 30, Current loss 1.3319697606876821 Accuracy 81.64786937850974\n",
      "Training:: Epoch 72, Iteration 40, Current loss 0.4775830055870498 Accuracy 89.7846378474214\n",
      "Training:: Epoch 72, Iteration 50, Current loss 0.45671758778261184 Accuracy 89.13529411764706\n",
      "Training:: Epoch 72, Iteration 60, Current loss 0.45471355835243915 Accuracy 86.79286653997954\n",
      "Training:: Epoch 72, Iteration 70, Current loss 0.5534716317467812 Accuracy 83.34707762086383\n",
      "Training:: Epoch 72, Iteration 80, Current loss 0.8081695153873133 Accuracy 87.04425979311515\n",
      "Training:: Epoch 72, Iteration 90, Current loss 0.3529007281621165 Accuracy 89.78338182993858\n",
      "Training:: Epoch 72, Iteration 100, Current loss 0.30916204141389225 Accuracy 81.16729988209092\n",
      "Training:: Epoch 72, Iteration 110, Current loss 0.36265623132496655 Accuracy 85.25566771471124\n",
      "Training:: Epoch 72, Iteration 120, Current loss 0.33736299334444686 Accuracy 86.07867925931434\n",
      "Training:: Epoch 72, Iteration 130, Current loss 0.2415749731731245 Accuracy 90.01079697684648\n",
      "Training:: Epoch 72, Iteration 140, Current loss 0.2515659899935703 Accuracy 84.13489851203329\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 72, Probability Accuracy 65.86758736985209\n",
      "Starting Training\n",
      "Training:: Epoch 73, Iteration 0, Current loss 0.2818628592177298 Accuracy 89.54045307443366\n",
      "Training:: Epoch 73, Iteration 10, Current loss 0.31948478333498 Accuracy 87.59424263193968\n",
      "Training:: Epoch 73, Iteration 20, Current loss 0.33203987249522593 Accuracy 86.0952055379882\n",
      "Training:: Epoch 73, Iteration 30, Current loss 0.39813979119830345 Accuracy 87.6097271648873\n",
      "Training:: Epoch 73, Iteration 40, Current loss 0.367872194238229 Accuracy 83.69050932368495\n",
      "Training:: Epoch 73, Iteration 50, Current loss 0.2830793792651107 Accuracy 88.2936507936508\n",
      "Training:: Epoch 73, Iteration 60, Current loss 0.24594111565428528 Accuracy 88.38011604202603\n",
      "Training:: Epoch 73, Iteration 70, Current loss 0.38957075352124193 Accuracy 83.48126974574996\n",
      "Training:: Epoch 73, Iteration 80, Current loss 0.2574168866819713 Accuracy 85.90275326509001\n",
      "Training:: Epoch 73, Iteration 90, Current loss 0.24620757442820534 Accuracy 93.54881208554741\n",
      "Training:: Epoch 73, Iteration 100, Current loss 0.2627329252401087 Accuracy 89.77074178006036\n",
      "Training:: Epoch 73, Iteration 110, Current loss 0.27563110006883657 Accuracy 89.59648806302243\n",
      "Training:: Epoch 73, Iteration 120, Current loss 0.3218893360593086 Accuracy 89.45077720207254\n",
      "Training:: Epoch 73, Iteration 130, Current loss 0.25998574195065055 Accuracy 88.38279192273924\n",
      "Training:: Epoch 73, Iteration 140, Current loss 0.3316397927159257 Accuracy 88.77638948728996\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 73, Probability Accuracy 66.15419055026503\n",
      "Starting Training\n",
      "Training:: Epoch 74, Iteration 0, Current loss 0.2614754953126198 Accuracy 85.75932385296485\n",
      "Training:: Epoch 74, Iteration 10, Current loss 0.2650681657633279 Accuracy 86.88046647230321\n",
      "Training:: Epoch 74, Iteration 20, Current loss 0.28590653615636963 Accuracy 89.12526875636529\n",
      "Training:: Epoch 74, Iteration 30, Current loss 0.2030269529847272 Accuracy 85.21642188938975\n",
      "Training:: Epoch 74, Iteration 40, Current loss 0.21405343848844455 Accuracy 86.26203888787934\n",
      "Training:: Epoch 74, Iteration 50, Current loss 0.21705941650785476 Accuracy 88.4199278749833\n",
      "Training:: Epoch 74, Iteration 60, Current loss 0.2571024478321664 Accuracy 88.47852573865367\n",
      "Training:: Epoch 74, Iteration 70, Current loss 0.3107784442556991 Accuracy 88.86497345386712\n",
      "Training:: Epoch 74, Iteration 80, Current loss 0.4193807573684821 Accuracy 83.31727062451812\n",
      "Training:: Epoch 74, Iteration 90, Current loss 0.3756236081010165 Accuracy 87.71346630165559\n",
      "Training:: Epoch 74, Iteration 100, Current loss 0.2764845898331363 Accuracy 80.38533834586467\n",
      "Training:: Epoch 74, Iteration 110, Current loss 0.2943955595846384 Accuracy 85.33864541832669\n",
      "Training:: Epoch 74, Iteration 120, Current loss 0.3647912452593129 Accuracy 88.9257488535467\n",
      "Training:: Epoch 74, Iteration 130, Current loss 0.31190519376066883 Accuracy 81.81197359435465\n",
      "Training:: Epoch 74, Iteration 140, Current loss 0.3392433432215261 Accuracy 88.26798629615531\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 74, Probability Accuracy 66.06056248733651\n",
      "Starting Training\n",
      "Training:: Epoch 75, Iteration 0, Current loss 0.246769390477398 Accuracy 90.11011336394296\n",
      "Training:: Epoch 75, Iteration 10, Current loss 0.2523552915094698 Accuracy 88.144578313253\n",
      "Training:: Epoch 75, Iteration 20, Current loss 0.3164201217517164 Accuracy 84.79472638262808\n",
      "Training:: Epoch 75, Iteration 30, Current loss 0.30237611394347436 Accuracy 84.51103241623535\n",
      "Training:: Epoch 75, Iteration 40, Current loss 0.3380421015167724 Accuracy 90.61468841331197\n",
      "Training:: Epoch 75, Iteration 50, Current loss 0.20899638947138008 Accuracy 87.849024835134\n",
      "Training:: Epoch 75, Iteration 60, Current loss 0.23159800353501903 Accuracy 88.06995345474265\n",
      "Training:: Epoch 75, Iteration 70, Current loss 0.28956941578166995 Accuracy 88.06427870461236\n",
      "Training:: Epoch 75, Iteration 80, Current loss 0.3290284139383405 Accuracy 87.00887969833353\n",
      "Training:: Epoch 75, Iteration 90, Current loss 0.23299166268926472 Accuracy 90.97915350600127\n",
      "Training:: Epoch 75, Iteration 100, Current loss 0.20792126396936744 Accuracy 90.98307642556861\n",
      "Training:: Epoch 75, Iteration 110, Current loss 0.315548029007505 Accuracy 89.13266735132107\n",
      "Training:: Epoch 75, Iteration 120, Current loss 0.24508246310218407 Accuracy 88.36965541337293\n",
      "Training:: Epoch 75, Iteration 130, Current loss 0.23874763111709063 Accuracy 87.44233419207957\n",
      "Training:: Epoch 75, Iteration 140, Current loss 0.2151788777541025 Accuracy 92.65720753050296\n",
      "Calculating Expectation\n",
      "Epoch 75 iter 0\n",
      "Epoch 75 iter 10\n",
      "Epoch 75 iter 20\n",
      "Epoch 75 iter 30\n",
      "Epoch 75 iter 40\n",
      "Epoch 75 iter 50\n",
      "Epoch 75 iter 60\n",
      "Epoch 75 iter 70\n",
      "Epoch 75 iter 80\n",
      "Epoch 75 iter 90\n",
      "Epoch 75 iter 100\n",
      "Epoch 75 iter 110\n",
      "Epoch 75 iter 120\n",
      "Epoch 75 iter 130\n",
      "Epoch 75 iter 140\n",
      "Train Boundary avergage error = 82.631\n",
      "Train From boundary avergage accuracy = 87.508\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 75, Probability Accuracy 66.7048477441029\n",
      "Starting Training\n",
      "Training:: Epoch 76, Iteration 0, Current loss 0.20358787875893977 Accuracy 89.89858338699291\n",
      "Training:: Epoch 76, Iteration 10, Current loss 0.19697110091100892 Accuracy 86.79483138985188\n",
      "Training:: Epoch 76, Iteration 20, Current loss 0.2575319561463239 Accuracy 87.70338157006823\n",
      "Training:: Epoch 76, Iteration 30, Current loss 0.16426777398662107 Accuracy 90.49653519512322\n",
      "Training:: Epoch 76, Iteration 40, Current loss 0.20254547952508664 Accuracy 88.82722278282318\n",
      "Training:: Epoch 76, Iteration 50, Current loss 0.25827184078614573 Accuracy 84.76387249114522\n",
      "Training:: Epoch 76, Iteration 60, Current loss 0.20010632530847136 Accuracy 86.49839743589743\n",
      "Training:: Epoch 76, Iteration 70, Current loss 0.26352696968866474 Accuracy 85.06963186872504\n",
      "Training:: Epoch 76, Iteration 80, Current loss 0.23250327697241024 Accuracy 87.70206896551724\n",
      "Training:: Epoch 76, Iteration 90, Current loss 0.29581136111341566 Accuracy 88.33628492719401\n",
      "Training:: Epoch 76, Iteration 100, Current loss 0.30357231030532505 Accuracy 79.24197886046657\n",
      "Training:: Epoch 76, Iteration 110, Current loss 0.2376664465319457 Accuracy 89.13875276901389\n",
      "Training:: Epoch 76, Iteration 120, Current loss 0.19036479521112099 Accuracy 81.90727478326423\n",
      "Training:: Epoch 76, Iteration 130, Current loss 0.6248346925890428 Accuracy 81.92888888888889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 76, Iteration 140, Current loss 0.4495535550754782 Accuracy 86.9930367299208\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 76, Probability Accuracy 65.83057732403479\n",
      "Starting Training\n",
      "Training:: Epoch 77, Iteration 0, Current loss 0.28437464559690373 Accuracy 86.16792249730894\n",
      "Training:: Epoch 77, Iteration 10, Current loss 0.3716090445559618 Accuracy 90.21676181020932\n",
      "Training:: Epoch 77, Iteration 20, Current loss 0.26087532554853504 Accuracy 81.81400477853336\n",
      "Training:: Epoch 77, Iteration 30, Current loss 0.35784000637836566 Accuracy 87.57848551327635\n",
      "Training:: Epoch 77, Iteration 40, Current loss 0.2970251876711101 Accuracy 89.1995221027479\n",
      "Training:: Epoch 77, Iteration 50, Current loss 0.5009995817653294 Accuracy 89.26824244296823\n",
      "Training:: Epoch 77, Iteration 60, Current loss 0.39201833588473567 Accuracy 90.85082613041689\n",
      "Training:: Epoch 77, Iteration 70, Current loss 1.6563327023749812 Accuracy 81.61071510692113\n",
      "Training:: Epoch 77, Iteration 80, Current loss 2.2247809915328123 Accuracy 73.44273504273504\n",
      "Training:: Epoch 77, Iteration 90, Current loss 2.7729309147240597 Accuracy 70.5098493626883\n",
      "Training:: Epoch 77, Iteration 100, Current loss 2.4847401291737237 Accuracy 78.93800059329575\n",
      "Training:: Epoch 77, Iteration 110, Current loss 2.531689421070897 Accuracy 70.71171283070426\n",
      "Training:: Epoch 77, Iteration 120, Current loss 0.8583413734324669 Accuracy 86.85486879741326\n",
      "Training:: Epoch 77, Iteration 130, Current loss 5.7599525253632216 Accuracy 62.51133958270336\n",
      "Training:: Epoch 77, Iteration 140, Current loss 4.501222312495097 Accuracy 73.47376973073352\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 77, Probability Accuracy 55.05027810639285\n",
      "Starting Training\n",
      "Training:: Epoch 78, Iteration 0, Current loss 3.136212702816719 Accuracy 78.47256857855362\n",
      "Training:: Epoch 78, Iteration 10, Current loss 4.0204140344849115 Accuracy 68.3054892601432\n",
      "Training:: Epoch 78, Iteration 20, Current loss 1.7579446784184118 Accuracy 81.97430434501905\n",
      "Training:: Epoch 78, Iteration 30, Current loss 1.7633364081441165 Accuracy 77.91302423370587\n",
      "Training:: Epoch 78, Iteration 40, Current loss 3.9902251429251425 Accuracy 75.29753667312482\n",
      "Training:: Epoch 78, Iteration 50, Current loss 1.62857058794951 Accuracy 81.61823361823362\n",
      "Training:: Epoch 78, Iteration 60, Current loss 2.977018428681157 Accuracy 70.94264117385505\n",
      "Training:: Epoch 78, Iteration 70, Current loss 1.4936346589888747 Accuracy 82.07671957671958\n",
      "Training:: Epoch 78, Iteration 80, Current loss 1.8121046798477045 Accuracy 76.76889965025558\n",
      "Training:: Epoch 78, Iteration 90, Current loss 1.9189353535860232 Accuracy 75.57231104651163\n",
      "Training:: Epoch 78, Iteration 100, Current loss 2.5714944642626723 Accuracy 76.20655412115194\n",
      "Training:: Epoch 78, Iteration 110, Current loss 1.737527661184853 Accuracy 75.18256013745705\n",
      "Training:: Epoch 78, Iteration 120, Current loss 0.825083480154594 Accuracy 78.6379599938922\n",
      "Training:: Epoch 78, Iteration 130, Current loss 3.7424302233015814 Accuracy 77.73340747106101\n",
      "Training:: Epoch 78, Iteration 140, Current loss 3.133685884473764 Accuracy 73.43313728984732\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 78, Probability Accuracy 52.41986875731214\n",
      "Starting Training\n",
      "Training:: Epoch 79, Iteration 0, Current loss 2.9528838462553315 Accuracy 74.7800586510264\n",
      "Training:: Epoch 79, Iteration 10, Current loss 2.625009018162731 Accuracy 75.49441100601892\n",
      "Training:: Epoch 79, Iteration 20, Current loss 1.2645985638679704 Accuracy 85.26868601135219\n",
      "Training:: Epoch 79, Iteration 30, Current loss 1.0189991419805264 Accuracy 81.29358326402661\n",
      "Training:: Epoch 79, Iteration 40, Current loss 0.8941526458509208 Accuracy 83.32507433102082\n",
      "Training:: Epoch 79, Iteration 50, Current loss 1.3517974230497676 Accuracy 83.31785563528915\n",
      "Training:: Epoch 79, Iteration 60, Current loss 1.1632819750327519 Accuracy 80.64226588211828\n",
      "Training:: Epoch 79, Iteration 70, Current loss 1.015800736246066 Accuracy 87.44125326370757\n",
      "Training:: Epoch 79, Iteration 80, Current loss 0.9453062925219643 Accuracy 86.67996537317927\n",
      "Training:: Epoch 79, Iteration 90, Current loss 1.039147552263612 Accuracy 83.63117785997594\n",
      "Training:: Epoch 79, Iteration 100, Current loss 0.6215310700334375 Accuracy 87.03114534494307\n",
      "Training:: Epoch 79, Iteration 110, Current loss 1.4686521290160326 Accuracy 79.4966418185844\n",
      "Training:: Epoch 79, Iteration 120, Current loss 1.6509412067655704 Accuracy 79.70251007127362\n",
      "Training:: Epoch 79, Iteration 130, Current loss 0.6274371741940983 Accuracy 87.39884393063583\n",
      "Training:: Epoch 79, Iteration 140, Current loss 0.6190130750400658 Accuracy 89.49763847144698\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 79, Probability Accuracy 65.91497330047909\n",
      "Starting Training\n",
      "Training:: Epoch 80, Iteration 0, Current loss 0.5550887220756989 Accuracy 90.05864129232131\n",
      "Training:: Epoch 80, Iteration 10, Current loss 0.5085142848503854 Accuracy 86.98948398141354\n",
      "Training:: Epoch 80, Iteration 20, Current loss 0.427900246395938 Accuracy 89.19765360906742\n",
      "Training:: Epoch 80, Iteration 30, Current loss 0.5382554053087958 Accuracy 89.1421052631579\n",
      "Training:: Epoch 80, Iteration 40, Current loss 0.5197742712899438 Accuracy 87.1049988410724\n",
      "Training:: Epoch 80, Iteration 50, Current loss 2.215458925717598 Accuracy 81.24588545095457\n",
      "Training:: Epoch 80, Iteration 60, Current loss 1.8674004763661087 Accuracy 83.2975871313673\n",
      "Training:: Epoch 80, Iteration 70, Current loss 0.6615352682617996 Accuracy 83.02278199666605\n",
      "Training:: Epoch 80, Iteration 80, Current loss 0.9664452551020086 Accuracy 84.10069876519574\n",
      "Training:: Epoch 80, Iteration 90, Current loss 4.577995727532112 Accuracy 76.50971560257686\n",
      "Training:: Epoch 80, Iteration 100, Current loss 0.7848003002873164 Accuracy 86.86905632772495\n",
      "Training:: Epoch 80, Iteration 110, Current loss 1.4195200090687772 Accuracy 87.3661245537485\n",
      "Training:: Epoch 80, Iteration 120, Current loss 1.201314148475802 Accuracy 83.7083236185591\n",
      "Training:: Epoch 80, Iteration 130, Current loss 1.0517519555716222 Accuracy 78.50437883475799\n",
      "Training:: Epoch 80, Iteration 140, Current loss 0.7949036349320623 Accuracy 90.90145282688604\n",
      "Calculating Expectation\n",
      "Epoch 80 iter 0\n",
      "Epoch 80 iter 10\n",
      "Epoch 80 iter 20\n",
      "Epoch 80 iter 30\n",
      "Epoch 80 iter 40\n",
      "Epoch 80 iter 50\n",
      "Epoch 80 iter 60\n",
      "Epoch 80 iter 70\n",
      "Epoch 80 iter 80\n",
      "Epoch 80 iter 90\n",
      "Epoch 80 iter 100\n",
      "Epoch 80 iter 110\n",
      "Epoch 80 iter 120\n",
      "Epoch 80 iter 130\n",
      "Epoch 80 iter 140\n",
      "Train Boundary avergage error = 83.119\n",
      "Train From boundary avergage accuracy = 87.225\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 80, Probability Accuracy 61.514617742599626\n",
      "Starting Training\n",
      "Training:: Epoch 81, Iteration 0, Current loss 0.8641982817717615 Accuracy 83.75894634311608\n",
      "Training:: Epoch 81, Iteration 10, Current loss 0.7978002741992611 Accuracy 79.78517844964765\n",
      "Training:: Epoch 81, Iteration 20, Current loss 2.112675339651969 Accuracy 78.57673196641727\n",
      "Training:: Epoch 81, Iteration 30, Current loss 0.9606148477771531 Accuracy 86.02217294900221\n",
      "Training:: Epoch 81, Iteration 40, Current loss 0.7755993888401287 Accuracy 85.77145397954646\n",
      "Training:: Epoch 81, Iteration 50, Current loss 0.5702404502283746 Accuracy 88.85803248337962\n",
      "Training:: Epoch 81, Iteration 60, Current loss 0.5276187007235614 Accuracy 82.9059437677443\n",
      "Training:: Epoch 81, Iteration 70, Current loss 0.5535002780855836 Accuracy 85.35719358045732\n",
      "Training:: Epoch 81, Iteration 80, Current loss 0.577077250252675 Accuracy 84.45566135138236\n",
      "Training:: Epoch 81, Iteration 90, Current loss 0.37363663417530296 Accuracy 93.14418066010423\n",
      "Training:: Epoch 81, Iteration 100, Current loss 0.3406980514208542 Accuracy 88.36174944403261\n",
      "Training:: Epoch 81, Iteration 110, Current loss 0.4162582104980716 Accuracy 87.05568912859835\n",
      "Training:: Epoch 81, Iteration 120, Current loss 0.4749459487956464 Accuracy 87.54071661237785\n",
      "Training:: Epoch 81, Iteration 130, Current loss 0.5177386718702919 Accuracy 88.78410914927768\n",
      "Training:: Epoch 81, Iteration 140, Current loss 0.7437451763912112 Accuracy 87.21481078137762\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 81, Probability Accuracy 64.62525898862084\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 82, Iteration 0, Current loss 0.38005955245846074 Accuracy 89.23573735199139\n",
      "Training:: Epoch 82, Iteration 10, Current loss 0.3081612081348332 Accuracy 85.31495493758736\n",
      "Training:: Epoch 82, Iteration 20, Current loss 0.5283290958499683 Accuracy 86.59276103846882\n",
      "Training:: Epoch 82, Iteration 30, Current loss 0.5456321338608261 Accuracy 80.8082271147161\n",
      "Training:: Epoch 82, Iteration 40, Current loss 0.46545215092539693 Accuracy 83.40816997043041\n",
      "Training:: Epoch 82, Iteration 50, Current loss 0.36198872065710797 Accuracy 85.67541363025052\n",
      "Training:: Epoch 82, Iteration 60, Current loss 0.40645506790904606 Accuracy 89.6981336484956\n",
      "Training:: Epoch 82, Iteration 70, Current loss 0.36178684813610584 Accuracy 85.084358021161\n",
      "Training:: Epoch 82, Iteration 80, Current loss 0.2823427341160984 Accuracy 89.7539174575149\n",
      "Training:: Epoch 82, Iteration 90, Current loss 0.26343382306784413 Accuracy 89.15245342429809\n",
      "Training:: Epoch 82, Iteration 100, Current loss 0.42227195431800446 Accuracy 89.1076341127923\n",
      "Training:: Epoch 82, Iteration 110, Current loss 0.8794423196567608 Accuracy 88.32330324306253\n",
      "Training:: Epoch 82, Iteration 120, Current loss 0.5228654403723018 Accuracy 87.15991872738987\n",
      "Training:: Epoch 82, Iteration 130, Current loss 0.32435919692314075 Accuracy 90.44114062880818\n",
      "Training:: Epoch 82, Iteration 140, Current loss 0.3495899427786037 Accuracy 87.86300968025814\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 82, Probability Accuracy 65.34756763116098\n",
      "Starting Training\n",
      "Training:: Epoch 83, Iteration 0, Current loss 0.2857510175815164 Accuracy 85.73099985375129\n",
      "Training:: Epoch 83, Iteration 10, Current loss 0.2655513920114315 Accuracy 88.52850505839955\n",
      "Training:: Epoch 83, Iteration 20, Current loss 0.3595469925802676 Accuracy 85.46271126344404\n",
      "Training:: Epoch 83, Iteration 30, Current loss 0.4355675771693947 Accuracy 89.98729121278141\n",
      "Training:: Epoch 83, Iteration 40, Current loss 0.3418045945901071 Accuracy 88.80129636929006\n",
      "Training:: Epoch 83, Iteration 50, Current loss 0.43437026568068626 Accuracy 87.1630472250948\n",
      "Training:: Epoch 83, Iteration 60, Current loss 0.3631712705502791 Accuracy 89.39143983136285\n",
      "Training:: Epoch 83, Iteration 70, Current loss 0.4131119978815823 Accuracy 83.80295375048581\n",
      "Training:: Epoch 83, Iteration 80, Current loss 0.32549730329756044 Accuracy 89.84298331697742\n",
      "Training:: Epoch 83, Iteration 90, Current loss 0.42729678159949724 Accuracy 87.94487556863794\n",
      "Training:: Epoch 83, Iteration 100, Current loss 0.47152899623271216 Accuracy 87.08695161836022\n",
      "Training:: Epoch 83, Iteration 110, Current loss 0.542651698936315 Accuracy 82.76168605081858\n",
      "Training:: Epoch 83, Iteration 120, Current loss 0.3412319695544896 Accuracy 91.6070577014783\n",
      "Training:: Epoch 83, Iteration 130, Current loss 0.32407941638734883 Accuracy 88.68562192344427\n",
      "Training:: Epoch 83, Iteration 140, Current loss 0.7386313531245278 Accuracy 84.26645280938298\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 83, Probability Accuracy 64.18432473414859\n",
      "Starting Training\n",
      "Training:: Epoch 84, Iteration 0, Current loss 0.39679600854893404 Accuracy 80.42024832855779\n",
      "Training:: Epoch 84, Iteration 10, Current loss 0.368962950571753 Accuracy 86.4201680672269\n",
      "Training:: Epoch 84, Iteration 20, Current loss 0.3872669070097997 Accuracy 85.17387510906144\n",
      "Training:: Epoch 84, Iteration 30, Current loss 0.41063005914886347 Accuracy 85.59418314019541\n",
      "Training:: Epoch 84, Iteration 40, Current loss 0.35990990702513387 Accuracy 82.41007740173016\n",
      "Training:: Epoch 84, Iteration 50, Current loss 0.4928769301339278 Accuracy 86.21449876799377\n",
      "Training:: Epoch 84, Iteration 60, Current loss 0.3692174534659254 Accuracy 86.51394519611195\n",
      "Training:: Epoch 84, Iteration 70, Current loss 0.34692048927779584 Accuracy 86.13991529136848\n",
      "Training:: Epoch 84, Iteration 80, Current loss 0.4034202481157008 Accuracy 84.23903231630258\n",
      "Training:: Epoch 84, Iteration 90, Current loss 0.5126940247284515 Accuracy 83.17428128355004\n",
      "Training:: Epoch 84, Iteration 100, Current loss 0.40341941953344096 Accuracy 87.1846060001109\n",
      "Training:: Epoch 84, Iteration 110, Current loss 0.33729006341254586 Accuracy 88.03677170897346\n",
      "Training:: Epoch 84, Iteration 120, Current loss 0.26220778795773686 Accuracy 91.2034861366258\n",
      "Training:: Epoch 84, Iteration 130, Current loss 0.35498143044229924 Accuracy 87.36067892503536\n",
      "Training:: Epoch 84, Iteration 140, Current loss 0.33769418308381205 Accuracy 83.70484242890085\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 84, Probability Accuracy 66.10263792573808\n",
      "Starting Training\n",
      "Training:: Epoch 85, Iteration 0, Current loss 0.39468109524256023 Accuracy 76.07901726427623\n",
      "Training:: Epoch 85, Iteration 10, Current loss 0.5868633297351049 Accuracy 84.69100281723911\n",
      "Training:: Epoch 85, Iteration 20, Current loss 0.2647983255744133 Accuracy 87.60077558934586\n",
      "Training:: Epoch 85, Iteration 30, Current loss 0.3455754118447954 Accuracy 88.2830459770115\n",
      "Training:: Epoch 85, Iteration 40, Current loss 0.3383231285583181 Accuracy 86.7323568575233\n",
      "Training:: Epoch 85, Iteration 50, Current loss 0.30256202359191015 Accuracy 89.52782377439911\n",
      "Training:: Epoch 85, Iteration 60, Current loss 0.2912312249476168 Accuracy 89.74987739087788\n",
      "Training:: Epoch 85, Iteration 70, Current loss 0.3216797715469062 Accuracy 86.90425337157502\n",
      "Training:: Epoch 85, Iteration 80, Current loss 0.28868152696869487 Accuracy 80.66939382670138\n",
      "Training:: Epoch 85, Iteration 90, Current loss 0.3258091096964992 Accuracy 89.24370945897783\n",
      "Training:: Epoch 85, Iteration 100, Current loss 0.2280976130924227 Accuracy 92.63196313700442\n",
      "Training:: Epoch 85, Iteration 110, Current loss 0.25315729950532984 Accuracy 87.51838481080358\n",
      "Training:: Epoch 85, Iteration 120, Current loss 0.4481193483692806 Accuracy 87.1088415177246\n",
      "Training:: Epoch 85, Iteration 130, Current loss 0.29766404130219704 Accuracy 85.61701530254106\n",
      "Training:: Epoch 85, Iteration 140, Current loss 0.4375610951481048 Accuracy 89.49480442679733\n",
      "Calculating Expectation\n",
      "Epoch 85 iter 0\n",
      "Epoch 85 iter 10\n",
      "Epoch 85 iter 20\n",
      "Epoch 85 iter 30\n",
      "Epoch 85 iter 40\n",
      "Epoch 85 iter 50\n",
      "Epoch 85 iter 60\n",
      "Epoch 85 iter 70\n",
      "Epoch 85 iter 80\n",
      "Epoch 85 iter 90\n",
      "Epoch 85 iter 100\n",
      "Epoch 85 iter 110\n",
      "Epoch 85 iter 120\n",
      "Epoch 85 iter 130\n",
      "Epoch 85 iter 140\n",
      "Train Boundary avergage error = 83.081\n",
      "Train From boundary avergage accuracy = 87.328\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 85, Probability Accuracy 65.27044294407153\n",
      "Starting Training\n",
      "Training:: Epoch 86, Iteration 0, Current loss 0.21821127845895716 Accuracy 88.07941903584673\n",
      "Training:: Epoch 86, Iteration 10, Current loss 0.2817198665871665 Accuracy 83.31503841931944\n",
      "Training:: Epoch 86, Iteration 20, Current loss 0.2893528636230633 Accuracy 83.43838165556156\n",
      "Training:: Epoch 86, Iteration 30, Current loss 0.19782269837574684 Accuracy 92.66869773773254\n",
      "Training:: Epoch 86, Iteration 40, Current loss 0.2283011999654624 Accuracy 90.0743476819624\n",
      "Training:: Epoch 86, Iteration 50, Current loss 0.24021053852836974 Accuracy 88.71699826008019\n",
      "Training:: Epoch 86, Iteration 60, Current loss 0.25549650937254775 Accuracy 81.32774895292867\n",
      "Training:: Epoch 86, Iteration 70, Current loss 0.248484507246314 Accuracy 84.32741538666134\n",
      "Training:: Epoch 86, Iteration 80, Current loss 0.299275828897904 Accuracy 88.02842699098835\n",
      "Training:: Epoch 86, Iteration 90, Current loss 0.23724970851752936 Accuracy 88.18342151675485\n",
      "Training:: Epoch 86, Iteration 100, Current loss 0.24842237592423566 Accuracy 81.71742734968147\n",
      "Training:: Epoch 86, Iteration 110, Current loss 0.2839222777549685 Accuracy 83.53288062902072\n",
      "Training:: Epoch 86, Iteration 120, Current loss 0.3399698946437511 Accuracy 85.9664750182201\n",
      "Training:: Epoch 86, Iteration 130, Current loss 0.25837102757034414 Accuracy 87.88853746319118\n",
      "Training:: Epoch 86, Iteration 140, Current loss 0.19108741777909097 Accuracy 88.45376352610091\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 86, Probability Accuracy 65.71292949627122\n",
      "Starting Training\n",
      "Training:: Epoch 87, Iteration 0, Current loss 0.24816722662360177 Accuracy 90.59593850825584\n",
      "Training:: Epoch 87, Iteration 10, Current loss 0.35769051163295645 Accuracy 82.78199291856347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 87, Iteration 20, Current loss 0.21848162574571972 Accuracy 90.00335457900033\n",
      "Training:: Epoch 87, Iteration 30, Current loss 0.2685748072098415 Accuracy 89.90805604203152\n",
      "Training:: Epoch 87, Iteration 40, Current loss 0.28738588328364323 Accuracy 84.98171074845244\n",
      "Training:: Epoch 87, Iteration 50, Current loss 0.298152991840902 Accuracy 86.18698298735758\n",
      "Training:: Epoch 87, Iteration 60, Current loss 0.35960799734993537 Accuracy 88.84991057917182\n",
      "Training:: Epoch 87, Iteration 70, Current loss 0.2596443472115506 Accuracy 86.62177985948477\n",
      "Training:: Epoch 87, Iteration 80, Current loss 0.17572684007811887 Accuracy 87.19641593963688\n",
      "Training:: Epoch 87, Iteration 90, Current loss 0.2969113138727379 Accuracy 89.09267581683469\n",
      "Training:: Epoch 87, Iteration 100, Current loss 0.4398046874821566 Accuracy 76.94142592101775\n",
      "Training:: Epoch 87, Iteration 110, Current loss 0.3731720962925324 Accuracy 89.15781326954198\n",
      "Training:: Epoch 87, Iteration 120, Current loss 0.31090608955883126 Accuracy 87.27329826489755\n",
      "Training:: Epoch 87, Iteration 130, Current loss 0.21706740653914608 Accuracy 87.78292181069959\n",
      "Training:: Epoch 87, Iteration 140, Current loss 0.27364414298066453 Accuracy 88.23237338629593\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 87, Probability Accuracy 65.7624396237884\n",
      "Starting Training\n",
      "Training:: Epoch 88, Iteration 0, Current loss 0.2721161187795784 Accuracy 88.75942426319396\n",
      "Training:: Epoch 88, Iteration 10, Current loss 0.24251464993551028 Accuracy 88.10952952609615\n",
      "Training:: Epoch 88, Iteration 20, Current loss 0.24028348420923776 Accuracy 84.53758732144719\n",
      "Training:: Epoch 88, Iteration 30, Current loss 0.27291742450917883 Accuracy 85.91963410650115\n",
      "Training:: Epoch 88, Iteration 40, Current loss 0.21289136865183217 Accuracy 88.02619865191403\n",
      "Training:: Epoch 88, Iteration 50, Current loss 0.23299361852675068 Accuracy 85.27145257546788\n",
      "Training:: Epoch 88, Iteration 60, Current loss 0.205421372119143 Accuracy 85.55717054263566\n",
      "Training:: Epoch 88, Iteration 70, Current loss 0.3067573803285433 Accuracy 87.11472602739725\n",
      "Training:: Epoch 88, Iteration 80, Current loss 0.29159767366150446 Accuracy 89.30895568639603\n",
      "Training:: Epoch 88, Iteration 90, Current loss 0.19238046911227757 Accuracy 86.18578100674624\n",
      "Training:: Epoch 88, Iteration 100, Current loss 0.24669266681189772 Accuracy 87.95464921625323\n",
      "Training:: Epoch 88, Iteration 110, Current loss 0.43976827251451706 Accuracy 84.24530057695887\n",
      "Training:: Epoch 88, Iteration 120, Current loss 0.293855138444039 Accuracy 87.2186554497823\n",
      "Training:: Epoch 88, Iteration 130, Current loss 0.21481019400751583 Accuracy 93.97075786389001\n",
      "Training:: Epoch 88, Iteration 140, Current loss 0.19359398696874572 Accuracy 90.57994579945799\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 88, Probability Accuracy 65.93302897404558\n",
      "Starting Training\n",
      "Training:: Epoch 89, Iteration 0, Current loss 0.26085786969963626 Accuracy 86.69197080291971\n",
      "Training:: Epoch 89, Iteration 10, Current loss 0.25735881067952215 Accuracy 84.92958536722213\n",
      "Training:: Epoch 89, Iteration 20, Current loss 0.24015277964922038 Accuracy 88.79761015683346\n",
      "Training:: Epoch 89, Iteration 30, Current loss 0.22004900996127594 Accuracy 89.03389411182583\n",
      "Training:: Epoch 89, Iteration 40, Current loss 0.17832194217069144 Accuracy 90.47407407407407\n",
      "Training:: Epoch 89, Iteration 50, Current loss 0.2340001106554765 Accuracy 86.36918922394393\n",
      "Training:: Epoch 89, Iteration 60, Current loss 0.22621215671667122 Accuracy 87.58161727774987\n",
      "Training:: Epoch 89, Iteration 70, Current loss 0.2525777416332 Accuracy 88.74474053295933\n",
      "Training:: Epoch 89, Iteration 80, Current loss 0.3069946911163563 Accuracy 83.15176083101089\n",
      "Training:: Epoch 89, Iteration 90, Current loss 0.2893234822134808 Accuracy 86.09887827170752\n",
      "Training:: Epoch 89, Iteration 100, Current loss 0.4247856254772088 Accuracy 81.52173913043478\n",
      "Training:: Epoch 89, Iteration 110, Current loss 0.21005771872676762 Accuracy 91.18157620645759\n",
      "Training:: Epoch 89, Iteration 120, Current loss 0.2232962684439667 Accuracy 91.96656605525888\n",
      "Training:: Epoch 89, Iteration 130, Current loss 0.23308088749728795 Accuracy 91.12101910828025\n",
      "Training:: Epoch 89, Iteration 140, Current loss 0.2244223329659193 Accuracy 91.62176127555917\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 89, Probability Accuracy 65.74144275452781\n",
      "Starting Training\n",
      "Training:: Epoch 90, Iteration 0, Current loss 0.24174447508803426 Accuracy 83.7547312641938\n",
      "Training:: Epoch 90, Iteration 10, Current loss 0.1959924290704542 Accuracy 88.78075729888232\n",
      "Training:: Epoch 90, Iteration 20, Current loss 0.19129484977287736 Accuracy 90.43663761801017\n",
      "Training:: Epoch 90, Iteration 30, Current loss 0.2674792520661455 Accuracy 89.91665099956133\n",
      "Training:: Epoch 90, Iteration 40, Current loss 0.4638702463105986 Accuracy 83.0728638116501\n",
      "Training:: Epoch 90, Iteration 50, Current loss 0.3344411517518418 Accuracy 88.7605817234643\n",
      "Training:: Epoch 90, Iteration 60, Current loss 0.23074443345333745 Accuracy 90.64692674712322\n",
      "Training:: Epoch 90, Iteration 70, Current loss 0.2127416464247217 Accuracy 88.59479471735646\n",
      "Training:: Epoch 90, Iteration 80, Current loss 0.2747127670034931 Accuracy 87.70453843778944\n",
      "Training:: Epoch 90, Iteration 90, Current loss 0.19198305530509424 Accuracy 91.04574597123549\n",
      "Training:: Epoch 90, Iteration 100, Current loss 0.32289505502027444 Accuracy 86.5928659286593\n",
      "Training:: Epoch 90, Iteration 110, Current loss 0.20543376590398943 Accuracy 86.99329359165425\n",
      "Training:: Epoch 90, Iteration 120, Current loss 0.2885395762836221 Accuracy 89.519958926967\n",
      "Training:: Epoch 90, Iteration 130, Current loss 0.1964000366928537 Accuracy 85.55108346546326\n",
      "Training:: Epoch 90, Iteration 140, Current loss 0.2490251207405924 Accuracy 85.77062322213602\n",
      "Calculating Expectation\n",
      "Epoch 90 iter 0\n",
      "Epoch 90 iter 10\n",
      "Epoch 90 iter 20\n",
      "Epoch 90 iter 30\n",
      "Epoch 90 iter 40\n",
      "Epoch 90 iter 50\n",
      "Epoch 90 iter 60\n",
      "Epoch 90 iter 70\n",
      "Epoch 90 iter 80\n",
      "Epoch 90 iter 90\n",
      "Epoch 90 iter 100\n",
      "Epoch 90 iter 110\n",
      "Epoch 90 iter 120\n",
      "Epoch 90 iter 130\n",
      "Epoch 90 iter 140\n",
      "Train Boundary avergage error = 82.898\n",
      "Train From boundary avergage accuracy = 87.415\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 90, Probability Accuracy 66.06244158458551\n",
      "Starting Training\n",
      "Training:: Epoch 91, Iteration 0, Current loss 0.22704395318437487 Accuracy 90.88122605363985\n",
      "Training:: Epoch 91, Iteration 10, Current loss 0.19281852197243704 Accuracy 90.13622974963181\n",
      "Training:: Epoch 91, Iteration 20, Current loss 0.15031462905446571 Accuracy 92.47855530474041\n",
      "Training:: Epoch 91, Iteration 30, Current loss 0.29321218563490303 Accuracy 84.55845771144278\n",
      "Training:: Epoch 91, Iteration 40, Current loss 0.16410244544606406 Accuracy 88.22059223037218\n",
      "Training:: Epoch 91, Iteration 50, Current loss 0.3023166028579198 Accuracy 84.9970331827103\n",
      "Training:: Epoch 91, Iteration 60, Current loss 0.22932626135218986 Accuracy 85.8441401042298\n",
      "Training:: Epoch 91, Iteration 70, Current loss 0.2208431673064217 Accuracy 88.04709855983488\n",
      "Training:: Epoch 91, Iteration 80, Current loss 0.25977216831640926 Accuracy 88.77745544964775\n",
      "Training:: Epoch 91, Iteration 90, Current loss 0.20853590495474617 Accuracy 80.8356248090437\n",
      "Training:: Epoch 91, Iteration 100, Current loss 0.2693613854932221 Accuracy 79.89764003411999\n",
      "Training:: Epoch 91, Iteration 110, Current loss 0.2166900115139274 Accuracy 89.20504546787915\n",
      "Training:: Epoch 91, Iteration 120, Current loss 0.20489639657611014 Accuracy 86.05792245093346\n",
      "Training:: Epoch 91, Iteration 130, Current loss 0.16028363199417053 Accuracy 87.67080529929943\n",
      "Training:: Epoch 91, Iteration 140, Current loss 0.21443646998516525 Accuracy 87.7517885230098\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 91, Probability Accuracy 65.87118216458931\n",
      "Starting Training\n",
      "Training:: Epoch 92, Iteration 0, Current loss 0.2599223594821426 Accuracy 87.07207492248307\n",
      "Training:: Epoch 92, Iteration 10, Current loss 0.19030362089915354 Accuracy 82.74627883195092\n",
      "Training:: Epoch 92, Iteration 20, Current loss 0.18752449704192248 Accuracy 90.065717415115\n",
      "Training:: Epoch 92, Iteration 30, Current loss 0.1773594460476379 Accuracy 79.8054325845767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 92, Iteration 40, Current loss 0.17510002474317954 Accuracy 88.68701550387597\n",
      "Training:: Epoch 92, Iteration 50, Current loss 0.1746223783561215 Accuracy 90.90682237859959\n",
      "Training:: Epoch 92, Iteration 60, Current loss 0.20502691968902495 Accuracy 86.95040710584752\n",
      "Training:: Epoch 92, Iteration 70, Current loss 0.1585137150512047 Accuracy 89.76613036987892\n",
      "Training:: Epoch 92, Iteration 80, Current loss 0.18724485809395114 Accuracy 85.20474077402685\n",
      "Training:: Epoch 92, Iteration 90, Current loss 0.18146949937836931 Accuracy 89.76187081135035\n",
      "Training:: Epoch 92, Iteration 100, Current loss 0.2690820478469832 Accuracy 83.36008560727662\n",
      "Training:: Epoch 92, Iteration 110, Current loss 0.16465824222668896 Accuracy 89.79645783769494\n",
      "Training:: Epoch 92, Iteration 120, Current loss 0.2702561006588964 Accuracy 86.73139158576052\n",
      "Training:: Epoch 92, Iteration 130, Current loss 0.27179068253638156 Accuracy 84.2636519632583\n",
      "Training:: Epoch 92, Iteration 140, Current loss 0.3326228066175442 Accuracy 87.9352694697298\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 92, Probability Accuracy 65.8987967241616\n",
      "Starting Training\n",
      "Training:: Epoch 93, Iteration 0, Current loss 0.2936788219382363 Accuracy 91.22780314561136\n",
      "Training:: Epoch 93, Iteration 10, Current loss 0.26660460371595057 Accuracy 82.82194848824189\n",
      "Training:: Epoch 93, Iteration 20, Current loss 0.19274939921628875 Accuracy 91.08584833310778\n",
      "Training:: Epoch 93, Iteration 30, Current loss 0.24448693418305353 Accuracy 90.72345929963966\n",
      "Training:: Epoch 93, Iteration 40, Current loss 0.23602546875982805 Accuracy 85.05265677357588\n",
      "Training:: Epoch 93, Iteration 50, Current loss 0.3289033899602418 Accuracy 84.67829342792393\n",
      "Training:: Epoch 93, Iteration 60, Current loss 0.24612247637514498 Accuracy 89.38615798483737\n",
      "Training:: Epoch 93, Iteration 70, Current loss 0.29298282721863106 Accuracy 83.31198770491804\n",
      "Training:: Epoch 93, Iteration 80, Current loss 0.31455055906317014 Accuracy 85.67422482172903\n",
      "Training:: Epoch 93, Iteration 90, Current loss 0.25735994339356516 Accuracy 82.70870194627634\n",
      "Training:: Epoch 93, Iteration 100, Current loss 0.20388217439636744 Accuracy 88.28200972447326\n",
      "Training:: Epoch 93, Iteration 110, Current loss 0.2513393265599084 Accuracy 85.52502706325069\n",
      "Training:: Epoch 93, Iteration 120, Current loss 0.21883998984383096 Accuracy 90.56275171437902\n",
      "Training:: Epoch 93, Iteration 130, Current loss 0.21559520803659518 Accuracy 89.21249281471546\n",
      "Training:: Epoch 93, Iteration 140, Current loss 0.2289328544651869 Accuracy 86.67762338761891\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 93, Probability Accuracy 65.69095222844594\n",
      "Starting Training\n",
      "Training:: Epoch 94, Iteration 0, Current loss 0.2104425503405819 Accuracy 88.31072915267893\n",
      "Training:: Epoch 94, Iteration 10, Current loss 0.2736477924808983 Accuracy 84.76358456007056\n",
      "Training:: Epoch 94, Iteration 20, Current loss 0.1467989731295196 Accuracy 83.89792568273393\n",
      "Training:: Epoch 94, Iteration 30, Current loss 0.25123713593555824 Accuracy 85.12378587599504\n",
      "Training:: Epoch 94, Iteration 40, Current loss 0.18822568618961608 Accuracy 85.15476140068594\n",
      "Training:: Epoch 94, Iteration 50, Current loss 0.23478306795121248 Accuracy 86.78229952433576\n",
      "Training:: Epoch 94, Iteration 60, Current loss 0.17313206262246056 Accuracy 88.84068972996421\n",
      "Training:: Epoch 94, Iteration 70, Current loss 0.15262687924777568 Accuracy 87.68531693211548\n",
      "Training:: Epoch 94, Iteration 80, Current loss 0.273352737260236 Accuracy 82.30337078651685\n",
      "Training:: Epoch 94, Iteration 90, Current loss 0.2591295438027611 Accuracy 86.67276608722172\n",
      "Training:: Epoch 94, Iteration 100, Current loss 0.21195863537419016 Accuracy 86.69593317480641\n",
      "Training:: Epoch 94, Iteration 110, Current loss 0.38865293494276937 Accuracy 84.69508769739717\n",
      "Training:: Epoch 94, Iteration 120, Current loss 0.3020612063417459 Accuracy 86.58762250702488\n",
      "Training:: Epoch 94, Iteration 130, Current loss 0.18122525850769955 Accuracy 88.83715691059963\n",
      "Training:: Epoch 94, Iteration 140, Current loss 0.23238086878637557 Accuracy 84.91695346401316\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 94, Probability Accuracy 66.53491199288884\n",
      "Starting Training\n",
      "Training:: Epoch 95, Iteration 0, Current loss 0.16146177249028107 Accuracy 86.99811100839999\n",
      "Training:: Epoch 95, Iteration 10, Current loss 0.2624798358063734 Accuracy 81.4622641509434\n",
      "Training:: Epoch 95, Iteration 20, Current loss 0.1969776297027391 Accuracy 86.619550543953\n",
      "Training:: Epoch 95, Iteration 30, Current loss 0.2209696947941027 Accuracy 83.95670026129153\n",
      "Training:: Epoch 95, Iteration 40, Current loss 0.19819091951141743 Accuracy 86.37342356198093\n",
      "Training:: Epoch 95, Iteration 50, Current loss 0.1859038614980826 Accuracy 87.85786077878286\n",
      "Training:: Epoch 95, Iteration 60, Current loss 0.15933957483688527 Accuracy 81.13026206189531\n",
      "Training:: Epoch 95, Iteration 70, Current loss 0.2642475028439587 Accuracy 86.85103833865814\n",
      "Training:: Epoch 95, Iteration 80, Current loss 0.20645909089912826 Accuracy 86.45117180081286\n",
      "Training:: Epoch 95, Iteration 90, Current loss 0.28163900480475473 Accuracy 84.35006086838902\n",
      "Training:: Epoch 95, Iteration 100, Current loss 0.209722541139766 Accuracy 88.48965051286775\n",
      "Training:: Epoch 95, Iteration 110, Current loss 0.20909295461207572 Accuracy 84.4813320922536\n",
      "Training:: Epoch 95, Iteration 120, Current loss 0.23561905579726908 Accuracy 88.83621940601722\n",
      "Training:: Epoch 95, Iteration 130, Current loss 0.2889008231430416 Accuracy 87.29763387297633\n",
      "Training:: Epoch 95, Iteration 140, Current loss 0.19679698666007703 Accuracy 88.49507735583686\n",
      "Calculating Expectation\n",
      "Epoch 95 iter 0\n",
      "Epoch 95 iter 10\n",
      "Epoch 95 iter 20\n",
      "Epoch 95 iter 30\n",
      "Epoch 95 iter 40\n",
      "Epoch 95 iter 50\n",
      "Epoch 95 iter 60\n",
      "Epoch 95 iter 70\n",
      "Epoch 95 iter 80\n",
      "Epoch 95 iter 90\n",
      "Epoch 95 iter 100\n",
      "Epoch 95 iter 110\n",
      "Epoch 95 iter 120\n",
      "Epoch 95 iter 130\n",
      "Epoch 95 iter 140\n",
      "Train Boundary avergage error = 83.278\n",
      "Train From boundary avergage accuracy = 87.361\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 95, Probability Accuracy 65.55606572591978\n",
      "Starting Training\n",
      "Training:: Epoch 96, Iteration 0, Current loss 0.24070307616582443 Accuracy 91.91234873615848\n",
      "Training:: Epoch 96, Iteration 10, Current loss 0.21500218625014045 Accuracy 89.67905795428308\n",
      "Training:: Epoch 96, Iteration 20, Current loss 0.2529433023518102 Accuracy 87.93483047115808\n",
      "Training:: Epoch 96, Iteration 30, Current loss 0.4107424065967518 Accuracy 84.17160598362969\n",
      "Training:: Epoch 96, Iteration 40, Current loss 0.30492433496074384 Accuracy 83.64505935605091\n",
      "Training:: Epoch 96, Iteration 50, Current loss 0.18765307858766173 Accuracy 87.5064479521304\n",
      "Training:: Epoch 96, Iteration 60, Current loss 0.3837284792641078 Accuracy 86.55310621242485\n",
      "Training:: Epoch 96, Iteration 70, Current loss 0.30236247877037553 Accuracy 84.26115276831024\n",
      "Training:: Epoch 96, Iteration 80, Current loss 0.28563574086252286 Accuracy 87.5577026301664\n",
      "Training:: Epoch 96, Iteration 90, Current loss 0.26656690930859717 Accuracy 88.31209040714175\n",
      "Training:: Epoch 96, Iteration 100, Current loss 0.21494848597952287 Accuracy 85.3240713486784\n",
      "Training:: Epoch 96, Iteration 110, Current loss 0.19865184610551884 Accuracy 89.9855800308289\n",
      "Training:: Epoch 96, Iteration 120, Current loss 0.8518285576034248 Accuracy 89.46376459143968\n",
      "Training:: Epoch 96, Iteration 130, Current loss 0.6215459433588029 Accuracy 85.74763082955978\n",
      "Training:: Epoch 96, Iteration 140, Current loss 0.27716997311941016 Accuracy 87.61534025374856\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 96, Probability Accuracy 65.31031248570253\n",
      "Starting Training\n",
      "Training:: Epoch 97, Iteration 0, Current loss 0.24475823490988594 Accuracy 90.39509067089568\n",
      "Training:: Epoch 97, Iteration 10, Current loss 0.3103353524562343 Accuracy 88.40090090090091\n",
      "Training:: Epoch 97, Iteration 20, Current loss 0.36194763342277697 Accuracy 90.98434158791474\n",
      "Training:: Epoch 97, Iteration 30, Current loss 0.4102556455462754 Accuracy 84.0852238419736\n",
      "Training:: Epoch 97, Iteration 40, Current loss 0.263402423725537 Accuracy 83.94432464222702\n",
      "Training:: Epoch 97, Iteration 50, Current loss 0.3175180266115174 Accuracy 86.89659901261656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 97, Iteration 60, Current loss 0.2517362094926973 Accuracy 89.019869964149\n",
      "Training:: Epoch 97, Iteration 70, Current loss 0.3040394308960369 Accuracy 83.19200919804541\n",
      "Training:: Epoch 97, Iteration 80, Current loss 0.2745844102759929 Accuracy 84.56934306569343\n",
      "Training:: Epoch 97, Iteration 90, Current loss 0.415805549530442 Accuracy 83.58923792083392\n",
      "Training:: Epoch 97, Iteration 100, Current loss 0.25734188731262253 Accuracy 79.29043230629277\n",
      "Training:: Epoch 97, Iteration 110, Current loss 0.20920926035143161 Accuracy 88.84033370652605\n",
      "Training:: Epoch 97, Iteration 120, Current loss 0.24943811126890475 Accuracy 86.39906708402381\n",
      "Training:: Epoch 97, Iteration 130, Current loss 0.2367393452413245 Accuracy 86.6459862298555\n",
      "Training:: Epoch 97, Iteration 140, Current loss 0.2850058510917796 Accuracy 88.36599503174165\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 97, Probability Accuracy 66.30991052229099\n",
      "Starting Training\n",
      "Training:: Epoch 98, Iteration 0, Current loss 0.3305098569803264 Accuracy 89.5753831243564\n",
      "Training:: Epoch 98, Iteration 10, Current loss 0.5783758399314389 Accuracy 78.7168110430312\n",
      "Training:: Epoch 98, Iteration 20, Current loss 0.39348405721687335 Accuracy 86.40470784486354\n",
      "Training:: Epoch 98, Iteration 30, Current loss 0.28957961713474 Accuracy 86.67883211678833\n",
      "Training:: Epoch 98, Iteration 40, Current loss 0.6126087117401949 Accuracy 86.82237828454194\n",
      "Training:: Epoch 98, Iteration 50, Current loss 0.18631339299264482 Accuracy 91.6650262928489\n",
      "Training:: Epoch 98, Iteration 60, Current loss 0.2812418299107367 Accuracy 86.54170385797877\n",
      "Training:: Epoch 98, Iteration 70, Current loss 0.2540833543802873 Accuracy 90.7645302409555\n",
      "Training:: Epoch 98, Iteration 80, Current loss 0.20224552203045135 Accuracy 87.01444622792937\n",
      "Training:: Epoch 98, Iteration 90, Current loss 0.3189129806423572 Accuracy 84.97576736672052\n",
      "Training:: Epoch 98, Iteration 100, Current loss 0.2197174407578267 Accuracy 89.80522682445759\n",
      "Training:: Epoch 98, Iteration 110, Current loss 0.2399940778708033 Accuracy 88.96712177799547\n",
      "Training:: Epoch 98, Iteration 120, Current loss 0.2372833683104914 Accuracy 89.96746411483254\n",
      "Training:: Epoch 98, Iteration 130, Current loss 0.21495227518113055 Accuracy 85.77088147903599\n",
      "Training:: Epoch 98, Iteration 140, Current loss 0.37734257322182063 Accuracy 81.57841674396096\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 98, Probability Accuracy 65.67567435081276\n",
      "Starting Training\n",
      "Training:: Epoch 99, Iteration 0, Current loss 0.23503722309604133 Accuracy 83.44565217391305\n",
      "Training:: Epoch 99, Iteration 10, Current loss 0.29742757340349896 Accuracy 89.16034353372801\n",
      "Training:: Epoch 99, Iteration 20, Current loss 0.2913065939027379 Accuracy 88.19593485671001\n",
      "Training:: Epoch 99, Iteration 30, Current loss 0.3002822833099774 Accuracy 83.6093585699264\n",
      "Training:: Epoch 99, Iteration 40, Current loss 0.2268743793572905 Accuracy 89.78555304740406\n",
      "Training:: Epoch 99, Iteration 50, Current loss 0.1925083443760115 Accuracy 92.2713220585561\n",
      "Training:: Epoch 99, Iteration 60, Current loss 0.20307667578584893 Accuracy 87.145387108631\n",
      "Training:: Epoch 99, Iteration 70, Current loss 0.21855384862109198 Accuracy 90.52592546814165\n",
      "Training:: Epoch 99, Iteration 80, Current loss 0.19629950674667543 Accuracy 89.021254713747\n",
      "Training:: Epoch 99, Iteration 90, Current loss 0.23401394817719207 Accuracy 87.37284387439186\n",
      "Training:: Epoch 99, Iteration 100, Current loss 0.30895364243983486 Accuracy 87.88884673748103\n",
      "Training:: Epoch 99, Iteration 110, Current loss 0.23874996725696537 Accuracy 86.71672354948805\n",
      "Training:: Epoch 99, Iteration 120, Current loss 0.23328483087186908 Accuracy 76.01114649681529\n",
      "Training:: Epoch 99, Iteration 130, Current loss 0.27403976384857376 Accuracy 80.98639788629025\n",
      "Training:: Epoch 99, Iteration 140, Current loss 0.26350301766648004 Accuracy 91.10559098324188\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 99, Probability Accuracy 66.33401198700645\n",
      "Starting Training\n",
      "Training:: Epoch 100, Iteration 0, Current loss 0.282505357929838 Accuracy 85.95353862776878\n",
      "Training:: Epoch 100, Iteration 10, Current loss 0.35300668221486914 Accuracy 86.70167870205383\n",
      "Training:: Epoch 100, Iteration 20, Current loss 0.23474468662507225 Accuracy 86.62260711030082\n",
      "Training:: Epoch 100, Iteration 30, Current loss 0.17676624872825494 Accuracy 89.61197231159208\n",
      "Training:: Epoch 100, Iteration 40, Current loss 0.25046912455476267 Accuracy 91.44319843978548\n",
      "Training:: Epoch 100, Iteration 50, Current loss 0.22850764903992152 Accuracy 89.58290101680846\n",
      "Training:: Epoch 100, Iteration 60, Current loss 0.25045713237813017 Accuracy 85.04218869854257\n",
      "Training:: Epoch 100, Iteration 70, Current loss 0.23609188656783725 Accuracy 86.61372299872936\n",
      "Training:: Epoch 100, Iteration 80, Current loss 0.1767005377526176 Accuracy 85.97750658052166\n",
      "Training:: Epoch 100, Iteration 90, Current loss 0.23684909893762057 Accuracy 83.18643311391276\n",
      "Training:: Epoch 100, Iteration 100, Current loss 0.24234554740849945 Accuracy 81.42212189616252\n",
      "Training:: Epoch 100, Iteration 110, Current loss 0.29386582015864054 Accuracy 87.30764172037354\n",
      "Training:: Epoch 100, Iteration 120, Current loss 0.31540142584180425 Accuracy 84.47458735087433\n",
      "Training:: Epoch 100, Iteration 130, Current loss 0.2410130867978418 Accuracy 83.08307727984231\n",
      "Training:: Epoch 100, Iteration 140, Current loss 0.19667339004243786 Accuracy 86.73863191453661\n",
      "Calculating Expectation\n",
      "Epoch 100 iter 0\n",
      "Epoch 100 iter 10\n",
      "Epoch 100 iter 20\n",
      "Epoch 100 iter 30\n",
      "Epoch 100 iter 40\n",
      "Epoch 100 iter 50\n",
      "Epoch 100 iter 60\n",
      "Epoch 100 iter 70\n",
      "Epoch 100 iter 80\n",
      "Epoch 100 iter 90\n",
      "Epoch 100 iter 100\n",
      "Epoch 100 iter 110\n",
      "Epoch 100 iter 120\n",
      "Epoch 100 iter 130\n",
      "Epoch 100 iter 140\n",
      "Train Boundary avergage error = 83.315\n",
      "Train From boundary avergage accuracy = 87.317\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 100, Probability Accuracy 66.22126615206635\n",
      "Starting Training\n",
      "Training:: Epoch 101, Iteration 0, Current loss 0.19282146638747605 Accuracy 89.26345609065156\n",
      "Training:: Epoch 101, Iteration 10, Current loss 0.21523562752366893 Accuracy 87.5453995157385\n",
      "Training:: Epoch 101, Iteration 20, Current loss 0.24107871691542632 Accuracy 85.24636320976067\n",
      "Training:: Epoch 101, Iteration 30, Current loss 0.1620733607359488 Accuracy 92.63447157401568\n",
      "Training:: Epoch 101, Iteration 40, Current loss 0.24635396639743157 Accuracy 87.96161425756148\n",
      "Training:: Epoch 101, Iteration 50, Current loss 0.35660251887184946 Accuracy 86.10829446359764\n",
      "Training:: Epoch 101, Iteration 60, Current loss 0.2050894033337376 Accuracy 90.7448607279523\n",
      "Training:: Epoch 101, Iteration 70, Current loss 0.2073709441037452 Accuracy 84.19723391461214\n",
      "Training:: Epoch 101, Iteration 80, Current loss 0.24214434977887334 Accuracy 88.55750651096362\n",
      "Training:: Epoch 101, Iteration 90, Current loss 0.33431332439653505 Accuracy 86.64716330581966\n",
      "Training:: Epoch 101, Iteration 100, Current loss 0.23874559357008818 Accuracy 92.92813264745543\n",
      "Training:: Epoch 101, Iteration 110, Current loss 0.30254420198019893 Accuracy 88.1633209502062\n",
      "Training:: Epoch 101, Iteration 120, Current loss 0.32669175872250866 Accuracy 88.27582494482425\n",
      "Training:: Epoch 101, Iteration 130, Current loss 0.441844947322906 Accuracy 89.33795493934142\n",
      "Training:: Epoch 101, Iteration 140, Current loss 0.3339235052271913 Accuracy 86.59638554216868\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 101, Probability Accuracy 65.18670056667037\n",
      "Starting Training\n",
      "Training:: Epoch 102, Iteration 0, Current loss 0.22496137750267767 Accuracy 88.80875724404379\n",
      "Training:: Epoch 102, Iteration 10, Current loss 0.264717553947513 Accuracy 86.45730462834946\n",
      "Training:: Epoch 102, Iteration 20, Current loss 0.24956676697138958 Accuracy 88.58777633289986\n",
      "Training:: Epoch 102, Iteration 30, Current loss 0.3479214355286778 Accuracy 86.48270718747087\n",
      "Training:: Epoch 102, Iteration 40, Current loss 0.6724699535278957 Accuracy 85.52557390253725\n",
      "Training:: Epoch 102, Iteration 50, Current loss 0.3829910277486043 Accuracy 88.3585313174946\n",
      "Training:: Epoch 102, Iteration 60, Current loss 0.3377934954500605 Accuracy 87.31464554133659\n",
      "Training:: Epoch 102, Iteration 70, Current loss 0.22705605782590513 Accuracy 82.53915519696251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 102, Iteration 80, Current loss 0.20963113876951625 Accuracy 90.12846053445078\n",
      "Training:: Epoch 102, Iteration 90, Current loss 0.32256001895315395 Accuracy 83.34840719525675\n",
      "Training:: Epoch 102, Iteration 100, Current loss 0.23717849052679071 Accuracy 85.26448362720403\n",
      "Training:: Epoch 102, Iteration 110, Current loss 0.289888131006907 Accuracy 83.44580345845635\n",
      "Training:: Epoch 102, Iteration 120, Current loss 0.23290176027434417 Accuracy 91.97144842397827\n",
      "Training:: Epoch 102, Iteration 130, Current loss 0.3082100518921701 Accuracy 91.24500031744016\n",
      "Training:: Epoch 102, Iteration 140, Current loss 0.24383384186216728 Accuracy 91.3565838253467\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 102, Probability Accuracy 66.28343976104419\n",
      "Starting Training\n",
      "Training:: Epoch 103, Iteration 0, Current loss 0.3227157072266829 Accuracy 90.43307943416757\n",
      "Training:: Epoch 103, Iteration 10, Current loss 0.22483093597201076 Accuracy 86.65811152047026\n",
      "Training:: Epoch 103, Iteration 20, Current loss 0.26416109445999253 Accuracy 80.77609277430865\n",
      "Training:: Epoch 103, Iteration 30, Current loss 0.4198316260394649 Accuracy 85.29329216952007\n",
      "Training:: Epoch 103, Iteration 40, Current loss 0.14521786914181192 Accuracy 89.52902761635951\n",
      "Training:: Epoch 103, Iteration 50, Current loss 0.24759990725107034 Accuracy 90.0591507018628\n",
      "Training:: Epoch 103, Iteration 60, Current loss 0.2327200487038267 Accuracy 78.21003692055244\n",
      "Training:: Epoch 103, Iteration 70, Current loss 0.23492384343292513 Accuracy 84.08732001857872\n",
      "Training:: Epoch 103, Iteration 80, Current loss 0.18867122365073014 Accuracy 86.4425477559078\n",
      "Training:: Epoch 103, Iteration 90, Current loss 0.17340205244619555 Accuracy 87.17868583483084\n",
      "Training:: Epoch 103, Iteration 100, Current loss 0.19508683833343368 Accuracy 88.82282590124723\n",
      "Training:: Epoch 103, Iteration 110, Current loss 0.195540167631065 Accuracy 89.25588313818223\n",
      "Training:: Epoch 103, Iteration 120, Current loss 0.2365043133689198 Accuracy 87.86455615469357\n",
      "Training:: Epoch 103, Iteration 130, Current loss 0.2388196039419179 Accuracy 85.32153793807417\n",
      "Training:: Epoch 103, Iteration 140, Current loss 0.15046638761096734 Accuracy 91.74192750216504\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 103, Probability Accuracy 66.31677331224387\n",
      "Starting Training\n",
      "Training:: Epoch 104, Iteration 0, Current loss 0.147928984931866 Accuracy 90.58026866329003\n",
      "Training:: Epoch 104, Iteration 10, Current loss 0.17667275429387777 Accuracy 90.40960779763286\n",
      "Training:: Epoch 104, Iteration 20, Current loss 0.1957668654291025 Accuracy 88.62844091837961\n",
      "Training:: Epoch 104, Iteration 30, Current loss 0.2126013954130281 Accuracy 84.51059832070929\n",
      "Training:: Epoch 104, Iteration 40, Current loss 0.25097423068688085 Accuracy 81.86654330981844\n",
      "Training:: Epoch 104, Iteration 50, Current loss 0.16589142788694258 Accuracy 89.91547080794182\n",
      "Training:: Epoch 104, Iteration 60, Current loss 0.15820591361780106 Accuracy 91.3895191190305\n",
      "Training:: Epoch 104, Iteration 70, Current loss 0.22615487033838322 Accuracy 87.76327161897831\n",
      "Training:: Epoch 104, Iteration 80, Current loss 0.23895655413586303 Accuracy 86.54214559386973\n",
      "Training:: Epoch 104, Iteration 90, Current loss 0.20109129501238454 Accuracy 88.94045409110382\n",
      "Training:: Epoch 104, Iteration 100, Current loss 0.2077076838062224 Accuracy 90.98360655737704\n",
      "Training:: Epoch 104, Iteration 110, Current loss 0.27682077673654737 Accuracy 83.42404750123701\n",
      "Training:: Epoch 104, Iteration 120, Current loss 0.2418953503205427 Accuracy 91.50658528750401\n",
      "Training:: Epoch 104, Iteration 130, Current loss 0.22695780140238397 Accuracy 88.7471988048234\n",
      "Training:: Epoch 104, Iteration 140, Current loss 0.3095085387094461 Accuracy 85.42880932556203\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 104, Probability Accuracy 66.4112183739763\n",
      "Starting Training\n",
      "Training:: Epoch 105, Iteration 0, Current loss 0.24663371119095473 Accuracy 84.88125850854637\n",
      "Training:: Epoch 105, Iteration 10, Current loss 0.18064712541785302 Accuracy 92.26998297125755\n",
      "Training:: Epoch 105, Iteration 20, Current loss 0.2419250842612783 Accuracy 90.12673934237348\n",
      "Training:: Epoch 105, Iteration 30, Current loss 0.1928793172399234 Accuracy 85.11273917063802\n",
      "Training:: Epoch 105, Iteration 40, Current loss 0.23748385867201602 Accuracy 82.72134917592948\n",
      "Training:: Epoch 105, Iteration 50, Current loss 0.19196771457855016 Accuracy 86.74200222823492\n",
      "Training:: Epoch 105, Iteration 60, Current loss 0.1436274025907228 Accuracy 89.09052982895285\n",
      "Training:: Epoch 105, Iteration 70, Current loss 0.1718464055780462 Accuracy 88.94971126082771\n",
      "Training:: Epoch 105, Iteration 80, Current loss 0.20797249906382298 Accuracy 83.62321672855188\n",
      "Training:: Epoch 105, Iteration 90, Current loss 0.1605008513122606 Accuracy 87.3585605639028\n",
      "Training:: Epoch 105, Iteration 100, Current loss 0.2049735006555744 Accuracy 87.57062146892656\n",
      "Training:: Epoch 105, Iteration 110, Current loss 0.2551597303176052 Accuracy 83.92813192222496\n",
      "Training:: Epoch 105, Iteration 120, Current loss 0.17732799414423744 Accuracy 90.42386185243328\n",
      "Training:: Epoch 105, Iteration 130, Current loss 0.2293723354738897 Accuracy 82.52669532658439\n",
      "Training:: Epoch 105, Iteration 140, Current loss 0.20778011811355962 Accuracy 86.3997208409666\n",
      "Calculating Expectation\n",
      "Epoch 105 iter 0\n",
      "Epoch 105 iter 10\n",
      "Epoch 105 iter 20\n",
      "Epoch 105 iter 30\n",
      "Epoch 105 iter 40\n",
      "Epoch 105 iter 50\n",
      "Epoch 105 iter 60\n",
      "Epoch 105 iter 70\n",
      "Epoch 105 iter 80\n",
      "Epoch 105 iter 90\n",
      "Epoch 105 iter 100\n",
      "Epoch 105 iter 110\n",
      "Epoch 105 iter 120\n",
      "Epoch 105 iter 130\n",
      "Epoch 105 iter 140\n",
      "Train Boundary avergage error = 83.527\n",
      "Train From boundary avergage accuracy = 87.237\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 105, Probability Accuracy 66.73352440212028\n",
      "Starting Training\n",
      "Training:: Epoch 106, Iteration 0, Current loss 0.18433803374844432 Accuracy 86.66970862394889\n",
      "Training:: Epoch 106, Iteration 10, Current loss 0.23048741139337128 Accuracy 80.25959978366684\n",
      "Training:: Epoch 106, Iteration 20, Current loss 0.1435504199068992 Accuracy 91.98319831983198\n",
      "Training:: Epoch 106, Iteration 30, Current loss 0.14942927025474428 Accuracy 89.34961258511387\n",
      "Training:: Epoch 106, Iteration 40, Current loss 0.17414988259279612 Accuracy 89.7801070980973\n",
      "Training:: Epoch 106, Iteration 50, Current loss 0.18741404673532266 Accuracy 84.36856946879048\n",
      "Training:: Epoch 106, Iteration 60, Current loss 0.24146022796290093 Accuracy 81.09302576263879\n",
      "Training:: Epoch 106, Iteration 70, Current loss 0.14026049588974757 Accuracy 86.77402415543497\n",
      "Training:: Epoch 106, Iteration 80, Current loss 0.14126858871723774 Accuracy 83.51420864437614\n",
      "Training:: Epoch 106, Iteration 90, Current loss 0.14977142655099618 Accuracy 85.82014345841485\n",
      "Training:: Epoch 106, Iteration 100, Current loss 0.16003613845876344 Accuracy 87.51018744906276\n",
      "Training:: Epoch 106, Iteration 110, Current loss 0.13204085964131662 Accuracy 90.80653101411224\n",
      "Training:: Epoch 106, Iteration 120, Current loss 0.15474848054731827 Accuracy 88.89094497902788\n",
      "Training:: Epoch 106, Iteration 130, Current loss 0.11544169216682347 Accuracy 90.48725438130643\n",
      "Training:: Epoch 106, Iteration 140, Current loss 0.21881107840144354 Accuracy 83.3130493576741\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 106, Probability Accuracy 66.74488068549468\n",
      "Starting Training\n",
      "Training:: Epoch 107, Iteration 0, Current loss 0.1685603342561665 Accuracy 84.03643336529242\n",
      "Training:: Epoch 107, Iteration 10, Current loss 0.16203276505872266 Accuracy 89.15943256404827\n",
      "Training:: Epoch 107, Iteration 20, Current loss 0.16787951185774144 Accuracy 88.7646782527008\n",
      "Training:: Epoch 107, Iteration 30, Current loss 0.12635058177876152 Accuracy 88.31884953019542\n",
      "Training:: Epoch 107, Iteration 40, Current loss 0.16075873643169925 Accuracy 89.9749111436337\n",
      "Training:: Epoch 107, Iteration 50, Current loss 0.16900426839942984 Accuracy 84.38602329450916\n",
      "Training:: Epoch 107, Iteration 60, Current loss 0.1469358514315583 Accuracy 87.86609240407205\n",
      "Training:: Epoch 107, Iteration 70, Current loss 0.30812052495776654 Accuracy 85.75919888216116\n",
      "Training:: Epoch 107, Iteration 80, Current loss 0.16550097592745316 Accuracy 90.8013432540989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 107, Iteration 90, Current loss 0.2072988180326979 Accuracy 87.13359639233371\n",
      "Training:: Epoch 107, Iteration 100, Current loss 0.16879922049110865 Accuracy 84.85388453314326\n",
      "Training:: Epoch 107, Iteration 110, Current loss 0.22505385387402702 Accuracy 89.56416830040718\n",
      "Training:: Epoch 107, Iteration 120, Current loss 0.21849881401232898 Accuracy 79.19246050078536\n",
      "Training:: Epoch 107, Iteration 130, Current loss 0.17697214709424003 Accuracy 89.47094423114466\n",
      "Training:: Epoch 107, Iteration 140, Current loss 0.1700431512523638 Accuracy 86.94762191450933\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 107, Probability Accuracy 66.57568023320414\n",
      "Starting Training\n",
      "Training:: Epoch 108, Iteration 0, Current loss 0.3590916002021844 Accuracy 87.36583869978534\n",
      "Training:: Epoch 108, Iteration 10, Current loss 0.2069951653895665 Accuracy 88.76548196015078\n",
      "Training:: Epoch 108, Iteration 20, Current loss 0.12684055973848693 Accuracy 86.0203790115227\n",
      "Training:: Epoch 108, Iteration 30, Current loss 0.21179891949753207 Accuracy 88.26643683821719\n",
      "Training:: Epoch 108, Iteration 40, Current loss 0.17998497750154754 Accuracy 79.86228400675589\n",
      "Training:: Epoch 108, Iteration 50, Current loss 0.22676137037054134 Accuracy 91.03798438472961\n",
      "Training:: Epoch 108, Iteration 60, Current loss 0.3214581322120637 Accuracy 89.44790739091718\n",
      "Training:: Epoch 108, Iteration 70, Current loss 0.24364499985675553 Accuracy 84.7862082399922\n",
      "Training:: Epoch 108, Iteration 80, Current loss 0.19915533028235535 Accuracy 87.34101579172001\n",
      "Training:: Epoch 108, Iteration 90, Current loss 0.22632481664525092 Accuracy 88.83032490974729\n",
      "Training:: Epoch 108, Iteration 100, Current loss 0.1986603555909311 Accuracy 86.73711855927964\n",
      "Training:: Epoch 108, Iteration 110, Current loss 0.17658706188569506 Accuracy 88.82300996593919\n",
      "Training:: Epoch 108, Iteration 120, Current loss 0.27886343711713507 Accuracy 88.16117216117216\n",
      "Training:: Epoch 108, Iteration 130, Current loss 0.2519062024680551 Accuracy 84.6943671432684\n",
      "Training:: Epoch 108, Iteration 140, Current loss 0.20234833992219275 Accuracy 86.50737522731865\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 108, Probability Accuracy 66.45394741142098\n",
      "Starting Training\n",
      "Training:: Epoch 109, Iteration 0, Current loss 0.16500003071713393 Accuracy 88.1768848862718\n",
      "Training:: Epoch 109, Iteration 10, Current loss 0.19472879511215557 Accuracy 86.80727874276262\n",
      "Training:: Epoch 109, Iteration 20, Current loss 0.22968617744747952 Accuracy 88.84312761249078\n",
      "Training:: Epoch 109, Iteration 30, Current loss 0.18180973729788003 Accuracy 87.96013595253183\n",
      "Training:: Epoch 109, Iteration 40, Current loss 0.19435095254309404 Accuracy 84.93458708094849\n",
      "Training:: Epoch 109, Iteration 50, Current loss 0.2991362856514531 Accuracy 86.06579299277882\n",
      "Training:: Epoch 109, Iteration 60, Current loss 0.17366476187788832 Accuracy 86.93475118728061\n",
      "Training:: Epoch 109, Iteration 70, Current loss 0.20431721645765133 Accuracy 82.9978298286313\n",
      "Training:: Epoch 109, Iteration 80, Current loss 0.22147398760476486 Accuracy 84.41952506596306\n",
      "Training:: Epoch 109, Iteration 90, Current loss 0.17151102258053727 Accuracy 90.4145193815819\n",
      "Training:: Epoch 109, Iteration 100, Current loss 0.2044346546238403 Accuracy 90.5149396058487\n",
      "Training:: Epoch 109, Iteration 110, Current loss 0.20552903085177715 Accuracy 88.36533876630976\n",
      "Training:: Epoch 109, Iteration 120, Current loss 0.22419143014348603 Accuracy 89.58460768503586\n",
      "Training:: Epoch 109, Iteration 130, Current loss 0.2185888594341305 Accuracy 87.33053808525507\n",
      "Training:: Epoch 109, Iteration 140, Current loss 0.2422210590788275 Accuracy 85.11838353787033\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 109, Probability Accuracy 66.29961633736168\n",
      "Starting Training\n",
      "Training:: Epoch 110, Iteration 0, Current loss 0.1892069759972085 Accuracy 87.22663689498917\n",
      "Training:: Epoch 110, Iteration 10, Current loss 0.27314951725216025 Accuracy 78.26045078019649\n",
      "Training:: Epoch 110, Iteration 20, Current loss 0.1705671844463667 Accuracy 84.6975546975547\n",
      "Training:: Epoch 110, Iteration 30, Current loss 0.17191321365680273 Accuracy 80.1380682150588\n",
      "Training:: Epoch 110, Iteration 40, Current loss 0.3590120078562994 Accuracy 84.22919802193077\n",
      "Training:: Epoch 110, Iteration 50, Current loss 0.1977939743538249 Accuracy 89.49902486591907\n",
      "Training:: Epoch 110, Iteration 60, Current loss 0.18150110522897106 Accuracy 90.78681578558408\n",
      "Training:: Epoch 110, Iteration 70, Current loss 0.18091967823609187 Accuracy 86.19885037846451\n",
      "Training:: Epoch 110, Iteration 80, Current loss 0.2533575517442691 Accuracy 84.43507696238105\n",
      "Training:: Epoch 110, Iteration 90, Current loss 0.6646680035745245 Accuracy 85.39152193111569\n",
      "Training:: Epoch 110, Iteration 100, Current loss 0.4737045984425129 Accuracy 90.41268697062534\n",
      "Training:: Epoch 110, Iteration 110, Current loss 0.486849667951467 Accuracy 89.49556541019956\n",
      "Training:: Epoch 110, Iteration 120, Current loss 0.4095841751329089 Accuracy 87.35944164404808\n",
      "Training:: Epoch 110, Iteration 130, Current loss 0.5260426703847658 Accuracy 80.99804941482445\n",
      "Training:: Epoch 110, Iteration 140, Current loss 0.5469534983317981 Accuracy 86.41975308641975\n",
      "Calculating Expectation\n",
      "Epoch 110 iter 0\n",
      "Epoch 110 iter 10\n",
      "Epoch 110 iter 20\n",
      "Epoch 110 iter 30\n",
      "Epoch 110 iter 40\n",
      "Epoch 110 iter 50\n",
      "Epoch 110 iter 60\n",
      "Epoch 110 iter 70\n",
      "Epoch 110 iter 80\n",
      "Epoch 110 iter 90\n",
      "Epoch 110 iter 100\n",
      "Epoch 110 iter 110\n",
      "Epoch 110 iter 120\n",
      "Epoch 110 iter 130\n",
      "Epoch 110 iter 140\n",
      "Train Boundary avergage error = 84.560\n",
      "Train From boundary avergage accuracy = 87.007\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 110, Probability Accuracy 64.83040738828359\n",
      "Starting Training\n",
      "Training:: Epoch 111, Iteration 0, Current loss 0.4069720985526258 Accuracy 83.47763991787915\n",
      "Training:: Epoch 111, Iteration 10, Current loss 0.2794574859791283 Accuracy 92.843109738984\n",
      "Training:: Epoch 111, Iteration 20, Current loss 0.8440401054905856 Accuracy 84.79612992398064\n",
      "Training:: Epoch 111, Iteration 30, Current loss 1.0216991898506156 Accuracy 85.00411329180868\n",
      "Training:: Epoch 111, Iteration 40, Current loss 2.72290414974899 Accuracy 75.3330074544788\n",
      "Training:: Epoch 111, Iteration 50, Current loss 6.291386163382891 Accuracy 35.12976385316811\n",
      "Training:: Epoch 111, Iteration 60, Current loss 3.3580174467906243 Accuracy 76.35241301907969\n",
      "Training:: Epoch 111, Iteration 70, Current loss 9.88313693887816 Accuracy 51.97008684464458\n",
      "Training:: Epoch 111, Iteration 80, Current loss 6.109764052984663 Accuracy 63.714001986097315\n",
      "Training:: Epoch 111, Iteration 90, Current loss 3.7663192180871095 Accuracy 68.49759615384616\n",
      "Training:: Epoch 111, Iteration 100, Current loss 2.6828133381781614 Accuracy 82.67278665372054\n",
      "Training:: Epoch 111, Iteration 110, Current loss 2.3171860749747575 Accuracy 78.97450188100878\n",
      "Training:: Epoch 111, Iteration 120, Current loss 3.8968922199977403 Accuracy 68.12328653318933\n",
      "Training:: Epoch 111, Iteration 130, Current loss 1.6909406456370581 Accuracy 87.27494510856306\n",
      "Training:: Epoch 111, Iteration 140, Current loss 1.680276357247255 Accuracy 83.66613881271485\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 111, Probability Accuracy 57.91990470525951\n",
      "Starting Training\n",
      "Training:: Epoch 112, Iteration 0, Current loss 1.5923298767912935 Accuracy 81.07323305650735\n",
      "Training:: Epoch 112, Iteration 10, Current loss 1.1559405972682602 Accuracy 88.43228013684846\n",
      "Training:: Epoch 112, Iteration 20, Current loss 1.4644892908102034 Accuracy 84.47373820270825\n",
      "Training:: Epoch 112, Iteration 30, Current loss 1.1300014010879105 Accuracy 88.35516739446871\n",
      "Training:: Epoch 112, Iteration 40, Current loss 0.7369420739442288 Accuracy 82.89911851126347\n",
      "Training:: Epoch 112, Iteration 50, Current loss 0.7598067120554451 Accuracy 86.56921754084264\n",
      "Training:: Epoch 112, Iteration 60, Current loss 0.5488069943929725 Accuracy 85.88263979193758\n",
      "Training:: Epoch 112, Iteration 70, Current loss 0.7232845846024506 Accuracy 78.06839186691312\n",
      "Training:: Epoch 112, Iteration 80, Current loss 0.5121139661538286 Accuracy 84.44154715341156\n",
      "Training:: Epoch 112, Iteration 90, Current loss 0.5672585354568905 Accuracy 87.33867378727192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 112, Iteration 100, Current loss 0.7512529479678846 Accuracy 76.27852084972463\n",
      "Training:: Epoch 112, Iteration 110, Current loss 0.7072116436599514 Accuracy 86.08543007606788\n",
      "Training:: Epoch 112, Iteration 120, Current loss 0.6418212843895253 Accuracy 87.34481377653184\n",
      "Training:: Epoch 112, Iteration 130, Current loss 0.7433425788834845 Accuracy 87.80878023806477\n",
      "Training:: Epoch 112, Iteration 140, Current loss 3.1811999027918283 Accuracy 69.43620178041543\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 112, Probability Accuracy 59.19891633278649\n",
      "Starting Training\n",
      "Training:: Epoch 113, Iteration 0, Current loss 0.9864688089151813 Accuracy 85.32643210974216\n",
      "Training:: Epoch 113, Iteration 10, Current loss 1.0068336079896878 Accuracy 73.18525671978111\n",
      "Training:: Epoch 113, Iteration 20, Current loss 0.9721402846679339 Accuracy 79.00659910440726\n",
      "Training:: Epoch 113, Iteration 30, Current loss 0.514911819036451 Accuracy 90.35364936042137\n",
      "Training:: Epoch 113, Iteration 40, Current loss 0.7551690386760269 Accuracy 84.30090990644624\n",
      "Training:: Epoch 113, Iteration 50, Current loss 0.43995738646866395 Accuracy 88.12543820511186\n",
      "Training:: Epoch 113, Iteration 60, Current loss 0.7253318027592406 Accuracy 81.86183243508084\n",
      "Training:: Epoch 113, Iteration 70, Current loss 0.5747203917142214 Accuracy 83.54406491790904\n",
      "Training:: Epoch 113, Iteration 80, Current loss 0.3950533539029695 Accuracy 80.22356341380483\n",
      "Training:: Epoch 113, Iteration 90, Current loss 0.5475783420541008 Accuracy 82.66142248443133\n",
      "Training:: Epoch 113, Iteration 100, Current loss 0.34674873527448974 Accuracy 90.26618056372261\n",
      "Training:: Epoch 113, Iteration 110, Current loss 0.3344975430331243 Accuracy 89.39643799472296\n",
      "Training:: Epoch 113, Iteration 120, Current loss 0.34058046752826104 Accuracy 88.20484470801085\n",
      "Training:: Epoch 113, Iteration 130, Current loss 0.5353109220328955 Accuracy 86.30682598544156\n",
      "Training:: Epoch 113, Iteration 140, Current loss 0.7893010206969081 Accuracy 85.8540925266904\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 113, Probability Accuracy 64.6540173465186\n",
      "Starting Training\n",
      "Training:: Epoch 114, Iteration 0, Current loss 1.054670525909776 Accuracy 84.0835719071694\n",
      "Training:: Epoch 114, Iteration 10, Current loss 0.622690451933774 Accuracy 80.45669431808045\n",
      "Training:: Epoch 114, Iteration 20, Current loss 0.6955045106120514 Accuracy 78.71124847803691\n",
      "Training:: Epoch 114, Iteration 30, Current loss 0.4864765189447923 Accuracy 91.36358388176885\n",
      "Training:: Epoch 114, Iteration 40, Current loss 0.4185353949495417 Accuracy 81.88731420670584\n",
      "Training:: Epoch 114, Iteration 50, Current loss 0.3749098941432427 Accuracy 84.91373264132417\n",
      "Training:: Epoch 114, Iteration 60, Current loss 0.34579415235172545 Accuracy 89.40318992853425\n",
      "Training:: Epoch 114, Iteration 70, Current loss 0.4421708308675449 Accuracy 88.57476154532354\n",
      "Training:: Epoch 114, Iteration 80, Current loss 0.3496164967670614 Accuracy 90.23350630096368\n",
      "Training:: Epoch 114, Iteration 90, Current loss 0.3982268866721942 Accuracy 84.25965512327205\n",
      "Training:: Epoch 114, Iteration 100, Current loss 0.5330842086793752 Accuracy 88.93617021276596\n",
      "Training:: Epoch 114, Iteration 110, Current loss 0.3691900160736252 Accuracy 84.2051282051282\n",
      "Training:: Epoch 114, Iteration 120, Current loss 0.30849058446324307 Accuracy 86.43970936402971\n",
      "Training:: Epoch 114, Iteration 130, Current loss 0.28807906582461135 Accuracy 88.38461922098648\n",
      "Training:: Epoch 114, Iteration 140, Current loss 0.36373894771502185 Accuracy 84.36202727977738\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 114, Probability Accuracy 66.3657115405983\n",
      "Starting Training\n",
      "Training:: Epoch 115, Iteration 0, Current loss 0.31586118015435266 Accuracy 79.49283351708931\n",
      "Training:: Epoch 115, Iteration 10, Current loss 0.29733842775281627 Accuracy 90.81923714759536\n",
      "Training:: Epoch 115, Iteration 20, Current loss 0.2820006944587171 Accuracy 89.79546954035628\n",
      "Training:: Epoch 115, Iteration 30, Current loss 0.28811709647926864 Accuracy 86.69721929770236\n",
      "Training:: Epoch 115, Iteration 40, Current loss 0.26420967270065987 Accuracy 86.40644281353511\n",
      "Training:: Epoch 115, Iteration 50, Current loss 0.23167595669323326 Accuracy 89.81771666133675\n",
      "Training:: Epoch 115, Iteration 60, Current loss 0.3180020039397963 Accuracy 83.72968091511137\n",
      "Training:: Epoch 115, Iteration 70, Current loss 0.2603231430647155 Accuracy 83.47370391166011\n",
      "Training:: Epoch 115, Iteration 80, Current loss 0.34109831775195354 Accuracy 79.65912983898595\n",
      "Training:: Epoch 115, Iteration 90, Current loss 0.2778990233456385 Accuracy 84.35554039068498\n",
      "Training:: Epoch 115, Iteration 100, Current loss 0.3073569213277432 Accuracy 88.35156918366428\n",
      "Training:: Epoch 115, Iteration 110, Current loss 0.313768342956758 Accuracy 91.2682065617184\n",
      "Training:: Epoch 115, Iteration 120, Current loss 0.2936740625560618 Accuracy 91.3091958546504\n",
      "Training:: Epoch 115, Iteration 130, Current loss 0.2548610403633006 Accuracy 84.85943991798413\n",
      "Training:: Epoch 115, Iteration 140, Current loss 0.28398255454130694 Accuracy 83.93082554910376\n",
      "Calculating Expectation\n",
      "Epoch 115 iter 0\n",
      "Epoch 115 iter 10\n",
      "Epoch 115 iter 20\n",
      "Epoch 115 iter 30\n",
      "Epoch 115 iter 40\n",
      "Epoch 115 iter 50\n",
      "Epoch 115 iter 60\n",
      "Epoch 115 iter 70\n",
      "Epoch 115 iter 80\n",
      "Epoch 115 iter 90\n",
      "Epoch 115 iter 100\n",
      "Epoch 115 iter 110\n",
      "Epoch 115 iter 120\n",
      "Epoch 115 iter 130\n",
      "Epoch 115 iter 140\n",
      "Train Boundary avergage error = 84.204\n",
      "Train From boundary avergage accuracy = 87.092\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 115, Probability Accuracy 65.98180380263923\n",
      "Starting Training\n",
      "Training:: Epoch 116, Iteration 0, Current loss 0.24845564440658469 Accuracy 87.8780507581286\n",
      "Training:: Epoch 116, Iteration 10, Current loss 0.24356444536164246 Accuracy 89.15320707982868\n",
      "Training:: Epoch 116, Iteration 20, Current loss 0.257909034704988 Accuracy 87.47833622183708\n",
      "Training:: Epoch 116, Iteration 30, Current loss 0.20186368350516348 Accuracy 88.76562629356735\n",
      "Training:: Epoch 116, Iteration 40, Current loss 0.26379655158012494 Accuracy 86.90396983810157\n",
      "Training:: Epoch 116, Iteration 50, Current loss 0.24240929939812164 Accuracy 88.7830818698986\n",
      "Training:: Epoch 116, Iteration 60, Current loss 0.2957684132242175 Accuracy 82.85968687393337\n",
      "Training:: Epoch 116, Iteration 70, Current loss 0.20656239019141143 Accuracy 88.31509243079186\n",
      "Training:: Epoch 116, Iteration 80, Current loss 0.21223033424892696 Accuracy 91.21351766513057\n",
      "Training:: Epoch 116, Iteration 90, Current loss 0.20228218455471914 Accuracy 88.30423940149626\n",
      "Training:: Epoch 116, Iteration 100, Current loss 0.24152173914002723 Accuracy 86.16506341523191\n",
      "Training:: Epoch 116, Iteration 110, Current loss 0.20960901572611756 Accuracy 88.91777142362014\n",
      "Training:: Epoch 116, Iteration 120, Current loss 0.19063765320769208 Accuracy 93.28919860627178\n",
      "Training:: Epoch 116, Iteration 130, Current loss 0.2386757123293352 Accuracy 79.77239117855076\n",
      "Training:: Epoch 116, Iteration 140, Current loss 0.220748441753344 Accuracy 85.99668409641627\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 116, Probability Accuracy 65.9697939202217\n",
      "Starting Training\n",
      "Training:: Epoch 117, Iteration 0, Current loss 0.1802784805941249 Accuracy 90.90277777777777\n",
      "Training:: Epoch 117, Iteration 10, Current loss 0.24927543736524152 Accuracy 91.38767737576018\n",
      "Training:: Epoch 117, Iteration 20, Current loss 0.2140682902540148 Accuracy 86.76177658142664\n",
      "Training:: Epoch 117, Iteration 30, Current loss 0.21519639036567165 Accuracy 85.84957078621065\n",
      "Training:: Epoch 117, Iteration 40, Current loss 0.19088600581794274 Accuracy 89.64320853399617\n",
      "Training:: Epoch 117, Iteration 50, Current loss 0.31506966128833636 Accuracy 85.9843602302999\n",
      "Training:: Epoch 117, Iteration 60, Current loss 0.2400472935147281 Accuracy 85.10052046127156\n",
      "Training:: Epoch 117, Iteration 70, Current loss 0.2395595136013017 Accuracy 86.78279936654891\n",
      "Training:: Epoch 117, Iteration 80, Current loss 0.18222509305995732 Accuracy 90.1610644257703\n",
      "Training:: Epoch 117, Iteration 90, Current loss 0.14847594057351307 Accuracy 88.3665620888574\n",
      "Training:: Epoch 117, Iteration 100, Current loss 0.19882049228550264 Accuracy 84.05806369100908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 117, Iteration 110, Current loss 0.19577505801113437 Accuracy 84.63781949305334\n",
      "Training:: Epoch 117, Iteration 120, Current loss 0.3156508854583131 Accuracy 80.61007330338141\n",
      "Training:: Epoch 117, Iteration 130, Current loss 0.2056501132564474 Accuracy 87.71960041336548\n",
      "Training:: Epoch 117, Iteration 140, Current loss 0.22543491545311511 Accuracy 87.7593984962406\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 117, Probability Accuracy 66.31121772037726\n",
      "Starting Training\n",
      "Training:: Epoch 118, Iteration 0, Current loss 0.20129289858291757 Accuracy 87.79704560051381\n",
      "Training:: Epoch 118, Iteration 10, Current loss 0.2764219852260387 Accuracy 82.83697710449303\n",
      "Training:: Epoch 118, Iteration 20, Current loss 0.19215493449202334 Accuracy 89.19712793733682\n",
      "Training:: Epoch 118, Iteration 30, Current loss 0.195795422622142 Accuracy 89.13573557301544\n",
      "Training:: Epoch 118, Iteration 40, Current loss 0.2805742050255838 Accuracy 82.55116807938805\n",
      "Training:: Epoch 118, Iteration 50, Current loss 0.22693041625520766 Accuracy 84.17127736348328\n",
      "Training:: Epoch 118, Iteration 60, Current loss 0.1924612695312849 Accuracy 86.25948930296757\n",
      "Training:: Epoch 118, Iteration 70, Current loss 0.22808466169240788 Accuracy 92.17681306879204\n",
      "Training:: Epoch 118, Iteration 80, Current loss 0.18234541468870546 Accuracy 88.31956250371515\n",
      "Training:: Epoch 118, Iteration 90, Current loss 0.1661386593964293 Accuracy 89.64765496111242\n",
      "Training:: Epoch 118, Iteration 100, Current loss 0.224630578786774 Accuracy 85.59608240459305\n",
      "Training:: Epoch 118, Iteration 110, Current loss 0.1894666433405456 Accuracy 87.13965130329709\n",
      "Training:: Epoch 118, Iteration 120, Current loss 0.16944865090344127 Accuracy 84.83864096282885\n",
      "Training:: Epoch 118, Iteration 130, Current loss 0.20003010746337274 Accuracy 88.23215714158741\n",
      "Training:: Epoch 118, Iteration 140, Current loss 0.21054287534996785 Accuracy 78.84728649558267\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 118, Probability Accuracy 66.29120124968136\n",
      "Starting Training\n",
      "Training:: Epoch 119, Iteration 0, Current loss 0.2178129634690995 Accuracy 87.87446504992867\n",
      "Training:: Epoch 119, Iteration 10, Current loss 0.15972213691925358 Accuracy 87.14009972655622\n",
      "Training:: Epoch 119, Iteration 20, Current loss 0.18647029098110146 Accuracy 87.71776310556042\n",
      "Training:: Epoch 119, Iteration 30, Current loss 0.21137764745273 Accuracy 83.72269994673161\n",
      "Training:: Epoch 119, Iteration 40, Current loss 0.2269636165037286 Accuracy 88.76781223805533\n",
      "Training:: Epoch 119, Iteration 50, Current loss 0.18530644618002517 Accuracy 85.47492992837122\n",
      "Training:: Epoch 119, Iteration 60, Current loss 0.15376574048243105 Accuracy 82.83614622905898\n",
      "Training:: Epoch 119, Iteration 70, Current loss 0.20515557826656014 Accuracy 81.62479545673308\n",
      "Training:: Epoch 119, Iteration 80, Current loss 0.25649146099191966 Accuracy 85.39875079207025\n",
      "Training:: Epoch 119, Iteration 90, Current loss 0.14377733959181543 Accuracy 88.72911347041169\n",
      "Training:: Epoch 119, Iteration 100, Current loss 0.20795569889874085 Accuracy 85.93914963048277\n",
      "Training:: Epoch 119, Iteration 110, Current loss 0.23288762512110556 Accuracy 85.88082901554404\n",
      "Training:: Epoch 119, Iteration 120, Current loss 0.22894874168522356 Accuracy 85.56592612067833\n",
      "Training:: Epoch 119, Iteration 130, Current loss 0.2061061446491226 Accuracy 79.00199600798403\n",
      "Training:: Epoch 119, Iteration 140, Current loss 0.20440064237716907 Accuracy 86.98260050562634\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 119, Probability Accuracy 66.20337387826065\n",
      "Starting Training\n",
      "Training:: Epoch 120, Iteration 0, Current loss 0.26397290374476556 Accuracy 83.34343871805977\n",
      "Training:: Epoch 120, Iteration 10, Current loss 0.1705200822103109 Accuracy 89.80187375211182\n",
      "Training:: Epoch 120, Iteration 20, Current loss 0.1542811152976783 Accuracy 85.68034418544917\n",
      "Training:: Epoch 120, Iteration 30, Current loss 0.17367526924181204 Accuracy 82.12587846217446\n",
      "Training:: Epoch 120, Iteration 40, Current loss 0.15915638329168455 Accuracy 87.12856829962766\n",
      "Training:: Epoch 120, Iteration 50, Current loss 0.1951264199672979 Accuracy 87.52330417323964\n",
      "Training:: Epoch 120, Iteration 60, Current loss 0.16658452817747937 Accuracy 86.22564290513714\n",
      "Training:: Epoch 120, Iteration 70, Current loss 0.15585989783678972 Accuracy 85.08234101849506\n",
      "Training:: Epoch 120, Iteration 80, Current loss 0.21374560882335125 Accuracy 86.62411971830986\n",
      "Training:: Epoch 120, Iteration 90, Current loss 0.1576809540204517 Accuracy 85.92505012080399\n",
      "Training:: Epoch 120, Iteration 100, Current loss 0.12719381183642284 Accuracy 85.29874640473219\n",
      "Training:: Epoch 120, Iteration 110, Current loss 0.17851973801136392 Accuracy 88.48770851624232\n",
      "Training:: Epoch 120, Iteration 120, Current loss 0.1787172649876178 Accuracy 88.58190388896163\n",
      "Training:: Epoch 120, Iteration 130, Current loss 0.16577622259125507 Accuracy 86.05784469096672\n",
      "Training:: Epoch 120, Iteration 140, Current loss 0.1355206974278091 Accuracy 79.64959568733154\n",
      "Calculating Expectation\n",
      "Epoch 120 iter 0\n",
      "Epoch 120 iter 10\n",
      "Epoch 120 iter 20\n",
      "Epoch 120 iter 30\n",
      "Epoch 120 iter 40\n",
      "Epoch 120 iter 50\n",
      "Epoch 120 iter 60\n",
      "Epoch 120 iter 70\n",
      "Epoch 120 iter 80\n",
      "Epoch 120 iter 90\n",
      "Epoch 120 iter 100\n",
      "Epoch 120 iter 110\n",
      "Epoch 120 iter 120\n",
      "Epoch 120 iter 130\n",
      "Epoch 120 iter 140\n",
      "Train Boundary avergage error = 84.395\n",
      "Train From boundary avergage accuracy = 87.004\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 120, Probability Accuracy 66.05631409355617\n",
      "Starting Training\n",
      "Training:: Epoch 121, Iteration 0, Current loss 0.16936309709585806 Accuracy 89.66256396072465\n",
      "Training:: Epoch 121, Iteration 10, Current loss 0.1635612410946344 Accuracy 86.50490526473452\n",
      "Training:: Epoch 121, Iteration 20, Current loss 0.20277858349578157 Accuracy 85.70022578590864\n",
      "Training:: Epoch 121, Iteration 30, Current loss 0.17977562414631446 Accuracy 89.03072263089571\n",
      "Training:: Epoch 121, Iteration 40, Current loss 0.20724078768395837 Accuracy 89.58802024746906\n",
      "Training:: Epoch 121, Iteration 50, Current loss 0.1388646324630424 Accuracy 89.15781780662913\n",
      "Training:: Epoch 121, Iteration 60, Current loss 0.22865978688708374 Accuracy 87.82152750296795\n",
      "Training:: Epoch 121, Iteration 70, Current loss 0.2029450595239215 Accuracy 86.44779066897063\n",
      "Training:: Epoch 121, Iteration 80, Current loss 0.19701952302417053 Accuracy 86.34686346863468\n",
      "Training:: Epoch 121, Iteration 90, Current loss 0.1917665728104017 Accuracy 84.73766576064574\n",
      "Training:: Epoch 121, Iteration 100, Current loss 0.12937568401733726 Accuracy 83.81863560732113\n",
      "Training:: Epoch 121, Iteration 110, Current loss 0.18317755041577263 Accuracy 91.16649620498465\n",
      "Training:: Epoch 121, Iteration 120, Current loss 0.137008471955054 Accuracy 82.64336377543924\n",
      "Training:: Epoch 121, Iteration 130, Current loss 0.17147409363931193 Accuracy 86.62859727483462\n",
      "Training:: Epoch 121, Iteration 140, Current loss 0.18023109178163674 Accuracy 84.58386450555454\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 121, Probability Accuracy 66.37510702684331\n",
      "Starting Training\n",
      "Training:: Epoch 122, Iteration 0, Current loss 0.17671053606955192 Accuracy 87.16618342743782\n",
      "Training:: Epoch 122, Iteration 10, Current loss 0.23528408421324654 Accuracy 85.22183737423718\n",
      "Training:: Epoch 122, Iteration 20, Current loss 0.1651844450145469 Accuracy 89.40845326190585\n",
      "Training:: Epoch 122, Iteration 30, Current loss 0.31342131396299894 Accuracy 82.01374745417515\n",
      "Training:: Epoch 122, Iteration 40, Current loss 0.14686363122988186 Accuracy 92.57449926722032\n",
      "Training:: Epoch 122, Iteration 50, Current loss 0.4179038436887563 Accuracy 85.47956581054629\n",
      "Training:: Epoch 122, Iteration 60, Current loss 0.18872769022307323 Accuracy 88.78639525895387\n",
      "Training:: Epoch 122, Iteration 70, Current loss 0.23002284863711642 Accuracy 85.42754671868119\n",
      "Training:: Epoch 122, Iteration 80, Current loss 0.21166021691784848 Accuracy 88.11089390438956\n",
      "Training:: Epoch 122, Iteration 90, Current loss 0.17559427046815854 Accuracy 90.7634348070844\n",
      "Training:: Epoch 122, Iteration 100, Current loss 0.1927292664086207 Accuracy 87.01744186046511\n",
      "Training:: Epoch 122, Iteration 110, Current loss 0.5012086182399514 Accuracy 82.35753786968021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 122, Iteration 120, Current loss 0.2856454637444108 Accuracy 82.9664482159861\n",
      "Training:: Epoch 122, Iteration 130, Current loss 0.2380127593430697 Accuracy 91.20429856325195\n",
      "Training:: Epoch 122, Iteration 140, Current loss 0.27640900793557466 Accuracy 88.96513694013848\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 122, Probability Accuracy 65.7594984280943\n",
      "Starting Training\n",
      "Training:: Epoch 123, Iteration 0, Current loss 0.37894210280643803 Accuracy 83.0752532561505\n",
      "Training:: Epoch 123, Iteration 10, Current loss 0.322104414497747 Accuracy 86.38308798356726\n",
      "Training:: Epoch 123, Iteration 20, Current loss 0.26078021793882966 Accuracy 88.7305141675997\n",
      "Training:: Epoch 123, Iteration 30, Current loss 0.16729270969360283 Accuracy 89.9325647161192\n",
      "Training:: Epoch 123, Iteration 40, Current loss 0.2454490232613844 Accuracy 87.94842122664903\n",
      "Training:: Epoch 123, Iteration 50, Current loss 0.19296467369232068 Accuracy 84.42507068803016\n",
      "Training:: Epoch 123, Iteration 60, Current loss 0.2841857474068078 Accuracy 91.0530089911192\n",
      "Training:: Epoch 123, Iteration 70, Current loss 0.2830221993561875 Accuracy 89.48183091324537\n",
      "Training:: Epoch 123, Iteration 80, Current loss 0.26398632595151267 Accuracy 86.23585250091274\n",
      "Training:: Epoch 123, Iteration 90, Current loss 0.2157383851945336 Accuracy 84.92122523497194\n",
      "Training:: Epoch 123, Iteration 100, Current loss 0.25402980885398235 Accuracy 86.81701153809479\n",
      "Training:: Epoch 123, Iteration 110, Current loss 0.2498576802195998 Accuracy 84.83220666344761\n",
      "Training:: Epoch 123, Iteration 120, Current loss 0.20792782970784288 Accuracy 90.36892585664823\n",
      "Training:: Epoch 123, Iteration 130, Current loss 0.4127518826204679 Accuracy 82.05456095481671\n",
      "Training:: Epoch 123, Iteration 140, Current loss 0.16947979469976168 Accuracy 83.36436493159556\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 123, Probability Accuracy 65.94397675801802\n",
      "Starting Training\n",
      "Training:: Epoch 124, Iteration 0, Current loss 0.29918203329905363 Accuracy 88.4822341797483\n",
      "Training:: Epoch 124, Iteration 10, Current loss 0.325039042842597 Accuracy 83.12056737588652\n",
      "Training:: Epoch 124, Iteration 20, Current loss 0.16243971848414704 Accuracy 91.709726443769\n",
      "Training:: Epoch 124, Iteration 30, Current loss 0.17736511825367116 Accuracy 86.98762256871886\n",
      "Training:: Epoch 124, Iteration 40, Current loss 0.27226765030241107 Accuracy 84.87747035573122\n",
      "Training:: Epoch 124, Iteration 50, Current loss 0.2561767920235638 Accuracy 89.26019335855402\n",
      "Training:: Epoch 124, Iteration 60, Current loss 0.2187229671123926 Accuracy 85.03719447396386\n",
      "Training:: Epoch 124, Iteration 70, Current loss 0.21642041864700723 Accuracy 81.61718256475048\n",
      "Training:: Epoch 124, Iteration 80, Current loss 0.21009820354601932 Accuracy 80.22533218814732\n",
      "Training:: Epoch 124, Iteration 90, Current loss 0.25660580876503114 Accuracy 81.23096798006829\n",
      "Training:: Epoch 124, Iteration 100, Current loss 0.17302056505906596 Accuracy 88.57265009466805\n",
      "Training:: Epoch 124, Iteration 110, Current loss 0.24075841905377457 Accuracy 81.68371998784318\n",
      "Training:: Epoch 124, Iteration 120, Current loss 0.16697293676323333 Accuracy 86.45727265606642\n",
      "Training:: Epoch 124, Iteration 130, Current loss 0.17158902463986606 Accuracy 88.34252113193679\n",
      "Training:: Epoch 124, Iteration 140, Current loss 0.19993153240929987 Accuracy 85.7769816390506\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 124, Probability Accuracy 66.53605579121432\n",
      "Starting Training\n",
      "Training:: Epoch 125, Iteration 0, Current loss 0.20559703035657093 Accuracy 86.63174331335314\n",
      "Training:: Epoch 125, Iteration 10, Current loss 0.21794941820966698 Accuracy 84.9989524408129\n",
      "Training:: Epoch 125, Iteration 20, Current loss 0.1673959481510876 Accuracy 83.4958395017612\n",
      "Training:: Epoch 125, Iteration 30, Current loss 0.1713276449500468 Accuracy 78.66435385949697\n",
      "Training:: Epoch 125, Iteration 40, Current loss 0.20659628891389803 Accuracy 84.17347865576748\n",
      "Training:: Epoch 125, Iteration 50, Current loss 0.12245788776282895 Accuracy 81.75633110747134\n",
      "Training:: Epoch 125, Iteration 60, Current loss 0.18222999008084056 Accuracy 85.4723827442548\n",
      "Training:: Epoch 125, Iteration 70, Current loss 0.17751234104954355 Accuracy 88.73788399405097\n",
      "Training:: Epoch 125, Iteration 80, Current loss 0.24550823944065972 Accuracy 79.51543406088861\n",
      "Training:: Epoch 125, Iteration 90, Current loss 0.150282396733671 Accuracy 80.30831473214286\n",
      "Training:: Epoch 125, Iteration 100, Current loss 0.1946390540754352 Accuracy 84.46062210456651\n",
      "Training:: Epoch 125, Iteration 110, Current loss 0.18991925455280861 Accuracy 88.37344720496894\n",
      "Training:: Epoch 125, Iteration 120, Current loss 0.15484893779939649 Accuracy 82.4102107450282\n",
      "Training:: Epoch 125, Iteration 130, Current loss 0.20194386070243708 Accuracy 83.15294117647059\n",
      "Training:: Epoch 125, Iteration 140, Current loss 0.13635124132839693 Accuracy 85.41022538871712\n",
      "Calculating Expectation\n",
      "Epoch 125 iter 0\n",
      "Epoch 125 iter 10\n",
      "Epoch 125 iter 20\n",
      "Epoch 125 iter 30\n",
      "Epoch 125 iter 40\n",
      "Epoch 125 iter 50\n",
      "Epoch 125 iter 60\n",
      "Epoch 125 iter 70\n",
      "Epoch 125 iter 80\n",
      "Epoch 125 iter 90\n",
      "Epoch 125 iter 100\n",
      "Epoch 125 iter 110\n",
      "Epoch 125 iter 120\n",
      "Epoch 125 iter 130\n",
      "Epoch 125 iter 140\n",
      "Train Boundary avergage error = 84.592\n",
      "Train From boundary avergage accuracy = 86.906\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 125, Probability Accuracy 66.3013320348499\n",
      "Starting Training\n",
      "Training:: Epoch 126, Iteration 0, Current loss 0.1342307683347163 Accuracy 91.60381543921916\n",
      "Training:: Epoch 126, Iteration 10, Current loss 0.15634383266300692 Accuracy 86.28328123315727\n",
      "Training:: Epoch 126, Iteration 20, Current loss 0.20108325888795614 Accuracy 88.64551266871892\n",
      "Training:: Epoch 126, Iteration 30, Current loss 0.1876419734789737 Accuracy 88.30218530604172\n",
      "Training:: Epoch 126, Iteration 40, Current loss 0.1662182867096609 Accuracy 84.26630753015576\n",
      "Training:: Epoch 126, Iteration 50, Current loss 0.15174973227313232 Accuracy 90.94571033487645\n",
      "Training:: Epoch 126, Iteration 60, Current loss 0.13600102455584367 Accuracy 87.21467999403252\n",
      "Training:: Epoch 126, Iteration 70, Current loss 0.15418234203848433 Accuracy 90.19680826315545\n",
      "Training:: Epoch 126, Iteration 80, Current loss 0.1745615352969642 Accuracy 82.68738747275657\n",
      "Training:: Epoch 126, Iteration 90, Current loss 0.15021018358396435 Accuracy 89.81402225507743\n",
      "Training:: Epoch 126, Iteration 100, Current loss 0.26254278708167555 Accuracy 86.6139846743295\n",
      "Training:: Epoch 126, Iteration 110, Current loss 0.18388280794916723 Accuracy 87.50888989461434\n",
      "Training:: Epoch 126, Iteration 120, Current loss 0.1615391876401611 Accuracy 83.19182117483972\n",
      "Training:: Epoch 126, Iteration 130, Current loss 0.13833164219220534 Accuracy 91.16237159848622\n",
      "Training:: Epoch 126, Iteration 140, Current loss 0.13964085324970474 Accuracy 87.44174168422397\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 126, Probability Accuracy 66.14365126569454\n",
      "Starting Training\n",
      "Training:: Epoch 127, Iteration 0, Current loss 0.1095299070906685 Accuracy 88.61571054245414\n",
      "Training:: Epoch 127, Iteration 10, Current loss 0.19909434589066916 Accuracy 87.60117361392149\n",
      "Training:: Epoch 127, Iteration 20, Current loss 0.264479711583303 Accuracy 81.90931234776092\n",
      "Training:: Epoch 127, Iteration 30, Current loss 0.11959509423270741 Accuracy 89.54871963590503\n",
      "Training:: Epoch 127, Iteration 40, Current loss 0.19256544658137165 Accuracy 89.96854714582078\n",
      "Training:: Epoch 127, Iteration 50, Current loss 0.14051234852270303 Accuracy 88.8138862102218\n",
      "Training:: Epoch 127, Iteration 60, Current loss 0.25868412894436743 Accuracy 86.64004914004914\n",
      "Training:: Epoch 127, Iteration 70, Current loss 0.12067714632036661 Accuracy 88.18390090474897\n",
      "Training:: Epoch 127, Iteration 80, Current loss 0.2881567482102792 Accuracy 83.28070175438596\n",
      "Training:: Epoch 127, Iteration 90, Current loss 0.21496829987315852 Accuracy 84.1944958120309\n",
      "Training:: Epoch 127, Iteration 100, Current loss 0.12179162373681414 Accuracy 89.01946712119853\n",
      "Training:: Epoch 127, Iteration 110, Current loss 0.1647757326915668 Accuracy 92.06951205705876\n",
      "Training:: Epoch 127, Iteration 120, Current loss 0.1428279911589456 Accuracy 86.45759717314488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 127, Iteration 130, Current loss 0.1376120400262035 Accuracy 84.89940404176188\n",
      "Training:: Epoch 127, Iteration 140, Current loss 0.17944943837042843 Accuracy 88.88719975676497\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 127, Probability Accuracy 66.24977941032294\n",
      "Starting Training\n",
      "Training:: Epoch 128, Iteration 0, Current loss 0.1475829987561551 Accuracy 90.22717104936123\n",
      "Training:: Epoch 128, Iteration 10, Current loss 0.17407153902112107 Accuracy 84.34228493400092\n",
      "Training:: Epoch 128, Iteration 20, Current loss 0.20409867939285536 Accuracy 84.17919333234113\n",
      "Training:: Epoch 128, Iteration 30, Current loss 0.19040310479051129 Accuracy 86.85934769947583\n",
      "Training:: Epoch 128, Iteration 40, Current loss 0.22234054557140198 Accuracy 83.09079546469066\n",
      "Training:: Epoch 128, Iteration 50, Current loss 0.19569199413483895 Accuracy 86.49165286096597\n",
      "Training:: Epoch 128, Iteration 60, Current loss 0.20437654360946722 Accuracy 85.38221242190372\n",
      "Training:: Epoch 128, Iteration 70, Current loss 0.14022546152921603 Accuracy 87.38153262929868\n",
      "Training:: Epoch 128, Iteration 80, Current loss 0.14118664916593832 Accuracy 85.70303785840824\n",
      "Training:: Epoch 128, Iteration 90, Current loss 0.18499552105065667 Accuracy 86.574676242719\n",
      "Training:: Epoch 128, Iteration 100, Current loss 0.24646921100982241 Accuracy 85.41875208541875\n",
      "Training:: Epoch 128, Iteration 110, Current loss 0.1875793708327359 Accuracy 86.11351930236115\n",
      "Training:: Epoch 128, Iteration 120, Current loss 0.18356960674660155 Accuracy 86.58280922431865\n",
      "Training:: Epoch 128, Iteration 130, Current loss 0.1652049108134732 Accuracy 88.50618218521322\n",
      "Training:: Epoch 128, Iteration 140, Current loss 0.14411687874053775 Accuracy 89.35708272409056\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 128, Probability Accuracy 66.39242740148629\n",
      "Starting Training\n",
      "Training:: Epoch 129, Iteration 0, Current loss 0.22502066274917445 Accuracy 85.60479375696767\n",
      "Training:: Epoch 129, Iteration 10, Current loss 0.20826191176891243 Accuracy 81.16700953805872\n",
      "Training:: Epoch 129, Iteration 20, Current loss 0.17339172775025152 Accuracy 85.82424050346357\n",
      "Training:: Epoch 129, Iteration 30, Current loss 0.18372149822719888 Accuracy 78.18217016745717\n",
      "Training:: Epoch 129, Iteration 40, Current loss 0.16108997969052666 Accuracy 89.75858037003921\n",
      "Training:: Epoch 129, Iteration 50, Current loss 0.1312920612268715 Accuracy 87.80271707028943\n",
      "Training:: Epoch 129, Iteration 60, Current loss 0.23421982414246567 Accuracy 83.69974874371859\n",
      "Training:: Epoch 129, Iteration 70, Current loss 0.15905753913223203 Accuracy 89.30206484163318\n",
      "Training:: Epoch 129, Iteration 80, Current loss 0.25258656662501316 Accuracy 85.92209072978304\n",
      "Training:: Epoch 129, Iteration 90, Current loss 0.12929606735423058 Accuracy 89.79055954985932\n",
      "Training:: Epoch 129, Iteration 100, Current loss 0.176883334229653 Accuracy 88.54390172072868\n",
      "Training:: Epoch 129, Iteration 110, Current loss 0.14840065272069322 Accuracy 90.16269676493904\n",
      "Training:: Epoch 129, Iteration 120, Current loss 0.15773186143201695 Accuracy 84.07008214234841\n",
      "Training:: Epoch 129, Iteration 130, Current loss 0.18778588119686945 Accuracy 87.22637479978644\n",
      "Training:: Epoch 129, Iteration 140, Current loss 0.22669622373805448 Accuracy 85.19954872373431\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 129, Probability Accuracy 66.96040496996713\n",
      "Starting Training\n",
      "Training:: Epoch 130, Iteration 0, Current loss 0.23103509413753937 Accuracy 87.64851365113235\n",
      "Training:: Epoch 130, Iteration 10, Current loss 0.36179895243749954 Accuracy 84.79596456056393\n",
      "Training:: Epoch 130, Iteration 20, Current loss 0.35493320281713064 Accuracy 84.06007509386734\n",
      "Training:: Epoch 130, Iteration 30, Current loss 1.0309117305410902 Accuracy 78.72482722746525\n",
      "Training:: Epoch 130, Iteration 40, Current loss 8.662436522405281 Accuracy 66.83560342096928\n",
      "Training:: Epoch 130, Iteration 50, Current loss 7.6686818287421294 Accuracy 58.03865370463612\n",
      "Training:: Epoch 130, Iteration 60, Current loss 3.6395399758042504 Accuracy 61.692439047528694\n",
      "Training:: Epoch 130, Iteration 70, Current loss 2.4984357812501186 Accuracy 75.37266428721394\n",
      "Training:: Epoch 130, Iteration 80, Current loss 1.6793929793682825 Accuracy 76.47058823529412\n",
      "Training:: Epoch 130, Iteration 90, Current loss 1.5571281463294628 Accuracy 83.29968029614673\n",
      "Training:: Epoch 130, Iteration 100, Current loss 2.674528771754766 Accuracy 78.22858658180854\n",
      "Training:: Epoch 130, Iteration 110, Current loss 1.7286189938815724 Accuracy 75.0754247604933\n",
      "Training:: Epoch 130, Iteration 120, Current loss 1.845082850989641 Accuracy 86.08\n",
      "Training:: Epoch 130, Iteration 130, Current loss 1.1246985548237909 Accuracy 86.03676983942286\n",
      "Training:: Epoch 130, Iteration 140, Current loss 1.0446691446486327 Accuracy 84.57537707110484\n",
      "Calculating Expectation\n",
      "Epoch 130 iter 0\n",
      "Epoch 130 iter 10\n",
      "Epoch 130 iter 20\n",
      "Epoch 130 iter 30\n",
      "Epoch 130 iter 40\n",
      "Epoch 130 iter 50\n",
      "Epoch 130 iter 60\n",
      "Epoch 130 iter 70\n",
      "Epoch 130 iter 80\n",
      "Epoch 130 iter 90\n",
      "Epoch 130 iter 100\n",
      "Epoch 130 iter 110\n",
      "Epoch 130 iter 120\n",
      "Epoch 130 iter 130\n",
      "Epoch 130 iter 140\n",
      "Train Boundary avergage error = 94.623\n",
      "Train From boundary avergage accuracy = 85.746\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 130, Probability Accuracy 59.73086425401473\n",
      "Starting Training\n",
      "Training:: Epoch 131, Iteration 0, Current loss 1.3183039248284985 Accuracy 85.60643873221862\n",
      "Training:: Epoch 131, Iteration 10, Current loss 2.608440788301258 Accuracy 82.130466928283\n",
      "Training:: Epoch 131, Iteration 20, Current loss 1.1085415031762473 Accuracy 85.61078998073218\n",
      "Training:: Epoch 131, Iteration 30, Current loss 0.502339923565202 Accuracy 88.30319664191153\n",
      "Training:: Epoch 131, Iteration 40, Current loss 1.1339127238962323 Accuracy 87.59020466106708\n",
      "Training:: Epoch 131, Iteration 50, Current loss 1.5465108205187235 Accuracy 84.70524314045096\n",
      "Training:: Epoch 131, Iteration 60, Current loss 0.7172777467548008 Accuracy 86.40094899169632\n",
      "Training:: Epoch 131, Iteration 70, Current loss 0.8772458654358402 Accuracy 83.44913408690242\n",
      "Training:: Epoch 131, Iteration 80, Current loss 0.4929396182945354 Accuracy 85.61724544257295\n",
      "Training:: Epoch 131, Iteration 90, Current loss 0.925539835049937 Accuracy 87.48893716308633\n",
      "Training:: Epoch 131, Iteration 100, Current loss 1.159679550942335 Accuracy 83.86772202844111\n",
      "Training:: Epoch 131, Iteration 110, Current loss 0.7255406355696002 Accuracy 78.26504120103849\n",
      "Training:: Epoch 131, Iteration 120, Current loss 0.8678415136646235 Accuracy 87.0817224370084\n",
      "Training:: Epoch 131, Iteration 130, Current loss 0.5806647541745875 Accuracy 81.10727780515853\n",
      "Training:: Epoch 131, Iteration 140, Current loss 0.7344065844981743 Accuracy 88.92517006802721\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 131, Probability Accuracy 63.07173576297884\n",
      "Starting Training\n",
      "Training:: Epoch 132, Iteration 0, Current loss 0.6812097966570909 Accuracy 84.14572864321607\n",
      "Training:: Epoch 132, Iteration 10, Current loss 0.8355871039788634 Accuracy 80.98327074086718\n",
      "Training:: Epoch 132, Iteration 20, Current loss 0.6453250412475716 Accuracy 83.42929292929293\n",
      "Training:: Epoch 132, Iteration 30, Current loss 0.42829922522838126 Accuracy 84.6132545689496\n",
      "Training:: Epoch 132, Iteration 40, Current loss 0.5942895296101648 Accuracy 80.88719091584422\n",
      "Training:: Epoch 132, Iteration 50, Current loss 0.9195550688605771 Accuracy 80.78614437453487\n",
      "Training:: Epoch 132, Iteration 60, Current loss 0.5393089902550948 Accuracy 79.22812380588461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-298:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 619, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3bc684dbca6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initialize_epoch = 15\n",
    "expectation_cal_gap = 5\n",
    "best_val_acc = 0\n",
    "for epoch in range(15, 1000):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        boundary_target_tensor = get_single_random(item_2, item[4])\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, boundary_target_tensor)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                            max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                es_loss, _ = get_estimated_loss(prob, item_1, item[4], item_2)\n",
    "                loss += es_loss\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(predictions[-1], dim=1)\n",
    "                correct = float(torch.sum((pred == item_2) * src_mask).item())\n",
    "                total = float(torch.sum(src_mask).item())\n",
    "                print(f\"Training:: Epoch {epoch}, Iteration {i}, Current loss {loss.item()}\" +\n",
    "                      f\" Accuracy {correct * 100.0 / total}\")\n",
    "    if epoch == initialize_epoch:\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-initial-15-epochs.wt\")\n",
    "    # Calculating Expectation Step\n",
    "    model.eval()\n",
    "    if (epoch >= initialize_epoch) and (epoch % expectation_cal_gap == 0):\n",
    "        print(\"Calculating Expectation\")\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, item in enumerate(trainloader):\n",
    "            with torch.no_grad():\n",
    "                item_0 = item[0].to(device)\n",
    "                item_1 = item[1].to(device)\n",
    "                item_2 = item[2].to(device)\n",
    "                src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "                src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "                middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "                prob = torch.softmax(predictions[-1], dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                calculate_element_probb(prob, item_1, item[4], item_2)\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "#                     pred = torch.argmax(prob, dim=2)\n",
    "#                     correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "#                     total += float(torch.sum(src_mask).item())\n",
    "                    print(f\"Epoch {epoch} iter {i}\")\n",
    "                    \n",
    "#         print(f\"Epoch {epoch} After Expectation}, train acc. {correct * 100.0 / total: .3f}\")\n",
    "        get_boundary_err()\n",
    "\n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if val_acc > best_val_acc:\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-last-model.wt\")\n",
    "    print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-tcn-emmax-best-model.wt  ms-tcn-initial-15-epochs.wt\r\n",
      "ms-tcn-emmax-last-model.wt\r\n"
     ]
    }
   ],
   "source": [
    "!ls '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split4/ms-tcn-emmax-best-model.wt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/\"\n",
    "                            f\"/results/em-maximize-mstcn-speed/ms-tcn-em.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 16, Probability Accuracy 59.57357998094212\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Validation Data Accuracy\")\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "        pred = torch.argmax(predictions[-1], dim=1)\n",
    "        correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "        total += float(torch.sum(src_mask).item())\n",
    "\n",
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_labels(labels_arr):\n",
    "    unique_ids = []\n",
    "    \n",
    "    prev_ele = None\n",
    "    start = 0\n",
    "    for i, ele in enumerate(labels_arr):\n",
    "        if prev_ele is not None and prev_ele != ele:\n",
    "            select_item = np.random.randint(start, i, 1)[0]\n",
    "            unique_ids.append(select_item)\n",
    "            start = i\n",
    "        prev_ele = ele\n",
    "    \n",
    "    select_item = np.random.randint(start, len(labels_arr), 1)[0]\n",
    "    unique_ids.append(select_item)\n",
    "    return unique_ids\n",
    "# get_selected_labels(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary(labels_arr):\n",
    "    unique_ids = []\n",
    "    \n",
    "    prev_ele = None\n",
    "    start = 0\n",
    "    for i, ele in enumerate(labels_arr):\n",
    "        if prev_ele is not None and prev_ele != ele:\n",
    "            unique_ids.append(i - 1)\n",
    "            start = i\n",
    "        prev_ele = ele\n",
    "    \n",
    "    unique_ids.append(len(labels_arr) - 1)\n",
    "    return unique_ids\n",
    "# get_boundary(np.array([2, 2, 2, 2, 3, 3, 4, 4, 4, 1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "boundary_dict = {}\n",
    "for file in glob.glob(\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/*txt\"):\n",
    "    video_id = file.split(\"/\")[-1].split(\".txt\")[0]\n",
    "    data = open(file).read().split(\"\\n\")[0:-1]\n",
    "    data = np.array(data)\n",
    "    boundary = get_boundary(data)\n",
    "    boundary_dict[video_id] = boundary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vidid_selected_frames = {}\n",
    "for batch in trainloader:\n",
    "    count_all = batch[1]\n",
    "    labels_all = batch[2]\n",
    "    video_ids = batch[5]\n",
    "    for i, count in enumerate(count_all):\n",
    "        video_id = video_ids[i]\n",
    "        labels = labels_all[i][:count]\n",
    "        selected_ids = get_selected_labels(labels)\n",
    "\n",
    "        loaded_vidid_selected_frames[video_id] = selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id_boundary_frames = {}\n",
    "for batch in trainloader:\n",
    "    count_all = batch[1]\n",
    "    labels_all = batch[2]\n",
    "    video_ids = batch[4]\n",
    "    for i, count in enumerate(count_all):\n",
    "        \n",
    "        labels = labels_all[i][:count]\n",
    "        selected_ids = get_boundary(labels)\n",
    "        video_id = video_ids[i]\n",
    "        video_id_boundary_frames[video_id] = selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in video_id_boundary_frames.keys():\n",
    "    if len(video_id_boundary_frames[ele]) != len(loaded_vidid_selected_frames[ele + \".txt\"]):\n",
    "        print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(video_id_boundary_frames, open(\"dump_dir/video_id_boundary_frames_dict.pkl\", \"wb\"))\n",
    "# pickle.dump(loaded_vidid_selected_frames, open(\"dump_dir/loaded_vidid_selected_frames_dict.pkl\", \"wb\"))\n",
    "pickle.dump(boundary_dict, open(\"dump_dir/chunk_1_video_id_boundary_frames_dict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_out(outp):\n",
    "    \n",
    "    weights = [1, 1, 1, 1, 0, 0]\n",
    "    ensemble_prob = F.softmax(outp[0], dim=1) * weights[0] / sum(weights)\n",
    "\n",
    "    for i, outp_ele in enumerate(outp[1]):\n",
    "        upped_logit = F.upsample(outp_ele, size=outp[0].shape[-1], mode='linear', align_corners=True)\n",
    "        ensemble_prob = ensemble_prob + F.softmax(upped_logit, dim=1) * weights[i + 1] / sum(weights)\n",
    "    \n",
    "    return ensemble_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/results/c2f-tcn-model/split2_c2ftcn_model.wt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration done\n",
      "11 iteration done\n",
      "21 iteration done\n",
      "31 iteration done\n",
      "41 iteration done\n",
      "51 iteration done\n",
      "61 iteration done\n",
      "71 iteration done\n",
      "81 iteration done\n",
      "91 iteration done\n",
      "101 iteration done\n",
      "111 iteration done\n",
      "121 iteration done\n",
      "131 iteration done\n",
      "141 iteration done\n",
      "151 iteration done\n",
      "Train Boundary avergage error = 107.269\n",
      "Train From boundary avergage accuracy = 87.407\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        prob = torch.softmax(predictions[-1], dim=1)\n",
    "        prob = prob.permute(0, 2, 1)\n",
    "        calculate_element_probb(prob, item_1, item[4], item_2)\n",
    "\n",
    "        if i%10==0:\n",
    "            print(f'{i+1} iteration done')\n",
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    idx = 4\n",
    "\n",
    "    cur_vid_feat = torch.softmax(predictions[-1], dim=1).permute(0, 2, 1)[idx]\n",
    "    cur_vidid = item[4][idx]\n",
    "\n",
    "    selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "    \n",
    "    bound_list = video_id_boundary_frames[cur_vidid]\n",
    "    \n",
    "    cumsum_feat = torch.cumsum(cur_vid_feat, dim=0)\n",
    "    prob_each_segment = prob_vals_per_segment(selected_frames, cur_vid_feat, item_2[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min prob 0 = 7.953912266787591e-36\n",
      "Min prob 1 = 2.7495868628582206e-249\n",
      "Min prob 2 = 8.185175464823537e-201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 442)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ymax = 1\n",
    "selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "\n",
    "plt.plot([0, item[1][idx].item()], [0, 0])\n",
    "\n",
    "for pivot in loaded_vidid_selected_frames[cur_vidid + \".txt\"]:\n",
    "    plt.plot([pivot, pivot], [0, ymax], '--')\n",
    "    \n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, ymax])\n",
    "    \n",
    "all_prob = []\n",
    "for i, segment in enumerate(prob_each_segment):\n",
    "    segment = segment.cpu().numpy()\n",
    "    print(f\"Min prob {i} = {np.min(segment).item()}\")\n",
    "    xs = np.arange(loaded_vidid_selected_frames[cur_vidid + \".txt\"][i], \n",
    "                   loaded_vidid_selected_frames[cur_vidid + \".txt\"][i+1])\n",
    "    plt.plot(xs, segment, '*')\n",
    "\n",
    "    \n",
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "\n",
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]], item_2[idx].unsqueeze(0))\n",
    "loss_arr = -loss_arr[0].detach().cpu().numpy()\n",
    "plt.plot(np.arange(selected_frames[0] - 1, selected_frames[-1] + 1), loss_arr/np.max(loss_arr), 'k+')\n",
    "\n",
    "plt.ylim([0, ymax])\n",
    "plt.xlim([0, item[1][idx].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1895, 48])\n"
     ]
    }
   ],
   "source": [
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "print(loss_prob.shape)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]], item_2[idx].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1387])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faf5b8ecb00>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "plt.plot(np.arange(selected_frames[0] - 1, selected_frames[-1] + 1), loss_arr[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3987, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([75, 345, 1305, 1415, 1440, 1519],\n",
       " [73, 282, 455, 1312, 1434, 1458],\n",
       " tensor(1520, device='cuda:0', dtype=torch.int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid], loaded_vidid_selected_frames[cur_vidid + \".txt\"], item_1[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_features_shortened = cur_vid_feat[:item[1][idx]]\n",
    "cur_features_shortened[:, item[2][idx][:item[1][idx]]].shape\n",
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47, 47, 47, 47, 47, 47, 47,  4,  4,  4,  4,  4,  4,  4,  4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[2][idx][video_id_boundary_frames[cur_vidid][1]-6:video_id_boundary_frames[cur_vidid][1]+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid][0]-6,video_id_boundary_frames[cur_vidid][0]+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0794, 13.3350],\n",
       "        [ 1.0831, 13.5102],\n",
       "        [ 1.1767, 13.7662],\n",
       "        [ 1.3750, 14.0177],\n",
       "        [ 1.7298, 14.1727],\n",
       "        [ 2.1706, 14.0367],\n",
       "        [ 2.7338, 13.4563],\n",
       "        [ 4.5600, 12.1745],\n",
       "        [ 7.8450, 10.3246],\n",
       "        [11.0151,  8.3563],\n",
       "        [13.4775,  6.6546],\n",
       "        [14.1836,  5.2898],\n",
       "        [11.2142,  4.2791],\n",
       "        [ 5.9829,  3.5694],\n",
       "        [ 2.3440,  2.9389],\n",
       "        [ 0.7406,  2.3515]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_vid_feat[video_id_boundary_frames[cur_vidid][1]-7:video_id_boundary_frames[cur_vidid][1]+9][:,[47,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frames_and_get_classification_value(model_output, count_list, video_ids_list, labels_all, p_criterion):\n",
    "    new_selected_frames = {}\n",
    "#     new_selected_frames_probs_values = {}\n",
    "#     new_selected_frames_labels = {}\n",
    "    \n",
    "    labels_arr = []\n",
    "    probs_arr = []\n",
    "    \n",
    "    for i, video_id in enumerate(video_ids_list):\n",
    "        current_boundary_frames = boundaries_dict[video_id]\n",
    "        current_video_logits = model_output[i].T\n",
    "        current_video_count = count_list[i]\n",
    "        current_selected_frames = loaded_vidid_selected_frames[video_id]\n",
    "        labels = labels_all[i]\n",
    "        cur_seg_start = 0\n",
    "        for seg_num, ele in enumerate(current_boundary_frames):\n",
    "            cur_seg_end = ele + 1\n",
    "            total_seg_len = cur_seg_end - cur_seg_start\n",
    "            per_frames_far_from_boundary = int(0.3 * total_seg_len)\n",
    "            new_frames_start = cur_seg_start + per_frames_far_from_boundary\n",
    "            new_frames_end = cur_seg_end - per_frames_far_from_boundary\n",
    "            \n",
    "            frames_added = list(range(new_frames_start, new_frames_end))\n",
    "            frames_added.append(current_selected_frames[seg_num])\n",
    "            frames_added = list(set(frames_added))\n",
    "            frames_added.sort()\n",
    "            new_selected_frames[video_id] = frames_added\n",
    "\n",
    "            \n",
    "            labels_seg = torch.stack([labels[current_selected_frames[seg_num]]] * len(frames_added))\n",
    "            frames_added = torch.tensor(np.array(frames_added), dtype=torch.long, device=current_video_logits.device)\n",
    "            prob_seg = current_video_logits[frames_added, :]\n",
    "            \n",
    "            labels_arr.append(labels_seg)\n",
    "            probs_arr.append(prob_seg)\n",
    "            \n",
    "            cur_seg_start = cur_seg_end\n",
    "            \n",
    "    labels_arr = torch.cat(labels_arr)\n",
    "    probs_arr = torch.cat(probs_arr)\n",
    "    loss = p_criterion(probs_arr, labels_arr)\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
