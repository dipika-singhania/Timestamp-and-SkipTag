{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 2, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split2-slup15/', 'project_name': 'breakfast-split-2s', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split2.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split2.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split2_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=2,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split2-slup15/\",\n",
    "    project_name=\"breakfast-split-2\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1261\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 451\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = Breakfast(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = iter(trainloader).next()\n",
    "# print(item[0]) # -- data feature\n",
    "# print(item[1]) # -- valid count\n",
    "# item[2] # -- Actual labels\n",
    "# print(item[5]) # video names\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_frames_dict = pickle.load(open(\"data/breakfast_len_assum_annotations.pkl\", 'rb'))\n",
    "# loaded_vidid_selected_frames\n",
    "boundary_frames_dict = pickle.load(open(\"data/breakfast_boundary_annotations.pkl\", \"rb\"))\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"data/breakfast_meanvar_actions.pkl\", \"rb\"))\n",
    "def get_possion_prob(cur_len, cur_class):\n",
    "    mean_class, std_class = loaded_mean_var_actions[label_id_to_label_name[cur_class]]\n",
    "    mean_class = mean_class\n",
    "    prob = cur_len * torch.log(torch.tensor(mean_class, device=device) + 1e-5)\n",
    "    prob = prob - mean_class\n",
    "    factorials = torch.cumsum(torch.log(torch.arange(1, torch.max(cur_len)+1, 1).type(torch.float).to(device)), \n",
    "                              dim=0)[min(cur_len)-1:]\n",
    "    prob = prob - factorials\n",
    "    return prob\n",
    "\n",
    "# get_possion_prob(torch.arange(10, 21), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_video_each_segment_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels):\n",
    "    prob_each_segment = []\n",
    "    \n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    cur_boundary = 0\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[i]\n",
    "        label_next_ele = labels[i + 1]\n",
    "\n",
    "        indices = torch.arange(cur_ele, next_ele).to(cumsum_feat.device)\n",
    "        strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "        end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "        left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "        right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "\n",
    "        cur_boundary_len = indices - cur_boundary\n",
    "        len_prob = get_possion_prob(cur_boundary_len, label_cur_ele)\n",
    "\n",
    "        prob = torch.softmax((left_sum + right_sum + len_prob), dim=0)\n",
    "#         prob = torch.softmax((left_sum + right_sum), dim=0)\n",
    "\n",
    "        cur_boundary = round(np.sum(np.arange(cur_ele, next_ele, 1) * prob.detach().cpu().numpy()).item())\n",
    "        prob_each_segment.append(prob)\n",
    "    \n",
    "    return prob_each_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_element_probb(data_feat, data_count, video_ids): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "        prob_video = prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels)\n",
    "        prob_video_each_segment_dict[cur_vidid] = prob_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_loss(data_feat, data_count, video_ids): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "#     global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    loss_arr = []\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "\n",
    "        prob_each_video = prob_video_each_segment_dict[cur_vidid]\n",
    "        \n",
    "        log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "        cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "        \n",
    "        \n",
    "        current_vid_prob_arr = []\n",
    "        # Start segment log probability\n",
    "        start_ele_idx = selected_frames_indices[0]\n",
    "        if start_ele_idx > 0:\n",
    "            start_ele_label_idx = selected_frames_labels[0]\n",
    "            first_segment_prob = (cumsum_feat[start_ele_idx - 1, :])[start_ele_label_idx]\n",
    "            current_vid_prob_arr.append(first_segment_prob.unsqueeze(0))\n",
    "        \n",
    "        for i, cur_ele in enumerate(selected_frames_indices[:-1]):\n",
    "            next_ele = selected_frames_indices[i + 1]\n",
    "            label_cur_ele = selected_frames_labels[i]\n",
    "            label_next_ele = selected_frames_labels[i + 1]\n",
    "\n",
    "            indices = torch.arange(cur_ele, next_ele)\n",
    "            strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "            end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "            left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "            right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "            current_vid_prob_arr.append((left_sum + right_sum)  * (prob_each_video[i]))\n",
    "        \n",
    "        # End segment log probability\n",
    "        end_index = cur_vid_count.item() - 1\n",
    "        last_ele_label_idx = selected_frames_labels[-1]\n",
    "        last_segment_sum_prob = (cumsum_feat[end_index, :] - cumsum_feat[selected_frames_indices[-1] - 1, \\\n",
    "                                                                         :])[last_ele_label_idx]\n",
    "        current_vid_prob_arr.append(last_segment_sum_prob.unsqueeze(0))\n",
    "            \n",
    "        loss_arr.append(torch.cat(current_vid_prob_arr))\n",
    "    return -torch.mean(torch.cat(loss_arr)), loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_file_list = set(open(config.train_split_file).read().split(\"\\n\")[0:-1])\n",
    "\n",
    "def get_estimated_boundaries():\n",
    "    estimated_boundary_dict = {}\n",
    "    for video_id in train_split_file_list:\n",
    "        ele = video_id.split(\".txt\")[0]\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[video_id]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        \n",
    "        boundary_list = []\n",
    "        for i, segment in enumerate(estimated_boundary_probs):\n",
    "            estimated_boundary = np.sum(np.arange(selected_frames_indices[i], selected_frames_indices[i + 1], 1) \\\n",
    "                                        * segment.detach().cpu().numpy())\n",
    "            estimated_boundary = round(estimated_boundary.item())\n",
    "            \n",
    "            if (estimated_boundary < selected_frames_indices[i]) or (estimated_boundary > selected_frames_indices[i + 1]):\n",
    "                print(\"Estimated value wrong\")\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "            boundary_list.append(estimated_boundary)\n",
    "\n",
    "        estimated_boundary_dict[ele] = boundary_list\n",
    "    return estimated_boundary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_err():\n",
    "    err_list = []\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    estimated_boundar_dict = get_estimated_boundaries()\n",
    "    for video_id in train_split_file_list:\n",
    "        ele = video_id.split(\".txt\")[0]\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        estimated_boundary_list = estimated_boundar_dict[ele]\n",
    "        \n",
    "        estimated = np.array(estimated_boundary_list) #.detach().cpu().numpy()\n",
    "        actual = np.array(boundary_frames_dict[video_id][:-1])\n",
    "        if len(actual) != len(estimated):\n",
    "            print(ele)\n",
    "            continue\n",
    "        \n",
    "        mse_err = (actual - estimated)**2\n",
    "        err_list.append(mse_err)\n",
    "        \n",
    "        estimated_labels = []\n",
    "        actual_labels = []\n",
    "        start_v1 = 0\n",
    "        start_v2 = 0\n",
    "        for i, v1 in enumerate(estimated):\n",
    "            estimated_labels.extend([i] * (v1 - start_v1))\n",
    "            start_v1 = v1\n",
    "            v2 = actual[i]\n",
    "            actual_labels.extend([i] * (v2 - start_v2))\n",
    "            start_v2 = v2\n",
    "            \n",
    "        last_ele = boundary_frames_dict[video_id][-1]\n",
    "        estimated_labels.extend([i+1] * (last_ele - start_v1))\n",
    "        actual_labels.extend([i+1] * (last_ele - start_v2))\n",
    "        \n",
    "        correct += np.sum(np.array(actual_labels) == np.array(estimated_labels))\n",
    "        total += len(actual_labels)\n",
    "        \n",
    "    print(f\"Train Boundary avergage error = {np.sqrt(np.mean(np.concatenate(err_list))):.3f}\")\n",
    "    print(f\"Train From boundary avergage accuracy = {correct * 100.0 / total:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_file=torch.load(\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split1/ms-tcn-best-model.wt\")\n",
    "# model.load_state_dict(loaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels_dir = \"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/length_segmentation_output/\"\n",
    "def get_single_random(output_p, video_ids):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((output_p.shape[0], output_p.shape[2]), dtype=torch.long, \n",
    "                                        device=output_p.device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        pseudo_l = open(pseudo_labels_dir + cur_vidid + \".txt\").read().split(\"\\n\")[0:-1]\n",
    "        pseudo_l = [label_name_to_label_id_dict[ele] for ele in pseudo_l]\n",
    "        abc = torch.tensor(pseudo_l).to(torch.long).to(boundary_target_tensor.device)\n",
    "        frame_idx_tensor = torch.arange(0, len(pseudo_l), 1).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = abc\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labels = pickle.load(open(\"data/breakfast_weaklysupervised_labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = pickle.load(open('data/breakfast_lengthmodel_multinomial_prior.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def change_selected_frames(model):\n",
    "    global selected_frames_dict\n",
    "    new_selected_frame_dict = {}\n",
    "    with torch.no_grad():\n",
    "        for train_idx, item in enumerate(trainloader):\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            if train_idx % 10 == 0:\n",
    "                print(f\"Completed {train_idx} videos selected frames calculation\")\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            \n",
    "            for idx, video_id in enumerate(item[4]):\n",
    "                start = 0\n",
    "                new_index_label_pair_list = []\n",
    "                weakly_labels_video = [label_name_to_label_id_dict[wl] for wl in weakly_labels[video_id + \".txt\"]]\n",
    "                cur_video_predictions = predictions[-1][idx][:, :item_1[idx]]\n",
    "                cur_preds_for_weakly_labels = torch.softmax(cur_video_predictions[weakly_labels_video], dim=0)\n",
    "                prior_probs_cur_vid = prior_probs[video_id]\n",
    "                weakly_labels_masked = []\n",
    "                for i, prob_class in enumerate(cur_preds_for_weakly_labels):\n",
    "                    prob_class_masked = prob_class * torch.tensor(prior_probs_cur_vid[i], \n",
    "                                                                  dtype=prob_class.dtype, device=prob_class.device)\n",
    "                    weakly_labels_masked.append(prob_class_masked)\n",
    "                    \n",
    "                weakly_labels_masked = torch.stack(weakly_labels_masked)\n",
    "                weakly_labels_masked = weakly_labels_masked / torch.sum(weakly_labels_masked, dim=0)\n",
    "\n",
    "                for i in range(len(weakly_labels_video)):\n",
    "                    cur_l = weakly_labels_video[i]\n",
    "                    prob_class = weakly_labels_masked[i]\n",
    "                    expected_value_of_class = torch.argmax(prob_class)\n",
    "                    new_index_label_pair_list.append((int(expected_value_of_class.item()),\n",
    "                                                      weakly_labels_video[i])) \n",
    "                \n",
    "                back_list = copy.deepcopy(new_index_label_pair_list)\n",
    "                error_list = []\n",
    "                if new_index_label_pair_list[0][0] > new_index_label_pair_list[1][0]:\n",
    "                    error_list.append(1)\n",
    "                else:\n",
    "                    error_list.append(0)\n",
    "                for i in range(1, len(new_index_label_pair_list) - 1, 1):\n",
    "                    err = 0\n",
    "                    prev_ele = new_index_label_pair_list[i - 1]\n",
    "                    cur_ele = new_index_label_pair_list[i]\n",
    "                    next_ele = new_index_label_pair_list[i + 1]\n",
    "                    if not (prev_ele[0] < cur_ele[0]):\n",
    "                        err += 1\n",
    "                    if not (cur_ele[0] < next_ele[0]):\n",
    "                        err += 1\n",
    "                    error_list.append(err)\n",
    "\n",
    "                if new_index_label_pair_list[-1][0] < new_index_label_pair_list[-2][0]:\n",
    "                    error_list.append(1)\n",
    "                else:\n",
    "                    error_list.append(0)\n",
    "                    \n",
    "                if error_list[0] == 1 and error_list[1] == 1:\n",
    "                    new_index = new_index_label_pair_list[1][0] // 2\n",
    "                    new_index_label_pair_list[0] = (new_index, new_index_label_pair_list[0][1])\n",
    "                    error_list[0] = 0\n",
    "                    error_list[1] = 0\n",
    "                    \n",
    "                if error_list[-1] == 1 and error_list[-2] == 1:\n",
    "                    new_index = (new_index_label_pair_list[-2][0] + weakly_labels_masked.shape[1]) // 2\n",
    "                    new_index_label_pair_list[-1] = (new_index, new_index_label_pair_list[-1][1])\n",
    "                    error_list[-1] = 0\n",
    "                    error_list[-2] = 0\n",
    "                    \n",
    "                start_flag = False\n",
    "                start_index = -1\n",
    "                end_index = -1\n",
    "                for i in range(1, len(error_list) - 1):\n",
    "                    if error_list[i] == 1 and error_list[i + 1] == 2:\n",
    "                        start_flag = True\n",
    "                        start_index = i\n",
    "                        \n",
    "                    if (start_flag is True) and (error_list[i] == 2 or error_list[i + 1] == 1):\n",
    "                        start_flag = False\n",
    "                        end_index = i + 1\n",
    "                        \n",
    "                        num_div = end_index - start_index - 1\n",
    "                        increm = (new_index_label_pair_list[end_index][0] - \\\n",
    "                                  new_index_label_pair_list[start_index][0]) // num_div\n",
    "                        value = list(range(new_index_label_pair_list[start_index][0], \n",
    "                                           new_index_label_pair_list[end_index][0], increm))\n",
    "                        count = 0\n",
    "                        for ch_i in range(start_index + 1, end_index):\n",
    "                            old_ele = new_index_label_pair_list[ch_i]\n",
    "                            new_ele = (value[count], old_ele[1])\n",
    "                            new_index_label_pair_list[ch_i] = new_ele\n",
    "                            count += 1\n",
    "                    \n",
    "                final_list = new_index_label_pair_list\n",
    "                is_valid_list = True\n",
    "                for i in range(1, len(final_list) - 1, 1):\n",
    "                    cur_ele = final_list[i]\n",
    "                    \n",
    "                    if not (final_list[i - 1][0] < cur_ele[0] and cur_ele[0] < final_list[i + 1][0]):\n",
    "                        is_valid_list  = False\n",
    "\n",
    "                if is_valid_list == False:\n",
    "                    print(f\"Could not find expected solution for video {video_id}\")\n",
    "                    print(final_list)\n",
    "                    print(back_list)\n",
    "                    print(error_list)\n",
    "                    new_selected_frame_dict[video_id + \".txt\"] = selected_frames_dict[video_id + \".txt\"]\n",
    "                else:\n",
    "                \n",
    "                    label_name_final_list = []\n",
    "                    for ele in final_list:\n",
    "                        label_name_final_list.append((ele[0], label_id_to_label_name[ele[1]]))\n",
    "                    new_selected_frame_dict[video_id + \".txt\"] = label_name_final_list\n",
    "                \n",
    "        return new_selected_frame_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_selected_frame_acc(selected_frame_dict):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    for video_id in selected_frame_dict.keys():\n",
    "        ground_labels = open(config.ground_truth_files_dir + video_id).read().split(\"\\n\")[0:-1]\n",
    "        ground_labels = np.array(ground_labels)\n",
    "\n",
    "        selected_frames_index = [ele[0] for ele in selected_frame_dict[video_id]]\n",
    "        selected_frames_labels = np.array([ele[1] for ele in selected_frame_dict[video_id]])\n",
    "\n",
    "        ground_selected_labels = ground_labels[selected_frames_index]\n",
    "\n",
    "        correct += np.sum(ground_selected_labels == selected_frames_labels)\n",
    "        total += len(ground_selected_labels)\n",
    "\n",
    "    print(\"Total correct pivots labels selected = \", correct * 100.0 / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# selected_frames_dict = change_selected_frames(model)\n",
    "# get_new_selected_frame_acc(selected_frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Expection Boundaries\n",
    "# print(\"Calculating Expectation\")\n",
    "# correct = 0.0\n",
    "# total = 0.0\n",
    "# model.eval()\n",
    "# for i, item in enumerate(trainloader):\n",
    "#     with torch.no_grad():\n",
    "#         item_0 = item[0].to(device)\n",
    "#         item_1 = item[1].to(device)\n",
    "#         item_2 = item[2].to(device)\n",
    "#         src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "#         src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "#         middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "#         prob = torch.softmax(predictions[-1], dim=1)\n",
    "#         prob = prob.permute(0, 2, 1)\n",
    "#         calculate_element_probb(prob, item_1, item[4])\n",
    "\n",
    "#         if i % 10 == 0:\n",
    "#             print(f\"Completed iter {i}\")\n",
    "\n",
    "# get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split2-slup15/'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ms-tcn-emmax-best-model.wt  ms-tcn-initial-25-epochs.wt\r\n",
      "ms-tcn-emmax-last-model.wt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split2-slup15/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Training:: Epoch 25, Iteration 0, Current loss 2.3112359046936035 Accuracy 66.56409486640648\n",
      "Training:: Epoch 25, Iteration 10, Current loss 3.308283805847168 Accuracy 57.179375611878605\n",
      "Training:: Epoch 25, Iteration 20, Current loss 2.2027230262756348 Accuracy 71.94739448632586\n",
      "Training:: Epoch 25, Iteration 30, Current loss 3.3358325958251953 Accuracy 59.08878504672897\n",
      "Training:: Epoch 25, Iteration 40, Current loss 2.6516690254211426 Accuracy 58.13093644418946\n",
      "Training:: Epoch 25, Iteration 50, Current loss 2.682396173477173 Accuracy 65.72937131630648\n",
      "Training:: Epoch 25, Iteration 60, Current loss 3.719512701034546 Accuracy 47.60024734814251\n",
      "Training:: Epoch 25, Iteration 70, Current loss 2.6149399280548096 Accuracy 59.7769547667596\n",
      "Training:: Epoch 25, Iteration 80, Current loss 2.610637903213501 Accuracy 59.45417515274949\n",
      "Training:: Epoch 25, Iteration 90, Current loss 3.0873522758483887 Accuracy 64.65588154647655\n",
      "Training:: Epoch 25, Iteration 100, Current loss 2.4340293407440186 Accuracy 62.52743444611297\n",
      "Training:: Epoch 25, Iteration 110, Current loss 2.9607954025268555 Accuracy 65.19005030743432\n",
      "Training:: Epoch 25, Iteration 120, Current loss 2.7500343322753906 Accuracy 68.58341225815181\n",
      "Training:: Epoch 25, Iteration 130, Current loss 2.6031455993652344 Accuracy 62.21602503060808\n",
      "Training:: Epoch 25, Iteration 140, Current loss 3.2666547298431396 Accuracy 63.74022850270595\n",
      "Training:: Epoch 25, Iteration 150, Current loss 2.6003966331481934 Accuracy 66.4989609537351\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 25, Probability Accuracy 51.00281725152256\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.874680900440936\n",
      "Calculating Expectation\n",
      "Epoch 25 iter 0\n",
      "Epoch 25 iter 10\n",
      "Epoch 25 iter 20\n",
      "Epoch 25 iter 30\n",
      "Epoch 25 iter 40\n",
      "Epoch 25 iter 50\n",
      "Epoch 25 iter 60\n",
      "Epoch 25 iter 70\n",
      "Epoch 25 iter 80\n",
      "Epoch 25 iter 90\n",
      "Epoch 25 iter 100\n",
      "Epoch 25 iter 110\n",
      "Epoch 25 iter 120\n",
      "Epoch 25 iter 130\n",
      "Epoch 25 iter 140\n",
      "Epoch 25 iter 150\n",
      "Train Boundary avergage error = 287.860\n",
      "Train From boundary avergage accuracy = 60.733\n",
      "Starting Training\n",
      "Training:: Epoch 26, Iteration 0, Current loss 1.9713215077091477 Accuracy 66.21150204325725\n",
      "Training:: Epoch 26, Iteration 10, Current loss 1.5045014202899505 Accuracy 61.20212821998631\n",
      "Training:: Epoch 26, Iteration 20, Current loss 1.4258272434189765 Accuracy 63.51847197788389\n",
      "Training:: Epoch 26, Iteration 30, Current loss 1.8312728716156614 Accuracy 57.46297242083759\n",
      "Training:: Epoch 26, Iteration 40, Current loss 1.8516056773860585 Accuracy 44.83747609942639\n",
      "Training:: Epoch 26, Iteration 50, Current loss 1.8558784859324993 Accuracy 71.09254781270609\n",
      "Training:: Epoch 26, Iteration 60, Current loss 1.8734538682891548 Accuracy 59.56879701474856\n",
      "Training:: Epoch 26, Iteration 70, Current loss 1.9827194269168449 Accuracy 64.448758283687\n",
      "Training:: Epoch 26, Iteration 80, Current loss 1.9539154735980213 Accuracy 60.869308101714964\n",
      "Training:: Epoch 26, Iteration 90, Current loss 1.5680528285623652 Accuracy 60.6017744631606\n",
      "Training:: Epoch 26, Iteration 100, Current loss 1.3049255380454432 Accuracy 68.3753987352398\n",
      "Training:: Epoch 26, Iteration 110, Current loss 1.4839739351306167 Accuracy 60.02893694791349\n",
      "Training:: Epoch 26, Iteration 120, Current loss 1.5177319426693785 Accuracy 60.922256864125515\n",
      "Training:: Epoch 26, Iteration 130, Current loss 2.8280151391988264 Accuracy 66.46554885162838\n",
      "Training:: Epoch 26, Iteration 140, Current loss 2.5913078984435223 Accuracy 51.797464291446\n",
      "Training:: Epoch 26, Iteration 150, Current loss 1.748825999687067 Accuracy 61.266181229773466\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 26, Probability Accuracy 54.90864647636409\n",
      "Starting Training\n",
      "Training:: Epoch 27, Iteration 0, Current loss 1.3755852258977246 Accuracy 54.43457310645987\n",
      "Training:: Epoch 27, Iteration 10, Current loss 1.7006372156483271 Accuracy 62.935417058934284\n",
      "Training:: Epoch 27, Iteration 20, Current loss 2.2551069222423665 Accuracy 60.81294068851099\n",
      "Training:: Epoch 27, Iteration 30, Current loss 1.885715658859435 Accuracy 70.92753989305713\n",
      "Training:: Epoch 27, Iteration 40, Current loss 1.3190110818527132 Accuracy 62.58699604990908\n",
      "Training:: Epoch 27, Iteration 50, Current loss 2.708025350265921 Accuracy 61.637683429944126\n",
      "Training:: Epoch 27, Iteration 60, Current loss 2.579196460651351 Accuracy 63.92878138909885\n",
      "Training:: Epoch 27, Iteration 70, Current loss 2.6399836335457105 Accuracy 66.45438999941034\n",
      "Training:: Epoch 27, Iteration 80, Current loss 2.7114859392511956 Accuracy 59.67914438502674\n",
      "Training:: Epoch 27, Iteration 90, Current loss 2.19962068043176 Accuracy 62.542116881607996\n",
      "Training:: Epoch 27, Iteration 100, Current loss 1.391631090526712 Accuracy 65.4602109300096\n",
      "Training:: Epoch 27, Iteration 110, Current loss 3.093280840861344 Accuracy 57.94486215538847\n",
      "Training:: Epoch 27, Iteration 120, Current loss 2.861874617619832 Accuracy 49.377793056033\n",
      "Training:: Epoch 27, Iteration 130, Current loss 3.222253656488152 Accuracy 56.038530422576116\n",
      "Training:: Epoch 27, Iteration 140, Current loss 2.567001483164389 Accuracy 49.31384438628965\n",
      "Training:: Epoch 27, Iteration 150, Current loss 3.1898212189195956 Accuracy 48.30004249893753\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 27, Probability Accuracy 48.62482910055102\n",
      "Starting Training\n",
      "Training:: Epoch 28, Iteration 0, Current loss 2.1399059956551203 Accuracy 56.427465152297366\n",
      "Training:: Epoch 28, Iteration 10, Current loss 2.0623337023862724 Accuracy 64.14224073798542\n",
      "Training:: Epoch 28, Iteration 20, Current loss 2.5427497456456036 Accuracy 64.23780913790695\n",
      "Training:: Epoch 28, Iteration 30, Current loss 2.1567951820754736 Accuracy 62.48146579114594\n",
      "Training:: Epoch 28, Iteration 40, Current loss 2.806289123133048 Accuracy 56.03444545415206\n",
      "Training:: Epoch 28, Iteration 50, Current loss 1.6653307678704126 Accuracy 55.13690428674064\n",
      "Training:: Epoch 28, Iteration 60, Current loss 1.2186022720152325 Accuracy 73.40063761955366\n",
      "Training:: Epoch 28, Iteration 70, Current loss 1.8004224222716205 Accuracy 63.34608787438976\n",
      "Training:: Epoch 28, Iteration 80, Current loss 2.5400016719946854 Accuracy 61.11962183218803\n",
      "Training:: Epoch 28, Iteration 90, Current loss 1.6737102635115315 Accuracy 59.983311479318154\n",
      "Training:: Epoch 28, Iteration 100, Current loss 2.6398240385883667 Accuracy 64.04101025256314\n",
      "Training:: Epoch 28, Iteration 110, Current loss 3.1056641054126146 Accuracy 66.4333732387881\n",
      "Training:: Epoch 28, Iteration 120, Current loss 2.015810035527944 Accuracy 66.17208575890956\n",
      "Training:: Epoch 28, Iteration 130, Current loss 3.6443820888742544 Accuracy 51.14620268821638\n",
      "Training:: Epoch 28, Iteration 140, Current loss 2.9460039907077142 Accuracy 48.09598613292888\n",
      "Training:: Epoch 28, Iteration 150, Current loss 1.600037581581304 Accuracy 55.32556876470943\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 28, Probability Accuracy 54.903156978912044\n",
      "Starting Training\n",
      "Training:: Epoch 29, Iteration 0, Current loss 1.6623237856841004 Accuracy 65.69013263372686\n",
      "Training:: Epoch 29, Iteration 10, Current loss 1.1929510872934046 Accuracy 57.65809589993051\n",
      "Training:: Epoch 29, Iteration 20, Current loss 1.7328921198633318 Accuracy 56.05860453944998\n",
      "Training:: Epoch 29, Iteration 30, Current loss 1.9259713864619987 Accuracy 49.329212615017205\n",
      "Training:: Epoch 29, Iteration 40, Current loss 1.2937045633227748 Accuracy 74.35310468871357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 29, Iteration 50, Current loss 1.0604662324247784 Accuracy 71.55172413793103\n",
      "Training:: Epoch 29, Iteration 60, Current loss 1.7307203784962628 Accuracy 72.40084038963519\n",
      "Training:: Epoch 29, Iteration 70, Current loss 1.2507676178023759 Accuracy 64.24065100118862\n",
      "Training:: Epoch 29, Iteration 80, Current loss 1.7603079247573108 Accuracy 55.421967111386905\n",
      "Training:: Epoch 29, Iteration 90, Current loss 2.129927713833119 Accuracy 69.53260242354298\n",
      "Training:: Epoch 29, Iteration 100, Current loss 2.6844662124125147 Accuracy 52.267337405677324\n",
      "Training:: Epoch 29, Iteration 110, Current loss 1.6559681727317375 Accuracy 67.9087816287476\n",
      "Training:: Epoch 29, Iteration 120, Current loss 1.6306890131294125 Accuracy 64.34749265050488\n",
      "Training:: Epoch 29, Iteration 130, Current loss 1.711145207981205 Accuracy 63.774962422160186\n",
      "Training:: Epoch 29, Iteration 140, Current loss 1.416694764951668 Accuracy 70.26651446721921\n",
      "Training:: Epoch 29, Iteration 150, Current loss 1.450483603079117 Accuracy 62.70060180541625\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 29, Probability Accuracy 51.900919749761776\n",
      "Starting Training\n",
      "Training:: Epoch 30, Iteration 0, Current loss 2.2361693831822342 Accuracy 74.43892410484838\n",
      "Training:: Epoch 30, Iteration 10, Current loss 1.028609636942066 Accuracy 62.1617738614051\n",
      "Training:: Epoch 30, Iteration 20, Current loss 1.3567330410176204 Accuracy 69.30608527352422\n",
      "Training:: Epoch 30, Iteration 30, Current loss 1.2748638961832781 Accuracy 73.99899720650383\n",
      "Training:: Epoch 30, Iteration 40, Current loss 1.4503413812410486 Accuracy 65.80574581430746\n",
      "Training:: Epoch 30, Iteration 50, Current loss 1.026247128842761 Accuracy 62.33089064261556\n",
      "Training:: Epoch 30, Iteration 60, Current loss 1.9626703016850466 Accuracy 55.6175411341007\n",
      "Training:: Epoch 30, Iteration 70, Current loss 1.6775367527112963 Accuracy 67.43318485523385\n",
      "Training:: Epoch 30, Iteration 80, Current loss 1.9157977216991737 Accuracy 66.93443334780721\n",
      "Training:: Epoch 30, Iteration 90, Current loss 1.1111009413637976 Accuracy 70.69266025434123\n",
      "Training:: Epoch 30, Iteration 100, Current loss 1.4141204842384327 Accuracy 59.78801991328088\n",
      "Training:: Epoch 30, Iteration 110, Current loss 1.2516017104582644 Accuracy 62.29177965445108\n",
      "Training:: Epoch 30, Iteration 120, Current loss 1.0255627451597322 Accuracy 72.7986673012851\n",
      "Training:: Epoch 30, Iteration 130, Current loss 1.4371456229460158 Accuracy 64.14565826330532\n",
      "Training:: Epoch 30, Iteration 140, Current loss 1.573339331041678 Accuracy 66.15146082659044\n",
      "Training:: Epoch 30, Iteration 150, Current loss 1.317547559848263 Accuracy 58.86363636363637\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 30, Probability Accuracy 48.47070887019928\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.584590392202365\n",
      "Calculating Expectation\n",
      "Epoch 30 iter 0\n",
      "Epoch 30 iter 10\n",
      "Epoch 30 iter 20\n",
      "Epoch 30 iter 30\n",
      "Epoch 30 iter 40\n",
      "Epoch 30 iter 50\n",
      "Epoch 30 iter 60\n",
      "Epoch 30 iter 70\n",
      "Epoch 30 iter 80\n",
      "Epoch 30 iter 90\n",
      "Epoch 30 iter 100\n",
      "Epoch 30 iter 110\n",
      "Epoch 30 iter 120\n",
      "Epoch 30 iter 130\n",
      "Epoch 30 iter 140\n",
      "Epoch 30 iter 150\n",
      "Train Boundary avergage error = 293.058\n",
      "Train From boundary avergage accuracy = 60.306\n",
      "Starting Training\n",
      "Training:: Epoch 31, Iteration 0, Current loss 1.4398100423457145 Accuracy 67.29496691397634\n",
      "Training:: Epoch 31, Iteration 10, Current loss 1.347276050523482 Accuracy 71.38349514563107\n",
      "Training:: Epoch 31, Iteration 20, Current loss 1.3729616443192594 Accuracy 62.39259748843357\n",
      "Training:: Epoch 31, Iteration 30, Current loss 2.242329485683018 Accuracy 51.22384794202106\n",
      "Training:: Epoch 31, Iteration 40, Current loss 1.2830918229475101 Accuracy 62.54202223946211\n",
      "Training:: Epoch 31, Iteration 50, Current loss 1.725319880615401 Accuracy 67.73110038792696\n",
      "Training:: Epoch 31, Iteration 60, Current loss 1.0200156152250548 Accuracy 59.29832435667265\n",
      "Training:: Epoch 31, Iteration 70, Current loss 1.0881897176610382 Accuracy 63.38905451448041\n",
      "Training:: Epoch 31, Iteration 80, Current loss 1.2144428487751333 Accuracy 61.245022007964785\n",
      "Training:: Epoch 31, Iteration 90, Current loss 1.0238013683201428 Accuracy 73.56748911465893\n",
      "Training:: Epoch 31, Iteration 100, Current loss 1.117711748027542 Accuracy 63.187285223367695\n",
      "Training:: Epoch 31, Iteration 110, Current loss 0.9193164508121988 Accuracy 63.61483820047356\n",
      "Training:: Epoch 31, Iteration 120, Current loss 1.423512233118428 Accuracy 65.02291582061844\n",
      "Training:: Epoch 31, Iteration 130, Current loss 1.0293540688596954 Accuracy 76.44070871379331\n",
      "Training:: Epoch 31, Iteration 140, Current loss 0.9787720995773996 Accuracy 56.7651632970451\n",
      "Training:: Epoch 31, Iteration 150, Current loss 1.305036804300405 Accuracy 61.72166045769026\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 31, Probability Accuracy 54.39884824128931\n",
      "Starting Training\n",
      "Training:: Epoch 32, Iteration 0, Current loss 0.8453824282731695 Accuracy 64.66034755134281\n",
      "Training:: Epoch 32, Iteration 10, Current loss 1.09075805100878 Accuracy 59.19251509425266\n",
      "Training:: Epoch 32, Iteration 20, Current loss 1.206235569481036 Accuracy 57.56682803620291\n",
      "Training:: Epoch 32, Iteration 30, Current loss 1.2165246230062292 Accuracy 59.39911448450348\n",
      "Training:: Epoch 32, Iteration 40, Current loss 1.746316193601019 Accuracy 59.630172911943816\n",
      "Training:: Epoch 32, Iteration 50, Current loss 1.2136462066645421 Accuracy 57.25806451612903\n",
      "Training:: Epoch 32, Iteration 60, Current loss 1.1171365870538428 Accuracy 68.32588176850471\n",
      "Training:: Epoch 32, Iteration 70, Current loss 1.1295220631498397 Accuracy 74.29831315181633\n",
      "Training:: Epoch 32, Iteration 80, Current loss 1.121619086657527 Accuracy 61.735078462276434\n",
      "Training:: Epoch 32, Iteration 90, Current loss 0.9619504614942158 Accuracy 70.43312253907648\n",
      "Training:: Epoch 32, Iteration 100, Current loss 1.256971264469495 Accuracy 71.73787944180694\n",
      "Training:: Epoch 32, Iteration 110, Current loss 0.9906699979175357 Accuracy 66.88188976377953\n",
      "Training:: Epoch 32, Iteration 120, Current loss 1.3224321160348294 Accuracy 58.00288970942366\n",
      "Training:: Epoch 32, Iteration 130, Current loss 1.1828255424637266 Accuracy 68.04599596092817\n",
      "Training:: Epoch 32, Iteration 140, Current loss 1.230653096633717 Accuracy 64.92954223296923\n",
      "Training:: Epoch 32, Iteration 150, Current loss 1.6564041299662922 Accuracy 65.17571884984025\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 32, Probability Accuracy 53.156461034925634\n",
      "Starting Training\n",
      "Training:: Epoch 33, Iteration 0, Current loss 1.1788838329458449 Accuracy 63.45378782703737\n",
      "Training:: Epoch 33, Iteration 10, Current loss 1.379472976148383 Accuracy 62.681194668742094\n",
      "Training:: Epoch 33, Iteration 20, Current loss 1.1984264994359806 Accuracy 59.02504911591355\n",
      "Training:: Epoch 33, Iteration 30, Current loss 1.2407924373258685 Accuracy 65.30530127753747\n",
      "Training:: Epoch 33, Iteration 40, Current loss 0.7264527886619389 Accuracy 73.8191089640365\n",
      "Training:: Epoch 33, Iteration 50, Current loss 0.918905570715817 Accuracy 61.33666037226868\n",
      "Training:: Epoch 33, Iteration 60, Current loss 1.2945148170957068 Accuracy 66.07337450054486\n",
      "Training:: Epoch 33, Iteration 70, Current loss 0.9180082549572093 Accuracy 69.11268672127763\n",
      "Training:: Epoch 33, Iteration 80, Current loss 0.942468876330905 Accuracy 74.06157101828992\n",
      "Training:: Epoch 33, Iteration 90, Current loss 1.0615042034090956 Accuracy 52.90814279983955\n",
      "Training:: Epoch 33, Iteration 100, Current loss 1.1899342992312874 Accuracy 61.50829113295601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 33, Iteration 110, Current loss 1.0282313663577 Accuracy 58.3607658716829\n",
      "Training:: Epoch 33, Iteration 120, Current loss 1.510437864895064 Accuracy 67.13483146067416\n",
      "Training:: Epoch 33, Iteration 130, Current loss 2.1919363498928797 Accuracy 62.353382753120016\n",
      "Training:: Epoch 33, Iteration 140, Current loss 1.4866315401994643 Accuracy 54.5111537697756\n",
      "Training:: Epoch 33, Iteration 150, Current loss 1.0887347071679963 Accuracy 67.11250134829037\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 33, Probability Accuracy 54.46265070224137\n",
      "Starting Training\n",
      "Training:: Epoch 34, Iteration 0, Current loss 0.9981233568347604 Accuracy 65.23156724712857\n",
      "Training:: Epoch 34, Iteration 10, Current loss 0.9054752200249921 Accuracy 66.09128773240586\n",
      "Training:: Epoch 34, Iteration 20, Current loss 0.8096024686747021 Accuracy 69.93119112833189\n",
      "Training:: Epoch 34, Iteration 30, Current loss 1.011462879946302 Accuracy 78.84615384615384\n",
      "Training:: Epoch 34, Iteration 40, Current loss 1.5216958931707314 Accuracy 53.14347855637871\n",
      "Training:: Epoch 34, Iteration 50, Current loss 1.094980004631446 Accuracy 63.87525987525988\n",
      "Training:: Epoch 34, Iteration 60, Current loss 1.1082405236005264 Accuracy 68.38043838469915\n",
      "Training:: Epoch 34, Iteration 70, Current loss 1.1664231172008526 Accuracy 68.66073834545945\n",
      "Training:: Epoch 34, Iteration 80, Current loss 0.9005087573925226 Accuracy 70.20241999321497\n",
      "Training:: Epoch 34, Iteration 90, Current loss 1.1010978642850218 Accuracy 70.30244008007358\n",
      "Training:: Epoch 34, Iteration 100, Current loss 1.005840318349485 Accuracy 61.210601719197705\n",
      "Training:: Epoch 34, Iteration 110, Current loss 1.3602608667872778 Accuracy 59.262397431323585\n",
      "Training:: Epoch 34, Iteration 120, Current loss 0.9314729497728277 Accuracy 63.92391834459695\n",
      "Training:: Epoch 34, Iteration 130, Current loss 1.6187409794084462 Accuracy 53.8694336359706\n",
      "Training:: Epoch 34, Iteration 140, Current loss 1.6406744070569979 Accuracy 62.51284158619273\n",
      "Training:: Epoch 34, Iteration 150, Current loss 1.5039123742670288 Accuracy 69.93689903846153\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 34, Probability Accuracy 49.6519865766251\n",
      "Starting Training\n",
      "Training:: Epoch 35, Iteration 0, Current loss 1.4482270610023362 Accuracy 69.85021070638795\n",
      "Training:: Epoch 35, Iteration 10, Current loss 3.135177646679347 Accuracy 60.16384778012685\n",
      "Training:: Epoch 35, Iteration 20, Current loss 1.2064988697424757 Accuracy 59.91184573002755\n",
      "Training:: Epoch 35, Iteration 30, Current loss 1.224528578172742 Accuracy 47.06544686840253\n",
      "Training:: Epoch 35, Iteration 40, Current loss 1.3513567100945878 Accuracy 73.3916687207296\n",
      "Training:: Epoch 35, Iteration 50, Current loss 0.902957595770083 Accuracy 73.2302845328345\n",
      "Training:: Epoch 35, Iteration 60, Current loss 1.1335723205337103 Accuracy 61.607834206331134\n",
      "Training:: Epoch 35, Iteration 70, Current loss 1.4458357732590426 Accuracy 65.77905442124059\n",
      "Training:: Epoch 35, Iteration 80, Current loss 1.1233603646577905 Accuracy 62.738572966624254\n",
      "Training:: Epoch 35, Iteration 90, Current loss 0.9014660250546987 Accuracy 70.10842605059882\n",
      "Training:: Epoch 35, Iteration 100, Current loss 0.795536592908061 Accuracy 74.08097245368101\n",
      "Training:: Epoch 35, Iteration 110, Current loss 0.9853152804272147 Accuracy 61.28875968992248\n",
      "Training:: Epoch 35, Iteration 120, Current loss 0.846697027464733 Accuracy 80.1019204454301\n",
      "Training:: Epoch 35, Iteration 130, Current loss 2.982994343359871 Accuracy 58.84094441566131\n",
      "Training:: Epoch 35, Iteration 140, Current loss 6.728610238957732 Accuracy 43.60934639819102\n",
      "Training:: Epoch 35, Iteration 150, Current loss 2.845423664032567 Accuracy 60.55230800241887\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 35, Probability Accuracy 47.58244603720429\n",
      "Calculating Expectation\n",
      "Epoch 35 iter 0\n",
      "Epoch 35 iter 10\n",
      "Epoch 35 iter 20\n",
      "Epoch 35 iter 30\n",
      "Epoch 35 iter 40\n",
      "Epoch 35 iter 50\n",
      "Epoch 35 iter 60\n",
      "Epoch 35 iter 70\n",
      "Epoch 35 iter 80\n",
      "Epoch 35 iter 90\n",
      "Epoch 35 iter 100\n",
      "Epoch 35 iter 110\n",
      "Epoch 35 iter 120\n",
      "Epoch 35 iter 130\n",
      "Epoch 35 iter 140\n",
      "Epoch 35 iter 150\n",
      "Train Boundary avergage error = 293.053\n",
      "Train From boundary avergage accuracy = 59.799\n",
      "Starting Training\n",
      "Training:: Epoch 36, Iteration 0, Current loss 1.9861509720693167 Accuracy 60.27876530669827\n",
      "Training:: Epoch 36, Iteration 10, Current loss 4.318548072833146 Accuracy 49.95436568299361\n",
      "Training:: Epoch 36, Iteration 20, Current loss 1.5405756549874146 Accuracy 72.4984078222755\n",
      "Training:: Epoch 36, Iteration 30, Current loss 1.516657665270487 Accuracy 67.8637037037037\n",
      "Training:: Epoch 36, Iteration 40, Current loss 1.534755983474919 Accuracy 50.847687508476874\n",
      "Training:: Epoch 36, Iteration 50, Current loss 1.8216980654468296 Accuracy 59.97424339987122\n",
      "Training:: Epoch 36, Iteration 60, Current loss 2.118004301822016 Accuracy 71.41926234849473\n",
      "Training:: Epoch 36, Iteration 70, Current loss 1.8236666644245174 Accuracy 69.14202144946377\n",
      "Training:: Epoch 36, Iteration 80, Current loss 4.404357759164354 Accuracy 58.853216351566445\n",
      "Training:: Epoch 36, Iteration 90, Current loss 1.285964872099877 Accuracy 74.64517018051536\n",
      "Training:: Epoch 36, Iteration 100, Current loss 1.459728585587318 Accuracy 69.15035900323807\n",
      "Training:: Epoch 36, Iteration 110, Current loss 1.0818087276863626 Accuracy 60.10233534505379\n",
      "Training:: Epoch 36, Iteration 120, Current loss 1.1680350540406552 Accuracy 49.144289294665235\n",
      "Training:: Epoch 36, Iteration 130, Current loss 2.029556647298258 Accuracy 55.75065847234416\n",
      "Training:: Epoch 36, Iteration 140, Current loss 1.3544874351969258 Accuracy 65.19337016574586\n",
      "Training:: Epoch 36, Iteration 150, Current loss 1.1561130275998344 Accuracy 62.94135707706479\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 36, Probability Accuracy 51.200232008948916\n",
      "Starting Training\n",
      "Training:: Epoch 37, Iteration 0, Current loss 0.9726478581057091 Accuracy 53.134408602150536\n",
      "Training:: Epoch 37, Iteration 10, Current loss 1.3155577123542948 Accuracy 55.63236047107015\n",
      "Training:: Epoch 37, Iteration 20, Current loss 1.034964794739181 Accuracy 69.83716542036481\n",
      "Training:: Epoch 37, Iteration 30, Current loss 0.9757619907085906 Accuracy 63.26631806707537\n",
      "Training:: Epoch 37, Iteration 40, Current loss 1.2423040187284362 Accuracy 64.07004830917874\n",
      "Training:: Epoch 37, Iteration 50, Current loss 1.0962898519153355 Accuracy 72.73440872875702\n",
      "Training:: Epoch 37, Iteration 60, Current loss 1.313594511650967 Accuracy 69.79233694062592\n",
      "Training:: Epoch 37, Iteration 70, Current loss 1.552412130184961 Accuracy 56.06157793457344\n",
      "Training:: Epoch 37, Iteration 80, Current loss 1.5920385852147871 Accuracy 64.63509549182781\n",
      "Training:: Epoch 37, Iteration 90, Current loss 1.0074254325920138 Accuracy 65.79806036436146\n",
      "Training:: Epoch 37, Iteration 100, Current loss 1.4546476967439719 Accuracy 66.1774861878453\n",
      "Training:: Epoch 37, Iteration 110, Current loss 1.1422057243546402 Accuracy 63.80632521690456\n",
      "Training:: Epoch 37, Iteration 120, Current loss 0.9905664670940744 Accuracy 56.06541129831516\n",
      "Training:: Epoch 37, Iteration 130, Current loss 1.1452925176138464 Accuracy 65.58523874360299\n",
      "Training:: Epoch 37, Iteration 140, Current loss 1.0106218109058946 Accuracy 64.02886806786528\n",
      "Training:: Epoch 37, Iteration 150, Current loss 1.6635666687686796 Accuracy 67.6047464034443\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 37, Probability Accuracy 53.54725110825703\n",
      "Starting Training\n",
      "Training:: Epoch 38, Iteration 0, Current loss 0.6942170112816394 Accuracy 66.09442060085837\n",
      "Training:: Epoch 38, Iteration 10, Current loss 1.0799434434135613 Accuracy 65.42025948908051\n",
      "Training:: Epoch 38, Iteration 20, Current loss 0.8295437212656046 Accuracy 67.24671072576244\n",
      "Training:: Epoch 38, Iteration 30, Current loss 1.087520707553507 Accuracy 61.54127694184628\n",
      "Training:: Epoch 38, Iteration 40, Current loss 0.8238757523368008 Accuracy 65.42132693095976\n",
      "Training:: Epoch 38, Iteration 50, Current loss 0.915241839238839 Accuracy 66.6117124220486\n",
      "Training:: Epoch 38, Iteration 60, Current loss 0.84575619032079 Accuracy 54.36071126164268\n",
      "Training:: Epoch 38, Iteration 70, Current loss 1.0448348323917378 Accuracy 64.06083650190114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 38, Iteration 80, Current loss 1.0183539952979315 Accuracy 64.97878746407554\n",
      "Training:: Epoch 38, Iteration 90, Current loss 0.9385099000318481 Accuracy 66.18895966029724\n",
      "Training:: Epoch 38, Iteration 100, Current loss 1.7861761861799592 Accuracy 65.67349252462269\n",
      "Training:: Epoch 38, Iteration 110, Current loss 1.3396738907522665 Accuracy 65.20406741886056\n",
      "Training:: Epoch 38, Iteration 120, Current loss 0.7486279986558009 Accuracy 68.42733512384363\n",
      "Training:: Epoch 38, Iteration 130, Current loss 0.985382230437795 Accuracy 71.75365637119761\n",
      "Training:: Epoch 38, Iteration 140, Current loss 1.0827536699523579 Accuracy 65.29991843997924\n",
      "Training:: Epoch 38, Iteration 150, Current loss 1.7301436559417167 Accuracy 45.82833133253301\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 38, Probability Accuracy 48.1144094129345\n",
      "Starting Training\n",
      "Training:: Epoch 39, Iteration 0, Current loss 5.305832548023728 Accuracy 57.719836400818\n",
      "Training:: Epoch 39, Iteration 10, Current loss 2.3575057399077926 Accuracy 59.95093171330101\n",
      "Training:: Epoch 39, Iteration 20, Current loss 2.115168147492241 Accuracy 63.11890266265679\n",
      "Training:: Epoch 39, Iteration 30, Current loss 1.8834235280937803 Accuracy 56.38214004156812\n",
      "Training:: Epoch 39, Iteration 40, Current loss 1.403488726831541 Accuracy 67.52140356796424\n",
      "Training:: Epoch 39, Iteration 50, Current loss 1.3875177470647502 Accuracy 70.76810176125245\n",
      "Training:: Epoch 39, Iteration 60, Current loss 2.800515044641166 Accuracy 63.25163722960905\n",
      "Training:: Epoch 39, Iteration 70, Current loss 5.3750439326573325 Accuracy 53.37257466753869\n",
      "Training:: Epoch 39, Iteration 80, Current loss 2.6904664272004872 Accuracy 61.2809821635395\n",
      "Training:: Epoch 39, Iteration 90, Current loss 3.78141359848812 Accuracy 58.676969740738066\n",
      "Training:: Epoch 39, Iteration 100, Current loss 1.5331167824310108 Accuracy 64.2869947118401\n",
      "Training:: Epoch 39, Iteration 110, Current loss 1.4314438397613967 Accuracy 63.93637645400071\n",
      "Training:: Epoch 39, Iteration 120, Current loss 1.8143938305973855 Accuracy 64.4678764100049\n",
      "Training:: Epoch 39, Iteration 130, Current loss 1.9285348166093184 Accuracy 59.48717948717949\n",
      "Training:: Epoch 39, Iteration 140, Current loss 1.3198671168495304 Accuracy 67.7522242739634\n",
      "Training:: Epoch 39, Iteration 150, Current loss 1.4955595483231376 Accuracy 59.8018166804294\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 39, Probability Accuracy 54.78601317479389\n",
      "Starting Training\n",
      "Training:: Epoch 40, Iteration 0, Current loss 1.9550217983259168 Accuracy 64.36875145315042\n",
      "Training:: Epoch 40, Iteration 10, Current loss 1.2936228625414352 Accuracy 54.23977583561278\n",
      "Training:: Epoch 40, Iteration 20, Current loss 1.4629381146242513 Accuracy 60.20470829068577\n",
      "Training:: Epoch 40, Iteration 30, Current loss 1.2386133268573554 Accuracy 55.25893430344532\n",
      "Training:: Epoch 40, Iteration 40, Current loss 1.2944395634869221 Accuracy 58.48265147591921\n",
      "Training:: Epoch 40, Iteration 50, Current loss 1.6398889241431034 Accuracy 61.78467507274491\n",
      "Training:: Epoch 40, Iteration 60, Current loss 1.2220275874614845 Accuracy 63.23151584356266\n",
      "Training:: Epoch 40, Iteration 70, Current loss 1.01385954669894 Accuracy 69.92783224400871\n",
      "Training:: Epoch 40, Iteration 80, Current loss 1.063326869795917 Accuracy 62.99641800342626\n",
      "Training:: Epoch 40, Iteration 90, Current loss 1.0269645258779831 Accuracy 65.74331680174187\n",
      "Training:: Epoch 40, Iteration 100, Current loss 0.8629469994980441 Accuracy 73.88971263150462\n",
      "Training:: Epoch 40, Iteration 110, Current loss 1.04912310011135 Accuracy 65.42584871947588\n",
      "Training:: Epoch 40, Iteration 120, Current loss 1.174861624233484 Accuracy 60.51601777541951\n",
      "Training:: Epoch 40, Iteration 130, Current loss 1.240724976737548 Accuracy 68.5384202041913\n",
      "Training:: Epoch 40, Iteration 140, Current loss 1.2972132283062048 Accuracy 55.642606140906736\n",
      "Training:: Epoch 40, Iteration 150, Current loss 1.4665667833727822 Accuracy 49.22834645669291\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 40, Probability Accuracy 56.119236027675356\n",
      "Calculating Expectation\n",
      "Epoch 40 iter 0\n",
      "Epoch 40 iter 10\n",
      "Epoch 40 iter 20\n",
      "Epoch 40 iter 30\n",
      "Epoch 40 iter 40\n",
      "Epoch 40 iter 50\n",
      "Epoch 40 iter 60\n",
      "Epoch 40 iter 70\n",
      "Epoch 40 iter 80\n",
      "Epoch 40 iter 90\n",
      "Epoch 40 iter 100\n",
      "Epoch 40 iter 110\n",
      "Epoch 40 iter 120\n",
      "Epoch 40 iter 130\n",
      "Epoch 40 iter 140\n",
      "Epoch 40 iter 150\n",
      "Train Boundary avergage error = 286.002\n",
      "Train From boundary avergage accuracy = 60.101\n",
      "Starting Training\n",
      "Training:: Epoch 41, Iteration 0, Current loss 0.7627989883286859 Accuracy 52.65497454134002\n",
      "Training:: Epoch 41, Iteration 10, Current loss 1.0030297933170222 Accuracy 70.63924948183703\n",
      "Training:: Epoch 41, Iteration 20, Current loss 1.0526333226688989 Accuracy 60.36145752143414\n",
      "Training:: Epoch 41, Iteration 30, Current loss 0.8215917545381182 Accuracy 66.97814503050428\n",
      "Training:: Epoch 41, Iteration 40, Current loss 1.0118310026001365 Accuracy 58.89894419306184\n",
      "Training:: Epoch 41, Iteration 50, Current loss 0.8521969852141313 Accuracy 63.034251307866946\n",
      "Training:: Epoch 41, Iteration 60, Current loss 0.904877730994545 Accuracy 62.55002457347469\n",
      "Training:: Epoch 41, Iteration 70, Current loss 0.815806471839756 Accuracy 56.08793686583991\n",
      "Training:: Epoch 41, Iteration 80, Current loss 0.8087139685433036 Accuracy 61.93455546518175\n",
      "Training:: Epoch 41, Iteration 90, Current loss 1.0840340322092137 Accuracy 44.472152950955945\n",
      "Training:: Epoch 41, Iteration 100, Current loss 0.6080944677904544 Accuracy 67.25282833251353\n",
      "Training:: Epoch 41, Iteration 110, Current loss 1.2601832532183572 Accuracy 65.18195755668522\n",
      "Training:: Epoch 41, Iteration 120, Current loss 1.0796240845126894 Accuracy 65.6649072024519\n",
      "Training:: Epoch 41, Iteration 130, Current loss 1.1762871461019289 Accuracy 57.27634344040828\n",
      "Training:: Epoch 41, Iteration 140, Current loss 0.5775516990253585 Accuracy 62.40391810080947\n",
      "Training:: Epoch 41, Iteration 150, Current loss 1.2916629846502103 Accuracy 50.02091369614723\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 41, Probability Accuracy 55.65842896797448\n",
      "Starting Training\n",
      "Training:: Epoch 42, Iteration 0, Current loss 0.6261083642398322 Accuracy 75.05720823798627\n",
      "Training:: Epoch 42, Iteration 10, Current loss 0.8175182645127042 Accuracy 65.51627777001536\n",
      "Training:: Epoch 42, Iteration 20, Current loss 0.9347058898197876 Accuracy 56.144487914679246\n",
      "Training:: Epoch 42, Iteration 30, Current loss 0.7515461466441828 Accuracy 65.09108574204518\n",
      "Training:: Epoch 42, Iteration 40, Current loss 0.7702386610319105 Accuracy 65.75927632129994\n",
      "Training:: Epoch 42, Iteration 50, Current loss 0.8349542455302402 Accuracy 68.38193657984145\n",
      "Training:: Epoch 42, Iteration 60, Current loss 0.7261552059226881 Accuracy 59.35476476992722\n",
      "Training:: Epoch 42, Iteration 70, Current loss 0.9604066747587207 Accuracy 62.2568093385214\n",
      "Training:: Epoch 42, Iteration 80, Current loss 0.8499801914133139 Accuracy 66.73494834342715\n",
      "Training:: Epoch 42, Iteration 90, Current loss 0.7814165398010332 Accuracy 69.59592500642069\n",
      "Training:: Epoch 42, Iteration 100, Current loss 0.8986832422557565 Accuracy 67.33654731596339\n",
      "Training:: Epoch 42, Iteration 110, Current loss 0.9688720509856363 Accuracy 50.38603364830606\n",
      "Training:: Epoch 42, Iteration 120, Current loss 0.8410169071978448 Accuracy 61.971079767689936\n",
      "Training:: Epoch 42, Iteration 130, Current loss 0.5407039941908379 Accuracy 65.39695268644748\n",
      "Training:: Epoch 42, Iteration 140, Current loss 0.8171066188124563 Accuracy 71.18394402504143\n",
      "Training:: Epoch 42, Iteration 150, Current loss 0.7444663441726347 Accuracy 64.43264764432648\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 42, Probability Accuracy 55.25873140821146\n",
      "Starting Training\n",
      "Training:: Epoch 43, Iteration 0, Current loss 0.6355834146222802 Accuracy 57.459630688402996\n",
      "Training:: Epoch 43, Iteration 10, Current loss 0.6526175468684191 Accuracy 67.8657748299702\n",
      "Training:: Epoch 43, Iteration 20, Current loss 0.6288657183933568 Accuracy 73.22453016815035\n",
      "Training:: Epoch 43, Iteration 30, Current loss 0.5803676213865471 Accuracy 60.6345640881651\n",
      "Training:: Epoch 43, Iteration 40, Current loss 1.2567148507603765 Accuracy 57.53931544865865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 43, Iteration 50, Current loss 1.0763526744888736 Accuracy 56.848453067645515\n",
      "Training:: Epoch 43, Iteration 60, Current loss 0.9009913924901913 Accuracy 59.95256106160652\n",
      "Training:: Epoch 43, Iteration 70, Current loss 0.6561363568120949 Accuracy 62.41438356164384\n",
      "Training:: Epoch 43, Iteration 80, Current loss 0.7566178740822147 Accuracy 50.298616168973055\n",
      "Training:: Epoch 43, Iteration 90, Current loss 0.6494374772146226 Accuracy 64.25763531902027\n",
      "Training:: Epoch 43, Iteration 100, Current loss 1.0764087764785994 Accuracy 56.57075204612138\n",
      "Training:: Epoch 43, Iteration 110, Current loss 0.8928933571954774 Accuracy 65.10225885225886\n",
      "Training:: Epoch 43, Iteration 120, Current loss 0.9044481844003915 Accuracy 63.96292450290373\n",
      "Training:: Epoch 43, Iteration 130, Current loss 0.7172390475773941 Accuracy 66.47859922178988\n",
      "Training:: Epoch 43, Iteration 140, Current loss 0.7010738501433554 Accuracy 62.15847710944465\n",
      "Training:: Epoch 43, Iteration 150, Current loss 0.7444993204738849 Accuracy 62.59680177008951\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 43, Probability Accuracy 53.10881634005883\n",
      "Starting Training\n",
      "Training:: Epoch 44, Iteration 0, Current loss 0.7831968678254828 Accuracy 67.18840579710145\n",
      "Training:: Epoch 44, Iteration 10, Current loss 1.103954870288324 Accuracy 72.67425905598243\n",
      "Training:: Epoch 44, Iteration 20, Current loss 4.678306907061753 Accuracy 53.453376861864925\n",
      "Training:: Epoch 44, Iteration 30, Current loss 3.3637986353672105 Accuracy 45.319400113681084\n",
      "Training:: Epoch 44, Iteration 40, Current loss 3.417572578337847 Accuracy 56.23423621011076\n",
      "Training:: Epoch 44, Iteration 50, Current loss 4.17789879236971 Accuracy 57.23672090881179\n",
      "Training:: Epoch 44, Iteration 60, Current loss 2.408970141719741 Accuracy 64.50975337286242\n",
      "Training:: Epoch 44, Iteration 70, Current loss 2.422423632008777 Accuracy 52.259734007341876\n",
      "Training:: Epoch 44, Iteration 80, Current loss 2.066039788909945 Accuracy 58.92249148808332\n",
      "Training:: Epoch 44, Iteration 90, Current loss 2.7395012334037694 Accuracy 54.02203856749311\n",
      "Training:: Epoch 44, Iteration 100, Current loss 1.325215844635996 Accuracy 61.796207543238175\n",
      "Training:: Epoch 44, Iteration 110, Current loss 1.460333686641518 Accuracy 60.84669551200475\n",
      "Training:: Epoch 44, Iteration 120, Current loss 0.9509031731730161 Accuracy 67.85478882522943\n",
      "Training:: Epoch 44, Iteration 130, Current loss 1.1504169538160158 Accuracy 73.32824208868311\n",
      "Training:: Epoch 44, Iteration 140, Current loss 3.478789581195999 Accuracy 50.121261115602266\n",
      "Training:: Epoch 44, Iteration 150, Current loss 1.7428852333645566 Accuracy 69.97217303313938\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 44, Probability Accuracy 56.51178688320835\n",
      "Starting Training\n",
      "Training:: Epoch 45, Iteration 0, Current loss 1.3735012461008667 Accuracy 59.09267459022761\n",
      "Training:: Epoch 45, Iteration 10, Current loss 0.9594493387367846 Accuracy 68.09850374064838\n",
      "Training:: Epoch 45, Iteration 20, Current loss 1.0977177651818664 Accuracy 69.61410452460196\n",
      "Training:: Epoch 45, Iteration 30, Current loss 0.8413895173950995 Accuracy 57.81994554118448\n",
      "Training:: Epoch 45, Iteration 40, Current loss 1.1665491745228789 Accuracy 55.91593579348006\n",
      "Training:: Epoch 45, Iteration 50, Current loss 0.9384481960885265 Accuracy 66.10869869729655\n",
      "Training:: Epoch 45, Iteration 60, Current loss 0.8287071357005144 Accuracy 59.17025783361332\n",
      "Training:: Epoch 45, Iteration 70, Current loss 0.9524098327208808 Accuracy 63.39674378748929\n",
      "Training:: Epoch 45, Iteration 80, Current loss 0.9073226994050949 Accuracy 62.06910090302316\n",
      "Training:: Epoch 45, Iteration 90, Current loss 0.8339041100855893 Accuracy 59.34827980879284\n",
      "Training:: Epoch 45, Iteration 100, Current loss 0.7855610814013039 Accuracy 64.0625\n",
      "Training:: Epoch 45, Iteration 110, Current loss 1.0570536496220302 Accuracy 59.76822072191803\n",
      "Training:: Epoch 45, Iteration 120, Current loss 1.3032799527711951 Accuracy 44.97144516503727\n",
      "Training:: Epoch 45, Iteration 130, Current loss 1.2616681232536795 Accuracy 58.89197408435806\n",
      "Training:: Epoch 45, Iteration 140, Current loss 0.6521757142674668 Accuracy 68.87206058190515\n",
      "Training:: Epoch 45, Iteration 150, Current loss 0.68361946888764 Accuracy 70.28128031037828\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 45, Probability Accuracy 55.016157766085264\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.085634718032026\n",
      "Calculating Expectation\n",
      "Epoch 45 iter 0\n",
      "Epoch 45 iter 10\n",
      "Epoch 45 iter 20\n",
      "Epoch 45 iter 30\n",
      "Epoch 45 iter 40\n",
      "Epoch 45 iter 50\n",
      "Epoch 45 iter 60\n",
      "Epoch 45 iter 70\n",
      "Epoch 45 iter 80\n",
      "Epoch 45 iter 90\n",
      "Epoch 45 iter 100\n",
      "Epoch 45 iter 110\n",
      "Epoch 45 iter 120\n",
      "Epoch 45 iter 130\n",
      "Epoch 45 iter 140\n",
      "Epoch 45 iter 150\n",
      "Train Boundary avergage error = 285.132\n",
      "Train From boundary avergage accuracy = 60.116\n",
      "Starting Training\n",
      "Training:: Epoch 46, Iteration 0, Current loss 0.6487094902240397 Accuracy 69.03724678719233\n",
      "Training:: Epoch 46, Iteration 10, Current loss 0.9062723730476112 Accuracy 58.29979879275654\n",
      "Training:: Epoch 46, Iteration 20, Current loss 0.6465748004759491 Accuracy 64.39735099337749\n",
      "Training:: Epoch 46, Iteration 30, Current loss 0.5952002724712008 Accuracy 66.01237842617152\n",
      "Training:: Epoch 46, Iteration 40, Current loss 0.6346203321527448 Accuracy 65.26943538699159\n",
      "Training:: Epoch 46, Iteration 50, Current loss 0.76343299717455 Accuracy 65.20897208326609\n",
      "Training:: Epoch 46, Iteration 60, Current loss 0.7341382409875131 Accuracy 62.84675176495757\n",
      "Training:: Epoch 46, Iteration 70, Current loss 0.6255076282734606 Accuracy 69.27086527258233\n",
      "Training:: Epoch 46, Iteration 80, Current loss 0.7387197651374653 Accuracy 50.633250089190156\n",
      "Training:: Epoch 46, Iteration 90, Current loss 1.012383448944254 Accuracy 55.95777671755725\n",
      "Training:: Epoch 46, Iteration 100, Current loss 0.6887646781581782 Accuracy 64.42746889273901\n",
      "Training:: Epoch 46, Iteration 110, Current loss 1.1706354531965808 Accuracy 60.25982678214524\n",
      "Training:: Epoch 46, Iteration 120, Current loss 1.1174534933495404 Accuracy 64.49829931972789\n",
      "Training:: Epoch 46, Iteration 130, Current loss 0.7222909449367988 Accuracy 67.90499034692564\n",
      "Training:: Epoch 46, Iteration 140, Current loss 0.6928116264181976 Accuracy 57.173500030642884\n",
      "Training:: Epoch 46, Iteration 150, Current loss 0.8686148778929759 Accuracy 63.00787669292231\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 46, Probability Accuracy 53.28810539835108\n",
      "Starting Training\n",
      "Training:: Epoch 47, Iteration 0, Current loss 1.3115924488655573 Accuracy 50.05849819187407\n",
      "Training:: Epoch 47, Iteration 10, Current loss 0.7994865484153109 Accuracy 72.640911969601\n",
      "Training:: Epoch 47, Iteration 20, Current loss 1.0006833282249101 Accuracy 64.39043870158024\n",
      "Training:: Epoch 47, Iteration 30, Current loss 0.6492406275977557 Accuracy 67.60976532929598\n",
      "Training:: Epoch 47, Iteration 40, Current loss 0.7990022471869925 Accuracy 67.44604316546763\n",
      "Training:: Epoch 47, Iteration 50, Current loss 0.9154471425084243 Accuracy 57.372598162071846\n",
      "Training:: Epoch 47, Iteration 60, Current loss 0.7441033934097201 Accuracy 53.55400481689619\n",
      "Training:: Epoch 47, Iteration 70, Current loss 0.6680070612650908 Accuracy 63.26094295037696\n",
      "Training:: Epoch 47, Iteration 80, Current loss 1.0084036729732413 Accuracy 64.35541377369113\n",
      "Training:: Epoch 47, Iteration 90, Current loss 0.6155241567080181 Accuracy 67.48230118908516\n",
      "Training:: Epoch 47, Iteration 100, Current loss 0.665854769837089 Accuracy 72.41602904940993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 47, Iteration 110, Current loss 0.8605906341440792 Accuracy 61.921995918838796\n",
      "Training:: Epoch 47, Iteration 120, Current loss 0.762801988384514 Accuracy 49.0034295939162\n",
      "Training:: Epoch 47, Iteration 130, Current loss 0.525698754753806 Accuracy 61.511985248924404\n",
      "Training:: Epoch 47, Iteration 140, Current loss 0.7482943683651275 Accuracy 69.8077513038143\n",
      "Training:: Epoch 47, Iteration 150, Current loss 0.647496935121515 Accuracy 61.91465841255803\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 47, Probability Accuracy 55.08410324398227\n",
      "Starting Training\n",
      "Training:: Epoch 48, Iteration 0, Current loss 0.6174856016000821 Accuracy 63.49437912983781\n",
      "Training:: Epoch 48, Iteration 10, Current loss 0.6315333868835629 Accuracy 68.24477233638092\n",
      "Training:: Epoch 48, Iteration 20, Current loss 0.580739724708218 Accuracy 65.55229397695152\n",
      "Training:: Epoch 48, Iteration 30, Current loss 0.6997522833908676 Accuracy 65.88360583850154\n",
      "Training:: Epoch 48, Iteration 40, Current loss 0.6431356515967117 Accuracy 63.2887189292543\n",
      "Training:: Epoch 48, Iteration 50, Current loss 0.6233765085108764 Accuracy 63.34480999744963\n",
      "Training:: Epoch 48, Iteration 60, Current loss 0.7715743763700356 Accuracy 58.22191592005513\n",
      "Training:: Epoch 48, Iteration 70, Current loss 0.5526074820579536 Accuracy 62.67496111975117\n",
      "Training:: Epoch 48, Iteration 80, Current loss 0.7727767149710071 Accuracy 59.290085679314565\n",
      "Training:: Epoch 48, Iteration 90, Current loss 0.9147193538291616 Accuracy 56.623911618762286\n",
      "Training:: Epoch 48, Iteration 100, Current loss 0.7176663201102201 Accuracy 58.838063862138874\n",
      "Training:: Epoch 48, Iteration 110, Current loss 0.5521948827913977 Accuracy 64.14913039300471\n",
      "Training:: Epoch 48, Iteration 120, Current loss 0.5505764144119035 Accuracy 75.152310035539\n",
      "Training:: Epoch 48, Iteration 130, Current loss 0.7137618487675634 Accuracy 65.20065156226862\n",
      "Training:: Epoch 48, Iteration 140, Current loss 0.6406335191619892 Accuracy 58.96357923618179\n",
      "Training:: Epoch 48, Iteration 150, Current loss 0.5899875866805812 Accuracy 57.55981550879216\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 48, Probability Accuracy 55.08917843973982\n",
      "Starting Training\n",
      "Training:: Epoch 49, Iteration 0, Current loss 0.6215450273362343 Accuracy 61.776836473079925\n",
      "Training:: Epoch 49, Iteration 10, Current loss 0.584184757977231 Accuracy 61.15919223708366\n",
      "Training:: Epoch 49, Iteration 20, Current loss 0.5616393446006509 Accuracy 69.77348066298343\n",
      "Training:: Epoch 49, Iteration 30, Current loss 0.7280232378124293 Accuracy 57.840150005859606\n",
      "Training:: Epoch 49, Iteration 40, Current loss 0.7019575588299118 Accuracy 66.53056096488473\n",
      "Training:: Epoch 49, Iteration 50, Current loss 0.6391664976741271 Accuracy 65.53184557745561\n",
      "Training:: Epoch 49, Iteration 60, Current loss 0.6580891397820331 Accuracy 70.4232946885953\n",
      "Training:: Epoch 49, Iteration 70, Current loss 0.586195153887596 Accuracy 72.33917094168288\n",
      "Training:: Epoch 49, Iteration 80, Current loss 0.5449777816374045 Accuracy 51.24967456391565\n",
      "Training:: Epoch 49, Iteration 90, Current loss 0.6582063041667473 Accuracy 56.633813495072026\n",
      "Training:: Epoch 49, Iteration 100, Current loss 0.6782635400148037 Accuracy 41.58756649629707\n",
      "Training:: Epoch 49, Iteration 110, Current loss 0.5555661953981733 Accuracy 68.58624817129937\n",
      "Training:: Epoch 49, Iteration 120, Current loss 0.8151358209850185 Accuracy 52.47962747380675\n",
      "Training:: Epoch 49, Iteration 130, Current loss 0.7522238757536576 Accuracy 62.48245106945247\n",
      "Training:: Epoch 49, Iteration 140, Current loss 0.6952766713819786 Accuracy 54.673418590678914\n",
      "Training:: Epoch 49, Iteration 150, Current loss 0.6450679143123709 Accuracy 66.77206255999097\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 49, Probability Accuracy 55.33206280813688\n",
      "Starting Training\n",
      "Training:: Epoch 50, Iteration 0, Current loss 0.5994860334364118 Accuracy 61.94434405493314\n",
      "Training:: Epoch 50, Iteration 10, Current loss 0.5420634460963016 Accuracy 67.28309232480534\n",
      "Training:: Epoch 50, Iteration 20, Current loss 0.6227370229266952 Accuracy 70.40381379697139\n",
      "Training:: Epoch 50, Iteration 30, Current loss 0.5704285087701956 Accuracy 57.76242359819293\n",
      "Training:: Epoch 50, Iteration 40, Current loss 0.7475337187463413 Accuracy 57.75949919930121\n",
      "Training:: Epoch 50, Iteration 50, Current loss 0.6563615453129492 Accuracy 63.404699738903396\n",
      "Training:: Epoch 50, Iteration 60, Current loss 0.7063031690077675 Accuracy 64.30446194225722\n",
      "Training:: Epoch 50, Iteration 70, Current loss 0.9422441036993903 Accuracy 48.54092526690391\n",
      "Training:: Epoch 50, Iteration 80, Current loss 0.48158553421466455 Accuracy 71.95121951219512\n",
      "Training:: Epoch 50, Iteration 90, Current loss 0.5308535000086803 Accuracy 66.51496345331678\n",
      "Training:: Epoch 50, Iteration 100, Current loss 0.49709535994194787 Accuracy 59.410714285714285\n",
      "Training:: Epoch 50, Iteration 110, Current loss 0.866383816055047 Accuracy 49.991538331358946\n",
      "Training:: Epoch 50, Iteration 120, Current loss 0.7323363840039322 Accuracy 60.10612090202767\n",
      "Training:: Epoch 50, Iteration 130, Current loss 0.7275360997974779 Accuracy 56.44456834866648\n",
      "Training:: Epoch 50, Iteration 140, Current loss 0.5007688844410186 Accuracy 66.1194693544801\n",
      "Training:: Epoch 50, Iteration 150, Current loss 0.4792777985529947 Accuracy 60.2363177930489\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 50, Probability Accuracy 53.71607904876331\n",
      "Calculating Expectation\n",
      "Epoch 50 iter 0\n",
      "Epoch 50 iter 10\n",
      "Epoch 50 iter 20\n",
      "Epoch 50 iter 30\n",
      "Epoch 50 iter 40\n",
      "Epoch 50 iter 50\n",
      "Epoch 50 iter 60\n",
      "Epoch 50 iter 70\n",
      "Epoch 50 iter 80\n",
      "Epoch 50 iter 90\n",
      "Epoch 50 iter 100\n",
      "Epoch 50 iter 110\n",
      "Epoch 50 iter 120\n",
      "Epoch 50 iter 130\n",
      "Epoch 50 iter 140\n",
      "Epoch 50 iter 150\n",
      "Train Boundary avergage error = 286.214\n",
      "Train From boundary avergage accuracy = 60.059\n",
      "Starting Training\n",
      "Training:: Epoch 51, Iteration 0, Current loss 0.5858050544036068 Accuracy 61.83323861329869\n",
      "Training:: Epoch 51, Iteration 10, Current loss 0.5449547421121086 Accuracy 64.00252127324299\n",
      "Training:: Epoch 51, Iteration 20, Current loss 0.5511586902953218 Accuracy 66.68947073822999\n",
      "Training:: Epoch 51, Iteration 30, Current loss 0.5274713617663396 Accuracy 70.00810591731964\n",
      "Training:: Epoch 51, Iteration 40, Current loss 0.47496222451662706 Accuracy 73.67441860465117\n",
      "Training:: Epoch 51, Iteration 50, Current loss 0.672851515358604 Accuracy 53.7987436292521\n",
      "Training:: Epoch 51, Iteration 60, Current loss 0.630528096412857 Accuracy 63.67464539007092\n",
      "Training:: Epoch 51, Iteration 70, Current loss 0.48903227002287386 Accuracy 62.74011923161846\n",
      "Training:: Epoch 51, Iteration 80, Current loss 0.4729898798246225 Accuracy 56.50749063670412\n",
      "Training:: Epoch 51, Iteration 90, Current loss 0.46021946288511284 Accuracy 63.43066238518408\n",
      "Training:: Epoch 51, Iteration 100, Current loss 0.5475002924533435 Accuracy 68.51319307804853\n",
      "Training:: Epoch 51, Iteration 110, Current loss 0.5326289354340139 Accuracy 66.24456973842314\n",
      "Training:: Epoch 51, Iteration 120, Current loss 0.79757629258949 Accuracy 57.987679671457904\n",
      "Training:: Epoch 51, Iteration 130, Current loss 0.6555453670681518 Accuracy 62.27457351746548\n",
      "Training:: Epoch 51, Iteration 140, Current loss 0.6950029809924758 Accuracy 63.563640673145294\n",
      "Training:: Epoch 51, Iteration 150, Current loss 0.849583905749641 Accuracy 61.02435670791593\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 51, Probability Accuracy 53.88801425197829\n",
      "Starting Training\n",
      "Training:: Epoch 52, Iteration 0, Current loss 0.5640071992955742 Accuracy 66.2239399052855\n",
      "Training:: Epoch 52, Iteration 10, Current loss 0.5011356473305362 Accuracy 65.566991361882\n",
      "Training:: Epoch 52, Iteration 20, Current loss 0.8090433351167272 Accuracy 56.07686411912844\n",
      "Training:: Epoch 52, Iteration 30, Current loss 0.5795254172437558 Accuracy 60.944381014516395\n",
      "Training:: Epoch 52, Iteration 40, Current loss 0.5389122408800178 Accuracy 64.16510318949344\n",
      "Training:: Epoch 52, Iteration 50, Current loss 0.7758783205376024 Accuracy 61.15217391304348\n",
      "Training:: Epoch 52, Iteration 60, Current loss 0.6441409207146 Accuracy 64.5736517886091\n",
      "Training:: Epoch 52, Iteration 70, Current loss 0.5216129448739136 Accuracy 65.28233923085072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 52, Iteration 80, Current loss 0.5463527575816267 Accuracy 66.8870523415978\n",
      "Training:: Epoch 52, Iteration 90, Current loss 0.535193325861192 Accuracy 59.26329974972727\n",
      "Training:: Epoch 52, Iteration 100, Current loss 0.5218000965485083 Accuracy 62.96407829640783\n",
      "Training:: Epoch 52, Iteration 110, Current loss 0.6765970927632563 Accuracy 60.83379278171254\n",
      "Training:: Epoch 52, Iteration 120, Current loss 0.6458530880681504 Accuracy 58.36750314362255\n",
      "Training:: Epoch 52, Iteration 130, Current loss 0.6226615328855587 Accuracy 64.37040613766833\n",
      "Training:: Epoch 52, Iteration 140, Current loss 0.7963528768369761 Accuracy 60.63278893757469\n",
      "Training:: Epoch 52, Iteration 150, Current loss 0.5779510117297592 Accuracy 68.55130057803468\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 52, Probability Accuracy 54.8839955255417\n",
      "Starting Training\n",
      "Training:: Epoch 53, Iteration 0, Current loss 0.5023833146331758 Accuracy 57.34588942168814\n",
      "Training:: Epoch 53, Iteration 10, Current loss 0.45324623767173694 Accuracy 67.53311494089161\n",
      "Training:: Epoch 53, Iteration 20, Current loss 0.5251823865796836 Accuracy 62.61054591395705\n",
      "Training:: Epoch 53, Iteration 30, Current loss 0.48750767789275595 Accuracy 65.71062740076825\n",
      "Training:: Epoch 53, Iteration 40, Current loss 0.577274854301393 Accuracy 56.18919110858604\n",
      "Training:: Epoch 53, Iteration 50, Current loss 0.5815695851403205 Accuracy 61.56437125748503\n",
      "Training:: Epoch 53, Iteration 60, Current loss 0.5217593495989079 Accuracy 64.94129218663552\n",
      "Training:: Epoch 53, Iteration 70, Current loss 0.45724476067103675 Accuracy 67.35525167297061\n",
      "Training:: Epoch 53, Iteration 80, Current loss 0.4888441336702164 Accuracy 68.8075594781274\n",
      "Training:: Epoch 53, Iteration 90, Current loss 0.617551889900198 Accuracy 66.58114706612596\n",
      "Training:: Epoch 53, Iteration 100, Current loss 0.45649153750378235 Accuracy 59.610357784675706\n",
      "Training:: Epoch 53, Iteration 110, Current loss 0.6908301130078482 Accuracy 66.47546207775653\n",
      "Training:: Epoch 53, Iteration 120, Current loss 0.6178867996903591 Accuracy 73.23735519855079\n",
      "Training:: Epoch 53, Iteration 130, Current loss 1.0237615161400655 Accuracy 65.83086186752944\n",
      "Training:: Epoch 53, Iteration 140, Current loss 0.7911516841358223 Accuracy 61.43572621035059\n",
      "Training:: Epoch 53, Iteration 150, Current loss 0.5523500718118548 Accuracy 67.93210537588348\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 53, Probability Accuracy 53.99873637983179\n",
      "Starting Training\n",
      "Training:: Epoch 54, Iteration 0, Current loss 0.6197584187838492 Accuracy 60.24758550771037\n",
      "Training:: Epoch 54, Iteration 10, Current loss 0.5580648035727336 Accuracy 68.71430628209436\n",
      "Training:: Epoch 54, Iteration 20, Current loss 0.3750359001947481 Accuracy 69.87109232294766\n",
      "Training:: Epoch 54, Iteration 30, Current loss 0.47084815950316544 Accuracy 67.27659910087546\n",
      "Training:: Epoch 54, Iteration 40, Current loss 0.42696366498150035 Accuracy 63.43462897526502\n",
      "Training:: Epoch 54, Iteration 50, Current loss 0.8677742816928087 Accuracy 56.64659564613247\n",
      "Training:: Epoch 54, Iteration 60, Current loss 0.43212441502363474 Accuracy 63.365455893254264\n",
      "Training:: Epoch 54, Iteration 70, Current loss 0.7087967919620748 Accuracy 55.327479829140955\n",
      "Training:: Epoch 54, Iteration 80, Current loss 0.5548625304931405 Accuracy 69.07022799979688\n",
      "Training:: Epoch 54, Iteration 90, Current loss 0.6386535750297535 Accuracy 62.75627562756276\n",
      "Training:: Epoch 54, Iteration 100, Current loss 0.5363419130398965 Accuracy 67.10484637313905\n",
      "Training:: Epoch 54, Iteration 110, Current loss 0.847718833367587 Accuracy 55.972696245733786\n",
      "Training:: Epoch 54, Iteration 120, Current loss 0.6000708961291352 Accuracy 64.67552993677947\n",
      "Training:: Epoch 54, Iteration 130, Current loss 0.5388968100900593 Accuracy 54.59551325628824\n",
      "Training:: Epoch 54, Iteration 140, Current loss 0.6085737411805417 Accuracy 55.07187853335487\n",
      "Training:: Epoch 54, Iteration 150, Current loss 0.6660105018558411 Accuracy 57.98436053091882\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 54, Probability Accuracy 53.714836143679825\n",
      "Starting Training\n",
      "Training:: Epoch 55, Iteration 0, Current loss 0.5743056731144348 Accuracy 57.22874589008924\n",
      "Training:: Epoch 55, Iteration 10, Current loss 0.5113595696948076 Accuracy 61.292845967856636\n",
      "Training:: Epoch 55, Iteration 20, Current loss 0.6279650023851081 Accuracy 66.0189821388536\n",
      "Training:: Epoch 55, Iteration 30, Current loss 0.4598778891857735 Accuracy 64.49661758853959\n",
      "Training:: Epoch 55, Iteration 40, Current loss 0.5409089708495327 Accuracy 64.26031533042602\n",
      "Training:: Epoch 55, Iteration 50, Current loss 1.2507230258518631 Accuracy 71.54904801324503\n",
      "Training:: Epoch 55, Iteration 60, Current loss 1.3419155187253327 Accuracy 65.87144622991347\n",
      "Training:: Epoch 55, Iteration 70, Current loss 0.721623330426667 Accuracy 70.26253577205425\n",
      "Training:: Epoch 55, Iteration 80, Current loss 0.6197520343765185 Accuracy 68.70767104353835\n",
      "Training:: Epoch 55, Iteration 90, Current loss 0.6060075063314844 Accuracy 67.06253207242871\n",
      "Training:: Epoch 55, Iteration 100, Current loss 0.6244470894489762 Accuracy 62.355682112347914\n",
      "Training:: Epoch 55, Iteration 110, Current loss 0.5485043975655316 Accuracy 64.05497802274472\n",
      "Training:: Epoch 55, Iteration 120, Current loss 0.6322835201506515 Accuracy 58.5733726468587\n",
      "Training:: Epoch 55, Iteration 130, Current loss 0.5366397422393671 Accuracy 61.149643705463184\n",
      "Training:: Epoch 55, Iteration 140, Current loss 0.705949000833815 Accuracy 62.819504522217855\n",
      "Training:: Epoch 55, Iteration 150, Current loss 1.0055297906404759 Accuracy 62.03465431463373\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 55, Probability Accuracy 54.19832622115425\n",
      "Calculating Expectation\n",
      "Epoch 55 iter 0\n",
      "Epoch 55 iter 10\n",
      "Epoch 55 iter 20\n",
      "Epoch 55 iter 30\n",
      "Epoch 55 iter 40\n",
      "Epoch 55 iter 50\n",
      "Epoch 55 iter 60\n",
      "Epoch 55 iter 70\n",
      "Epoch 55 iter 80\n",
      "Epoch 55 iter 90\n",
      "Epoch 55 iter 100\n",
      "Epoch 55 iter 110\n",
      "Epoch 55 iter 120\n",
      "Epoch 55 iter 130\n",
      "Epoch 55 iter 140\n",
      "Epoch 55 iter 150\n",
      "Train Boundary avergage error = 284.939\n",
      "Train From boundary avergage accuracy = 60.340\n",
      "Starting Training\n",
      "Training:: Epoch 56, Iteration 0, Current loss 0.45759056875214205 Accuracy 53.97453657893001\n",
      "Training:: Epoch 56, Iteration 10, Current loss 0.42389514321787725 Accuracy 69.21523570781979\n",
      "Training:: Epoch 56, Iteration 20, Current loss 0.5808865836052637 Accuracy 60.88080931010877\n",
      "Training:: Epoch 56, Iteration 30, Current loss 0.47546386303761967 Accuracy 62.44952893674294\n",
      "Training:: Epoch 56, Iteration 40, Current loss 0.5060665162678314 Accuracy 49.440179142674346\n",
      "Training:: Epoch 56, Iteration 50, Current loss 0.5743478181651163 Accuracy 66.50027731558514\n",
      "Training:: Epoch 56, Iteration 60, Current loss 0.5079130205955553 Accuracy 48.397304424260184\n",
      "Training:: Epoch 56, Iteration 70, Current loss 0.5672366386831421 Accuracy 63.247755153661316\n",
      "Training:: Epoch 56, Iteration 80, Current loss 0.5803110389367095 Accuracy 63.11041720877787\n",
      "Training:: Epoch 56, Iteration 90, Current loss 0.682367078996202 Accuracy 62.456011730205276\n",
      "Training:: Epoch 56, Iteration 100, Current loss 0.5467084998624165 Accuracy 64.91391551295705\n",
      "Training:: Epoch 56, Iteration 110, Current loss 0.7868230372871152 Accuracy 57.34125702474\n",
      "Training:: Epoch 56, Iteration 120, Current loss 0.390681309087085 Accuracy 69.74172856178258\n",
      "Training:: Epoch 56, Iteration 130, Current loss 0.4726401833339884 Accuracy 69.18053042672433\n",
      "Training:: Epoch 56, Iteration 140, Current loss 1.230297874501117 Accuracy 62.278319220322736\n",
      "Training:: Epoch 56, Iteration 150, Current loss 4.4394269646335855 Accuracy 34.00716323681175\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 56, Probability Accuracy 45.045055309276215\n",
      "Starting Training\n",
      "Training:: Epoch 57, Iteration 0, Current loss 4.5486951729241785 Accuracy 50.98255685581806\n",
      "Training:: Epoch 57, Iteration 10, Current loss 2.325047669142305 Accuracy 61.86544505406701\n",
      "Training:: Epoch 57, Iteration 20, Current loss 3.5690370706351686 Accuracy 57.86370032835221\n",
      "Training:: Epoch 57, Iteration 30, Current loss 4.091668425794955 Accuracy 58.09036052938492\n",
      "Training:: Epoch 57, Iteration 40, Current loss 3.2468073203448906 Accuracy 51.559073138171065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 57, Iteration 50, Current loss 6.885093098806506 Accuracy 43.16026264591439\n",
      "Training:: Epoch 57, Iteration 60, Current loss 2.7762814786467014 Accuracy 66.52325675785372\n",
      "Training:: Epoch 57, Iteration 70, Current loss 2.093266588499585 Accuracy 64.27678199249688\n",
      "Training:: Epoch 57, Iteration 80, Current loss 1.4189804393234597 Accuracy 61.98725055432372\n",
      "Training:: Epoch 57, Iteration 90, Current loss 1.166567852796174 Accuracy 58.704871683340585\n",
      "Training:: Epoch 57, Iteration 100, Current loss 1.0719235690667595 Accuracy 62.88122506755887\n",
      "Training:: Epoch 57, Iteration 110, Current loss 1.7019779343713335 Accuracy 57.27239532619279\n",
      "Training:: Epoch 57, Iteration 120, Current loss 1.0747543642019461 Accuracy 59.796025353857885\n",
      "Training:: Epoch 57, Iteration 130, Current loss 1.193097452481278 Accuracy 71.36154823575409\n",
      "Training:: Epoch 57, Iteration 140, Current loss 1.2312824191368688 Accuracy 68.22608921498605\n",
      "Training:: Epoch 57, Iteration 150, Current loss 1.0549233017240778 Accuracy 75.11097957975733\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 57, Probability Accuracy 55.691365952686745\n",
      "Starting Training\n",
      "Training:: Epoch 58, Iteration 0, Current loss 0.985790859257614 Accuracy 58.73860182370821\n",
      "Training:: Epoch 58, Iteration 10, Current loss 0.8290059981462882 Accuracy 62.61280886288666\n",
      "Training:: Epoch 58, Iteration 20, Current loss 0.664300805129625 Accuracy 72.45832707613756\n",
      "Training:: Epoch 58, Iteration 30, Current loss 0.7978696445123468 Accuracy 57.22787007190677\n",
      "Training:: Epoch 58, Iteration 40, Current loss 0.9007636494902953 Accuracy 56.751703992210324\n",
      "Training:: Epoch 58, Iteration 50, Current loss 0.7795280752987093 Accuracy 59.49705358366452\n",
      "Training:: Epoch 58, Iteration 60, Current loss 0.9184588549618347 Accuracy 60.752994865944096\n",
      "Training:: Epoch 58, Iteration 70, Current loss 0.9404804730869826 Accuracy 51.63825055596738\n",
      "Training:: Epoch 58, Iteration 80, Current loss 0.6270157449654225 Accuracy 73.62753751103266\n",
      "Training:: Epoch 58, Iteration 90, Current loss 0.7851228470064129 Accuracy 61.102817689867514\n",
      "Training:: Epoch 58, Iteration 100, Current loss 0.5674781688391822 Accuracy 72.48398429427567\n",
      "Training:: Epoch 58, Iteration 110, Current loss 0.9517886975575388 Accuracy 63.62090680100756\n",
      "Training:: Epoch 58, Iteration 120, Current loss 0.7953256524280974 Accuracy 70.53896326810847\n",
      "Training:: Epoch 58, Iteration 130, Current loss 0.6014803582888858 Accuracy 64.15094339622641\n",
      "Training:: Epoch 58, Iteration 140, Current loss 0.6601968788285402 Accuracy 53.111342351716964\n",
      "Training:: Epoch 58, Iteration 150, Current loss 0.6208956730430037 Accuracy 60.9884694983739\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 58, Probability Accuracy 56.89128723536479\n",
      "Starting Training\n",
      "Training:: Epoch 59, Iteration 0, Current loss 0.7426953300643524 Accuracy 59.771181199752625\n",
      "Training:: Epoch 59, Iteration 10, Current loss 0.5548380557707 Accuracy 67.60523523169438\n",
      "Training:: Epoch 59, Iteration 20, Current loss 0.5958790173368227 Accuracy 70.10477224813135\n",
      "Training:: Epoch 59, Iteration 30, Current loss 0.466116663063857 Accuracy 68.57986917071112\n",
      "Training:: Epoch 59, Iteration 40, Current loss 0.5317538340630409 Accuracy 67.8495602062481\n",
      "Training:: Epoch 59, Iteration 50, Current loss 0.5864195710997524 Accuracy 60.81614743308469\n",
      "Training:: Epoch 59, Iteration 60, Current loss 0.4712478554391376 Accuracy 71.00052938062467\n",
      "Training:: Epoch 59, Iteration 70, Current loss 0.383753102373861 Accuracy 68.97224133975682\n",
      "Training:: Epoch 59, Iteration 80, Current loss 0.6080880653258652 Accuracy 59.111497626553614\n",
      "Training:: Epoch 59, Iteration 90, Current loss 0.5364542573734128 Accuracy 68.90199456629779\n",
      "Training:: Epoch 59, Iteration 100, Current loss 0.6072422329243045 Accuracy 62.84018606640646\n",
      "Training:: Epoch 59, Iteration 110, Current loss 0.4856788344601013 Accuracy 60.341699425461144\n",
      "Training:: Epoch 59, Iteration 120, Current loss 0.4923033926981561 Accuracy 62.21670623785884\n",
      "Training:: Epoch 59, Iteration 130, Current loss 0.5501050638161886 Accuracy 67.22308088614116\n",
      "Training:: Epoch 59, Iteration 140, Current loss 0.7866795382986305 Accuracy 53.35123581958678\n",
      "Training:: Epoch 59, Iteration 150, Current loss 0.5863344206600439 Accuracy 61.60475843651372\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 59, Probability Accuracy 55.80074160003314\n",
      "Starting Training\n",
      "Training:: Epoch 60, Iteration 0, Current loss 0.5810825629749926 Accuracy 56.5744036551028\n",
      "Training:: Epoch 60, Iteration 10, Current loss 0.5971966041754496 Accuracy 61.42218196229406\n",
      "Training:: Epoch 60, Iteration 20, Current loss 0.5844384290473638 Accuracy 64.52951022487446\n",
      "Training:: Epoch 60, Iteration 30, Current loss 0.5554017978742425 Accuracy 57.19746504375817\n",
      "Training:: Epoch 60, Iteration 40, Current loss 0.5347735471687789 Accuracy 72.03007518796993\n",
      "Training:: Epoch 60, Iteration 50, Current loss 0.5618518873601305 Accuracy 55.87944989142594\n",
      "Training:: Epoch 60, Iteration 60, Current loss 0.5382555030908744 Accuracy 65.48046155337923\n",
      "Training:: Epoch 60, Iteration 70, Current loss 0.39317643385544326 Accuracy 69.86785293732828\n",
      "Training:: Epoch 60, Iteration 80, Current loss 0.42025065652054433 Accuracy 70.81224696356276\n",
      "Training:: Epoch 60, Iteration 90, Current loss 0.4974025078568586 Accuracy 62.99321824907521\n",
      "Training:: Epoch 60, Iteration 100, Current loss 0.46920953354983697 Accuracy 61.4241589448201\n",
      "Training:: Epoch 60, Iteration 110, Current loss 0.4648976548690016 Accuracy 69.05685107312544\n",
      "Training:: Epoch 60, Iteration 120, Current loss 0.44911967512330087 Accuracy 69.03205331640748\n",
      "Training:: Epoch 60, Iteration 130, Current loss 0.4856476997439559 Accuracy 60.69795427196149\n",
      "Training:: Epoch 60, Iteration 140, Current loss 0.507444062755817 Accuracy 60.080389253226144\n",
      "Training:: Epoch 60, Iteration 150, Current loss 0.4545313710328614 Accuracy 50.32398836286696\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 60, Probability Accuracy 56.03326842606786\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  58.74912972847528\n",
      "Calculating Expectation\n",
      "Epoch 60 iter 0\n",
      "Epoch 60 iter 10\n",
      "Epoch 60 iter 20\n",
      "Epoch 60 iter 30\n",
      "Epoch 60 iter 40\n",
      "Epoch 60 iter 50\n",
      "Epoch 60 iter 60\n",
      "Epoch 60 iter 70\n",
      "Epoch 60 iter 80\n",
      "Epoch 60 iter 90\n",
      "Epoch 60 iter 100\n",
      "Epoch 60 iter 110\n",
      "Epoch 60 iter 120\n",
      "Epoch 60 iter 130\n",
      "Epoch 60 iter 140\n",
      "Epoch 60 iter 150\n",
      "Train Boundary avergage error = 285.759\n",
      "Train From boundary avergage accuracy = 60.139\n",
      "Starting Training\n",
      "Training:: Epoch 61, Iteration 0, Current loss 0.4479995896836484 Accuracy 60.79093799682035\n",
      "Training:: Epoch 61, Iteration 10, Current loss 1.8658616223971916 Accuracy 63.12794440039181\n",
      "Training:: Epoch 61, Iteration 20, Current loss 0.4929722198446842 Accuracy 65.51335794281424\n",
      "Training:: Epoch 61, Iteration 30, Current loss 0.5285499137011012 Accuracy 65.38837163877857\n",
      "Training:: Epoch 61, Iteration 40, Current loss 0.40856357251836023 Accuracy 65.304312777106\n",
      "Training:: Epoch 61, Iteration 50, Current loss 0.4926950196563463 Accuracy 55.548690064260995\n",
      "Training:: Epoch 61, Iteration 60, Current loss 0.48989245399238696 Accuracy 53.5384396759983\n",
      "Training:: Epoch 61, Iteration 70, Current loss 0.3766591669270363 Accuracy 68.04606162582816\n",
      "Training:: Epoch 61, Iteration 80, Current loss 0.5275738999215059 Accuracy 59.65270684371808\n",
      "Training:: Epoch 61, Iteration 90, Current loss 0.5387332359188095 Accuracy 56.672203765227025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 61, Iteration 100, Current loss 0.6195406711606146 Accuracy 63.180531975099036\n",
      "Training:: Epoch 61, Iteration 110, Current loss 0.4187495200372012 Accuracy 62.683915385042475\n",
      "Training:: Epoch 61, Iteration 120, Current loss 0.4024215949065362 Accuracy 70.56171188383645\n",
      "Training:: Epoch 61, Iteration 130, Current loss 0.4646827966825175 Accuracy 72.51840465981716\n",
      "Training:: Epoch 61, Iteration 140, Current loss 0.427180706441045 Accuracy 66.39082058414465\n",
      "Training:: Epoch 61, Iteration 150, Current loss 0.3410070700650788 Accuracy 73.46576153811108\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 61, Probability Accuracy 55.091664249906785\n",
      "Starting Training\n",
      "Training:: Epoch 62, Iteration 0, Current loss 0.35154360572531984 Accuracy 62.41886768202558\n",
      "Training:: Epoch 62, Iteration 10, Current loss 0.73392403902897 Accuracy 63.26302195436935\n",
      "Training:: Epoch 62, Iteration 20, Current loss 0.31229471934109837 Accuracy 62.61057782796913\n",
      "Training:: Epoch 62, Iteration 30, Current loss 0.6347384947385183 Accuracy 58.09312638580931\n",
      "Training:: Epoch 62, Iteration 40, Current loss 0.585906809212443 Accuracy 47.266427104722794\n",
      "Training:: Epoch 62, Iteration 50, Current loss 0.6413326175286335 Accuracy 64.36592859413074\n",
      "Training:: Epoch 62, Iteration 60, Current loss 0.38466330647396163 Accuracy 61.02195265954592\n",
      "Training:: Epoch 62, Iteration 70, Current loss 0.5280651041997477 Accuracy 58.390755857097425\n",
      "Training:: Epoch 62, Iteration 80, Current loss 0.5648404142874286 Accuracy 60.90122894856623\n",
      "Training:: Epoch 62, Iteration 90, Current loss 0.4335254406870053 Accuracy 51.384239572966614\n",
      "Training:: Epoch 62, Iteration 100, Current loss 0.4331981907187846 Accuracy 62.207438766253404\n",
      "Training:: Epoch 62, Iteration 110, Current loss 0.38438403809248267 Accuracy 54.5354118080275\n",
      "Training:: Epoch 62, Iteration 120, Current loss 0.5278353176990489 Accuracy 68.46316257361929\n",
      "Training:: Epoch 62, Iteration 130, Current loss 0.5381696567759741 Accuracy 65.73020101719544\n",
      "Training:: Epoch 62, Iteration 140, Current loss 0.45785993396646185 Accuracy 66.09020799252161\n",
      "Training:: Epoch 62, Iteration 150, Current loss 0.35837316287553156 Accuracy 64.38730289601155\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 62, Probability Accuracy 55.972055350706384\n",
      "Starting Training\n",
      "Training:: Epoch 63, Iteration 0, Current loss 0.38632174299710087 Accuracy 63.89791497427566\n",
      "Training:: Epoch 63, Iteration 10, Current loss 0.4559444242954588 Accuracy 65.04433497536945\n",
      "Training:: Epoch 63, Iteration 20, Current loss 0.3370752266731196 Accuracy 75.35319048740287\n",
      "Training:: Epoch 63, Iteration 30, Current loss 0.49302782373712584 Accuracy 70.48632218844985\n",
      "Training:: Epoch 63, Iteration 40, Current loss 0.3754697222058897 Accuracy 58.84670677812683\n",
      "Training:: Epoch 63, Iteration 50, Current loss 0.40722502736292154 Accuracy 75.56555351371902\n",
      "Training:: Epoch 63, Iteration 60, Current loss 0.4697698532218503 Accuracy 64.32673899170389\n",
      "Training:: Epoch 63, Iteration 70, Current loss 0.3429076620664986 Accuracy 55.02533783783784\n",
      "Training:: Epoch 63, Iteration 80, Current loss 0.3173236233370934 Accuracy 60.28840820854132\n",
      "Training:: Epoch 63, Iteration 90, Current loss 0.43951011668757833 Accuracy 65.9223817118554\n",
      "Training:: Epoch 63, Iteration 100, Current loss 0.4476566079128215 Accuracy 69.26229508196721\n",
      "Training:: Epoch 63, Iteration 110, Current loss 0.45074355217283607 Accuracy 58.404933481152995\n",
      "Training:: Epoch 63, Iteration 120, Current loss 0.4829037280545189 Accuracy 66.4819643633203\n",
      "Training:: Epoch 63, Iteration 130, Current loss 0.5125721227865275 Accuracy 61.19823275234258\n",
      "Training:: Epoch 63, Iteration 140, Current loss 0.4043634875817636 Accuracy 68.35954283750108\n",
      "Training:: Epoch 63, Iteration 150, Current loss 0.605181406334737 Accuracy 72.32943321683635\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 63, Probability Accuracy 55.868272776235656\n",
      "Starting Training\n",
      "Training:: Epoch 64, Iteration 0, Current loss 0.3785695603193524 Accuracy 65.0634844101575\n",
      "Training:: Epoch 64, Iteration 10, Current loss 0.4858379699397095 Accuracy 54.5246495661295\n",
      "Training:: Epoch 64, Iteration 20, Current loss 0.35640061061021583 Accuracy 59.24593873757375\n",
      "Training:: Epoch 64, Iteration 30, Current loss 0.4901866898838044 Accuracy 70.78855454056959\n",
      "Training:: Epoch 64, Iteration 40, Current loss 0.5471834470522967 Accuracy 57.667879385829686\n",
      "Training:: Epoch 64, Iteration 50, Current loss 0.43104220220843764 Accuracy 64.06376811594203\n",
      "Training:: Epoch 64, Iteration 60, Current loss 0.4097480664946894 Accuracy 58.929961089494164\n",
      "Training:: Epoch 64, Iteration 70, Current loss 0.30825545150943945 Accuracy 66.6951566951567\n",
      "Training:: Epoch 64, Iteration 80, Current loss 0.40832516522050405 Accuracy 64.24599460441557\n",
      "Training:: Epoch 64, Iteration 90, Current loss 0.42521905400755844 Accuracy 60.927991886409735\n",
      "Training:: Epoch 64, Iteration 100, Current loss 0.37089390315710385 Accuracy 58.17037653422093\n",
      "Training:: Epoch 64, Iteration 110, Current loss 0.4110339057761347 Accuracy 66.46892274504516\n",
      "Training:: Epoch 64, Iteration 120, Current loss 0.4677981164508717 Accuracy 69.68257078475555\n",
      "Training:: Epoch 64, Iteration 130, Current loss 0.5325023705061541 Accuracy 64.80302666346385\n",
      "Training:: Epoch 64, Iteration 140, Current loss 0.6022357441752871 Accuracy 63.03708826834961\n",
      "Training:: Epoch 64, Iteration 150, Current loss 0.44370133320749516 Accuracy 71.77444069874349\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 64, Probability Accuracy 55.825081824584665\n",
      "Starting Training\n",
      "Training:: Epoch 65, Iteration 0, Current loss 0.4283798981123598 Accuracy 64.27570327360097\n",
      "Training:: Epoch 65, Iteration 10, Current loss 0.487633408340471 Accuracy 71.14039608333947\n",
      "Training:: Epoch 65, Iteration 20, Current loss 0.3957110434431105 Accuracy 63.75833041038232\n",
      "Training:: Epoch 65, Iteration 30, Current loss 0.37650751648866115 Accuracy 65.27215252395536\n",
      "Training:: Epoch 65, Iteration 40, Current loss 0.35277513194281984 Accuracy 68.64063166880068\n",
      "Training:: Epoch 65, Iteration 50, Current loss 0.5050104236521159 Accuracy 63.95428886135206\n",
      "Training:: Epoch 65, Iteration 60, Current loss 0.3494069302430464 Accuracy 67.95545282622399\n",
      "Training:: Epoch 65, Iteration 70, Current loss 0.4898761216329967 Accuracy 54.58829866020333\n",
      "Training:: Epoch 65, Iteration 80, Current loss 0.5303969432642782 Accuracy 64.59348070438367\n",
      "Training:: Epoch 65, Iteration 90, Current loss 0.364045457381039 Accuracy 61.818048314854245\n",
      "Training:: Epoch 65, Iteration 100, Current loss 0.39290205128474337 Accuracy 62.64776464314283\n",
      "Training:: Epoch 65, Iteration 110, Current loss 0.4698974993626577 Accuracy 54.12764617927127\n",
      "Training:: Epoch 65, Iteration 120, Current loss 0.4743677919639311 Accuracy 60.185034013605446\n",
      "Training:: Epoch 65, Iteration 130, Current loss 0.46945306157495253 Accuracy 56.245331562785296\n",
      "Training:: Epoch 65, Iteration 140, Current loss 0.31661692357176363 Accuracy 75.02798209146147\n",
      "Training:: Epoch 65, Iteration 150, Current loss 0.4099139906737609 Accuracy 64.95793742056527\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 65, Probability Accuracy 54.211583875378054\n",
      "Calculating Expectation\n",
      "Epoch 65 iter 0\n",
      "Epoch 65 iter 10\n",
      "Epoch 65 iter 20\n",
      "Epoch 65 iter 30\n",
      "Epoch 65 iter 40\n",
      "Epoch 65 iter 50\n",
      "Epoch 65 iter 60\n",
      "Epoch 65 iter 70\n",
      "Epoch 65 iter 80\n",
      "Epoch 65 iter 90\n",
      "Epoch 65 iter 100\n",
      "Epoch 65 iter 110\n",
      "Epoch 65 iter 120\n",
      "Epoch 65 iter 130\n",
      "Epoch 65 iter 140\n",
      "Epoch 65 iter 150\n",
      "Train Boundary avergage error = 286.492\n",
      "Train From boundary avergage accuracy = 60.115\n",
      "Starting Training\n",
      "Training:: Epoch 66, Iteration 0, Current loss 0.3799241432458787 Accuracy 54.92737542868671\n",
      "Training:: Epoch 66, Iteration 10, Current loss 0.5102048600564899 Accuracy 63.14817348474484\n",
      "Training:: Epoch 66, Iteration 20, Current loss 0.4038194458909327 Accuracy 66.73725822391641\n",
      "Training:: Epoch 66, Iteration 30, Current loss 0.3465929190919734 Accuracy 64.93028150486714\n",
      "Training:: Epoch 66, Iteration 40, Current loss 0.4821768140512948 Accuracy 60.55881494927231\n",
      "Training:: Epoch 66, Iteration 50, Current loss 0.3748216017848632 Accuracy 63.01188476940964\n",
      "Training:: Epoch 66, Iteration 60, Current loss 0.4486397266574742 Accuracy 69.05798603911812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 66, Iteration 70, Current loss 0.3781808894252786 Accuracy 71.4808105206656\n",
      "Training:: Epoch 66, Iteration 80, Current loss 0.3767962634968294 Accuracy 58.32690596262237\n",
      "Training:: Epoch 66, Iteration 90, Current loss 0.4568493266039351 Accuracy 61.16725097958342\n",
      "Training:: Epoch 66, Iteration 100, Current loss 0.4980518449288141 Accuracy 60.96142663306843\n",
      "Training:: Epoch 66, Iteration 110, Current loss 0.37214415262103395 Accuracy 67.30031773857785\n",
      "Training:: Epoch 66, Iteration 120, Current loss 0.5710518418992562 Accuracy 59.92750704792589\n",
      "Training:: Epoch 66, Iteration 130, Current loss 0.5261021714313947 Accuracy 68.8819083145185\n",
      "Training:: Epoch 66, Iteration 140, Current loss 0.32060475453295906 Accuracy 72.93399168399168\n",
      "Training:: Epoch 66, Iteration 150, Current loss 0.5576918313106228 Accuracy 60.94060812730889\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 66, Probability Accuracy 54.754836972283215\n",
      "Starting Training\n",
      "Training:: Epoch 67, Iteration 0, Current loss 0.32201108682548496 Accuracy 68.14520619130693\n",
      "Training:: Epoch 67, Iteration 10, Current loss 0.4724708663613337 Accuracy 72.41740954378605\n",
      "Training:: Epoch 67, Iteration 20, Current loss 0.41563375731690094 Accuracy 73.43326098752034\n",
      "Training:: Epoch 67, Iteration 30, Current loss 0.40465113240780815 Accuracy 68.10520102315209\n",
      "Training:: Epoch 67, Iteration 40, Current loss 0.4759605419740095 Accuracy 67.7199045503168\n",
      "Training:: Epoch 67, Iteration 50, Current loss 0.49544476570153617 Accuracy 64.08590885280252\n",
      "Training:: Epoch 67, Iteration 60, Current loss 0.6365334127724869 Accuracy 53.46487006737247\n",
      "Training:: Epoch 67, Iteration 70, Current loss 0.5512931448442676 Accuracy 56.67447306791569\n",
      "Training:: Epoch 67, Iteration 80, Current loss 0.5075350764487763 Accuracy 63.01141107709435\n",
      "Training:: Epoch 67, Iteration 90, Current loss 0.4417635924219472 Accuracy 61.24686891177289\n",
      "Training:: Epoch 67, Iteration 100, Current loss 0.651707768997419 Accuracy 58.25881115202525\n",
      "Training:: Epoch 67, Iteration 110, Current loss 0.4533032013345778 Accuracy 69.64213447418628\n",
      "Training:: Epoch 67, Iteration 120, Current loss 0.7203780326605251 Accuracy 65.88001915315685\n",
      "Training:: Epoch 67, Iteration 130, Current loss 0.5620096599244407 Accuracy 57.05642565972967\n",
      "Training:: Epoch 67, Iteration 140, Current loss 0.41373785586642287 Accuracy 67.75358354305723\n",
      "Training:: Epoch 67, Iteration 150, Current loss 0.6293398592548667 Accuracy 57.22623252956535\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 67, Probability Accuracy 52.96132493681899\n",
      "Starting Training\n",
      "Training:: Epoch 68, Iteration 0, Current loss 0.4406434809389532 Accuracy 54.882920110192835\n",
      "Training:: Epoch 68, Iteration 10, Current loss 0.7526828008405746 Accuracy 61.735136072109555\n",
      "Training:: Epoch 68, Iteration 20, Current loss 1.7154007779921145 Accuracy 64.87705073314893\n",
      "Training:: Epoch 68, Iteration 30, Current loss 0.4457838412135196 Accuracy 59.277145972892974\n",
      "Training:: Epoch 68, Iteration 40, Current loss 1.2353720843677993 Accuracy 65.53229741877487\n",
      "Training:: Epoch 68, Iteration 50, Current loss 0.7450276809688315 Accuracy 63.98723446693926\n",
      "Training:: Epoch 68, Iteration 60, Current loss 0.6537596224846098 Accuracy 55.12300876614196\n",
      "Training:: Epoch 68, Iteration 70, Current loss 0.6361437674866304 Accuracy 57.64069264069264\n",
      "Training:: Epoch 68, Iteration 80, Current loss 0.38545286236444726 Accuracy 63.27498176513494\n",
      "Training:: Epoch 68, Iteration 90, Current loss 0.6791480480508949 Accuracy 53.821088925093775\n",
      "Training:: Epoch 68, Iteration 100, Current loss 0.5262786021695282 Accuracy 49.598991172761664\n",
      "Training:: Epoch 68, Iteration 110, Current loss 0.5591670362775498 Accuracy 72.63475910319606\n",
      "Training:: Epoch 68, Iteration 120, Current loss 0.4887042419821336 Accuracy 67.94409377817854\n",
      "Training:: Epoch 68, Iteration 130, Current loss 0.4571492205734564 Accuracy 61.72898572059473\n",
      "Training:: Epoch 68, Iteration 140, Current loss 0.7639117039152842 Accuracy 69.5311416285199\n",
      "Training:: Epoch 68, Iteration 150, Current loss 0.5493748243574841 Accuracy 64.44389151530231\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 68, Probability Accuracy 53.83964452914613\n",
      "Starting Training\n",
      "Training:: Epoch 69, Iteration 0, Current loss 0.5879584741890145 Accuracy 66.62520729684908\n",
      "Training:: Epoch 69, Iteration 10, Current loss 0.6214827530383665 Accuracy 62.08161688980432\n",
      "Training:: Epoch 69, Iteration 20, Current loss 0.5534148775351801 Accuracy 59.29583290249199\n",
      "Training:: Epoch 69, Iteration 30, Current loss 0.8567087043625186 Accuracy 66.00270502889462\n",
      "Training:: Epoch 69, Iteration 40, Current loss 0.40166572583872184 Accuracy 69.78037143645756\n",
      "Training:: Epoch 69, Iteration 50, Current loss 0.7089736791438634 Accuracy 55.91598116819287\n",
      "Training:: Epoch 69, Iteration 60, Current loss 0.4856102839524937 Accuracy 69.14109506618531\n",
      "Training:: Epoch 69, Iteration 70, Current loss 0.31864834396141717 Accuracy 69.85095240835587\n",
      "Training:: Epoch 69, Iteration 80, Current loss 0.4597865305770769 Accuracy 51.29032258064516\n",
      "Training:: Epoch 69, Iteration 90, Current loss 0.5216266231458453 Accuracy 75.1059014681135\n",
      "Training:: Epoch 69, Iteration 100, Current loss 0.2891762587726411 Accuracy 72.14582438046125\n",
      "Training:: Epoch 69, Iteration 110, Current loss 0.521193295314598 Accuracy 62.640530412222546\n",
      "Training:: Epoch 69, Iteration 120, Current loss 0.7388404959195178 Accuracy 67.26090993500465\n",
      "Training:: Epoch 69, Iteration 130, Current loss 0.4815042839294841 Accuracy 60.25297048677654\n",
      "Training:: Epoch 69, Iteration 140, Current loss 0.3748577882474622 Accuracy 66.50988836629456\n",
      "Training:: Epoch 69, Iteration 150, Current loss 0.5216110223708295 Accuracy 71.08669639943436\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 69, Probability Accuracy 53.885528441811324\n",
      "Starting Training\n",
      "Training:: Epoch 70, Iteration 0, Current loss 0.6561254722561563 Accuracy 66.31571656161252\n",
      "Training:: Epoch 70, Iteration 10, Current loss 0.3969547507015819 Accuracy 64.07555167684828\n",
      "Training:: Epoch 70, Iteration 20, Current loss 0.4967996030260968 Accuracy 61.18285607336702\n",
      "Training:: Epoch 70, Iteration 30, Current loss 0.29814171305122567 Accuracy 66.90813810110974\n",
      "Training:: Epoch 70, Iteration 40, Current loss 0.4382045474771381 Accuracy 59.09282345013477\n",
      "Training:: Epoch 70, Iteration 50, Current loss 0.3858503163257109 Accuracy 69.10377358490567\n",
      "Training:: Epoch 70, Iteration 60, Current loss 0.3110764255177386 Accuracy 65.20039100684262\n",
      "Training:: Epoch 70, Iteration 70, Current loss 0.40432152561214335 Accuracy 70.43404366583867\n",
      "Training:: Epoch 70, Iteration 80, Current loss 0.8178306101924295 Accuracy 73.26356258009397\n",
      "Training:: Epoch 70, Iteration 90, Current loss 4.976493418902161 Accuracy 39.67904749579397\n",
      "Training:: Epoch 70, Iteration 100, Current loss 6.954781526274736 Accuracy 36.82520347710537\n",
      "Training:: Epoch 70, Iteration 110, Current loss 3.1628461352688424 Accuracy 49.782940996637116\n",
      "Training:: Epoch 70, Iteration 120, Current loss 2.590834410504082 Accuracy 57.86879259980526\n",
      "Training:: Epoch 70, Iteration 130, Current loss 3.4339008349828877 Accuracy 63.37420134691763\n",
      "Training:: Epoch 70, Iteration 140, Current loss 4.719759783489913 Accuracy 46.760757314974185\n",
      "Training:: Epoch 70, Iteration 150, Current loss 4.028288045314334 Accuracy 48.19068453194786\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 70, Probability Accuracy 47.29978870613581\n",
      "Calculating Expectation\n",
      "Epoch 70 iter 0\n",
      "Epoch 70 iter 10\n",
      "Epoch 70 iter 20\n",
      "Epoch 70 iter 30\n",
      "Epoch 70 iter 40\n",
      "Epoch 70 iter 50\n",
      "Epoch 70 iter 60\n",
      "Epoch 70 iter 70\n",
      "Epoch 70 iter 80\n",
      "Epoch 70 iter 90\n",
      "Epoch 70 iter 100\n",
      "Epoch 70 iter 110\n",
      "Epoch 70 iter 120\n",
      "Epoch 70 iter 130\n",
      "Epoch 70 iter 140\n",
      "Epoch 70 iter 150\n",
      "Train Boundary avergage error = 286.513\n",
      "Train From boundary avergage accuracy = 60.186\n",
      "Starting Training\n",
      "Training:: Epoch 71, Iteration 0, Current loss 2.4975590625053576 Accuracy 59.63443004320372\n",
      "Training:: Epoch 71, Iteration 10, Current loss 3.7164061977792713 Accuracy 51.89471595793929\n",
      "Training:: Epoch 71, Iteration 20, Current loss 2.0933003167549273 Accuracy 59.75116640746501\n",
      "Training:: Epoch 71, Iteration 30, Current loss 1.6074371763620916 Accuracy 62.8514292436184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 71, Iteration 40, Current loss 1.4657663732786197 Accuracy 63.2750054007345\n",
      "Training:: Epoch 71, Iteration 50, Current loss 1.6366482381646832 Accuracy 70.71368831892947\n",
      "Training:: Epoch 71, Iteration 60, Current loss 1.8272710020676106 Accuracy 66.74848298902297\n",
      "Training:: Epoch 71, Iteration 70, Current loss 1.6038850241901377 Accuracy 65.87745147850828\n",
      "Training:: Epoch 71, Iteration 80, Current loss 1.2135042381046128 Accuracy 60.34874905231236\n",
      "Training:: Epoch 71, Iteration 90, Current loss 1.0050030933431002 Accuracy 74.08036589349885\n",
      "Training:: Epoch 71, Iteration 100, Current loss 0.9244057478148082 Accuracy 58.12360178970917\n",
      "Training:: Epoch 71, Iteration 110, Current loss 0.7248142110260163 Accuracy 70.01815331297962\n",
      "Training:: Epoch 71, Iteration 120, Current loss 0.9082684375577625 Accuracy 74.86484636967084\n",
      "Training:: Epoch 71, Iteration 130, Current loss 1.1529957809391105 Accuracy 57.28077945084145\n",
      "Training:: Epoch 71, Iteration 140, Current loss 1.0332848405195865 Accuracy 62.10392902408112\n",
      "Training:: Epoch 71, Iteration 150, Current loss 0.8262283096119181 Accuracy 63.561776061776065\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 71, Probability Accuracy 51.93209595227245\n",
      "Starting Training\n",
      "Training:: Epoch 72, Iteration 0, Current loss 0.7780285982449711 Accuracy 67.11267139166722\n",
      "Training:: Epoch 72, Iteration 10, Current loss 0.6727059253369275 Accuracy 71.34502923976608\n",
      "Training:: Epoch 72, Iteration 20, Current loss 0.7985032737789237 Accuracy 69.76846942382467\n",
      "Training:: Epoch 72, Iteration 30, Current loss 1.211186891796354 Accuracy 65.91832129963899\n",
      "Training:: Epoch 72, Iteration 40, Current loss 0.8068718574362069 Accuracy 67.71030993042378\n",
      "Training:: Epoch 72, Iteration 50, Current loss 0.9328560047697795 Accuracy 69.94279771190848\n",
      "Training:: Epoch 72, Iteration 60, Current loss 1.179078206932139 Accuracy 66.73523025939893\n",
      "Training:: Epoch 72, Iteration 70, Current loss 0.611717204561167 Accuracy 57.51198166284642\n",
      "Training:: Epoch 72, Iteration 80, Current loss 0.956825869603412 Accuracy 63.87252591894439\n",
      "Training:: Epoch 72, Iteration 90, Current loss 0.6592378341442362 Accuracy 64.73853091665944\n",
      "Training:: Epoch 72, Iteration 100, Current loss 0.5761292382921482 Accuracy 67.70145310435932\n",
      "Training:: Epoch 72, Iteration 110, Current loss 0.8452786214103916 Accuracy 64.76977729197978\n",
      "Training:: Epoch 72, Iteration 120, Current loss 1.0300930723828388 Accuracy 59.443247335624015\n",
      "Training:: Epoch 72, Iteration 130, Current loss 0.7451571591792034 Accuracy 52.9745889387145\n",
      "Training:: Epoch 72, Iteration 140, Current loss 0.6794531199752618 Accuracy 68.88053832037053\n",
      "Training:: Epoch 72, Iteration 150, Current loss 0.8807754335303123 Accuracy 51.26146788990825\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 72, Probability Accuracy 54.913514521274394\n",
      "Starting Training\n",
      "Training:: Epoch 73, Iteration 0, Current loss 0.84523417610713 Accuracy 62.841888347695765\n",
      "Training:: Epoch 73, Iteration 10, Current loss 0.7619383456408553 Accuracy 64.69596827495043\n",
      "Training:: Epoch 73, Iteration 20, Current loss 0.6046669812533471 Accuracy 63.656904492917356\n",
      "Training:: Epoch 73, Iteration 30, Current loss 0.5808911723190517 Accuracy 65.10225099308518\n",
      "Training:: Epoch 73, Iteration 40, Current loss 0.4270142923912838 Accuracy 71.78588944160303\n",
      "Training:: Epoch 73, Iteration 50, Current loss 0.8605792664812539 Accuracy 69.76677718074768\n",
      "Training:: Epoch 73, Iteration 60, Current loss 0.5804112936898751 Accuracy 63.6237988679742\n",
      "Training:: Epoch 73, Iteration 70, Current loss 0.6906302263635119 Accuracy 68.92869445401308\n",
      "Training:: Epoch 73, Iteration 80, Current loss 0.8011046867478128 Accuracy 52.765221273508566\n",
      "Training:: Epoch 73, Iteration 90, Current loss 0.7968229041579264 Accuracy 65.77499040061436\n",
      "Training:: Epoch 73, Iteration 100, Current loss 0.6999958429612274 Accuracy 66.05865720463491\n",
      "Training:: Epoch 73, Iteration 110, Current loss 0.8603481983225617 Accuracy 62.590757174138524\n",
      "Training:: Epoch 73, Iteration 120, Current loss 0.6632044071807819 Accuracy 69.95403808273146\n",
      "Training:: Epoch 73, Iteration 130, Current loss 0.6294336968124605 Accuracy 70.01051694846696\n",
      "Training:: Epoch 73, Iteration 140, Current loss 0.7381692703340679 Accuracy 60.42099792099792\n",
      "Training:: Epoch 73, Iteration 150, Current loss 0.986403125749076 Accuracy 75.93572778827978\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 73, Probability Accuracy 54.782491610390686\n",
      "Starting Training\n",
      "Training:: Epoch 74, Iteration 0, Current loss 0.9694149959624605 Accuracy 59.434900387477285\n",
      "Training:: Epoch 74, Iteration 10, Current loss 0.7258291290357787 Accuracy 68.62270450751252\n",
      "Training:: Epoch 74, Iteration 20, Current loss 0.6815979242623974 Accuracy 63.356973995271865\n",
      "Training:: Epoch 74, Iteration 30, Current loss 0.4744598936548354 Accuracy 64.02329426989719\n",
      "Training:: Epoch 74, Iteration 40, Current loss 0.6803803676059819 Accuracy 62.21240994654892\n",
      "Training:: Epoch 74, Iteration 50, Current loss 0.8832516587137733 Accuracy 59.01525658807212\n",
      "Training:: Epoch 74, Iteration 60, Current loss 0.6109774459319571 Accuracy 58.32466857291396\n",
      "Training:: Epoch 74, Iteration 70, Current loss 0.49482986058403877 Accuracy 63.55144640899776\n",
      "Training:: Epoch 74, Iteration 80, Current loss 0.5329026440245339 Accuracy 67.2711534299935\n",
      "Training:: Epoch 74, Iteration 90, Current loss 1.0643900631196928 Accuracy 68.75037711941108\n",
      "Training:: Epoch 74, Iteration 100, Current loss 0.6054521106272777 Accuracy 66.4925043205659\n",
      "Training:: Epoch 74, Iteration 110, Current loss 0.7378536901493105 Accuracy 60.298951322585694\n",
      "Training:: Epoch 74, Iteration 120, Current loss 0.6580349581589522 Accuracy 68.68890456515167\n",
      "Training:: Epoch 74, Iteration 130, Current loss 0.4317106083025664 Accuracy 56.36378347762764\n",
      "Training:: Epoch 74, Iteration 140, Current loss 0.5628671738222495 Accuracy 52.616703136396794\n",
      "Training:: Epoch 74, Iteration 150, Current loss 1.169112169230095 Accuracy 61.153095440668636\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 74, Probability Accuracy 54.980424244935165\n",
      "Starting Training\n",
      "Training:: Epoch 75, Iteration 0, Current loss 0.49497226271668676 Accuracy 67.1951144284745\n",
      "Training:: Epoch 75, Iteration 10, Current loss 0.5387422223955953 Accuracy 56.905169232833515\n",
      "Training:: Epoch 75, Iteration 20, Current loss 0.5531425404086439 Accuracy 60.48990400529626\n",
      "Training:: Epoch 75, Iteration 30, Current loss 0.7208424565393695 Accuracy 65.67247386759581\n",
      "Training:: Epoch 75, Iteration 40, Current loss 0.6991813754278389 Accuracy 63.43559821820691\n",
      "Training:: Epoch 75, Iteration 50, Current loss 0.5516018113560581 Accuracy 64.64735147790459\n",
      "Training:: Epoch 75, Iteration 60, Current loss 0.626909769531675 Accuracy 70.30545305453055\n",
      "Training:: Epoch 75, Iteration 70, Current loss 0.7298958933156007 Accuracy 73.16226672735549\n",
      "Training:: Epoch 75, Iteration 80, Current loss 0.5007877778996769 Accuracy 65.08185301288749\n",
      "Training:: Epoch 75, Iteration 90, Current loss 0.8465741233782912 Accuracy 67.37702627166014\n",
      "Training:: Epoch 75, Iteration 100, Current loss 0.5634148946515787 Accuracy 67.04348900420064\n",
      "Training:: Epoch 75, Iteration 110, Current loss 0.6355426178509934 Accuracy 56.776018099547514\n",
      "Training:: Epoch 75, Iteration 120, Current loss 0.46232010441323407 Accuracy 62.66032864811704\n",
      "Training:: Epoch 75, Iteration 130, Current loss 0.5203667736861685 Accuracy 69.13517626172965\n",
      "Training:: Epoch 75, Iteration 140, Current loss 0.656289249213329 Accuracy 65.21849271690944\n",
      "Training:: Epoch 75, Iteration 150, Current loss 0.6744892298314982 Accuracy 64.56174249077814\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 75, Probability Accuracy 54.709263785888886\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.06242747737294\n",
      "Calculating Expectation\n",
      "Epoch 75 iter 0\n",
      "Epoch 75 iter 10\n",
      "Epoch 75 iter 20\n",
      "Epoch 75 iter 30\n",
      "Epoch 75 iter 40\n",
      "Epoch 75 iter 50\n",
      "Epoch 75 iter 60\n",
      "Epoch 75 iter 70\n",
      "Epoch 75 iter 80\n",
      "Epoch 75 iter 90\n",
      "Epoch 75 iter 100\n",
      "Epoch 75 iter 110\n",
      "Epoch 75 iter 120\n",
      "Epoch 75 iter 130\n",
      "Epoch 75 iter 140\n",
      "Epoch 75 iter 150\n",
      "Train Boundary avergage error = 284.544\n",
      "Train From boundary avergage accuracy = 60.382\n",
      "Starting Training\n",
      "Training:: Epoch 76, Iteration 0, Current loss 0.6159304305017264 Accuracy 51.35705245394459\n",
      "Training:: Epoch 76, Iteration 10, Current loss 0.7708491105487004 Accuracy 64.86236052662059\n",
      "Training:: Epoch 76, Iteration 20, Current loss 0.6652503919778088 Accuracy 70.90261282660333\n",
      "Training:: Epoch 76, Iteration 30, Current loss 0.5783325171250628 Accuracy 61.17686005131176\n",
      "Training:: Epoch 76, Iteration 40, Current loss 0.8297212280282457 Accuracy 55.58154178285508\n",
      "Training:: Epoch 76, Iteration 50, Current loss 0.62764611680086 Accuracy 70.43057996485061\n",
      "Training:: Epoch 76, Iteration 60, Current loss 0.8840587032900245 Accuracy 71.20658845466552\n",
      "Training:: Epoch 76, Iteration 70, Current loss 0.6807818763930539 Accuracy 65.56190816508844\n",
      "Training:: Epoch 76, Iteration 80, Current loss 0.49323804199571536 Accuracy 60.46632393415381\n",
      "Training:: Epoch 76, Iteration 90, Current loss 0.6423081831128408 Accuracy 55.05600127095083\n",
      "Training:: Epoch 76, Iteration 100, Current loss 0.7845198903334542 Accuracy 61.043400713436384\n",
      "Training:: Epoch 76, Iteration 110, Current loss 0.6862712044866673 Accuracy 67.59461788294558\n",
      "Training:: Epoch 76, Iteration 120, Current loss 0.6320127269796478 Accuracy 47.40773286467487\n",
      "Training:: Epoch 76, Iteration 130, Current loss 0.9291781334225865 Accuracy 67.51954038345914\n",
      "Training:: Epoch 76, Iteration 140, Current loss 0.5753164996863489 Accuracy 58.89220894200974\n",
      "Training:: Epoch 76, Iteration 150, Current loss 0.5086932743049517 Accuracy 70.88892220056962\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 76, Probability Accuracy 55.103264697352614\n",
      "Starting Training\n",
      "Training:: Epoch 77, Iteration 0, Current loss 0.42035562172440505 Accuracy 69.20470400637831\n",
      "Training:: Epoch 77, Iteration 10, Current loss 0.5567064963619912 Accuracy 59.33616742969261\n",
      "Training:: Epoch 77, Iteration 20, Current loss 0.6311360459113262 Accuracy 67.11550599621292\n",
      "Training:: Epoch 77, Iteration 30, Current loss 0.33038874129690543 Accuracy 60.283882282018965\n",
      "Training:: Epoch 77, Iteration 40, Current loss 0.5199196127749852 Accuracy 58.97727272727273\n",
      "Training:: Epoch 77, Iteration 50, Current loss 0.6889580546713424 Accuracy 59.261120884644384\n",
      "Training:: Epoch 77, Iteration 60, Current loss 0.5827198976960445 Accuracy 67.78964667214461\n",
      "Training:: Epoch 77, Iteration 70, Current loss 0.415988844742603 Accuracy 63.40309372156506\n",
      "Training:: Epoch 77, Iteration 80, Current loss 0.45482240053021 Accuracy 59.36592143488695\n",
      "Training:: Epoch 77, Iteration 90, Current loss 0.48611262804004296 Accuracy 64.38170830702624\n",
      "Training:: Epoch 77, Iteration 100, Current loss 0.5891470058187378 Accuracy 57.17183770883055\n",
      "Training:: Epoch 77, Iteration 110, Current loss 0.38790136449849305 Accuracy 66.83506044905009\n",
      "Training:: Epoch 77, Iteration 120, Current loss 0.5526652248819722 Accuracy 60.294914886696304\n",
      "Training:: Epoch 77, Iteration 130, Current loss 0.6106206238078449 Accuracy 49.731876861966235\n",
      "Training:: Epoch 77, Iteration 140, Current loss 0.5666763553145664 Accuracy 58.3999504244903\n",
      "Training:: Epoch 77, Iteration 150, Current loss 0.5855442419823437 Accuracy 70.51225678795207\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 77, Probability Accuracy 55.032522683017774\n",
      "Starting Training\n",
      "Training:: Epoch 78, Iteration 0, Current loss 0.5794965479745374 Accuracy 68.08352980801617\n",
      "Training:: Epoch 78, Iteration 10, Current loss 0.5367735155354768 Accuracy 66.02746212121212\n",
      "Training:: Epoch 78, Iteration 20, Current loss 0.586528753062884 Accuracy 67.84589544404787\n",
      "Training:: Epoch 78, Iteration 30, Current loss 0.5472164216357426 Accuracy 69.71555399801413\n",
      "Training:: Epoch 78, Iteration 40, Current loss 0.4632090628113242 Accuracy 65.61764076214943\n",
      "Training:: Epoch 78, Iteration 50, Current loss 0.4329291624829994 Accuracy 68.1573042554029\n",
      "Training:: Epoch 78, Iteration 60, Current loss 0.5327320989620744 Accuracy 58.19857089131252\n",
      "Training:: Epoch 78, Iteration 70, Current loss 0.5084900317574685 Accuracy 63.228161408070406\n",
      "Training:: Epoch 78, Iteration 80, Current loss 0.7547015159231997 Accuracy 62.249553659988095\n",
      "Training:: Epoch 78, Iteration 90, Current loss 0.43949280853064887 Accuracy 67.34366648850882\n",
      "Training:: Epoch 78, Iteration 100, Current loss 0.429492416712588 Accuracy 76.49400567401848\n",
      "Training:: Epoch 78, Iteration 110, Current loss 0.46480961359054057 Accuracy 64.01282253402701\n",
      "Training:: Epoch 78, Iteration 120, Current loss 0.5204132324553019 Accuracy 71.8718618196425\n",
      "Training:: Epoch 78, Iteration 130, Current loss 0.5974561501652891 Accuracy 60.22076120393269\n",
      "Training:: Epoch 78, Iteration 140, Current loss 0.5976509382985845 Accuracy 63.34944555018482\n",
      "Training:: Epoch 78, Iteration 150, Current loss 0.44549404621741084 Accuracy 57.212368544969394\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 78, Probability Accuracy 53.11969175953929\n",
      "Starting Training\n",
      "Training:: Epoch 79, Iteration 0, Current loss 0.6424422052651936 Accuracy 63.59372844728493\n",
      "Training:: Epoch 79, Iteration 10, Current loss 0.5651122018017181 Accuracy 57.458250778375316\n",
      "Training:: Epoch 79, Iteration 20, Current loss 0.48079784044990276 Accuracy 54.44835634320978\n",
      "Training:: Epoch 79, Iteration 30, Current loss 0.49814042537312353 Accuracy 65.19941424756654\n",
      "Training:: Epoch 79, Iteration 40, Current loss 0.38719083118245123 Accuracy 61.1036733327755\n",
      "Training:: Epoch 79, Iteration 50, Current loss 0.33418980476677157 Accuracy 70.01082153485436\n",
      "Training:: Epoch 79, Iteration 60, Current loss 0.45485248744345025 Accuracy 56.849279967201355\n",
      "Training:: Epoch 79, Iteration 70, Current loss 0.49312361996419507 Accuracy 63.78703128237\n",
      "Training:: Epoch 79, Iteration 80, Current loss 0.38903794223668203 Accuracy 64.25992779783394\n",
      "Training:: Epoch 79, Iteration 90, Current loss 0.40905709872990914 Accuracy 66.8394572343345\n",
      "Training:: Epoch 79, Iteration 100, Current loss 0.4394685903747203 Accuracy 64.95980426424327\n",
      "Training:: Epoch 79, Iteration 110, Current loss 0.3564613407937155 Accuracy 69.13791872009142\n",
      "Training:: Epoch 79, Iteration 120, Current loss 0.498245169792801 Accuracy 67.97366352201257\n",
      "Training:: Epoch 79, Iteration 130, Current loss 0.4097344077312328 Accuracy 61.76991976114947\n",
      "Training:: Epoch 79, Iteration 140, Current loss 0.43993305263611815 Accuracy 59.943818092092776\n",
      "Training:: Epoch 79, Iteration 150, Current loss 0.43846349637147447 Accuracy 61.317189249720045\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 79, Probability Accuracy 54.876020217922694\n",
      "Starting Training\n",
      "Training:: Epoch 80, Iteration 0, Current loss 0.44718079323339244 Accuracy 61.387736284001846\n",
      "Training:: Epoch 80, Iteration 10, Current loss 0.29562525929326666 Accuracy 53.79622641509434\n",
      "Training:: Epoch 80, Iteration 20, Current loss 0.376989445850042 Accuracy 57.89187720728063\n",
      "Training:: Epoch 80, Iteration 30, Current loss 0.41568921729374264 Accuracy 60.15357649611885\n",
      "Training:: Epoch 80, Iteration 40, Current loss 0.6044737962565492 Accuracy 65.1531952144733\n",
      "Training:: Epoch 80, Iteration 50, Current loss 0.35494047569188525 Accuracy 68.076161020635\n",
      "Training:: Epoch 80, Iteration 60, Current loss 0.3992253689830284 Accuracy 62.24515012974175\n",
      "Training:: Epoch 80, Iteration 70, Current loss 0.42466097355343707 Accuracy 64.46532672061255\n",
      "Training:: Epoch 80, Iteration 80, Current loss 0.4616793492046326 Accuracy 59.292769984228435\n",
      "Training:: Epoch 80, Iteration 90, Current loss 0.4522338817170967 Accuracy 60.58063737324964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 80, Iteration 100, Current loss 0.5027113806873797 Accuracy 69.03686673782741\n",
      "Training:: Epoch 80, Iteration 110, Current loss 0.700585669525337 Accuracy 53.193257359924026\n",
      "Training:: Epoch 80, Iteration 120, Current loss 0.5243151323637433 Accuracy 69.88748241912799\n",
      "Training:: Epoch 80, Iteration 130, Current loss 0.46741881958805676 Accuracy 53.513710770514024\n",
      "Training:: Epoch 80, Iteration 140, Current loss 0.5029759276717569 Accuracy 63.207864790249815\n",
      "Training:: Epoch 80, Iteration 150, Current loss 0.42539789357325736 Accuracy 60.47781029981805\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 80, Probability Accuracy 55.074263578738034\n",
      "Calculating Expectation\n",
      "Epoch 80 iter 0\n",
      "Epoch 80 iter 10\n",
      "Epoch 80 iter 20\n",
      "Epoch 80 iter 30\n",
      "Epoch 80 iter 40\n",
      "Epoch 80 iter 50\n",
      "Epoch 80 iter 60\n",
      "Epoch 80 iter 70\n",
      "Epoch 80 iter 80\n",
      "Epoch 80 iter 90\n",
      "Epoch 80 iter 100\n",
      "Epoch 80 iter 110\n",
      "Epoch 80 iter 120\n",
      "Epoch 80 iter 130\n",
      "Epoch 80 iter 140\n",
      "Epoch 80 iter 150\n",
      "Train Boundary avergage error = 284.278\n",
      "Train From boundary avergage accuracy = 60.407\n",
      "Starting Training\n",
      "Training:: Epoch 81, Iteration 0, Current loss 0.4013566679916227 Accuracy 63.70311793944871\n",
      "Training:: Epoch 81, Iteration 10, Current loss 0.3875483066727251 Accuracy 68.09714156422054\n",
      "Training:: Epoch 81, Iteration 20, Current loss 0.3056599948067516 Accuracy 60.842422502870264\n",
      "Training:: Epoch 81, Iteration 30, Current loss 0.2832353590815605 Accuracy 66.40538370359042\n",
      "Training:: Epoch 81, Iteration 40, Current loss 0.6864728153994579 Accuracy 59.72566949706074\n",
      "Training:: Epoch 81, Iteration 50, Current loss 0.37515222128311293 Accuracy 51.61094894531035\n",
      "Training:: Epoch 81, Iteration 60, Current loss 0.29951618476717323 Accuracy 60.65094620033687\n",
      "Training:: Epoch 81, Iteration 70, Current loss 0.3668869047872904 Accuracy 62.08192016697104\n",
      "Training:: Epoch 81, Iteration 80, Current loss 0.3175289543853943 Accuracy 70.18479292966182\n",
      "Training:: Epoch 81, Iteration 90, Current loss 0.3509757460193128 Accuracy 76.06484978790168\n",
      "Training:: Epoch 81, Iteration 100, Current loss 0.32919018179199605 Accuracy 67.99367399247423\n",
      "Training:: Epoch 81, Iteration 110, Current loss 0.4143993414698096 Accuracy 72.2994560055263\n",
      "Training:: Epoch 81, Iteration 120, Current loss 0.3172125483759369 Accuracy 66.66984278227727\n",
      "Training:: Epoch 81, Iteration 130, Current loss 0.3907010359568729 Accuracy 58.638956805215976\n",
      "Training:: Epoch 81, Iteration 140, Current loss 0.2809859780592775 Accuracy 62.616362517941354\n",
      "Training:: Epoch 81, Iteration 150, Current loss 0.35906606703545413 Accuracy 68.24783019678611\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 81, Probability Accuracy 54.28356879479637\n",
      "Starting Training\n",
      "Training:: Epoch 82, Iteration 0, Current loss 0.3493021416718282 Accuracy 70.86666225953593\n",
      "Training:: Epoch 82, Iteration 10, Current loss 0.33928241602749465 Accuracy 60.321348800345845\n",
      "Training:: Epoch 82, Iteration 20, Current loss 0.4533622961127507 Accuracy 62.43223852040816\n",
      "Training:: Epoch 82, Iteration 30, Current loss 0.5720533506939555 Accuracy 68.72888267505535\n",
      "Training:: Epoch 82, Iteration 40, Current loss 0.2877951355770576 Accuracy 65.1829400303096\n",
      "Training:: Epoch 82, Iteration 50, Current loss 0.4827270360615602 Accuracy 61.36536167443878\n",
      "Training:: Epoch 82, Iteration 60, Current loss 0.47977881083404567 Accuracy 57.728602434651314\n",
      "Training:: Epoch 82, Iteration 70, Current loss 0.5873108513784208 Accuracy 67.82405605293889\n",
      "Training:: Epoch 82, Iteration 80, Current loss 0.602601109010888 Accuracy 53.27160493827161\n",
      "Training:: Epoch 82, Iteration 90, Current loss 0.4285447346976831 Accuracy 69.60673362568963\n",
      "Training:: Epoch 82, Iteration 100, Current loss 0.3650821898093435 Accuracy 60.945231189216855\n",
      "Training:: Epoch 82, Iteration 110, Current loss 0.4270114282755926 Accuracy 61.848838184716044\n",
      "Training:: Epoch 82, Iteration 120, Current loss 0.3712742101769212 Accuracy 65.7396073054889\n",
      "Training:: Epoch 82, Iteration 130, Current loss 0.42609630634260975 Accuracy 41.38131473261467\n",
      "Training:: Epoch 82, Iteration 140, Current loss 0.3669460725019572 Accuracy 62.786956252707135\n",
      "Training:: Epoch 82, Iteration 150, Current loss 0.32183881902975703 Accuracy 74.05832320777643\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 82, Probability Accuracy 53.89485022993744\n",
      "Starting Training\n",
      "Training:: Epoch 83, Iteration 0, Current loss 0.35466454499240607 Accuracy 58.824503311258276\n",
      "Training:: Epoch 83, Iteration 10, Current loss 0.3281755894746545 Accuracy 62.21001221001221\n",
      "Training:: Epoch 83, Iteration 20, Current loss 0.3588069323869222 Accuracy 58.482479003764844\n",
      "Training:: Epoch 83, Iteration 30, Current loss 0.6249047113102559 Accuracy 63.04563492063492\n",
      "Training:: Epoch 83, Iteration 40, Current loss 0.5755917579624457 Accuracy 62.24841024444315\n",
      "Training:: Epoch 83, Iteration 50, Current loss 0.5235744524637639 Accuracy 67.05350414468727\n",
      "Training:: Epoch 83, Iteration 60, Current loss 0.5470403859256239 Accuracy 62.943678498093284\n",
      "Training:: Epoch 83, Iteration 70, Current loss 0.45871978408589864 Accuracy 64.97713234947427\n",
      "Training:: Epoch 83, Iteration 80, Current loss 0.8269279843393366 Accuracy 50.06018778589198\n",
      "Training:: Epoch 83, Iteration 90, Current loss 0.6452620018589165 Accuracy 56.91971672513072\n",
      "Training:: Epoch 83, Iteration 100, Current loss 0.814430167900828 Accuracy 49.10387231815803\n",
      "Training:: Epoch 83, Iteration 110, Current loss 0.6481942105684576 Accuracy 70.5506573042606\n",
      "Training:: Epoch 83, Iteration 120, Current loss 0.5422127273881298 Accuracy 66.99361578641904\n",
      "Training:: Epoch 83, Iteration 130, Current loss 0.8018304498047029 Accuracy 66.85865576664034\n",
      "Training:: Epoch 83, Iteration 140, Current loss 0.6177334828817748 Accuracy 62.50321916044296\n",
      "Training:: Epoch 83, Iteration 150, Current loss 0.5966565650628401 Accuracy 62.32879828912044\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 83, Probability Accuracy 52.884886274184865\n",
      "Starting Training\n",
      "Training:: Epoch 84, Iteration 0, Current loss 0.4337065627751697 Accuracy 69.93559110741741\n",
      "Training:: Epoch 84, Iteration 10, Current loss 0.5047990051886245 Accuracy 60.81273456710237\n",
      "Training:: Epoch 84, Iteration 20, Current loss 0.4108659617516726 Accuracy 60.53609861083937\n",
      "Training:: Epoch 84, Iteration 30, Current loss 0.36145267588384566 Accuracy 68.74981400470196\n",
      "Training:: Epoch 84, Iteration 40, Current loss 0.3088977578749152 Accuracy 69.02461523522844\n",
      "Training:: Epoch 84, Iteration 50, Current loss 0.3589620126786261 Accuracy 62.5902552731821\n",
      "Training:: Epoch 84, Iteration 60, Current loss 0.3522161686281646 Accuracy 67.47754491017965\n",
      "Training:: Epoch 84, Iteration 70, Current loss 0.6693648284605518 Accuracy 56.812886906742996\n",
      "Training:: Epoch 84, Iteration 80, Current loss 0.6036942771373894 Accuracy 58.62853144406542\n",
      "Training:: Epoch 84, Iteration 90, Current loss 0.512404562093594 Accuracy 74.76635514018692\n",
      "Training:: Epoch 84, Iteration 100, Current loss 0.5800961430540408 Accuracy 55.94981858434291\n",
      "Training:: Epoch 84, Iteration 110, Current loss 0.4580800925217462 Accuracy 59.417769030072776\n",
      "Training:: Epoch 84, Iteration 120, Current loss 0.43920859178461613 Accuracy 65.44395465994963\n",
      "Training:: Epoch 84, Iteration 130, Current loss 1.117897048808689 Accuracy 63.04668935842271\n",
      "Training:: Epoch 84, Iteration 140, Current loss 0.5102261292768401 Accuracy 54.84362528118424\n",
      "Training:: Epoch 84, Iteration 150, Current loss 0.47343226495002644 Accuracy 66.05150966536237\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 84, Probability Accuracy 54.31629862866139\n",
      "Starting Training\n",
      "Training:: Epoch 85, Iteration 0, Current loss 0.504046303089468 Accuracy 64.60498629088822\n",
      "Training:: Epoch 85, Iteration 10, Current loss 0.40707887890675537 Accuracy 64.87435328898744\n",
      "Training:: Epoch 85, Iteration 20, Current loss 0.3490357042671303 Accuracy 70.32471763683753\n",
      "Training:: Epoch 85, Iteration 30, Current loss 0.3247139054952668 Accuracy 77.34219591480277\n",
      "Training:: Epoch 85, Iteration 40, Current loss 0.4530413754108074 Accuracy 60.43725666367176\n",
      "Training:: Epoch 85, Iteration 50, Current loss 0.428181543446603 Accuracy 65.16277037360716\n",
      "Training:: Epoch 85, Iteration 60, Current loss 0.3322402559814754 Accuracy 64.07887586367518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 85, Iteration 70, Current loss 0.45740793882524594 Accuracy 47.755786648775576\n",
      "Training:: Epoch 85, Iteration 80, Current loss 0.3960061901739247 Accuracy 58.97035881435257\n",
      "Training:: Epoch 85, Iteration 90, Current loss 0.34145713550447493 Accuracy 63.49041349041349\n",
      "Training:: Epoch 85, Iteration 100, Current loss 0.38020000653610136 Accuracy 59.317539915845295\n",
      "Training:: Epoch 85, Iteration 110, Current loss 0.3833300662701826 Accuracy 54.09185803757829\n",
      "Training:: Epoch 85, Iteration 120, Current loss 0.4516252113898742 Accuracy 71.68159818762228\n",
      "Training:: Epoch 85, Iteration 130, Current loss 0.38309450409912643 Accuracy 62.468953480566555\n",
      "Training:: Epoch 85, Iteration 140, Current loss 0.4169663443723386 Accuracy 63.983050847457626\n",
      "Training:: Epoch 85, Iteration 150, Current loss 0.4850845158954535 Accuracy 64.26457341397503\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 85, Probability Accuracy 53.89485022993744\n",
      "Calculating Expectation\n",
      "Epoch 85 iter 0\n",
      "Epoch 85 iter 10\n",
      "Epoch 85 iter 20\n",
      "Epoch 85 iter 30\n",
      "Epoch 85 iter 40\n",
      "Epoch 85 iter 50\n",
      "Epoch 85 iter 60\n",
      "Epoch 85 iter 70\n",
      "Epoch 85 iter 80\n",
      "Epoch 85 iter 90\n",
      "Epoch 85 iter 100\n",
      "Epoch 85 iter 110\n",
      "Epoch 85 iter 120\n",
      "Epoch 85 iter 130\n",
      "Epoch 85 iter 140\n",
      "Epoch 85 iter 150\n",
      "Train Boundary avergage error = 284.329\n",
      "Train From boundary avergage accuracy = 60.522\n",
      "Starting Training\n",
      "Training:: Epoch 86, Iteration 0, Current loss 0.2875508944816946 Accuracy 63.34154517184282\n",
      "Training:: Epoch 86, Iteration 10, Current loss 0.449479740852999 Accuracy 73.63321093431253\n",
      "Training:: Epoch 86, Iteration 20, Current loss 0.3620513091879758 Accuracy 59.817656215254615\n",
      "Training:: Epoch 86, Iteration 30, Current loss 0.3785580089477686 Accuracy 63.4167968585061\n",
      "Training:: Epoch 86, Iteration 40, Current loss 0.44532063077149536 Accuracy 68.75981161695448\n",
      "Training:: Epoch 86, Iteration 50, Current loss 0.5735166503890312 Accuracy 41.109685062691284\n",
      "Training:: Epoch 86, Iteration 60, Current loss 0.5606471034877485 Accuracy 64.85803016858918\n",
      "Training:: Epoch 86, Iteration 70, Current loss 0.5543970623339745 Accuracy 72.08427389014297\n",
      "Training:: Epoch 86, Iteration 80, Current loss 0.5227513579834892 Accuracy 67.24885262621112\n",
      "Training:: Epoch 86, Iteration 90, Current loss 0.5057021358124117 Accuracy 58.14714788444226\n",
      "Training:: Epoch 86, Iteration 100, Current loss 0.7075987486270336 Accuracy 55.31653020816611\n",
      "Training:: Epoch 86, Iteration 110, Current loss 0.8510391121691705 Accuracy 75.78209620898376\n",
      "Training:: Epoch 86, Iteration 120, Current loss 0.5216786258657579 Accuracy 68.84613294200771\n",
      "Training:: Epoch 86, Iteration 130, Current loss 0.4837395278266078 Accuracy 75.49443757725587\n",
      "Training:: Epoch 86, Iteration 140, Current loss 0.5578527818304336 Accuracy 59.49033828423824\n",
      "Training:: Epoch 86, Iteration 150, Current loss 0.5140135484688623 Accuracy 57.12055222286137\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 86, Probability Accuracy 51.32421179102622\n",
      "Starting Training\n",
      "Training:: Epoch 87, Iteration 0, Current loss 1.2391120994849538 Accuracy 60.04371836171192\n",
      "Training:: Epoch 87, Iteration 10, Current loss 1.2019438558885631 Accuracy 59.15977961432507\n",
      "Training:: Epoch 87, Iteration 20, Current loss 1.2751174068431308 Accuracy 59.88209742475954\n",
      "Training:: Epoch 87, Iteration 30, Current loss 1.137282910354747 Accuracy 59.33887868639948\n",
      "Training:: Epoch 87, Iteration 40, Current loss 1.101682271091539 Accuracy 64.04776626990261\n",
      "Training:: Epoch 87, Iteration 50, Current loss 1.010232339031004 Accuracy 53.797127468581685\n",
      "Training:: Epoch 87, Iteration 60, Current loss 0.9282862606523367 Accuracy 58.85196905766526\n",
      "Training:: Epoch 87, Iteration 70, Current loss 0.7659825023238469 Accuracy 66.19236311239193\n",
      "Training:: Epoch 87, Iteration 80, Current loss 0.5739731752348309 Accuracy 67.73726851851852\n",
      "Training:: Epoch 87, Iteration 90, Current loss 0.9327560809674464 Accuracy 59.7469220246238\n",
      "Training:: Epoch 87, Iteration 100, Current loss 0.8773417397228735 Accuracy 69.68235375180872\n",
      "Training:: Epoch 87, Iteration 110, Current loss 0.6085357165059357 Accuracy 65.83173996175908\n",
      "Training:: Epoch 87, Iteration 120, Current loss 0.697342753840398 Accuracy 63.23504519448864\n",
      "Training:: Epoch 87, Iteration 130, Current loss 1.3866740475452404 Accuracy 67.84765279007972\n",
      "Training:: Epoch 87, Iteration 140, Current loss 0.6598900802606669 Accuracy 73.31457310501736\n",
      "Training:: Epoch 87, Iteration 150, Current loss 1.2050182671334237 Accuracy 72.33939393939394\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 87, Probability Accuracy 45.767286738202756\n",
      "Starting Training\n",
      "Training:: Epoch 88, Iteration 0, Current loss 4.618500849034433 Accuracy 56.99306709448232\n",
      "Training:: Epoch 88, Iteration 10, Current loss 2.0679430583154814 Accuracy 57.89775990809879\n",
      "Training:: Epoch 88, Iteration 20, Current loss 3.025456671110101 Accuracy 59.86269009301639\n",
      "Training:: Epoch 88, Iteration 30, Current loss 1.3903536270483934 Accuracy 61.33376956213534\n",
      "Training:: Epoch 88, Iteration 40, Current loss 1.149682687571243 Accuracy 70.51729873586162\n",
      "Training:: Epoch 88, Iteration 50, Current loss 0.9433352692188802 Accuracy 60.058968058968055\n",
      "Training:: Epoch 88, Iteration 60, Current loss 3.1956134729277963 Accuracy 50.396206401697135\n",
      "Training:: Epoch 88, Iteration 70, Current loss 0.7981694187309606 Accuracy 59.63630588422139\n",
      "Training:: Epoch 88, Iteration 80, Current loss 2.501772859104839 Accuracy 58.106055603249025\n",
      "Training:: Epoch 88, Iteration 90, Current loss 0.8475899187409216 Accuracy 59.455419113721305\n",
      "Training:: Epoch 88, Iteration 100, Current loss 5.759961353566996 Accuracy 49.318157977551664\n",
      "Training:: Epoch 88, Iteration 110, Current loss 1.3438909275695208 Accuracy 69.93244909028155\n",
      "Training:: Epoch 88, Iteration 120, Current loss 7.973720286729112 Accuracy 40.72473688713956\n",
      "Training:: Epoch 88, Iteration 130, Current loss 1.8725764291728955 Accuracy 55.81831831831832\n",
      "Training:: Epoch 88, Iteration 140, Current loss 2.0989241238110523 Accuracy 53.31612903225806\n",
      "Training:: Epoch 88, Iteration 150, Current loss 2.207239205440449 Accuracy 54.495097415000636\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 88, Probability Accuracy 48.41550316940796\n",
      "Starting Training\n",
      "Training:: Epoch 89, Iteration 0, Current loss 2.0678129169007162 Accuracy 54.65677904083525\n",
      "Training:: Epoch 89, Iteration 10, Current loss 0.8171396965574172 Accuracy 71.51021452637865\n",
      "Training:: Epoch 89, Iteration 20, Current loss 0.7250236521282626 Accuracy 60.894848135332566\n",
      "Training:: Epoch 89, Iteration 30, Current loss 0.9924107228596111 Accuracy 50.21614837540092\n",
      "Training:: Epoch 89, Iteration 40, Current loss 0.7109144330718244 Accuracy 61.466149913416345\n",
      "Training:: Epoch 89, Iteration 50, Current loss 0.711495288989805 Accuracy 70.48784414748027\n",
      "Training:: Epoch 89, Iteration 60, Current loss 0.5146888819960503 Accuracy 67.13415680219592\n",
      "Training:: Epoch 89, Iteration 70, Current loss 0.7050747911942764 Accuracy 66.22103030060441\n",
      "Training:: Epoch 89, Iteration 80, Current loss 0.576886389051151 Accuracy 62.58026159334126\n",
      "Training:: Epoch 89, Iteration 90, Current loss 0.7143914969373121 Accuracy 60.94845891512772\n",
      "Training:: Epoch 89, Iteration 100, Current loss 0.4625698351290275 Accuracy 69.85925163062136\n",
      "Training:: Epoch 89, Iteration 110, Current loss 0.6276154907043852 Accuracy 60.14968814968815\n",
      "Training:: Epoch 89, Iteration 120, Current loss 0.5359807937626884 Accuracy 64.67706587598299\n",
      "Training:: Epoch 89, Iteration 130, Current loss 0.4853199385049303 Accuracy 68.77488340348083\n",
      "Training:: Epoch 89, Iteration 140, Current loss 0.5944359522775899 Accuracy 56.23163353500432\n",
      "Training:: Epoch 89, Iteration 150, Current loss 0.6474540009211345 Accuracy 68.77945116880717\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 89, Probability Accuracy 56.84105315490741\n",
      "Starting Training\n",
      "Training:: Epoch 90, Iteration 0, Current loss 0.47651483095603764 Accuracy 63.312780269058294\n",
      "Training:: Epoch 90, Iteration 10, Current loss 0.4734172108172887 Accuracy 53.262518968133534\n",
      "Training:: Epoch 90, Iteration 20, Current loss 0.44991531371762117 Accuracy 68.53218299466455\n",
      "Training:: Epoch 90, Iteration 30, Current loss 0.38532592320720216 Accuracy 74.23857371857528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 90, Iteration 40, Current loss 0.533905750262825 Accuracy 64.76745334254962\n",
      "Training:: Epoch 90, Iteration 50, Current loss 0.27560338704280807 Accuracy 65.90374250360586\n",
      "Training:: Epoch 90, Iteration 60, Current loss 0.5664990172395233 Accuracy 69.21257773495664\n",
      "Training:: Epoch 90, Iteration 70, Current loss 0.7778380703858879 Accuracy 48.49646342909077\n",
      "Training:: Epoch 90, Iteration 80, Current loss 0.3159685275837333 Accuracy 57.70971914264597\n",
      "Training:: Epoch 90, Iteration 90, Current loss 0.4696166839076369 Accuracy 60.82651519099484\n",
      "Training:: Epoch 90, Iteration 100, Current loss 0.4897836668495078 Accuracy 66.60164224470354\n",
      "Training:: Epoch 90, Iteration 110, Current loss 0.3625245272546638 Accuracy 61.516754850088184\n",
      "Training:: Epoch 90, Iteration 120, Current loss 0.36870526100118395 Accuracy 58.25337058180493\n",
      "Training:: Epoch 90, Iteration 130, Current loss 0.4260469673975278 Accuracy 69.07355978067365\n",
      "Training:: Epoch 90, Iteration 140, Current loss 0.4223996542529458 Accuracy 63.11763489766384\n",
      "Training:: Epoch 90, Iteration 150, Current loss 0.3300466617757361 Accuracy 57.14072674852115\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 90, Probability Accuracy 56.87481874300866\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.201670921327455\n",
      "Calculating Expectation\n",
      "Epoch 90 iter 0\n",
      "Epoch 90 iter 10\n",
      "Epoch 90 iter 20\n",
      "Epoch 90 iter 30\n",
      "Epoch 90 iter 40\n",
      "Epoch 90 iter 50\n",
      "Epoch 90 iter 60\n",
      "Epoch 90 iter 70\n",
      "Epoch 90 iter 80\n",
      "Epoch 90 iter 90\n",
      "Epoch 90 iter 100\n",
      "Epoch 90 iter 110\n",
      "Epoch 90 iter 120\n",
      "Epoch 90 iter 130\n",
      "Epoch 90 iter 140\n",
      "Epoch 90 iter 150\n",
      "Train Boundary avergage error = 283.919\n",
      "Train From boundary avergage accuracy = 60.693\n",
      "Starting Training\n",
      "Training:: Epoch 91, Iteration 0, Current loss 0.2771188438234409 Accuracy 67.4720472946922\n",
      "Training:: Epoch 91, Iteration 10, Current loss 0.29603804477782775 Accuracy 62.05048201928077\n",
      "Training:: Epoch 91, Iteration 20, Current loss 0.27627843059122625 Accuracy 66.02658788774004\n",
      "Training:: Epoch 91, Iteration 30, Current loss 0.3698187426147691 Accuracy 57.47402524857558\n",
      "Training:: Epoch 91, Iteration 40, Current loss 0.41618783973263335 Accuracy 63.467799009200284\n",
      "Training:: Epoch 91, Iteration 50, Current loss 0.4746156531250453 Accuracy 50.298294260986474\n",
      "Training:: Epoch 91, Iteration 60, Current loss 0.34505867739595664 Accuracy 54.58428246013668\n",
      "Training:: Epoch 91, Iteration 70, Current loss 0.4106573619986871 Accuracy 62.57461344839986\n",
      "Training:: Epoch 91, Iteration 80, Current loss 0.308428416881593 Accuracy 61.019262854542696\n",
      "Training:: Epoch 91, Iteration 90, Current loss 0.32311365646011825 Accuracy 58.04887061758049\n",
      "Training:: Epoch 91, Iteration 100, Current loss 0.3628598827331932 Accuracy 59.92248497444251\n",
      "Training:: Epoch 91, Iteration 110, Current loss 0.39537106782448317 Accuracy 67.67657275183326\n",
      "Training:: Epoch 91, Iteration 120, Current loss 0.35924326820477354 Accuracy 64.69075178300012\n",
      "Training:: Epoch 91, Iteration 130, Current loss 0.3793198054921071 Accuracy 68.65432098765432\n",
      "Training:: Epoch 91, Iteration 140, Current loss 0.4522376989782575 Accuracy 53.41640879819353\n",
      "Training:: Epoch 91, Iteration 150, Current loss 0.37573793346527545 Accuracy 70.81887398352929\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 91, Probability Accuracy 56.10815345734764\n",
      "Starting Training\n",
      "Training:: Epoch 92, Iteration 0, Current loss 0.26428343681197997 Accuracy 60.36648061104583\n",
      "Training:: Epoch 92, Iteration 10, Current loss 0.32038074754338386 Accuracy 71.08453121647715\n",
      "Training:: Epoch 92, Iteration 20, Current loss 0.3407265575528039 Accuracy 57.382310984308134\n",
      "Training:: Epoch 92, Iteration 30, Current loss 0.3717725699168795 Accuracy 65.05562972852692\n",
      "Training:: Epoch 92, Iteration 40, Current loss 0.3011178087856345 Accuracy 66.85079519242443\n",
      "Training:: Epoch 92, Iteration 50, Current loss 0.45551142350397117 Accuracy 54.164852255054434\n",
      "Training:: Epoch 92, Iteration 60, Current loss 0.33041047439226245 Accuracy 64.49621251426792\n",
      "Training:: Epoch 92, Iteration 70, Current loss 0.2905099109231201 Accuracy 60.77154847734854\n",
      "Training:: Epoch 92, Iteration 80, Current loss 0.2627378848182665 Accuracy 69.62439903846153\n",
      "Training:: Epoch 92, Iteration 90, Current loss 0.34558118286117767 Accuracy 65.18399297680884\n",
      "Training:: Epoch 92, Iteration 100, Current loss 0.35553327719625283 Accuracy 66.71388101983003\n",
      "Training:: Epoch 92, Iteration 110, Current loss 0.44613889466387485 Accuracy 57.38011210296865\n",
      "Training:: Epoch 92, Iteration 120, Current loss 0.35423781783892505 Accuracy 62.899866091355456\n",
      "Training:: Epoch 92, Iteration 130, Current loss 0.31781194740955143 Accuracy 58.28463117990839\n",
      "Training:: Epoch 92, Iteration 140, Current loss 0.3887635237922003 Accuracy 71.66762537258798\n",
      "Training:: Epoch 92, Iteration 150, Current loss 0.4251978012993147 Accuracy 61.28357896937389\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 92, Probability Accuracy 56.45699548411153\n",
      "Starting Training\n",
      "Training:: Epoch 93, Iteration 0, Current loss 0.28965575180426345 Accuracy 68.41163310961969\n",
      "Training:: Epoch 93, Iteration 10, Current loss 0.2940322436068251 Accuracy 71.44512497930806\n",
      "Training:: Epoch 93, Iteration 20, Current loss 0.2534924061907695 Accuracy 70.47286575690256\n",
      "Training:: Epoch 93, Iteration 30, Current loss 0.3145168220237599 Accuracy 65.85245322979173\n",
      "Training:: Epoch 93, Iteration 40, Current loss 0.24670062147402225 Accuracy 64.02598535054064\n",
      "Training:: Epoch 93, Iteration 50, Current loss 0.23271097885571557 Accuracy 70.44446205038821\n",
      "Training:: Epoch 93, Iteration 60, Current loss 0.27230373359312393 Accuracy 73.1169474727453\n",
      "Training:: Epoch 93, Iteration 70, Current loss 0.27771864134275565 Accuracy 65.89078233927188\n",
      "Training:: Epoch 93, Iteration 80, Current loss 0.38244000175155946 Accuracy 55.301170013000146\n",
      "Training:: Epoch 93, Iteration 90, Current loss 0.2610820709353369 Accuracy 60.12081600316895\n",
      "Training:: Epoch 93, Iteration 100, Current loss 0.25989236837755036 Accuracy 64.64162854204348\n",
      "Training:: Epoch 93, Iteration 110, Current loss 0.25969728181367374 Accuracy 65.93040968491943\n",
      "Training:: Epoch 93, Iteration 120, Current loss 0.3002777228841781 Accuracy 70.83734359961501\n",
      "Training:: Epoch 93, Iteration 130, Current loss 0.28842749267141715 Accuracy 69.11317310617585\n",
      "Training:: Epoch 93, Iteration 140, Current loss 0.3413144412482507 Accuracy 51.97851893725269\n",
      "Training:: Epoch 93, Iteration 150, Current loss 0.2794997451525987 Accuracy 74.54998085024894\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 93, Probability Accuracy 56.11157144632722\n",
      "Starting Training\n",
      "Training:: Epoch 94, Iteration 0, Current loss 0.36056712572687105 Accuracy 54.00325588278822\n",
      "Training:: Epoch 94, Iteration 10, Current loss 0.3392267501279491 Accuracy 65.61123766135155\n",
      "Training:: Epoch 94, Iteration 20, Current loss 0.45505911071149296 Accuracy 68.61744966442953\n",
      "Training:: Epoch 94, Iteration 30, Current loss 0.40257402651575497 Accuracy 62.60972716488731\n",
      "Training:: Epoch 94, Iteration 40, Current loss 0.32697644708149215 Accuracy 58.06275414213753\n",
      "Training:: Epoch 94, Iteration 50, Current loss 0.49904364980464766 Accuracy 55.32912298977798\n",
      "Training:: Epoch 94, Iteration 60, Current loss 0.2761941580749978 Accuracy 59.37222911863805\n",
      "Training:: Epoch 94, Iteration 70, Current loss 0.3425377102317253 Accuracy 59.40609615586048\n",
      "Training:: Epoch 94, Iteration 80, Current loss 0.2961523061852392 Accuracy 63.52153593532904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 94, Iteration 90, Current loss 0.2456149090192964 Accuracy 67.16824402532852\n",
      "Training:: Epoch 94, Iteration 100, Current loss 0.2799190142575264 Accuracy 60.67516494779322\n",
      "Training:: Epoch 94, Iteration 110, Current loss 0.28852667638380225 Accuracy 55.691755153029355\n",
      "Training:: Epoch 94, Iteration 120, Current loss 0.38487533527863227 Accuracy 74.94270435446906\n",
      "Training:: Epoch 94, Iteration 130, Current loss 0.26637652206206336 Accuracy 67.69854761265694\n",
      "Training:: Epoch 94, Iteration 140, Current loss 0.25835696304309214 Accuracy 73.06592163906073\n",
      "Training:: Epoch 94, Iteration 150, Current loss 0.2405528727955834 Accuracy 67.02965708989805\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 94, Probability Accuracy 56.32462609272072\n",
      "Starting Training\n",
      "Training:: Epoch 95, Iteration 0, Current loss 0.3263205411944224 Accuracy 58.64102427880784\n",
      "Training:: Epoch 95, Iteration 10, Current loss 0.3614032695707979 Accuracy 64.6927374301676\n",
      "Training:: Epoch 95, Iteration 20, Current loss 0.4249536707689325 Accuracy 67.01030927835052\n",
      "Training:: Epoch 95, Iteration 30, Current loss 0.29804037332518524 Accuracy 57.730227123347696\n",
      "Training:: Epoch 95, Iteration 40, Current loss 0.19203003022990744 Accuracy 64.62198004727753\n",
      "Training:: Epoch 95, Iteration 50, Current loss 0.2776820119961375 Accuracy 74.32621067325245\n",
      "Training:: Epoch 95, Iteration 60, Current loss 0.37684285321867467 Accuracy 48.04296645085344\n",
      "Training:: Epoch 95, Iteration 70, Current loss 0.26304106081796536 Accuracy 65.46194646601703\n",
      "Training:: Epoch 95, Iteration 80, Current loss 0.274504386913924 Accuracy 54.35283687943262\n",
      "Training:: Epoch 95, Iteration 90, Current loss 0.38192953972500177 Accuracy 68.6471218466933\n",
      "Training:: Epoch 95, Iteration 100, Current loss 0.344004578825868 Accuracy 69.56739184796199\n",
      "Training:: Epoch 95, Iteration 110, Current loss 0.30359468626489505 Accuracy 64.113014264471\n",
      "Training:: Epoch 95, Iteration 120, Current loss 0.3405838288756279 Accuracy 60.88572313409724\n",
      "Training:: Epoch 95, Iteration 130, Current loss 0.34847472006947805 Accuracy 49.416504584606834\n",
      "Training:: Epoch 95, Iteration 140, Current loss 0.26923076827812165 Accuracy 69.68026943095832\n",
      "Training:: Epoch 95, Iteration 150, Current loss 0.22533336550966845 Accuracy 62.427050117321464\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 95, Probability Accuracy 56.17920619795335\n",
      "Calculating Expectation\n",
      "Epoch 95 iter 0\n",
      "Epoch 95 iter 10\n",
      "Epoch 95 iter 20\n",
      "Epoch 95 iter 30\n",
      "Epoch 95 iter 40\n",
      "Epoch 95 iter 50\n",
      "Epoch 95 iter 60\n",
      "Epoch 95 iter 70\n",
      "Epoch 95 iter 80\n",
      "Epoch 95 iter 90\n",
      "Epoch 95 iter 100\n",
      "Epoch 95 iter 110\n",
      "Epoch 95 iter 120\n",
      "Epoch 95 iter 130\n",
      "Epoch 95 iter 140\n",
      "Epoch 95 iter 150\n",
      "Train Boundary avergage error = 283.759\n",
      "Train From boundary avergage accuracy = 60.654\n",
      "Starting Training\n",
      "Training:: Epoch 96, Iteration 0, Current loss 0.3021455686350598 Accuracy 76.05660142126916\n",
      "Training:: Epoch 96, Iteration 10, Current loss 0.22689390994979539 Accuracy 76.05476390053087\n",
      "Training:: Epoch 96, Iteration 20, Current loss 0.3003264637002129 Accuracy 60.508389050081995\n",
      "Training:: Epoch 96, Iteration 30, Current loss 0.30006738129783717 Accuracy 55.60816809707014\n",
      "Training:: Epoch 96, Iteration 40, Current loss 0.2646057132932593 Accuracy 63.26048951048951\n",
      "Training:: Epoch 96, Iteration 50, Current loss 0.31160571513014873 Accuracy 66.22709136403597\n",
      "Training:: Epoch 96, Iteration 60, Current loss 0.2501063870747426 Accuracy 71.84110503383702\n",
      "Training:: Epoch 96, Iteration 70, Current loss 0.31931299170404304 Accuracy 65.62857659177158\n",
      "Training:: Epoch 96, Iteration 80, Current loss 0.5393484214022461 Accuracy 64.55208419656915\n",
      "Training:: Epoch 96, Iteration 90, Current loss 0.5378491352345195 Accuracy 67.22170470423848\n",
      "Training:: Epoch 96, Iteration 100, Current loss 0.5990033905829174 Accuracy 66.32869388883768\n",
      "Training:: Epoch 96, Iteration 110, Current loss 0.2920389969197519 Accuracy 62.567108088761636\n",
      "Training:: Epoch 96, Iteration 120, Current loss 0.30131585398159333 Accuracy 67.44073536526366\n",
      "Training:: Epoch 96, Iteration 130, Current loss 0.3448963711841053 Accuracy 62.67623952968108\n",
      "Training:: Epoch 96, Iteration 140, Current loss 0.273824740880426 Accuracy 58.36818492890274\n",
      "Training:: Epoch 96, Iteration 150, Current loss 0.3542889731864237 Accuracy 60.54507602044035\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 96, Probability Accuracy 54.74603306127522\n",
      "Starting Training\n",
      "Training:: Epoch 97, Iteration 0, Current loss 0.32519610394664544 Accuracy 64.67730742539902\n",
      "Training:: Epoch 97, Iteration 10, Current loss 0.3546608656161499 Accuracy 53.46631539330072\n",
      "Training:: Epoch 97, Iteration 20, Current loss 0.3372876684382702 Accuracy 66.34395835236094\n",
      "Training:: Epoch 97, Iteration 30, Current loss 0.3166881716794331 Accuracy 59.572655639951726\n",
      "Training:: Epoch 97, Iteration 40, Current loss 0.2649481564984281 Accuracy 63.85177716158306\n",
      "Training:: Epoch 97, Iteration 50, Current loss 0.2566450350425659 Accuracy 56.87743110154763\n",
      "Training:: Epoch 97, Iteration 60, Current loss 0.2934553754242919 Accuracy 64.75251549954264\n",
      "Training:: Epoch 97, Iteration 70, Current loss 0.43833303042019056 Accuracy 56.34756995581738\n",
      "Training:: Epoch 97, Iteration 80, Current loss 0.36346795615820515 Accuracy 75.73529411764706\n",
      "Training:: Epoch 97, Iteration 90, Current loss 0.30315572574659694 Accuracy 61.01819857175766\n",
      "Training:: Epoch 97, Iteration 100, Current loss 0.3785451458689932 Accuracy 63.4653961885657\n",
      "Training:: Epoch 97, Iteration 110, Current loss 0.2643078469210428 Accuracy 59.909126063418405\n",
      "Training:: Epoch 97, Iteration 120, Current loss 0.2768913861217503 Accuracy 69.15684057502827\n",
      "Training:: Epoch 97, Iteration 130, Current loss 0.285619571688677 Accuracy 68.15246384950161\n",
      "Training:: Epoch 97, Iteration 140, Current loss 0.45076051944860496 Accuracy 69.05804528090934\n",
      "Training:: Epoch 97, Iteration 150, Current loss 0.5173535913368531 Accuracy 60.83847903802405\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 97, Probability Accuracy 55.264945933628866\n",
      "Starting Training\n",
      "Training:: Epoch 98, Iteration 0, Current loss 0.3102570662462697 Accuracy 60.273733763403364\n",
      "Training:: Epoch 98, Iteration 10, Current loss 0.27572542870602856 Accuracy 63.729319852941174\n",
      "Training:: Epoch 98, Iteration 20, Current loss 0.2297851268106916 Accuracy 74.6432337434095\n",
      "Training:: Epoch 98, Iteration 30, Current loss 0.2944262005500214 Accuracy 63.34915997078159\n",
      "Training:: Epoch 98, Iteration 40, Current loss 0.273152219628119 Accuracy 65.12309165680807\n",
      "Training:: Epoch 98, Iteration 50, Current loss 0.22539696912552426 Accuracy 65.39663931223134\n",
      "Training:: Epoch 98, Iteration 60, Current loss 0.42113393099713475 Accuracy 60.72846630313939\n",
      "Training:: Epoch 98, Iteration 70, Current loss 0.35403695323766743 Accuracy 61.572296865003196\n",
      "Training:: Epoch 98, Iteration 80, Current loss 0.29450273938798305 Accuracy 59.691676684817196\n",
      "Training:: Epoch 98, Iteration 90, Current loss 0.36445861311889194 Accuracy 62.17398620225475\n",
      "Training:: Epoch 98, Iteration 100, Current loss 0.2820455815512442 Accuracy 70.02358490566037\n",
      "Training:: Epoch 98, Iteration 110, Current loss 0.2738288982644008 Accuracy 66.08095492131235\n",
      "Training:: Epoch 98, Iteration 120, Current loss 0.29163887842864467 Accuracy 63.199214916584886\n",
      "Training:: Epoch 98, Iteration 130, Current loss 0.2802687191629494 Accuracy 65.22521226075695\n",
      "Training:: Epoch 98, Iteration 140, Current loss 0.21323951380204692 Accuracy 66.00824687416866\n",
      "Training:: Epoch 98, Iteration 150, Current loss 0.3191855787060096 Accuracy 65.69727658409744\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 98, Probability Accuracy 55.99515267017442\n",
      "Starting Training\n",
      "Training:: Epoch 99, Iteration 0, Current loss 0.3950595445073386 Accuracy 62.67133448050792\n",
      "Training:: Epoch 99, Iteration 10, Current loss 0.2568197687504893 Accuracy 67.69097597922527\n",
      "Training:: Epoch 99, Iteration 20, Current loss 0.3643555222171461 Accuracy 62.78485555356182\n",
      "Training:: Epoch 99, Iteration 30, Current loss 0.2435145636284765 Accuracy 73.78450106157112\n",
      "Training:: Epoch 99, Iteration 40, Current loss 0.2605312184478309 Accuracy 67.5452112561836\n",
      "Training:: Epoch 99, Iteration 50, Current loss 0.30602028736238857 Accuracy 53.21869488536155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 99, Iteration 60, Current loss 0.2746436671333411 Accuracy 69.07176588991251\n",
      "Training:: Epoch 99, Iteration 70, Current loss 0.2656971585208595 Accuracy 54.89437081747802\n",
      "Training:: Epoch 99, Iteration 80, Current loss 0.22918384244315554 Accuracy 66.3111072724132\n",
      "Training:: Epoch 99, Iteration 90, Current loss 0.30572270045223693 Accuracy 64.75424486148347\n",
      "Training:: Epoch 99, Iteration 100, Current loss 0.2187934409291602 Accuracy 51.187039764359355\n",
      "Training:: Epoch 99, Iteration 110, Current loss 0.25648000672686194 Accuracy 72.76984312807305\n",
      "Training:: Epoch 99, Iteration 120, Current loss 0.29222304208495337 Accuracy 63.74058863791923\n",
      "Training:: Epoch 99, Iteration 130, Current loss 0.4435602911836065 Accuracy 59.66537966537967\n",
      "Training:: Epoch 99, Iteration 140, Current loss 0.2714475457866567 Accuracy 60.03928866832093\n",
      "Training:: Epoch 99, Iteration 150, Current loss 0.2514039784892472 Accuracy 67.49458170784568\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 99, Probability Accuracy 55.46702158511828\n",
      "Starting Training\n",
      "Training:: Epoch 100, Iteration 0, Current loss 0.2562421800588812 Accuracy 65.51866458772815\n",
      "Training:: Epoch 100, Iteration 10, Current loss 0.24859899013128792 Accuracy 68.79229777634548\n",
      "Training:: Epoch 100, Iteration 20, Current loss 0.2314715409917367 Accuracy 57.1957936905358\n",
      "Training:: Epoch 100, Iteration 30, Current loss 0.3106396581853935 Accuracy 58.54403834631516\n",
      "Training:: Epoch 100, Iteration 40, Current loss 0.282342976007939 Accuracy 68.96266247205895\n",
      "Training:: Epoch 100, Iteration 50, Current loss 0.26331601728965276 Accuracy 76.74162257495591\n",
      "Training:: Epoch 100, Iteration 60, Current loss 0.32494749698036907 Accuracy 67.38029613486314\n",
      "Training:: Epoch 100, Iteration 70, Current loss 0.2624872512009852 Accuracy 63.74664107485604\n",
      "Training:: Epoch 100, Iteration 80, Current loss 0.2737868481978829 Accuracy 68.45425867507886\n",
      "Training:: Epoch 100, Iteration 90, Current loss 0.25092147174019747 Accuracy 67.23264972127039\n",
      "Training:: Epoch 100, Iteration 100, Current loss 0.3389785295515155 Accuracy 62.711475158845595\n",
      "Training:: Epoch 100, Iteration 110, Current loss 0.23686673350491522 Accuracy 65.95072866065233\n",
      "Training:: Epoch 100, Iteration 120, Current loss 0.2970942894773448 Accuracy 66.4333706606943\n",
      "Training:: Epoch 100, Iteration 130, Current loss 0.2985658469134139 Accuracy 68.2350700066673\n",
      "Training:: Epoch 100, Iteration 140, Current loss 0.2720153235266176 Accuracy 68.35834574407149\n",
      "Training:: Epoch 100, Iteration 150, Current loss 0.22715119664998099 Accuracy 69.73396291604284\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 100, Probability Accuracy 56.00157434643908\n",
      "Calculating Expectation\n",
      "Epoch 100 iter 0\n",
      "Epoch 100 iter 10\n",
      "Epoch 100 iter 20\n",
      "Epoch 100 iter 30\n",
      "Epoch 100 iter 40\n",
      "Epoch 100 iter 50\n",
      "Epoch 100 iter 60\n",
      "Epoch 100 iter 70\n",
      "Epoch 100 iter 80\n",
      "Epoch 100 iter 90\n",
      "Epoch 100 iter 100\n",
      "Epoch 100 iter 110\n",
      "Epoch 100 iter 120\n",
      "Epoch 100 iter 130\n",
      "Epoch 100 iter 140\n",
      "Epoch 100 iter 150\n",
      "Train Boundary avergage error = 283.749\n",
      "Train From boundary avergage accuracy = 60.667\n",
      "Starting Training\n",
      "Training:: Epoch 101, Iteration 0, Current loss 0.23410136299914375 Accuracy 64.41545690441124\n",
      "Training:: Epoch 101, Iteration 10, Current loss 0.3372904052283291 Accuracy 62.32217115342526\n",
      "Training:: Epoch 101, Iteration 20, Current loss 0.26838303009974845 Accuracy 55.484619849100405\n",
      "Training:: Epoch 101, Iteration 30, Current loss 0.274172166344961 Accuracy 66.689470083671\n",
      "Training:: Epoch 101, Iteration 40, Current loss 0.25615854698276247 Accuracy 60.66087451929924\n",
      "Training:: Epoch 101, Iteration 50, Current loss 0.24470325676466156 Accuracy 64.61796718470785\n",
      "Training:: Epoch 101, Iteration 60, Current loss 0.2068024427524478 Accuracy 69.34112189674427\n",
      "Training:: Epoch 101, Iteration 70, Current loss 0.2069624199486943 Accuracy 72.24530399672304\n",
      "Training:: Epoch 101, Iteration 80, Current loss 0.23912206351542206 Accuracy 66.70172616469715\n",
      "Training:: Epoch 101, Iteration 90, Current loss 0.23623356104347204 Accuracy 62.19693221177635\n",
      "Training:: Epoch 101, Iteration 100, Current loss 0.27567398334217863 Accuracy 65.96263200649878\n",
      "Training:: Epoch 101, Iteration 110, Current loss 0.21929987593960446 Accuracy 65.6266409942237\n",
      "Training:: Epoch 101, Iteration 120, Current loss 0.239534730775906 Accuracy 63.27337418462147\n",
      "Training:: Epoch 101, Iteration 130, Current loss 0.3276281378027923 Accuracy 60.932203389830505\n",
      "Training:: Epoch 101, Iteration 140, Current loss 0.4669277284381058 Accuracy 54.74233005815119\n",
      "Training:: Epoch 101, Iteration 150, Current loss 0.2907252011189646 Accuracy 66.68226016640492\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 101, Probability Accuracy 55.147284252392595\n",
      "Starting Training\n",
      "Training:: Epoch 102, Iteration 0, Current loss 0.26909874909909365 Accuracy 64.82369534555713\n",
      "Training:: Epoch 102, Iteration 10, Current loss 0.32448918048637493 Accuracy 61.68864531597876\n",
      "Training:: Epoch 102, Iteration 20, Current loss 0.3509759727401502 Accuracy 60.323338793533225\n",
      "Training:: Epoch 102, Iteration 30, Current loss 0.28961018870273847 Accuracy 63.49720341477774\n",
      "Training:: Epoch 102, Iteration 40, Current loss 0.25639709866303523 Accuracy 64.98522895125554\n",
      "Training:: Epoch 102, Iteration 50, Current loss 0.2660734173653814 Accuracy 63.46913137114142\n",
      "Training:: Epoch 102, Iteration 60, Current loss 0.3104241460834054 Accuracy 62.78482610616676\n",
      "Training:: Epoch 102, Iteration 70, Current loss 0.3878443529186031 Accuracy 63.42558273618318\n",
      "Training:: Epoch 102, Iteration 80, Current loss 0.37382528808494525 Accuracy 62.67717729098764\n",
      "Training:: Epoch 102, Iteration 90, Current loss 0.4691855335303694 Accuracy 61.062282163964234\n",
      "Training:: Epoch 102, Iteration 100, Current loss 0.5603582955591787 Accuracy 63.53334128593582\n",
      "Training:: Epoch 102, Iteration 110, Current loss 0.5271646848301575 Accuracy 54.55320358005398\n",
      "Training:: Epoch 102, Iteration 120, Current loss 0.44494792613229184 Accuracy 61.729212281684404\n",
      "Training:: Epoch 102, Iteration 130, Current loss 0.38953385160895854 Accuracy 64.58792861439743\n",
      "Training:: Epoch 102, Iteration 140, Current loss 0.39518273982881913 Accuracy 60.69757549978733\n",
      "Training:: Epoch 102, Iteration 150, Current loss 0.3183713082191888 Accuracy 64.4672297421901\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 102, Probability Accuracy 55.813481377138835\n",
      "Starting Training\n",
      "Training:: Epoch 103, Iteration 0, Current loss 0.4305904963300159 Accuracy 54.67618813100221\n",
      "Training:: Epoch 103, Iteration 10, Current loss 0.39353948246880155 Accuracy 66.44708700487638\n",
      "Training:: Epoch 103, Iteration 20, Current loss 0.27678068360604124 Accuracy 63.76046956407043\n",
      "Training:: Epoch 103, Iteration 30, Current loss 0.2389623645237395 Accuracy 71.94280627573161\n",
      "Training:: Epoch 103, Iteration 40, Current loss 0.42091159540715234 Accuracy 59.47292764734068\n",
      "Training:: Epoch 103, Iteration 50, Current loss 0.31229285156006653 Accuracy 62.783309915083386\n",
      "Training:: Epoch 103, Iteration 60, Current loss 0.35924754963806094 Accuracy 62.88062622309198\n",
      "Training:: Epoch 103, Iteration 70, Current loss 0.23491037249102406 Accuracy 68.15076424270495\n",
      "Training:: Epoch 103, Iteration 80, Current loss 0.341660383093791 Accuracy 70.68190916774165\n",
      "Training:: Epoch 103, Iteration 90, Current loss 0.27876361201451644 Accuracy 65.9152436484798\n",
      "Training:: Epoch 103, Iteration 100, Current loss 0.39181124587158056 Accuracy 67.88928279247341\n",
      "Training:: Epoch 103, Iteration 110, Current loss 0.24607534534836925 Accuracy 66.43091505650747\n",
      "Training:: Epoch 103, Iteration 120, Current loss 0.36053487791933425 Accuracy 67.54064897585697\n",
      "Training:: Epoch 103, Iteration 130, Current loss 0.42405853727206655 Accuracy 62.91407018694654\n",
      "Training:: Epoch 103, Iteration 140, Current loss 0.26730524245539455 Accuracy 65.25813398521623\n",
      "Training:: Epoch 103, Iteration 150, Current loss 0.3095643268216856 Accuracy 59.74882082173098\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 103, Probability Accuracy 55.23677341840328\n",
      "Starting Training\n",
      "Training:: Epoch 104, Iteration 0, Current loss 0.2268618711738184 Accuracy 70.86386003280481\n",
      "Training:: Epoch 104, Iteration 10, Current loss 0.29874830421100534 Accuracy 67.96926745264274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 104, Iteration 20, Current loss 0.3996726554787937 Accuracy 60.79285790200871\n",
      "Training:: Epoch 104, Iteration 30, Current loss 0.32799103824782083 Accuracy 65.20698731754008\n",
      "Training:: Epoch 104, Iteration 40, Current loss 0.35733691005233276 Accuracy 63.14655172413793\n",
      "Training:: Epoch 104, Iteration 50, Current loss 0.30899558004443367 Accuracy 61.33936779577116\n",
      "Training:: Epoch 104, Iteration 60, Current loss 0.29809379041342066 Accuracy 66.67286591035894\n",
      "Training:: Epoch 104, Iteration 70, Current loss 0.30975744951259765 Accuracy 68.28966880869996\n",
      "Training:: Epoch 104, Iteration 80, Current loss 0.2835909188424769 Accuracy 63.78697022055087\n",
      "Training:: Epoch 104, Iteration 90, Current loss 0.23320732498752655 Accuracy 49.51163278138755\n",
      "Training:: Epoch 104, Iteration 100, Current loss 0.31427096082186035 Accuracy 66.38640321902588\n",
      "Training:: Epoch 104, Iteration 110, Current loss 0.3142389076724168 Accuracy 60.58234054449271\n",
      "Training:: Epoch 104, Iteration 120, Current loss 0.26215735161560233 Accuracy 47.20182737803883\n",
      "Training:: Epoch 104, Iteration 130, Current loss 0.4276565753155341 Accuracy 68.58179041801871\n",
      "Training:: Epoch 104, Iteration 140, Current loss 0.4453832541130825 Accuracy 58.96637608966376\n",
      "Training:: Epoch 104, Iteration 150, Current loss 0.46496392100413175 Accuracy 66.25067824199674\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 104, Probability Accuracy 55.17214235406223\n",
      "Starting Training\n",
      "Training:: Epoch 105, Iteration 0, Current loss 0.2856739213260879 Accuracy 67.43793812259527\n",
      "Training:: Epoch 105, Iteration 10, Current loss 0.3202494474399261 Accuracy 62.75652394223461\n",
      "Training:: Epoch 105, Iteration 20, Current loss 0.3310533023108832 Accuracy 60.55637227185344\n",
      "Training:: Epoch 105, Iteration 30, Current loss 0.2090677234445505 Accuracy 66.8286942284077\n",
      "Training:: Epoch 105, Iteration 40, Current loss 0.2188720492957723 Accuracy 70.58291327387876\n",
      "Training:: Epoch 105, Iteration 50, Current loss 0.2134771088452446 Accuracy 67.85714285714286\n",
      "Training:: Epoch 105, Iteration 60, Current loss 0.29743047264055356 Accuracy 59.640178152836384\n",
      "Training:: Epoch 105, Iteration 70, Current loss 0.2625821917539206 Accuracy 65.6793842034806\n",
      "Training:: Epoch 105, Iteration 80, Current loss 0.26237438670725743 Accuracy 74.01254532980496\n",
      "Training:: Epoch 105, Iteration 90, Current loss 0.22182773671333317 Accuracy 65.29301578806529\n",
      "Training:: Epoch 105, Iteration 100, Current loss 0.19472952235338178 Accuracy 64.55802056175907\n",
      "Training:: Epoch 105, Iteration 110, Current loss 0.19443651981133872 Accuracy 69.37478852588443\n",
      "Training:: Epoch 105, Iteration 120, Current loss 0.22974656498639714 Accuracy 63.37249481686247\n",
      "Training:: Epoch 105, Iteration 130, Current loss 0.18809021530867653 Accuracy 62.5947285639388\n",
      "Training:: Epoch 105, Iteration 140, Current loss 0.2842044371576821 Accuracy 69.96105919003115\n",
      "Training:: Epoch 105, Iteration 150, Current loss 0.4516350579908218 Accuracy 58.805595408895265\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 105, Probability Accuracy 55.10171106599826\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.10884195869111\n",
      "Calculating Expectation\n",
      "Epoch 105 iter 0\n",
      "Epoch 105 iter 10\n",
      "Epoch 105 iter 20\n",
      "Epoch 105 iter 30\n",
      "Epoch 105 iter 40\n",
      "Epoch 105 iter 50\n",
      "Epoch 105 iter 60\n",
      "Epoch 105 iter 70\n",
      "Epoch 105 iter 80\n",
      "Epoch 105 iter 90\n",
      "Epoch 105 iter 100\n",
      "Epoch 105 iter 110\n",
      "Epoch 105 iter 120\n",
      "Epoch 105 iter 130\n",
      "Epoch 105 iter 140\n",
      "Epoch 105 iter 150\n",
      "Train Boundary avergage error = 283.866\n",
      "Train From boundary avergage accuracy = 60.637\n",
      "Starting Training\n",
      "Training:: Epoch 106, Iteration 0, Current loss 0.3029579014633954 Accuracy 58.91684024995994\n",
      "Training:: Epoch 106, Iteration 10, Current loss 0.3035482364632596 Accuracy 63.48728684199049\n",
      "Training:: Epoch 106, Iteration 20, Current loss 0.3675751788679215 Accuracy 59.882931795045806\n",
      "Training:: Epoch 106, Iteration 30, Current loss 0.2165846426665659 Accuracy 71.88428059395801\n",
      "Training:: Epoch 106, Iteration 40, Current loss 0.2666893721980156 Accuracy 66.20262954369683\n",
      "Training:: Epoch 106, Iteration 50, Current loss 0.2418108679808684 Accuracy 67.22684592402902\n",
      "Training:: Epoch 106, Iteration 60, Current loss 0.2924931948227014 Accuracy 71.78651302073462\n",
      "Training:: Epoch 106, Iteration 70, Current loss 0.2955412110100786 Accuracy 64.34475632856896\n",
      "Training:: Epoch 106, Iteration 80, Current loss 0.4655283959616895 Accuracy 63.05668016194332\n",
      "Training:: Epoch 106, Iteration 90, Current loss 0.23116601006515264 Accuracy 48.51393188854489\n",
      "Training:: Epoch 106, Iteration 100, Current loss 0.41665194818187506 Accuracy 64.87224284778335\n",
      "Training:: Epoch 106, Iteration 110, Current loss 0.2300689677773101 Accuracy 68.68163091348202\n",
      "Training:: Epoch 106, Iteration 120, Current loss 0.36057686259950983 Accuracy 56.52260406823494\n",
      "Training:: Epoch 106, Iteration 130, Current loss 0.3085742581605557 Accuracy 59.254698639014904\n",
      "Training:: Epoch 106, Iteration 140, Current loss 0.3407339741242251 Accuracy 75.4214463840399\n",
      "Training:: Epoch 106, Iteration 150, Current loss 0.23591462303383356 Accuracy 62.567696718700226\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 106, Probability Accuracy 55.47157890375772\n",
      "Starting Training\n",
      "Training:: Epoch 107, Iteration 0, Current loss 0.24935134845715345 Accuracy 69.23694779116465\n",
      "Training:: Epoch 107, Iteration 10, Current loss 0.3129117156494514 Accuracy 58.976441917140534\n",
      "Training:: Epoch 107, Iteration 20, Current loss 0.3434104308923748 Accuracy 71.9627681100769\n",
      "Training:: Epoch 107, Iteration 30, Current loss 0.3528797983308263 Accuracy 62.179034157832746\n",
      "Training:: Epoch 107, Iteration 40, Current loss 0.32853068923179873 Accuracy 64.83243335904689\n",
      "Training:: Epoch 107, Iteration 50, Current loss 0.5995981544128374 Accuracy 61.58627050002005\n",
      "Training:: Epoch 107, Iteration 60, Current loss 0.2621881060431136 Accuracy 64.2545260915868\n",
      "Training:: Epoch 107, Iteration 70, Current loss 0.3182213015717711 Accuracy 61.05778844231154\n",
      "Training:: Epoch 107, Iteration 80, Current loss 0.28044121114655796 Accuracy 63.18636532048907\n",
      "Training:: Epoch 107, Iteration 90, Current loss 0.29985135111650757 Accuracy 59.138010692363544\n",
      "Training:: Epoch 107, Iteration 100, Current loss 0.28908762965450674 Accuracy 67.62795817281233\n",
      "Training:: Epoch 107, Iteration 110, Current loss 0.4216386105388611 Accuracy 61.39375476009139\n",
      "Training:: Epoch 107, Iteration 120, Current loss 0.27177710616056994 Accuracy 59.37857340010252\n",
      "Training:: Epoch 107, Iteration 130, Current loss 0.24935597027952622 Accuracy 65.01088208936116\n",
      "Training:: Epoch 107, Iteration 140, Current loss 0.2504453201743698 Accuracy 70.36296252720749\n",
      "Training:: Epoch 107, Iteration 150, Current loss 0.36495615181830393 Accuracy 61.62323793250748\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 107, Probability Accuracy 54.918693292455565\n",
      "Starting Training\n",
      "Training:: Epoch 108, Iteration 0, Current loss 0.34420184356197137 Accuracy 67.46818443435441\n",
      "Training:: Epoch 108, Iteration 10, Current loss 0.36321989272965977 Accuracy 70.4880721571272\n",
      "Training:: Epoch 108, Iteration 20, Current loss 0.26020122035808585 Accuracy 62.78221848268125\n",
      "Training:: Epoch 108, Iteration 30, Current loss 0.30459641909441404 Accuracy 57.0613505168479\n",
      "Training:: Epoch 108, Iteration 40, Current loss 0.37287171904462446 Accuracy 68.42311305981835\n",
      "Training:: Epoch 108, Iteration 50, Current loss 0.25151403664893035 Accuracy 62.41889792561455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 108, Iteration 60, Current loss 0.30429934203598463 Accuracy 60.24270965404818\n",
      "Training:: Epoch 108, Iteration 70, Current loss 0.27664234464768656 Accuracy 53.72266170311773\n",
      "Training:: Epoch 108, Iteration 80, Current loss 0.4165599464430399 Accuracy 65.45008183306055\n",
      "Training:: Epoch 108, Iteration 90, Current loss 0.42503757445327617 Accuracy 67.5610345661107\n",
      "Training:: Epoch 108, Iteration 100, Current loss 0.3170357636196973 Accuracy 52.89581128081053\n",
      "Training:: Epoch 108, Iteration 110, Current loss 0.30543165067281963 Accuracy 70.77422345850718\n",
      "Training:: Epoch 108, Iteration 120, Current loss 0.686111021363877 Accuracy 64.05489507699673\n",
      "Training:: Epoch 108, Iteration 130, Current loss 0.5185222205859861 Accuracy 69.3158953722334\n",
      "Training:: Epoch 108, Iteration 140, Current loss 0.3728127475016585 Accuracy 60.6042654028436\n",
      "Training:: Epoch 108, Iteration 150, Current loss 0.3326369144199964 Accuracy 68.55251654802048\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 108, Probability Accuracy 55.12014749140324\n",
      "Starting Training\n",
      "Training:: Epoch 109, Iteration 0, Current loss 0.45465192843223073 Accuracy 69.67395115110436\n",
      "Training:: Epoch 109, Iteration 10, Current loss 0.27838004356123236 Accuracy 68.75330629518604\n",
      "Training:: Epoch 109, Iteration 20, Current loss 0.3186613611040725 Accuracy 71.65417867435158\n",
      "Training:: Epoch 109, Iteration 30, Current loss 0.286482779456927 Accuracy 57.55695208169678\n",
      "Training:: Epoch 109, Iteration 40, Current loss 0.4333477899470434 Accuracy 61.48623853211009\n",
      "Training:: Epoch 109, Iteration 50, Current loss 0.2696009137541281 Accuracy 54.88362130515493\n",
      "Training:: Epoch 109, Iteration 60, Current loss 0.33728254769743343 Accuracy 63.68597296291703\n",
      "Training:: Epoch 109, Iteration 70, Current loss 0.2561942346616788 Accuracy 72.9321421401325\n",
      "Training:: Epoch 109, Iteration 80, Current loss 0.29469008929109836 Accuracy 65.32813904704825\n",
      "Training:: Epoch 109, Iteration 90, Current loss 0.2787209368420503 Accuracy 61.40423274184991\n",
      "Training:: Epoch 109, Iteration 100, Current loss 0.23782722871107492 Accuracy 64.29038053241875\n",
      "Training:: Epoch 109, Iteration 110, Current loss 0.41600004691037906 Accuracy 70.65228199264195\n",
      "Training:: Epoch 109, Iteration 120, Current loss 0.4091397900779635 Accuracy 64.71232876712328\n",
      "Training:: Epoch 109, Iteration 130, Current loss 0.40496881429959636 Accuracy 65.42454728370221\n",
      "Training:: Epoch 109, Iteration 140, Current loss 0.3392466077797996 Accuracy 67.83402946711341\n",
      "Training:: Epoch 109, Iteration 150, Current loss 1.060799614328765 Accuracy 58.31388739304733\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 109, Probability Accuracy 54.372850809959814\n",
      "Starting Training\n",
      "Training:: Epoch 110, Iteration 0, Current loss 0.47472104987161684 Accuracy 67.49301675977654\n",
      "Training:: Epoch 110, Iteration 10, Current loss 0.3520964133146171 Accuracy 59.35313402162744\n",
      "Training:: Epoch 110, Iteration 20, Current loss 0.4164454377166066 Accuracy 65.78336057816398\n",
      "Training:: Epoch 110, Iteration 30, Current loss 0.28697078380808366 Accuracy 69.56444127097465\n",
      "Training:: Epoch 110, Iteration 40, Current loss 0.47525804227310253 Accuracy 61.19554848966614\n",
      "Training:: Epoch 110, Iteration 50, Current loss 0.41620341947473805 Accuracy 56.83686465207827\n",
      "Training:: Epoch 110, Iteration 60, Current loss 0.34227457936179556 Accuracy 64.65881306957101\n",
      "Training:: Epoch 110, Iteration 70, Current loss 0.4677104034583556 Accuracy 66.05546642218657\n",
      "Training:: Epoch 110, Iteration 80, Current loss 0.2705174916969275 Accuracy 60.24768345702868\n",
      "Training:: Epoch 110, Iteration 90, Current loss 0.2893575899451839 Accuracy 66.98128214645527\n",
      "Training:: Epoch 110, Iteration 100, Current loss 0.20542804081692842 Accuracy 67.72228989037758\n",
      "Training:: Epoch 110, Iteration 110, Current loss 0.36001061161485187 Accuracy 50.800366687821736\n",
      "Training:: Epoch 110, Iteration 120, Current loss 0.38068650439098856 Accuracy 62.81195079086116\n",
      "Training:: Epoch 110, Iteration 130, Current loss 0.3756920674215258 Accuracy 65.26107725251194\n",
      "Training:: Epoch 110, Iteration 140, Current loss 0.34206199048449426 Accuracy 63.5095250872015\n",
      "Training:: Epoch 110, Iteration 150, Current loss 0.3235346345525756 Accuracy 66.91465178755941\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 110, Probability Accuracy 53.94788084683266\n",
      "Calculating Expectation\n",
      "Epoch 110 iter 0\n",
      "Epoch 110 iter 10\n",
      "Epoch 110 iter 20\n",
      "Epoch 110 iter 30\n",
      "Epoch 110 iter 40\n",
      "Epoch 110 iter 50\n",
      "Epoch 110 iter 60\n",
      "Epoch 110 iter 70\n",
      "Epoch 110 iter 80\n",
      "Epoch 110 iter 90\n",
      "Epoch 110 iter 100\n",
      "Epoch 110 iter 110\n",
      "Epoch 110 iter 120\n",
      "Epoch 110 iter 130\n",
      "Epoch 110 iter 140\n",
      "Epoch 110 iter 150\n",
      "Train Boundary avergage error = 283.669\n",
      "Train From boundary avergage accuracy = 60.675\n",
      "Starting Training\n",
      "Training:: Epoch 111, Iteration 0, Current loss 0.3281580569583057 Accuracy 59.73088444728184\n",
      "Training:: Epoch 111, Iteration 10, Current loss 0.2847978240806169 Accuracy 65.78691315981513\n",
      "Training:: Epoch 111, Iteration 20, Current loss 0.43254530362282656 Accuracy 68.35900265890734\n",
      "Training:: Epoch 111, Iteration 30, Current loss 0.2524560364949133 Accuracy 70.76916228968219\n",
      "Training:: Epoch 111, Iteration 40, Current loss 0.2825819150722767 Accuracy 66.26819923371647\n",
      "Training:: Epoch 111, Iteration 50, Current loss 0.3971318138601616 Accuracy 66.33656741385079\n",
      "Training:: Epoch 111, Iteration 60, Current loss 0.3652400065232917 Accuracy 67.0416748190178\n",
      "Training:: Epoch 111, Iteration 70, Current loss 0.3404771808295915 Accuracy 68.72084146238018\n",
      "Training:: Epoch 111, Iteration 80, Current loss 0.3763639350663053 Accuracy 54.28631314189897\n",
      "Training:: Epoch 111, Iteration 90, Current loss 0.3593623808050281 Accuracy 60.0059514953132\n",
      "Training:: Epoch 111, Iteration 100, Current loss 0.42206049416762426 Accuracy 66.01809954751131\n",
      "Training:: Epoch 111, Iteration 110, Current loss 0.40692001052396687 Accuracy 52.44102128691855\n",
      "Training:: Epoch 111, Iteration 120, Current loss 0.37387417905283915 Accuracy 72.18045112781955\n",
      "Training:: Epoch 111, Iteration 130, Current loss 0.31552903873499666 Accuracy 60.17173699705594\n",
      "Training:: Epoch 111, Iteration 140, Current loss 0.4739597653839333 Accuracy 66.59809630068686\n",
      "Training:: Epoch 111, Iteration 150, Current loss 0.3318908658718013 Accuracy 66.92033381125694\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 111, Probability Accuracy 52.818080125947716\n",
      "Starting Training\n",
      "Training:: Epoch 112, Iteration 0, Current loss 1.200027229966782 Accuracy 61.26597620096959\n",
      "Training:: Epoch 112, Iteration 10, Current loss 1.556067351227444 Accuracy 56.297564687975644\n",
      "Training:: Epoch 112, Iteration 20, Current loss 1.6196929528230282 Accuracy 68.24510566117746\n",
      "Training:: Epoch 112, Iteration 30, Current loss 2.0624213241251415 Accuracy 56.134495333456954\n",
      "Training:: Epoch 112, Iteration 40, Current loss 8.92166895294528 Accuracy 44.80657271886392\n",
      "Training:: Epoch 112, Iteration 50, Current loss 5.917982997395135 Accuracy 40.61530230069556\n",
      "Training:: Epoch 112, Iteration 60, Current loss 9.978368615633094 Accuracy 34.620950684626514\n",
      "Training:: Epoch 112, Iteration 70, Current loss 4.5839319456009155 Accuracy 52.2594172511026\n",
      "Training:: Epoch 112, Iteration 80, Current loss 8.623737793484247 Accuracy 27.74346391403672\n",
      "Training:: Epoch 112, Iteration 90, Current loss 2.5936649592525463 Accuracy 65.04004623895632\n",
      "Training:: Epoch 112, Iteration 100, Current loss 4.735933626319394 Accuracy 51.0126187879732\n",
      "Training:: Epoch 112, Iteration 110, Current loss 2.2891613378732982 Accuracy 49.89035087719298\n",
      "Training:: Epoch 112, Iteration 120, Current loss 1.5378637819709007 Accuracy 66.0263852242744\n",
      "Training:: Epoch 112, Iteration 130, Current loss 2.637304408959973 Accuracy 52.099705304518665\n",
      "Training:: Epoch 112, Iteration 140, Current loss 2.246829400881303 Accuracy 46.78696059239084\n",
      "Training:: Epoch 112, Iteration 150, Current loss 1.6235962070741525 Accuracy 56.39042054151922\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 112, Probability Accuracy 45.269296101421055\n",
      "Starting Training\n",
      "Training:: Epoch 113, Iteration 0, Current loss 3.3141830861250625 Accuracy 56.51822298900151\n",
      "Training:: Epoch 113, Iteration 10, Current loss 1.4252310510038548 Accuracy 64.65985834294186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 113, Iteration 20, Current loss 1.1955770204920495 Accuracy 74.97645211930926\n",
      "Training:: Epoch 113, Iteration 30, Current loss 0.9132745200088064 Accuracy 63.79724535554132\n",
      "Training:: Epoch 113, Iteration 40, Current loss 0.9547976217469551 Accuracy 64.49006622516556\n",
      "Training:: Epoch 113, Iteration 50, Current loss 0.6601232415162146 Accuracy 61.00495399858457\n",
      "Training:: Epoch 113, Iteration 60, Current loss 0.5991113814933036 Accuracy 66.8108504398827\n",
      "Training:: Epoch 113, Iteration 70, Current loss 0.7637788131433232 Accuracy 59.68283366130339\n",
      "Training:: Epoch 113, Iteration 80, Current loss 0.9372526867359056 Accuracy 63.51467194197164\n",
      "Training:: Epoch 113, Iteration 90, Current loss 0.4849649019765515 Accuracy 68.301903189363\n",
      "Training:: Epoch 113, Iteration 100, Current loss 0.591806923226346 Accuracy 67.21715446802992\n",
      "Training:: Epoch 113, Iteration 110, Current loss 0.4142798484132101 Accuracy 67.98639034952058\n",
      "Training:: Epoch 113, Iteration 120, Current loss 1.0357916969636163 Accuracy 65.0529062182925\n",
      "Training:: Epoch 113, Iteration 130, Current loss 0.9544917514184749 Accuracy 70.36491288896593\n",
      "Training:: Epoch 113, Iteration 140, Current loss 0.9087051194322977 Accuracy 68.71010138941044\n",
      "Training:: Epoch 113, Iteration 150, Current loss 0.6276196692017122 Accuracy 64.77336006236774\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 113, Probability Accuracy 53.1929195840411\n",
      "Starting Training\n",
      "Training:: Epoch 114, Iteration 0, Current loss 0.5956957241275294 Accuracy 61.85075608152531\n",
      "Training:: Epoch 114, Iteration 10, Current loss 1.0151121293299585 Accuracy 66.90866939173937\n",
      "Training:: Epoch 114, Iteration 20, Current loss 0.4630743404151243 Accuracy 65.87865835041654\n",
      "Training:: Epoch 114, Iteration 30, Current loss 0.689663562703937 Accuracy 50.93055093055093\n",
      "Training:: Epoch 114, Iteration 40, Current loss 0.44533123825044924 Accuracy 70.48465984882169\n",
      "Training:: Epoch 114, Iteration 50, Current loss 0.5831534878418553 Accuracy 60.425\n",
      "Training:: Epoch 114, Iteration 60, Current loss 0.36993437785912436 Accuracy 70.34704729918836\n",
      "Training:: Epoch 114, Iteration 70, Current loss 0.4685131548800989 Accuracy 62.721765469493725\n",
      "Training:: Epoch 114, Iteration 80, Current loss 0.45312821486742605 Accuracy 56.67886550777676\n",
      "Training:: Epoch 114, Iteration 90, Current loss 0.3016533658178362 Accuracy 69.58122411412793\n",
      "Training:: Epoch 114, Iteration 100, Current loss 0.399429355799631 Accuracy 64.48371448371448\n",
      "Training:: Epoch 114, Iteration 110, Current loss 0.5694113783769083 Accuracy 63.88652783680408\n",
      "Training:: Epoch 114, Iteration 120, Current loss 0.520986642433246 Accuracy 62.765391497799484\n",
      "Training:: Epoch 114, Iteration 130, Current loss 0.5400140402106133 Accuracy 74.44060740810824\n",
      "Training:: Epoch 114, Iteration 140, Current loss 0.37899026900903643 Accuracy 64.99470419125436\n",
      "Training:: Epoch 114, Iteration 150, Current loss 0.586455821660369 Accuracy 55.13411222642751\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 114, Probability Accuracy 55.246923809918385\n",
      "Starting Training\n",
      "Training:: Epoch 115, Iteration 0, Current loss 0.4399815357754768 Accuracy 62.22222222222222\n",
      "Training:: Epoch 115, Iteration 10, Current loss 0.4187048392431252 Accuracy 64.4988635530464\n",
      "Training:: Epoch 115, Iteration 20, Current loss 0.34778174527974925 Accuracy 69.95841209829868\n",
      "Training:: Epoch 115, Iteration 30, Current loss 0.3327881245124465 Accuracy 66.11800455811598\n",
      "Training:: Epoch 115, Iteration 40, Current loss 0.40081141652497054 Accuracy 65.61821489349217\n",
      "Training:: Epoch 115, Iteration 50, Current loss 0.3106663237481103 Accuracy 66.01665436913672\n",
      "Training:: Epoch 115, Iteration 60, Current loss 0.4546831356655217 Accuracy 56.05154776139232\n",
      "Training:: Epoch 115, Iteration 70, Current loss 0.3351539273271903 Accuracy 63.277230313072295\n",
      "Training:: Epoch 115, Iteration 80, Current loss 0.4082551346226771 Accuracy 62.73863374990416\n",
      "Training:: Epoch 115, Iteration 90, Current loss 0.332406814709946 Accuracy 58.802347292611366\n",
      "Training:: Epoch 115, Iteration 100, Current loss 0.40591270183738853 Accuracy 59.60909574872614\n",
      "Training:: Epoch 115, Iteration 110, Current loss 0.256013653769894 Accuracy 57.794803464357095\n",
      "Training:: Epoch 115, Iteration 120, Current loss 0.29718297602793153 Accuracy 58.976738431081415\n",
      "Training:: Epoch 115, Iteration 130, Current loss 0.45215882783726646 Accuracy 62.3773173391494\n",
      "Training:: Epoch 115, Iteration 140, Current loss 0.34546389043794057 Accuracy 64.5571819484863\n",
      "Training:: Epoch 115, Iteration 150, Current loss 0.33761812658041096 Accuracy 67.7176215577122\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 115, Probability Accuracy 55.52440236980569\n",
      "Calculating Expectation\n",
      "Epoch 115 iter 0\n",
      "Epoch 115 iter 10\n",
      "Epoch 115 iter 20\n",
      "Epoch 115 iter 30\n",
      "Epoch 115 iter 40\n",
      "Epoch 115 iter 50\n",
      "Epoch 115 iter 60\n",
      "Epoch 115 iter 70\n",
      "Epoch 115 iter 80\n",
      "Epoch 115 iter 90\n",
      "Epoch 115 iter 100\n",
      "Epoch 115 iter 110\n",
      "Epoch 115 iter 120\n",
      "Epoch 115 iter 130\n",
      "Epoch 115 iter 140\n",
      "Epoch 115 iter 150\n",
      "Train Boundary avergage error = 283.827\n",
      "Train From boundary avergage accuracy = 60.657\n",
      "Starting Training\n",
      "Training:: Epoch 116, Iteration 0, Current loss 0.3195096246770366 Accuracy 70.93043427976637\n",
      "Training:: Epoch 116, Iteration 10, Current loss 0.24030529943609716 Accuracy 60.74500025443998\n",
      "Training:: Epoch 116, Iteration 20, Current loss 0.2535277374977425 Accuracy 63.1107843985125\n",
      "Training:: Epoch 116, Iteration 30, Current loss 0.2627192563073891 Accuracy 71.63725604768027\n",
      "Training:: Epoch 116, Iteration 40, Current loss 0.2924295538795172 Accuracy 56.01755738774542\n",
      "Training:: Epoch 116, Iteration 50, Current loss 0.29391192410238703 Accuracy 57.270045306079446\n",
      "Training:: Epoch 116, Iteration 60, Current loss 0.24895007822769086 Accuracy 62.248362842590346\n",
      "Training:: Epoch 116, Iteration 70, Current loss 0.22057572124209232 Accuracy 67.32437727399945\n",
      "Training:: Epoch 116, Iteration 80, Current loss 0.2929820526361574 Accuracy 69.21502356357405\n",
      "Training:: Epoch 116, Iteration 90, Current loss 0.28353860388046404 Accuracy 53.38950593642283\n",
      "Training:: Epoch 116, Iteration 100, Current loss 0.3190148207541922 Accuracy 53.87624698441677\n",
      "Training:: Epoch 116, Iteration 110, Current loss 0.30723152662385694 Accuracy 61.434474616292796\n",
      "Training:: Epoch 116, Iteration 120, Current loss 0.2403518028235092 Accuracy 74.1462383770076\n",
      "Training:: Epoch 116, Iteration 130, Current loss 0.20881351764748568 Accuracy 63.0897520298442\n",
      "Training:: Epoch 116, Iteration 140, Current loss 0.26851450295771684 Accuracy 59.58354559347937\n",
      "Training:: Epoch 116, Iteration 150, Current loss 0.30222350759554284 Accuracy 54.704016913319236\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 116, Probability Accuracy 55.4300451588847\n",
      "Starting Training\n",
      "Training:: Epoch 117, Iteration 0, Current loss 0.25580863338840015 Accuracy 67.65617851878208\n",
      "Training:: Epoch 117, Iteration 10, Current loss 0.3666124989039587 Accuracy 65.81595974119338\n",
      "Training:: Epoch 117, Iteration 20, Current loss 0.23785511973228843 Accuracy 70.76343907435088\n",
      "Training:: Epoch 117, Iteration 30, Current loss 0.2991710320840241 Accuracy 62.805710738671635\n",
      "Training:: Epoch 117, Iteration 40, Current loss 0.31580048230377755 Accuracy 61.582869738637555\n",
      "Training:: Epoch 117, Iteration 50, Current loss 0.2875370402165389 Accuracy 67.1301446051168\n",
      "Training:: Epoch 117, Iteration 60, Current loss 0.17541966831727207 Accuracy 63.927731167043994\n",
      "Training:: Epoch 117, Iteration 70, Current loss 0.2339992785297434 Accuracy 59.02750243304617\n",
      "Training:: Epoch 117, Iteration 80, Current loss 0.3637603731370393 Accuracy 62.60141987829615\n",
      "Training:: Epoch 117, Iteration 90, Current loss 0.21482041118239933 Accuracy 68.56234330092337\n",
      "Training:: Epoch 117, Iteration 100, Current loss 0.21767050223392242 Accuracy 67.15367106029326\n",
      "Training:: Epoch 117, Iteration 110, Current loss 0.2842020109264187 Accuracy 68.52030171722035\n",
      "Training:: Epoch 117, Iteration 120, Current loss 0.27626395549678123 Accuracy 69.62454480766816\n",
      "Training:: Epoch 117, Iteration 130, Current loss 0.27447134581089294 Accuracy 66.75236806495263\n",
      "Training:: Epoch 117, Iteration 140, Current loss 0.2638141327551733 Accuracy 70.89410009943653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 117, Iteration 150, Current loss 0.3443740169029198 Accuracy 60.6702518363064\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 117, Probability Accuracy 55.463810746985956\n",
      "Starting Training\n",
      "Training:: Epoch 118, Iteration 0, Current loss 0.22150817206576529 Accuracy 61.828203950390446\n",
      "Training:: Epoch 118, Iteration 10, Current loss 0.26280692731933974 Accuracy 73.7163192679207\n",
      "Training:: Epoch 118, Iteration 20, Current loss 0.24860006633034712 Accuracy 69.78851963746223\n",
      "Training:: Epoch 118, Iteration 30, Current loss 0.20928830080457972 Accuracy 66.25682336106841\n",
      "Training:: Epoch 118, Iteration 40, Current loss 0.2663291690257542 Accuracy 60.647218613440415\n",
      "Training:: Epoch 118, Iteration 50, Current loss 0.2756151552751162 Accuracy 63.82105263157895\n",
      "Training:: Epoch 118, Iteration 60, Current loss 0.18339172892475522 Accuracy 61.57747721258453\n",
      "Training:: Epoch 118, Iteration 70, Current loss 0.25505541985844205 Accuracy 63.85811018775008\n",
      "Training:: Epoch 118, Iteration 80, Current loss 0.25342508362040156 Accuracy 64.01214546960182\n",
      "Training:: Epoch 118, Iteration 90, Current loss 0.21647532054671476 Accuracy 66.06782529453882\n",
      "Training:: Epoch 118, Iteration 100, Current loss 0.2774041488470707 Accuracy 65.83594417544859\n",
      "Training:: Epoch 118, Iteration 110, Current loss 0.21189606882865827 Accuracy 64.5839636913767\n",
      "Training:: Epoch 118, Iteration 120, Current loss 0.19238874095952627 Accuracy 72.96269897837966\n",
      "Training:: Epoch 118, Iteration 130, Current loss 0.24810343393560105 Accuracy 64.75869198541814\n",
      "Training:: Epoch 118, Iteration 140, Current loss 0.2584400343475992 Accuracy 58.22251054168018\n",
      "Training:: Epoch 118, Iteration 150, Current loss 0.33250559947651487 Accuracy 61.026455026455025\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 118, Probability Accuracy 55.65573600696027\n",
      "Starting Training\n",
      "Training:: Epoch 119, Iteration 0, Current loss 0.16463644269988895 Accuracy 71.513132244001\n",
      "Training:: Epoch 119, Iteration 10, Current loss 0.22479097600823283 Accuracy 64.94933637790781\n",
      "Training:: Epoch 119, Iteration 20, Current loss 0.21601661247692527 Accuracy 66.27498563126636\n",
      "Training:: Epoch 119, Iteration 30, Current loss 0.20111561478481457 Accuracy 67.65422279663966\n",
      "Training:: Epoch 119, Iteration 40, Current loss 0.2942980817831628 Accuracy 68.4188839180598\n",
      "Training:: Epoch 119, Iteration 50, Current loss 0.24966952837407436 Accuracy 61.620523241046484\n",
      "Training:: Epoch 119, Iteration 60, Current loss 0.26138290808496506 Accuracy 69.05351067120321\n",
      "Training:: Epoch 119, Iteration 70, Current loss 0.23686530576471435 Accuracy 69.63630898707544\n",
      "Training:: Epoch 119, Iteration 80, Current loss 0.25236654431573474 Accuracy 55.41171088746569\n",
      "Training:: Epoch 119, Iteration 90, Current loss 0.19378782373680925 Accuracy 66.08724482546299\n",
      "Training:: Epoch 119, Iteration 100, Current loss 0.2827754140195416 Accuracy 76.6157008865476\n",
      "Training:: Epoch 119, Iteration 110, Current loss 0.16982362935520734 Accuracy 61.43238909673971\n",
      "Training:: Epoch 119, Iteration 120, Current loss 0.21027177134418445 Accuracy 65.55758380351809\n",
      "Training:: Epoch 119, Iteration 130, Current loss 0.19398049777616586 Accuracy 63.883146556413884\n",
      "Training:: Epoch 119, Iteration 140, Current loss 0.2939081700031342 Accuracy 73.19860085503304\n",
      "Training:: Epoch 119, Iteration 150, Current loss 0.20705041023710105 Accuracy 59.07543450994446\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 119, Probability Accuracy 55.76200439159796\n",
      "Starting Training\n",
      "Training:: Epoch 120, Iteration 0, Current loss 0.16517588097195318 Accuracy 54.197080291970806\n",
      "Training:: Epoch 120, Iteration 10, Current loss 0.17035887225518195 Accuracy 67.68579695124585\n",
      "Training:: Epoch 120, Iteration 20, Current loss 0.1991194878432133 Accuracy 70.88186356073211\n",
      "Training:: Epoch 120, Iteration 30, Current loss 0.2331981265146761 Accuracy 57.34926864074206\n",
      "Training:: Epoch 120, Iteration 40, Current loss 0.31593831936298 Accuracy 65.98153352067443\n",
      "Training:: Epoch 120, Iteration 50, Current loss 0.1856950732959344 Accuracy 58.98566703417861\n",
      "Training:: Epoch 120, Iteration 60, Current loss 0.26795809302655643 Accuracy 57.202684871780164\n",
      "Training:: Epoch 120, Iteration 70, Current loss 0.14902204524151907 Accuracy 72.21763332734781\n",
      "Training:: Epoch 120, Iteration 80, Current loss 0.1490922133059533 Accuracy 62.42676579925651\n",
      "Training:: Epoch 120, Iteration 90, Current loss 0.24634228978370212 Accuracy 67.72115245403214\n",
      "Training:: Epoch 120, Iteration 100, Current loss 0.2855899119934592 Accuracy 61.699200275174135\n",
      "Training:: Epoch 120, Iteration 110, Current loss 0.21720849678552978 Accuracy 64.56350929837723\n",
      "Training:: Epoch 120, Iteration 120, Current loss 0.2653794769284175 Accuracy 65.08846657929227\n",
      "Training:: Epoch 120, Iteration 130, Current loss 0.16148542042866149 Accuracy 61.60599374885089\n",
      "Training:: Epoch 120, Iteration 140, Current loss 0.3049518305078892 Accuracy 68.99098083427283\n",
      "Training:: Epoch 120, Iteration 150, Current loss 0.3120091871096467 Accuracy 60.68311971638942\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 120, Probability Accuracy 55.02257944234992\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  58.7259224878162\n",
      "Calculating Expectation\n",
      "Epoch 120 iter 0\n",
      "Epoch 120 iter 10\n",
      "Epoch 120 iter 20\n",
      "Epoch 120 iter 30\n",
      "Epoch 120 iter 40\n",
      "Epoch 120 iter 50\n",
      "Epoch 120 iter 60\n",
      "Epoch 120 iter 70\n",
      "Epoch 120 iter 80\n",
      "Epoch 120 iter 90\n",
      "Epoch 120 iter 100\n",
      "Epoch 120 iter 110\n",
      "Epoch 120 iter 120\n",
      "Epoch 120 iter 130\n",
      "Epoch 120 iter 140\n",
      "Epoch 120 iter 150\n",
      "Train Boundary avergage error = 283.782\n",
      "Train From boundary avergage accuracy = 60.625\n",
      "Starting Training\n",
      "Training:: Epoch 121, Iteration 0, Current loss 0.2006358235381374 Accuracy 69.58018317044686\n",
      "Training:: Epoch 121, Iteration 10, Current loss 0.28661120710489896 Accuracy 62.855564761115716\n",
      "Training:: Epoch 121, Iteration 20, Current loss 0.23749521795129308 Accuracy 69.27229010255655\n",
      "Training:: Epoch 121, Iteration 30, Current loss 0.2537615856961618 Accuracy 72.48237906729749\n",
      "Training:: Epoch 121, Iteration 40, Current loss 0.25409363895542575 Accuracy 69.46886311590455\n",
      "Training:: Epoch 121, Iteration 50, Current loss 0.22107727519626355 Accuracy 58.404121988580975\n",
      "Training:: Epoch 121, Iteration 60, Current loss 0.22671046444727666 Accuracy 54.03417036541619\n",
      "Training:: Epoch 121, Iteration 70, Current loss 0.18490682345017312 Accuracy 67.64532484376842\n",
      "Training:: Epoch 121, Iteration 80, Current loss 0.2981723970687689 Accuracy 66.74991388219084\n",
      "Training:: Epoch 121, Iteration 90, Current loss 0.22863251507697196 Accuracy 62.267839687194524\n",
      "Training:: Epoch 121, Iteration 100, Current loss 0.23560710038273786 Accuracy 67.28035982008996\n",
      "Training:: Epoch 121, Iteration 110, Current loss 0.23749836906278887 Accuracy 59.0104821802935\n",
      "Training:: Epoch 121, Iteration 120, Current loss 0.2511226192391357 Accuracy 56.25224965805197\n",
      "Training:: Epoch 121, Iteration 130, Current loss 0.2658968648787594 Accuracy 62.297734627831716\n",
      "Training:: Epoch 121, Iteration 140, Current loss 0.24519396177060715 Accuracy 59.11163989688677\n",
      "Training:: Epoch 121, Iteration 150, Current loss 0.3506484308304983 Accuracy 42.36460717009916\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 121, Probability Accuracy 54.66534780627253\n",
      "Starting Training\n",
      "Training:: Epoch 122, Iteration 0, Current loss 0.24665538672219298 Accuracy 52.84811895578288\n",
      "Training:: Epoch 122, Iteration 10, Current loss 0.2569204592508808 Accuracy 47.68014781359064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 122, Iteration 20, Current loss 0.3172679789220781 Accuracy 60.178456443749425\n",
      "Training:: Epoch 122, Iteration 30, Current loss 0.2933455358708946 Accuracy 70.8461404627965\n",
      "Training:: Epoch 122, Iteration 40, Current loss 0.20591650243567702 Accuracy 64.2581330244232\n",
      "Training:: Epoch 122, Iteration 50, Current loss 0.23887717307950118 Accuracy 71.68538194269601\n",
      "Training:: Epoch 122, Iteration 60, Current loss 0.24780076962773734 Accuracy 71.88486361709144\n",
      "Training:: Epoch 122, Iteration 70, Current loss 0.23870426394664956 Accuracy 69.69238527483611\n",
      "Training:: Epoch 122, Iteration 80, Current loss 0.29995767975249005 Accuracy 60.901719104768084\n",
      "Training:: Epoch 122, Iteration 90, Current loss 0.22044774218190255 Accuracy 61.52740341419587\n",
      "Training:: Epoch 122, Iteration 100, Current loss 0.22027339452430728 Accuracy 63.66556258155174\n",
      "Training:: Epoch 122, Iteration 110, Current loss 0.23231619584882876 Accuracy 72.31599188120927\n",
      "Training:: Epoch 122, Iteration 120, Current loss 0.21302529753744903 Accuracy 70.38509682644872\n",
      "Training:: Epoch 122, Iteration 130, Current loss 0.22054029541361875 Accuracy 77.35228923029887\n",
      "Training:: Epoch 122, Iteration 140, Current loss 0.2646421478451701 Accuracy 77.50061500615006\n",
      "Training:: Epoch 122, Iteration 150, Current loss 0.2517668133132065 Accuracy 75.0370164723302\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 122, Probability Accuracy 54.36912209470937\n",
      "Starting Training\n",
      "Training:: Epoch 123, Iteration 0, Current loss 0.23591882901658998 Accuracy 66.50571611162394\n",
      "Training:: Epoch 123, Iteration 10, Current loss 0.2103821915956458 Accuracy 57.42716857610475\n",
      "Training:: Epoch 123, Iteration 20, Current loss 0.21980125436603176 Accuracy 72.35939343617532\n",
      "Training:: Epoch 123, Iteration 30, Current loss 0.20244695280060812 Accuracy 66.40829243682062\n",
      "Training:: Epoch 123, Iteration 40, Current loss 0.2025237125148311 Accuracy 68.13974080334863\n",
      "Training:: Epoch 123, Iteration 50, Current loss 0.18038054333506742 Accuracy 68.40866290018832\n",
      "Training:: Epoch 123, Iteration 60, Current loss 0.24822356401960788 Accuracy 61.91635634488685\n",
      "Training:: Epoch 123, Iteration 70, Current loss 0.2640783101702021 Accuracy 64.89088575096277\n",
      "Training:: Epoch 123, Iteration 80, Current loss 0.2598653046595241 Accuracy 59.99114148316882\n",
      "Training:: Epoch 123, Iteration 90, Current loss 0.2328749835760578 Accuracy 60.03881820142333\n",
      "Training:: Epoch 123, Iteration 100, Current loss 0.1925595402448363 Accuracy 58.56190168871679\n",
      "Training:: Epoch 123, Iteration 110, Current loss 0.3272532996511688 Accuracy 64.1886832816344\n",
      "Training:: Epoch 123, Iteration 120, Current loss 0.2150654556858361 Accuracy 66.94437121012392\n",
      "Training:: Epoch 123, Iteration 130, Current loss 0.3155022703387863 Accuracy 67.64233185603662\n",
      "Training:: Epoch 123, Iteration 140, Current loss 0.21813927945029532 Accuracy 62.31369217700208\n",
      "Training:: Epoch 123, Iteration 150, Current loss 0.19206269961687347 Accuracy 62.558051964352956\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 123, Probability Accuracy 55.326987612379334\n",
      "Starting Training\n",
      "Training:: Epoch 124, Iteration 0, Current loss 0.24664293782837868 Accuracy 62.146716541978385\n",
      "Training:: Epoch 124, Iteration 10, Current loss 0.26261464283783226 Accuracy 70.70264086185527\n",
      "Training:: Epoch 124, Iteration 20, Current loss 0.16616987992426946 Accuracy 62.0618874121209\n",
      "Training:: Epoch 124, Iteration 30, Current loss 0.22212472362283145 Accuracy 62.034458753915764\n",
      "Training:: Epoch 124, Iteration 40, Current loss 0.1758593454832434 Accuracy 57.86251530523002\n",
      "Training:: Epoch 124, Iteration 50, Current loss 0.18471246517007103 Accuracy 62.04255319148936\n",
      "Training:: Epoch 124, Iteration 60, Current loss 0.25796542028333613 Accuracy 64.41375968992249\n",
      "Training:: Epoch 124, Iteration 70, Current loss 0.258736927536707 Accuracy 61.52073732718894\n",
      "Training:: Epoch 124, Iteration 80, Current loss 0.3347987413150451 Accuracy 61.93565588339851\n",
      "Training:: Epoch 124, Iteration 90, Current loss 0.3012850675174121 Accuracy 53.755646601533776\n",
      "Training:: Epoch 124, Iteration 100, Current loss 0.23089892914165877 Accuracy 65.0860344137655\n",
      "Training:: Epoch 124, Iteration 110, Current loss 0.22446057099977923 Accuracy 66.98157770429853\n",
      "Training:: Epoch 124, Iteration 120, Current loss 0.24714347332289704 Accuracy 69.01755996786412\n",
      "Training:: Epoch 124, Iteration 130, Current loss 0.21747702423163853 Accuracy 61.24107478391582\n",
      "Training:: Epoch 124, Iteration 140, Current loss 0.2460814662560721 Accuracy 71.49790425766601\n",
      "Training:: Epoch 124, Iteration 150, Current loss 0.22691211872599176 Accuracy 58.62298969836211\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 124, Probability Accuracy 54.93050089074864\n",
      "Starting Training\n",
      "Training:: Epoch 125, Iteration 0, Current loss 0.22512357672678396 Accuracy 57.87049880707984\n",
      "Training:: Epoch 125, Iteration 10, Current loss 0.27099481762143224 Accuracy 60.633484162895925\n",
      "Training:: Epoch 125, Iteration 20, Current loss 0.1624808293356939 Accuracy 74.45830597504924\n",
      "Training:: Epoch 125, Iteration 30, Current loss 0.20321765388301882 Accuracy 69.77988778593009\n",
      "Training:: Epoch 125, Iteration 40, Current loss 0.17735029674298886 Accuracy 70.07366482504604\n",
      "Training:: Epoch 125, Iteration 50, Current loss 0.19164464339394158 Accuracy 71.33636496992813\n",
      "Training:: Epoch 125, Iteration 60, Current loss 0.19376893837573522 Accuracy 69.83265696958642\n",
      "Training:: Epoch 125, Iteration 70, Current loss 0.24794478466873535 Accuracy 59.930561035271836\n",
      "Training:: Epoch 125, Iteration 80, Current loss 0.2363668668528357 Accuracy 73.40924775707384\n",
      "Training:: Epoch 125, Iteration 90, Current loss 0.1901541538485995 Accuracy 59.58434026099565\n",
      "Training:: Epoch 125, Iteration 100, Current loss 0.17363307333700737 Accuracy 62.03419942260715\n",
      "Training:: Epoch 125, Iteration 110, Current loss 0.1533380590426002 Accuracy 64.91378920215413\n",
      "Training:: Epoch 125, Iteration 120, Current loss 0.2985668384897702 Accuracy 71.91833003199756\n",
      "Training:: Epoch 125, Iteration 130, Current loss 0.22891702518177684 Accuracy 54.83783539615141\n",
      "Training:: Epoch 125, Iteration 140, Current loss 0.20003623517452085 Accuracy 72.89438288605649\n",
      "Training:: Epoch 125, Iteration 150, Current loss 0.20605552670761507 Accuracy 65.8526900933095\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 125, Probability Accuracy 54.3635290218337\n",
      "Calculating Expectation\n",
      "Epoch 125 iter 0\n",
      "Epoch 125 iter 10\n",
      "Epoch 125 iter 20\n",
      "Epoch 125 iter 30\n",
      "Epoch 125 iter 40\n",
      "Epoch 125 iter 50\n",
      "Epoch 125 iter 60\n",
      "Epoch 125 iter 70\n",
      "Epoch 125 iter 80\n",
      "Epoch 125 iter 90\n",
      "Epoch 125 iter 100\n",
      "Epoch 125 iter 110\n",
      "Epoch 125 iter 120\n",
      "Epoch 125 iter 130\n",
      "Epoch 125 iter 140\n",
      "Epoch 125 iter 150\n",
      "Train Boundary avergage error = 283.725\n",
      "Train From boundary avergage accuracy = 60.639\n",
      "Starting Training\n",
      "Training:: Epoch 126, Iteration 0, Current loss 0.1737633721450542 Accuracy 61.427486712224756\n",
      "Training:: Epoch 126, Iteration 10, Current loss 0.1876889925410497 Accuracy 58.70556061987238\n",
      "Training:: Epoch 126, Iteration 20, Current loss 0.1848957331111009 Accuracy 74.05687497235859\n",
      "Training:: Epoch 126, Iteration 30, Current loss 0.2321036970329749 Accuracy 60.40327293980128\n",
      "Training:: Epoch 126, Iteration 40, Current loss 0.17814046199835878 Accuracy 70.95430817056719\n",
      "Training:: Epoch 126, Iteration 50, Current loss 0.20271566107556374 Accuracy 56.5499948828165\n",
      "Training:: Epoch 126, Iteration 60, Current loss 0.23070556953901677 Accuracy 63.016567099833715\n",
      "Training:: Epoch 126, Iteration 70, Current loss 0.2150456594629712 Accuracy 68.08124560992742\n",
      "Training:: Epoch 126, Iteration 80, Current loss 0.25322177780755917 Accuracy 66.74596607364501\n",
      "Training:: Epoch 126, Iteration 90, Current loss 0.21831026571971418 Accuracy 58.14461118690314\n",
      "Training:: Epoch 126, Iteration 100, Current loss 0.20607630386580683 Accuracy 57.139900662251655\n",
      "Training:: Epoch 126, Iteration 110, Current loss 0.22457009340169146 Accuracy 69.7994320198793\n",
      "Training:: Epoch 126, Iteration 120, Current loss 0.1776309561537161 Accuracy 67.01735928458706\n",
      "Training:: Epoch 126, Iteration 130, Current loss 0.259988994567245 Accuracy 66.52861035422343\n",
      "Training:: Epoch 126, Iteration 140, Current loss 0.23562215053033975 Accuracy 58.91472868217054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 126, Iteration 150, Current loss 0.29445393016279564 Accuracy 60.48403226881792\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 126, Probability Accuracy 54.533703442847084\n",
      "Starting Training\n",
      "Training:: Epoch 127, Iteration 0, Current loss 0.21320201500311659 Accuracy 66.87835322457023\n",
      "Training:: Epoch 127, Iteration 10, Current loss 0.20542902574231678 Accuracy 61.15494237680202\n",
      "Training:: Epoch 127, Iteration 20, Current loss 0.3131901665558533 Accuracy 64.15724368217349\n",
      "Training:: Epoch 127, Iteration 30, Current loss 0.21473611093123712 Accuracy 58.12439396038233\n",
      "Training:: Epoch 127, Iteration 40, Current loss 0.2045074921633367 Accuracy 67.8195549128304\n",
      "Training:: Epoch 127, Iteration 50, Current loss 0.27138541127047144 Accuracy 71.22155132373432\n",
      "Training:: Epoch 127, Iteration 60, Current loss 0.2037956529147515 Accuracy 68.85507554798893\n",
      "Training:: Epoch 127, Iteration 70, Current loss 0.2566556685828044 Accuracy 71.16797900262468\n",
      "Training:: Epoch 127, Iteration 80, Current loss 0.2049348812918727 Accuracy 70.0462699894472\n",
      "Training:: Epoch 127, Iteration 90, Current loss 0.33481943796341246 Accuracy 54.023365712785505\n",
      "Training:: Epoch 127, Iteration 100, Current loss 0.2274967772577761 Accuracy 52.71421241662391\n",
      "Training:: Epoch 127, Iteration 110, Current loss 0.16695580428419532 Accuracy 73.43920740147155\n",
      "Training:: Epoch 127, Iteration 120, Current loss 0.2585089010460809 Accuracy 45.16206482593037\n",
      "Training:: Epoch 127, Iteration 130, Current loss 0.23653794349498933 Accuracy 71.94608979311529\n",
      "Training:: Epoch 127, Iteration 140, Current loss 0.21410307040154708 Accuracy 70.46440623493491\n",
      "Training:: Epoch 127, Iteration 150, Current loss 0.1775954247486908 Accuracy 68.54724964739069\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 127, Probability Accuracy 54.82371462899283\n",
      "Starting Training\n",
      "Training:: Epoch 128, Iteration 0, Current loss 0.19592591454260902 Accuracy 60.03176283748015\n",
      "Training:: Epoch 128, Iteration 10, Current loss 0.30482823132943887 Accuracy 60.693991969088565\n",
      "Training:: Epoch 128, Iteration 20, Current loss 0.26426517993148135 Accuracy 65.26432327705508\n",
      "Training:: Epoch 128, Iteration 30, Current loss 0.21580980466755723 Accuracy 63.63017487129303\n",
      "Training:: Epoch 128, Iteration 40, Current loss 0.2386993816377709 Accuracy 58.98361924416355\n",
      "Training:: Epoch 128, Iteration 50, Current loss 0.2141613361068203 Accuracy 69.98445719751315\n",
      "Training:: Epoch 128, Iteration 60, Current loss 0.18950304206975338 Accuracy 65.92377003428754\n",
      "Training:: Epoch 128, Iteration 70, Current loss 0.21925775974414022 Accuracy 56.76926042536786\n",
      "Training:: Epoch 128, Iteration 80, Current loss 0.21949457453471743 Accuracy 61.807350792401934\n",
      "Training:: Epoch 128, Iteration 90, Current loss 0.15848555058314062 Accuracy 72.47648047993455\n",
      "Training:: Epoch 128, Iteration 100, Current loss 0.2641768613755371 Accuracy 59.40237797246558\n",
      "Training:: Epoch 128, Iteration 110, Current loss 0.18044363926484136 Accuracy 66.69434016748484\n",
      "Training:: Epoch 128, Iteration 120, Current loss 0.26026496803065063 Accuracy 60.01514896482074\n",
      "Training:: Epoch 128, Iteration 130, Current loss 0.31925550532784774 Accuracy 72.07157351042243\n",
      "Training:: Epoch 128, Iteration 140, Current loss 0.14647340750468063 Accuracy 68.35864897776068\n",
      "Training:: Epoch 128, Iteration 150, Current loss 0.2663803474677526 Accuracy 70.70058828023531\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 128, Probability Accuracy 53.96352073579981\n",
      "Starting Training\n",
      "Training:: Epoch 129, Iteration 0, Current loss 0.3077222549927377 Accuracy 65.55260159513863\n",
      "Training:: Epoch 129, Iteration 10, Current loss 0.2513361313264959 Accuracy 63.92645314353499\n",
      "Training:: Epoch 129, Iteration 20, Current loss 0.22428677920427245 Accuracy 64.78950495954656\n",
      "Training:: Epoch 129, Iteration 30, Current loss 0.16973019843765866 Accuracy 77.43462448767535\n",
      "Training:: Epoch 129, Iteration 40, Current loss 0.22076319702408367 Accuracy 67.47610943840817\n",
      "Training:: Epoch 129, Iteration 50, Current loss 0.2308557392647871 Accuracy 61.1397408315405\n",
      "Training:: Epoch 129, Iteration 60, Current loss 0.23562285033536495 Accuracy 66.96740802909498\n",
      "Training:: Epoch 129, Iteration 70, Current loss 0.2110571162589303 Accuracy 62.32771822358346\n",
      "Training:: Epoch 129, Iteration 80, Current loss 0.2109434878215111 Accuracy 62.267777065983346\n",
      "Training:: Epoch 129, Iteration 90, Current loss 0.22063910311062299 Accuracy 70.44406544122292\n",
      "Training:: Epoch 129, Iteration 100, Current loss 0.26648324206046 Accuracy 60.53655824298026\n",
      "Training:: Epoch 129, Iteration 110, Current loss 0.22962414129622669 Accuracy 59.78806469604016\n",
      "Training:: Epoch 129, Iteration 120, Current loss 0.19646405693541652 Accuracy 66.92689042110662\n",
      "Training:: Epoch 129, Iteration 130, Current loss 0.23167877427849493 Accuracy 56.549377167073324\n",
      "Training:: Epoch 129, Iteration 140, Current loss 0.30828828108921513 Accuracy 71.65157887233588\n",
      "Training:: Epoch 129, Iteration 150, Current loss 0.264355231807927 Accuracy 56.752466266016555\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 129, Probability Accuracy 54.23820275924928\n",
      "Starting Training\n",
      "Training:: Epoch 130, Iteration 0, Current loss 0.2315287708280678 Accuracy 69.35707549786432\n",
      "Training:: Epoch 130, Iteration 10, Current loss 0.3067557126781555 Accuracy 51.22490152752426\n",
      "Training:: Epoch 130, Iteration 20, Current loss 0.2055479114313308 Accuracy 65.80187371805532\n",
      "Training:: Epoch 130, Iteration 30, Current loss 0.215011003436561 Accuracy 62.77941796710249\n",
      "Training:: Epoch 130, Iteration 40, Current loss 0.2726468931555287 Accuracy 71.72837061967927\n",
      "Training:: Epoch 130, Iteration 50, Current loss 0.22782498940227489 Accuracy 62.30775360586501\n",
      "Training:: Epoch 130, Iteration 60, Current loss 0.18352323906762727 Accuracy 63.71077077579714\n",
      "Training:: Epoch 130, Iteration 70, Current loss 0.29617592895312084 Accuracy 58.963783992782574\n",
      "Training:: Epoch 130, Iteration 80, Current loss 0.3024813403281544 Accuracy 67.01973302379571\n",
      "Training:: Epoch 130, Iteration 90, Current loss 0.29695478595314917 Accuracy 54.658319185059426\n",
      "Training:: Epoch 130, Iteration 100, Current loss 0.2164038879413116 Accuracy 63.00722090868426\n",
      "Training:: Epoch 130, Iteration 110, Current loss 0.23067691014784886 Accuracy 63.879528222409434\n",
      "Training:: Epoch 130, Iteration 120, Current loss 0.2518016100235182 Accuracy 66.97839406643018\n",
      "Training:: Epoch 130, Iteration 130, Current loss 0.239602638644806 Accuracy 65.81604552964934\n",
      "Training:: Epoch 130, Iteration 140, Current loss 0.19333703995278287 Accuracy 63.61987966702382\n",
      "Training:: Epoch 130, Iteration 150, Current loss 0.2901053597940018 Accuracy 66.02942398803091\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 130, Probability Accuracy 55.052823466047975\n",
      "Calculating Expectation\n",
      "Epoch 130 iter 0\n",
      "Epoch 130 iter 10\n",
      "Epoch 130 iter 20\n",
      "Epoch 130 iter 30\n",
      "Epoch 130 iter 40\n",
      "Epoch 130 iter 50\n",
      "Epoch 130 iter 60\n",
      "Epoch 130 iter 70\n",
      "Epoch 130 iter 80\n",
      "Epoch 130 iter 90\n",
      "Epoch 130 iter 100\n",
      "Epoch 130 iter 110\n",
      "Epoch 130 iter 120\n",
      "Epoch 130 iter 130\n",
      "Epoch 130 iter 140\n",
      "Epoch 130 iter 150\n",
      "Train Boundary avergage error = 283.557\n",
      "Train From boundary avergage accuracy = 60.657\n",
      "Starting Training\n",
      "Training:: Epoch 131, Iteration 0, Current loss 0.23467129859089178 Accuracy 69.65505464480874\n",
      "Training:: Epoch 131, Iteration 10, Current loss 0.1682566756640021 Accuracy 60.04386357532898\n",
      "Training:: Epoch 131, Iteration 20, Current loss 0.1619522792083695 Accuracy 63.95182446935368\n",
      "Training:: Epoch 131, Iteration 30, Current loss 0.24728935831117413 Accuracy 72.22656686403754\n",
      "Training:: Epoch 131, Iteration 40, Current loss 0.19513710481033333 Accuracy 67.60453302071122\n",
      "Training:: Epoch 131, Iteration 50, Current loss 0.24902311234056107 Accuracy 60.1867008804141\n",
      "Training:: Epoch 131, Iteration 60, Current loss 0.22303814659475452 Accuracy 59.64305812364338\n",
      "Training:: Epoch 131, Iteration 70, Current loss 0.22999786124578403 Accuracy 65.31670953398142\n",
      "Training:: Epoch 131, Iteration 80, Current loss 0.2598865675113084 Accuracy 47.205945405173644\n",
      "Training:: Epoch 131, Iteration 90, Current loss 0.2166334357668457 Accuracy 56.543571503295325\n",
      "Training:: Epoch 131, Iteration 100, Current loss 0.20249487499373625 Accuracy 67.37387355424679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 131, Iteration 110, Current loss 0.2079433598325556 Accuracy 63.475416145482534\n",
      "Training:: Epoch 131, Iteration 120, Current loss 0.20218527869337047 Accuracy 60.303030303030305\n",
      "Training:: Epoch 131, Iteration 130, Current loss 0.23130713230957298 Accuracy 66.02978364709188\n",
      "Training:: Epoch 131, Iteration 140, Current loss 0.20482114679388588 Accuracy 55.11201629327902\n",
      "Training:: Epoch 131, Iteration 150, Current loss 0.2905798065573737 Accuracy 60.18645462023581\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 131, Probability Accuracy 53.95917056800762\n",
      "Starting Training\n",
      "Training:: Epoch 132, Iteration 0, Current loss 0.1888680479757505 Accuracy 67.78359017861351\n",
      "Training:: Epoch 132, Iteration 10, Current loss 0.2750765299535488 Accuracy 69.5226586102719\n",
      "Training:: Epoch 132, Iteration 20, Current loss 0.17750934611383698 Accuracy 70.19551740581784\n",
      "Training:: Epoch 132, Iteration 30, Current loss 0.2791066740036121 Accuracy 64.52484796363413\n",
      "Training:: Epoch 132, Iteration 40, Current loss 0.2630157573910106 Accuracy 61.65311653116531\n",
      "Training:: Epoch 132, Iteration 50, Current loss 0.21375417706378733 Accuracy 65.43084848751707\n",
      "Training:: Epoch 132, Iteration 60, Current loss 0.25456837238146746 Accuracy 68.70496865350425\n",
      "Training:: Epoch 132, Iteration 70, Current loss 0.28325041509185245 Accuracy 65.62963879267689\n",
      "Training:: Epoch 132, Iteration 80, Current loss 0.18854188609125302 Accuracy 63.16381968577162\n",
      "Training:: Epoch 132, Iteration 90, Current loss 0.19667158246540972 Accuracy 65.97266118836916\n",
      "Training:: Epoch 132, Iteration 100, Current loss 0.18400401385114937 Accuracy 57.937960086804814\n",
      "Training:: Epoch 132, Iteration 110, Current loss 0.26071243045137626 Accuracy 62.94572002962649\n",
      "Training:: Epoch 132, Iteration 120, Current loss 0.19548350291738661 Accuracy 69.83983983983984\n",
      "Training:: Epoch 132, Iteration 130, Current loss 0.20993783583001815 Accuracy 53.53829843625762\n",
      "Training:: Epoch 132, Iteration 140, Current loss 0.23860683760074738 Accuracy 77.8157526798198\n",
      "Training:: Epoch 132, Iteration 150, Current loss 0.22124868077501317 Accuracy 57.6117859912122\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 132, Probability Accuracy 53.83591581389568\n",
      "Starting Training\n",
      "Training:: Epoch 133, Iteration 0, Current loss 0.3219294755926276 Accuracy 66.62035428968392\n",
      "Training:: Epoch 133, Iteration 10, Current loss 0.2756369875431376 Accuracy 73.69794665131452\n",
      "Training:: Epoch 133, Iteration 20, Current loss 0.2557597462670805 Accuracy 61.46289752650177\n",
      "Training:: Epoch 133, Iteration 30, Current loss 0.24885714253245542 Accuracy 69.10011248593926\n",
      "Training:: Epoch 133, Iteration 40, Current loss 0.2636852361130854 Accuracy 57.30566037735849\n",
      "Training:: Epoch 133, Iteration 50, Current loss 0.28858411740753653 Accuracy 65.2549286199864\n",
      "Training:: Epoch 133, Iteration 60, Current loss 0.25815603621248373 Accuracy 65.45020274398712\n",
      "Training:: Epoch 133, Iteration 70, Current loss 0.20052192018824744 Accuracy 49.498064828253504\n",
      "Training:: Epoch 133, Iteration 80, Current loss 0.2787762484934692 Accuracy 65.44684616356972\n",
      "Training:: Epoch 133, Iteration 90, Current loss 0.2814270009361192 Accuracy 62.12415856394914\n",
      "Training:: Epoch 133, Iteration 100, Current loss 0.26724275451454244 Accuracy 70.91708291708292\n",
      "Training:: Epoch 133, Iteration 110, Current loss 0.20010209203677426 Accuracy 59.83853606027987\n",
      "Training:: Epoch 133, Iteration 120, Current loss 0.19551948971335395 Accuracy 68.32120272043909\n",
      "Training:: Epoch 133, Iteration 130, Current loss 0.20327305378075222 Accuracy 68.41098426411601\n",
      "Training:: Epoch 133, Iteration 140, Current loss 0.17282631034170334 Accuracy 64.08517650041193\n",
      "Training:: Epoch 133, Iteration 150, Current loss 0.23598374349422482 Accuracy 60.106238820532276\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 133, Probability Accuracy 54.625989145295605\n",
      "Starting Training\n",
      "Training:: Epoch 134, Iteration 0, Current loss 0.2535129763881436 Accuracy 64.84830516849492\n",
      "Training:: Epoch 134, Iteration 10, Current loss 0.2519986257366494 Accuracy 58.49066959385291\n",
      "Training:: Epoch 134, Iteration 20, Current loss 0.24034904733938117 Accuracy 67.7890815303052\n",
      "Training:: Epoch 134, Iteration 30, Current loss 0.2496701970306671 Accuracy 68.87353507084136\n",
      "Training:: Epoch 134, Iteration 40, Current loss 0.1722145325400593 Accuracy 61.95939178730766\n",
      "Training:: Epoch 134, Iteration 50, Current loss 0.17854234237468625 Accuracy 66.01295745053406\n",
      "Training:: Epoch 134, Iteration 60, Current loss 0.1956025741228795 Accuracy 65.4144939874428\n",
      "Training:: Epoch 134, Iteration 70, Current loss 0.2623537892450281 Accuracy 72.23526163192048\n",
      "Training:: Epoch 134, Iteration 80, Current loss 0.2097587244198963 Accuracy 64.62821403752606\n",
      "Training:: Epoch 134, Iteration 90, Current loss 0.1852699512958379 Accuracy 60.35835264753075\n",
      "Training:: Epoch 134, Iteration 100, Current loss 0.2184754353295201 Accuracy 68.31869510664994\n",
      "Training:: Epoch 134, Iteration 110, Current loss 0.16728559079279132 Accuracy 59.91834113221397\n",
      "Training:: Epoch 134, Iteration 120, Current loss 0.24512041313333086 Accuracy 56.89867841409691\n",
      "Training:: Epoch 134, Iteration 130, Current loss 0.2818638292965212 Accuracy 56.642728904847395\n",
      "Training:: Epoch 134, Iteration 140, Current loss 0.3005415750196113 Accuracy 54.113584950589356\n",
      "Training:: Epoch 134, Iteration 150, Current loss 0.2354354643426348 Accuracy 67.45567079290733\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 134, Probability Accuracy 53.98682520611509\n",
      "Starting Training\n",
      "Training:: Epoch 135, Iteration 0, Current loss 0.20208000620129818 Accuracy 58.888821125815696\n",
      "Training:: Epoch 135, Iteration 10, Current loss 0.19803014872327024 Accuracy 57.32316727628664\n",
      "Training:: Epoch 135, Iteration 20, Current loss 0.27034837446635634 Accuracy 59.08356883326605\n",
      "Training:: Epoch 135, Iteration 30, Current loss 0.28245109905474985 Accuracy 63.087339201083275\n",
      "Training:: Epoch 135, Iteration 40, Current loss 0.20656716679884796 Accuracy 69.7597911227154\n",
      "Training:: Epoch 135, Iteration 50, Current loss 0.21870892839802727 Accuracy 60.82054197460678\n",
      "Training:: Epoch 135, Iteration 60, Current loss 0.1807948895220569 Accuracy 61.75935550935551\n",
      "Training:: Epoch 135, Iteration 70, Current loss 0.21721887162634337 Accuracy 57.9625087596356\n",
      "Training:: Epoch 135, Iteration 80, Current loss 0.17911953533767666 Accuracy 62.41645244215938\n",
      "Training:: Epoch 135, Iteration 90, Current loss 0.2424005204824987 Accuracy 43.96880101578088\n",
      "Training:: Epoch 135, Iteration 100, Current loss 0.23508909679239015 Accuracy 64.87655580493777\n",
      "Training:: Epoch 135, Iteration 110, Current loss 0.22148208450544168 Accuracy 62.44043140205668\n",
      "Training:: Epoch 135, Iteration 120, Current loss 0.2352483177479278 Accuracy 70.61822443598008\n",
      "Training:: Epoch 135, Iteration 130, Current loss 0.18660871344664348 Accuracy 62.62885062265388\n",
      "Training:: Epoch 135, Iteration 140, Current loss 0.40493198585482937 Accuracy 67.40217477577586\n",
      "Training:: Epoch 135, Iteration 150, Current loss 0.26901160989506767 Accuracy 66.84506655688212\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 135, Probability Accuracy 53.381116128764965\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  58.83035507078208\n",
      "Calculating Expectation\n",
      "Epoch 135 iter 0\n",
      "Epoch 135 iter 10\n",
      "Epoch 135 iter 20\n",
      "Epoch 135 iter 30\n",
      "Epoch 135 iter 40\n",
      "Epoch 135 iter 50\n",
      "Epoch 135 iter 60\n",
      "Epoch 135 iter 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 iter 80\n",
      "Epoch 135 iter 90\n",
      "Epoch 135 iter 100\n",
      "Epoch 135 iter 110\n",
      "Epoch 135 iter 120\n",
      "Epoch 135 iter 130\n",
      "Epoch 135 iter 140\n",
      "Epoch 135 iter 150\n",
      "Train Boundary avergage error = 283.905\n",
      "Train From boundary avergage accuracy = 60.552\n",
      "Starting Training\n",
      "Training:: Epoch 136, Iteration 0, Current loss 0.20974679206774613 Accuracy 58.59110781159779\n",
      "Training:: Epoch 136, Iteration 10, Current loss 0.23705228900080605 Accuracy 66.68174280114579\n",
      "Training:: Epoch 136, Iteration 20, Current loss 0.2939092430094078 Accuracy 59.56989247311828\n",
      "Training:: Epoch 136, Iteration 30, Current loss 0.20940324367320623 Accuracy 74.26027397260275\n",
      "Training:: Epoch 136, Iteration 40, Current loss 0.286029335373896 Accuracy 56.97518851860861\n",
      "Training:: Epoch 136, Iteration 50, Current loss 0.21630673949435159 Accuracy 68.24372335386073\n",
      "Training:: Epoch 136, Iteration 60, Current loss 0.20642225554356075 Accuracy 57.81908302354399\n",
      "Training:: Epoch 136, Iteration 70, Current loss 0.24565141061485724 Accuracy 66.47746937080363\n",
      "Training:: Epoch 136, Iteration 80, Current loss 0.1577968221477533 Accuracy 71.03110457996571\n",
      "Training:: Epoch 136, Iteration 90, Current loss 0.5348252309026869 Accuracy 62.54407522171172\n",
      "Training:: Epoch 136, Iteration 100, Current loss 0.2882113406476612 Accuracy 68.73699375700336\n",
      "Training:: Epoch 136, Iteration 110, Current loss 0.28344620999013526 Accuracy 62.713440405748095\n",
      "Training:: Epoch 136, Iteration 120, Current loss 0.21310279989475675 Accuracy 64.94578339698846\n",
      "Training:: Epoch 136, Iteration 130, Current loss 0.3091352286382543 Accuracy 63.656912456472604\n",
      "Training:: Epoch 136, Iteration 140, Current loss 0.3893381026819017 Accuracy 62.92134831460674\n",
      "Training:: Epoch 136, Iteration 150, Current loss 0.4515749976358797 Accuracy 69.20122131389736\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 136, Probability Accuracy 54.06533537722169\n",
      "Starting Training\n",
      "Training:: Epoch 137, Iteration 0, Current loss 0.4012106643144663 Accuracy 66.58238884045336\n",
      "Training:: Epoch 137, Iteration 10, Current loss 0.332285334536105 Accuracy 69.65546860087802\n",
      "Training:: Epoch 137, Iteration 20, Current loss 0.30949086767396267 Accuracy 62.30218727950811\n",
      "Training:: Epoch 137, Iteration 30, Current loss 1.3028395341005017 Accuracy 64.74816196642159\n",
      "Training:: Epoch 137, Iteration 40, Current loss 0.45768520614494146 Accuracy 60.78637648760602\n",
      "Training:: Epoch 137, Iteration 50, Current loss 0.34898489943755456 Accuracy 64.70435234957517\n",
      "Training:: Epoch 137, Iteration 60, Current loss 0.41445146723987003 Accuracy 55.306372549019606\n",
      "Training:: Epoch 137, Iteration 70, Current loss 0.3507389643551825 Accuracy 69.27769784172662\n",
      "Training:: Epoch 137, Iteration 80, Current loss 0.560573569321495 Accuracy 65.95977395637115\n",
      "Training:: Epoch 137, Iteration 90, Current loss 0.27485740727057745 Accuracy 60.1877368239752\n",
      "Training:: Epoch 137, Iteration 100, Current loss 0.3642267308437765 Accuracy 71.78711823404899\n",
      "Training:: Epoch 137, Iteration 110, Current loss 0.5862828106941949 Accuracy 63.46042597948988\n",
      "Training:: Epoch 137, Iteration 120, Current loss 0.3454955684268443 Accuracy 56.77070086836464\n",
      "Training:: Epoch 137, Iteration 130, Current loss 0.42210456237837024 Accuracy 66.90569665892156\n",
      "Training:: Epoch 137, Iteration 140, Current loss 0.35214817632205536 Accuracy 67.90078519057771\n",
      "Training:: Epoch 137, Iteration 150, Current loss 0.5435174687288766 Accuracy 65.6294334625934\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 137, Probability Accuracy 50.45842482495753\n",
      "Starting Training\n",
      "Training:: Epoch 138, Iteration 0, Current loss 0.3821854839081801 Accuracy 57.44026496333097\n",
      "Training:: Epoch 138, Iteration 10, Current loss 0.4593078118235824 Accuracy 71.47871376811594\n",
      "Training:: Epoch 138, Iteration 20, Current loss 0.42875589356062527 Accuracy 64.53951561504142\n",
      "Training:: Epoch 138, Iteration 30, Current loss 0.41366994537147506 Accuracy 62.715371811597464\n",
      "Training:: Epoch 138, Iteration 40, Current loss 0.3842746152772393 Accuracy 61.32024300282057\n",
      "Training:: Epoch 138, Iteration 50, Current loss 0.4252004320396192 Accuracy 73.55291576673866\n",
      "Training:: Epoch 138, Iteration 60, Current loss 0.9486859084895188 Accuracy 62.040205303678356\n",
      "Training:: Epoch 138, Iteration 70, Current loss 1.320427110863717 Accuracy 63.79633280757098\n",
      "Training:: Epoch 138, Iteration 80, Current loss 1.6602407802412191 Accuracy 65.42056074766356\n",
      "Training:: Epoch 138, Iteration 90, Current loss 1.124253172913349 Accuracy 64.01716206652512\n",
      "Training:: Epoch 138, Iteration 100, Current loss 0.7664940170996237 Accuracy 61.57320286036884\n",
      "Training:: Epoch 138, Iteration 110, Current loss 2.0566914680663824 Accuracy 60.236465463596765\n",
      "Training:: Epoch 138, Iteration 120, Current loss 1.1359998018533426 Accuracy 58.76911600149198\n",
      "Training:: Epoch 138, Iteration 130, Current loss 2.8696440846722706 Accuracy 64.882400648824\n",
      "Training:: Epoch 138, Iteration 140, Current loss 1.2652519319057158 Accuracy 67.82205617822056\n",
      "Training:: Epoch 138, Iteration 150, Current loss 3.6499965063928084 Accuracy 52.672258837627325\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 138, Probability Accuracy 47.02469238099184\n",
      "Starting Training\n",
      "Training:: Epoch 139, Iteration 0, Current loss 4.446203890300538 Accuracy 39.11194406400923\n",
      "Training:: Epoch 139, Iteration 10, Current loss 2.2055863156706597 Accuracy 48.178208571762234\n",
      "Training:: Epoch 139, Iteration 130, Current loss 0.38730372530436935 Accuracy 65.00422654268809\n",
      "Training:: Epoch 139, Iteration 140, Current loss 0.32457729709456556 Accuracy 62.2507614531981\n",
      "Training:: Epoch 139, Iteration 150, Current loss 0.5087016676579593 Accuracy 72.79362227711655\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 139, Probability Accuracy 54.77689853751502\n",
      "Starting Training\n",
      "Training:: Epoch 140, Iteration 0, Current loss 0.36084578942084244 Accuracy 66.50660264105642\n",
      "Training:: Epoch 140, Iteration 10, Current loss 0.382510083184039 Accuracy 60.109005969374515\n",
      "Training:: Epoch 140, Iteration 20, Current loss 0.25355703549295616 Accuracy 69.77898938759614\n",
      "Training:: Epoch 140, Iteration 30, Current loss 0.3528534793915341 Accuracy 67.53138611324623\n",
      "Training:: Epoch 140, Iteration 40, Current loss 0.3017083023714433 Accuracy 67.03478414929428\n",
      "Training:: Epoch 140, Iteration 50, Current loss 0.3033547674103547 Accuracy 69.23726860741992\n",
      "Training:: Epoch 140, Iteration 60, Current loss 0.3139457022541938 Accuracy 68.59498454139471\n",
      "Training:: Epoch 140, Iteration 70, Current loss 0.29060121643302833 Accuracy 75.4982745263751\n",
      "Training:: Epoch 140, Iteration 80, Current loss 0.2950004287187496 Accuracy 62.212041884816756\n",
      "Training:: Epoch 140, Iteration 90, Current loss 0.2798112662313438 Accuracy 62.318769351747186\n",
      "Training:: Epoch 140, Iteration 100, Current loss 0.26710566830569454 Accuracy 73.38627914836093\n",
      "Training:: Epoch 140, Iteration 110, Current loss 0.24002874428579415 Accuracy 55.112770496799754\n",
      "Training:: Epoch 140, Iteration 120, Current loss 0.28770260293363714 Accuracy 67.30628654970761\n",
      "Training:: Epoch 140, Iteration 130, Current loss 0.26380343560804603 Accuracy 66.19484137683114\n",
      "Training:: Epoch 140, Iteration 140, Current loss 0.28884325759916635 Accuracy 58.48288890503524\n",
      "Training:: Epoch 140, Iteration 150, Current loss 0.31435531047040355 Accuracy 61.591488086317995\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 140, Probability Accuracy 55.04909475079753\n",
      "Calculating Expectation\n",
      "Epoch 140 iter 0\n",
      "Epoch 140 iter 10\n",
      "Epoch 140 iter 20\n",
      "Epoch 140 iter 30\n",
      "Epoch 140 iter 40\n",
      "Epoch 140 iter 50\n",
      "Epoch 140 iter 60\n",
      "Epoch 140 iter 70\n",
      "Epoch 140 iter 80\n",
      "Epoch 140 iter 90\n",
      "Epoch 140 iter 100\n",
      "Epoch 140 iter 110\n",
      "Epoch 140 iter 120\n",
      "Epoch 140 iter 130\n",
      "Epoch 140 iter 140\n",
      "Epoch 140 iter 150\n",
      "Train Boundary avergage error = 283.818\n",
      "Train From boundary avergage accuracy = 60.608\n",
      "Starting Training\n",
      "Training:: Epoch 141, Iteration 0, Current loss 0.26032613651352043 Accuracy 68.12304631997726\n",
      "Training:: Epoch 141, Iteration 10, Current loss 0.2739689723804579 Accuracy 49.19120964103886\n",
      "Training:: Epoch 141, Iteration 20, Current loss 0.28374900422421595 Accuracy 59.99645043925814\n",
      "Training:: Epoch 141, Iteration 30, Current loss 0.28538730601455964 Accuracy 59.03776978417266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 141, Iteration 40, Current loss 0.24737722412463103 Accuracy 63.376344086021504\n",
      "Training:: Epoch 141, Iteration 50, Current loss 0.2684620981001807 Accuracy 53.771025501899075\n",
      "Training:: Epoch 141, Iteration 60, Current loss 0.21235539825255517 Accuracy 51.31791285637439\n",
      "Training:: Epoch 141, Iteration 70, Current loss 0.1878591541722 Accuracy 63.84558733276052\n",
      "Training:: Epoch 141, Iteration 80, Current loss 0.24873919513136405 Accuracy 64.06297701600593\n",
      "Training:: Epoch 141, Iteration 90, Current loss 0.2037882820686207 Accuracy 67.3336693548387\n",
      "Training:: Epoch 141, Iteration 100, Current loss 0.2420311446007865 Accuracy 66.26513391219274\n",
      "Training:: Epoch 141, Iteration 110, Current loss 0.22084330818490416 Accuracy 66.22101878490439\n",
      "Training:: Epoch 141, Iteration 120, Current loss 0.18920834578340281 Accuracy 71.41495753055729\n",
      "Training:: Epoch 141, Iteration 130, Current loss 0.2542032799576971 Accuracy 62.51489868891537\n",
      "Training:: Epoch 141, Iteration 140, Current loss 0.20625940335430945 Accuracy 69.72488282046056\n",
      "Training:: Epoch 141, Iteration 150, Current loss 0.21034143264898833 Accuracy 72.07248432709468\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 141, Probability Accuracy 55.535277789286155\n",
      "Starting Training\n",
      "Training:: Epoch 142, Iteration 0, Current loss 0.20657099058862233 Accuracy 64.82876225664346\n",
      "Training:: Epoch 142, Iteration 10, Current loss 0.20901217903058453 Accuracy 62.448132780082986\n",
      "Training:: Epoch 142, Iteration 20, Current loss 0.2145059167075483 Accuracy 65.33724021921971\n",
      "Training:: Epoch 142, Iteration 30, Current loss 0.19375681213841062 Accuracy 74.26106888647605\n",
      "Training:: Epoch 142, Iteration 40, Current loss 0.17873345019711734 Accuracy 69.1384146041431\n",
      "Training:: Epoch 142, Iteration 50, Current loss 0.21131905471767826 Accuracy 64.95100371039862\n",
      "Training:: Epoch 142, Iteration 60, Current loss 0.21266523722150288 Accuracy 64.45258309749737\n",
      "Training:: Epoch 142, Iteration 70, Current loss 0.17674009983826203 Accuracy 58.43501457293879\n",
      "Training:: Epoch 142, Iteration 80, Current loss 0.22256097568859856 Accuracy 63.3984997932786\n",
      "Training:: Epoch 142, Iteration 90, Current loss 0.25264943819963953 Accuracy 64.592186429061\n",
      "Training:: Epoch 142, Iteration 100, Current loss 0.22378587854334767 Accuracy 63.57438247457248\n",
      "Training:: Epoch 142, Iteration 110, Current loss 0.1684909248096986 Accuracy 65.78830932599183\n",
      "Training:: Epoch 142, Iteration 120, Current loss 0.18067481737018198 Accuracy 55.68280123583934\n",
      "Training:: Epoch 142, Iteration 130, Current loss 0.21934294864290912 Accuracy 63.413611310807575\n",
      "Training:: Epoch 142, Iteration 140, Current loss 0.17629574172643767 Accuracy 63.84086648614872\n",
      "Training:: Epoch 142, Iteration 150, Current loss 0.21447019630528105 Accuracy 69.31317581097316\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 142, Probability Accuracy 54.86473049674773\n",
      "Starting Training\n",
      "Training:: Epoch 143, Iteration 0, Current loss 0.35793978834601775 Accuracy 47.69079271294929\n",
      "Training:: Epoch 143, Iteration 10, Current loss 0.1901065396836526 Accuracy 62.575327284061785\n",
      "Training:: Epoch 143, Iteration 20, Current loss 0.15982577612855278 Accuracy 64.83873348586611\n",
      "Training:: Epoch 143, Iteration 30, Current loss 0.20663376512243156 Accuracy 64.2080638502821\n",
      "Training:: Epoch 143, Iteration 40, Current loss 0.23058688400171617 Accuracy 62.049485933792795\n",
      "Training:: Epoch 143, Iteration 50, Current loss 0.2558833092336663 Accuracy 67.93472014710953\n",
      "Training:: Epoch 143, Iteration 60, Current loss 0.19579228069388951 Accuracy 69.42687945397972\n",
      "Training:: Epoch 143, Iteration 70, Current loss 0.17704062041509253 Accuracy 60.52258977989445\n",
      "Training:: Epoch 143, Iteration 80, Current loss 0.2118753202038465 Accuracy 53.266078184110974\n",
      "Training:: Epoch 143, Iteration 90, Current loss 0.22480510954404478 Accuracy 73.36452803023487\n",
      "Training:: Epoch 143, Iteration 100, Current loss 0.1732301110883411 Accuracy 70.96512570965126\n",
      "Training:: Epoch 143, Iteration 110, Current loss 0.25560760684322303 Accuracy 68.26479808224231\n",
      "Training:: Epoch 143, Iteration 120, Current loss 0.21210451676912062 Accuracy 54.87719787887245\n",
      "Training:: Epoch 143, Iteration 130, Current loss 0.23248914211101332 Accuracy 58.332505217132066\n",
      "Training:: Epoch 143, Iteration 140, Current loss 0.26991447405021457 Accuracy 62.88213244481466\n",
      "Training:: Epoch 143, Iteration 150, Current loss 0.14994410262194457 Accuracy 70.9216738512067\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 143, Probability Accuracy 55.16033475576915\n",
      "Starting Training\n",
      "Training:: Epoch 144, Iteration 0, Current loss 0.15168451064939828 Accuracy 59.245569140365845\n",
      "Training:: Epoch 144, Iteration 10, Current loss 0.2178964728699617 Accuracy 66.28204328572319\n",
      "Training:: Epoch 144, Iteration 20, Current loss 0.18544361941961862 Accuracy 59.63960342979635\n",
      "Training:: Epoch 144, Iteration 30, Current loss 0.21069054606616397 Accuracy 61.92599197503344\n",
      "Training:: Epoch 144, Iteration 40, Current loss 0.22588122753640996 Accuracy 64.57198298380476\n",
      "Training:: Epoch 144, Iteration 50, Current loss 0.2700336706803979 Accuracy 59.594755661501786\n",
      "Training:: Epoch 144, Iteration 60, Current loss 0.19058452190595881 Accuracy 73.28304164152082\n",
      "Training:: Epoch 144, Iteration 70, Current loss 0.19069001492619556 Accuracy 54.35662127491612\n",
      "Training:: Epoch 144, Iteration 80, Current loss 0.17671033842544595 Accuracy 64.49643947100712\n",
      "Training:: Epoch 144, Iteration 90, Current loss 0.18631477144027164 Accuracy 59.909235745666976\n",
      "Training:: Epoch 144, Iteration 100, Current loss 0.18141531005076858 Accuracy 59.60488166677904\n",
      "Training:: Epoch 144, Iteration 110, Current loss 0.16495171963005878 Accuracy 66.38225754609473\n",
      "Training:: Epoch 144, Iteration 120, Current loss 0.21038385567090587 Accuracy 64.52355170546832\n",
      "Training:: Epoch 144, Iteration 130, Current loss 0.17025116544841956 Accuracy 67.68577956696768\n",
      "Training:: Epoch 144, Iteration 140, Current loss 0.22848284124493445 Accuracy 66.71283762513379\n",
      "Training:: Epoch 144, Iteration 150, Current loss 0.21080487179927965 Accuracy 74.45568005830373\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 144, Probability Accuracy 54.90346770518291\n",
      "Starting Training\n",
      "Training:: Epoch 145, Iteration 0, Current loss 0.18690995021148352 Accuracy 64.41885510728191\n",
      "Training:: Epoch 145, Iteration 10, Current loss 0.1579774409248049 Accuracy 58.20848938826467\n",
      "Training:: Epoch 145, Iteration 20, Current loss 0.23446370315048473 Accuracy 60.995542347696876\n",
      "Training:: Epoch 145, Iteration 30, Current loss 0.24292351205037865 Accuracy 74.6602534738128\n",
      "Training:: Epoch 145, Iteration 40, Current loss 0.26262324061981623 Accuracy 66.34079409999143\n",
      "Training:: Epoch 145, Iteration 50, Current loss 0.14504709450512285 Accuracy 57.853083561355504\n",
      "Training:: Epoch 145, Iteration 60, Current loss 0.22879775266960772 Accuracy 60.150635710337205\n",
      "Training:: Epoch 145, Iteration 70, Current loss 0.3229546794269386 Accuracy 55.840421708398225\n",
      "Training:: Epoch 145, Iteration 80, Current loss 0.2887150191029911 Accuracy 63.14484126984127\n",
      "Training:: Epoch 145, Iteration 90, Current loss 0.222011569527688 Accuracy 66.92870905587668\n",
      "Training:: Epoch 145, Iteration 100, Current loss 0.2209139806358993 Accuracy 70.90669014084507\n",
      "Training:: Epoch 145, Iteration 110, Current loss 0.16474868291943323 Accuracy 67.92503108900337\n",
      "Training:: Epoch 145, Iteration 120, Current loss 0.20296315481512706 Accuracy 50.8439166529221\n",
      "Training:: Epoch 145, Iteration 130, Current loss 0.23405640190291596 Accuracy 56.336985490079954\n",
      "Training:: Epoch 145, Iteration 140, Current loss 0.18208084875637626 Accuracy 71.82006479366935\n",
      "Training:: Epoch 145, Iteration 150, Current loss 0.2195588363707849 Accuracy 57.62929925379535\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 145, Probability Accuracy 54.50677383270497\n",
      "Calculating Expectation\n",
      "Epoch 145 iter 0\n",
      "Epoch 145 iter 10\n",
      "Epoch 145 iter 20\n",
      "Epoch 145 iter 30\n",
      "Epoch 145 iter 40\n",
      "Epoch 145 iter 50\n",
      "Epoch 145 iter 60\n",
      "Epoch 145 iter 70\n",
      "Epoch 145 iter 80\n",
      "Epoch 145 iter 90\n",
      "Epoch 145 iter 100\n",
      "Epoch 145 iter 110\n",
      "Epoch 145 iter 120\n",
      "Epoch 145 iter 130\n",
      "Epoch 145 iter 140\n",
      "Epoch 145 iter 150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Boundary avergage error = 284.035\n",
      "Train From boundary avergage accuracy = 60.560\n",
      "Starting Training\n",
      "Training:: Epoch 146, Iteration 0, Current loss 0.21145611924585372 Accuracy 47.81017970515442\n",
      "Training:: Epoch 146, Iteration 10, Current loss 0.1457398370396441 Accuracy 64.73150088335593\n",
      "Training:: Epoch 146, Iteration 20, Current loss 0.21164484269327966 Accuracy 66.47843658307036\n",
      "Training:: Epoch 146, Iteration 30, Current loss 0.17149816715008162 Accuracy 69.38114267199481\n",
      "Training:: Epoch 146, Iteration 40, Current loss 0.20266180566280617 Accuracy 64.0592905124077\n",
      "Training:: Epoch 146, Iteration 50, Current loss 0.14767221563942956 Accuracy 72.5730278117894\n",
      "Training:: Epoch 146, Iteration 60, Current loss 0.15236930369306478 Accuracy 70.03369366839814\n",
      "Training:: Epoch 146, Iteration 70, Current loss 0.1495852116076083 Accuracy 72.76624359082122\n",
      "Training:: Epoch 146, Iteration 80, Current loss 0.23838198436305713 Accuracy 56.87540348612008\n",
      "Training:: Epoch 146, Iteration 90, Current loss 0.16841617876677503 Accuracy 65.02475892624446\n",
      "Training:: Epoch 146, Iteration 100, Current loss 0.17514309686164173 Accuracy 64.5988708440789\n",
      "Training:: Epoch 146, Iteration 110, Current loss 0.22350105327088504 Accuracy 52.054039150813345\n",
      "Training:: Epoch 146, Iteration 120, Current loss 0.1915559578226051 Accuracy 72.03321878579611\n",
      "Training:: Epoch 146, Iteration 130, Current loss 0.27891902086850723 Accuracy 67.21296034661393\n",
      "Training:: Epoch 146, Iteration 140, Current loss 0.18176734467988856 Accuracy 79.23659587108273\n",
      "Training:: Epoch 146, Iteration 150, Current loss 0.17157364064874778 Accuracy 70.74739009500415\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 146, Probability Accuracy 54.79429920868376\n",
      "Starting Training\n",
      "Training:: Epoch 147, Iteration 0, Current loss 0.18782688802190164 Accuracy 51.49513388129696\n",
      "Training:: Epoch 147, Iteration 10, Current loss 0.14841220376888 Accuracy 66.96275449628425\n",
      "Training:: Epoch 147, Iteration 20, Current loss 0.13283245415496317 Accuracy 71.57809110629067\n",
      "Training:: Epoch 147, Iteration 30, Current loss 0.21967901723834143 Accuracy 68.76988335100742\n",
      "Training:: Epoch 147, Iteration 40, Current loss 0.1675296998477577 Accuracy 69.47413793103448\n",
      "Training:: Epoch 147, Iteration 50, Current loss 0.1555575433697413 Accuracy 70.55442567866301\n",
      "Training:: Epoch 147, Iteration 60, Current loss 0.21007867142839973 Accuracy 68.42330396098896\n",
      "Training:: Epoch 147, Iteration 70, Current loss 0.19281639043584894 Accuracy 63.064570090331216\n",
      "Training:: Epoch 147, Iteration 80, Current loss 0.2209214139510164 Accuracy 74.98544537162817\n",
      "Training:: Epoch 147, Iteration 90, Current loss 0.18602418840801713 Accuracy 64.56057474658006\n",
      "Training:: Epoch 147, Iteration 100, Current loss 0.24717040799986714 Accuracy 63.641613728240245\n",
      "Training:: Epoch 147, Iteration 110, Current loss 0.21690000785554425 Accuracy 64.09129875696529\n",
      "Training:: Epoch 147, Iteration 120, Current loss 0.17579939628891925 Accuracy 61.6245384833854\n",
      "Training:: Epoch 147, Iteration 130, Current loss 0.2879147612121601 Accuracy 59.60762331838565\n",
      "Training:: Epoch 147, Iteration 140, Current loss 0.22098491080224683 Accuracy 61.50901371197884\n",
      "Training:: Epoch 147, Iteration 150, Current loss 0.19718256730359532 Accuracy 61.78214957326776\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 147, Probability Accuracy 54.63365372664374\n",
      "Starting Training\n",
      "Training:: Epoch 148, Iteration 0, Current loss 0.2983565010080739 Accuracy 49.51814969482814\n",
      "Training:: Epoch 148, Iteration 10, Current loss 0.2128829902759063 Accuracy 63.23842334583038\n",
      "Training:: Epoch 148, Iteration 20, Current loss 0.23398654378260106 Accuracy 51.61141804788214\n",
      "Training:: Epoch 148, Iteration 30, Current loss 0.16235301647132136 Accuracy 63.82633823166649\n",
      "Training:: Epoch 148, Iteration 40, Current loss 0.21593378459451493 Accuracy 64.84978882779504\n",
      "Training:: Epoch 148, Iteration 50, Current loss 0.16732028994005838 Accuracy 61.1533551645668\n",
      "Training:: Epoch 148, Iteration 60, Current loss 0.20475340064397374 Accuracy 60.04910260751778\n",
      "Training:: Epoch 148, Iteration 70, Current loss 0.16204842661444951 Accuracy 68.09371016658608\n",
      "Training:: Epoch 148, Iteration 80, Current loss 0.2288257696251479 Accuracy 64.54708425603712\n",
      "Training:: Epoch 148, Iteration 90, Current loss 0.17045986414292488 Accuracy 70.76530921891121\n",
      "Training:: Epoch 148, Iteration 100, Current loss 0.1693941436812817 Accuracy 69.51138256524153\n",
      "Training:: Epoch 148, Iteration 110, Current loss 0.16244064960988083 Accuracy 66.84560327198363\n",
      "Training:: Epoch 148, Iteration 120, Current loss 0.1261659094650169 Accuracy 69.81086904476898\n",
      "Training:: Epoch 148, Iteration 130, Current loss 0.14318708974841715 Accuracy 61.10328638497653\n",
      "Training:: Epoch 148, Iteration 140, Current loss 0.1835694866548247 Accuracy 62.30862351349427\n",
      "Training:: Epoch 148, Iteration 150, Current loss 0.1718775232695161 Accuracy 76.21027937726595\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 148, Probability Accuracy 54.790674068856944\n",
      "Starting Training\n",
      "Training:: Epoch 149, Iteration 0, Current loss 0.18600141922978536 Accuracy 65.05939629990263\n",
      "Training:: Epoch 149, Iteration 10, Current loss 0.24711827219420682 Accuracy 63.15231386806029\n",
      "Training:: Epoch 149, Iteration 20, Current loss 0.1529054383647242 Accuracy 72.6470588235294\n",
      "Training:: Epoch 149, Iteration 30, Current loss 0.22036095108073053 Accuracy 65.37302853092326\n",
      "Training:: Epoch 149, Iteration 40, Current loss 0.15216248730887044 Accuracy 57.2766499950966\n",
      "Training:: Epoch 149, Iteration 50, Current loss 0.15847352252452443 Accuracy 70.15683074970538\n",
      "Training:: Epoch 149, Iteration 60, Current loss 0.2115846153714056 Accuracy 67.86768753440424\n",
      "Training:: Epoch 149, Iteration 70, Current loss 0.1881206960481321 Accuracy 59.219977176612744\n",
      "Training:: Epoch 149, Iteration 80, Current loss 0.10469628864364502 Accuracy 66.35772877383616\n",
      "Training:: Epoch 149, Iteration 90, Current loss 0.1486284109224064 Accuracy 64.86997635933807\n",
      "Training:: Epoch 149, Iteration 100, Current loss 0.19567021086157158 Accuracy 72.41353039768399\n",
      "Training:: Epoch 149, Iteration 110, Current loss 0.16221259880395525 Accuracy 67.93958680608173\n",
      "Training:: Epoch 149, Iteration 120, Current loss 0.1665926618653562 Accuracy 55.182941842714335\n",
      "Training:: Epoch 149, Iteration 130, Current loss 0.18550652736644796 Accuracy 74.20415319708509\n",
      "Training:: Epoch 149, Iteration 140, Current loss 0.23658508614136833 Accuracy 68.86750555144337\n",
      "Training:: Epoch 149, Iteration 150, Current loss 0.15193424664924746 Accuracy 58.32435237296931\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 149, Probability Accuracy 54.39232298960103\n"
     ]
    }
   ],
   "source": [
    "initialize_epoch = 25\n",
    "expectation_cal_gap = 5\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(25, 150):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        psuedo_l = get_single_random(predictions[-1], item[4])\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, psuedo_l)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                            max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                es_loss, _ = get_estimated_loss(prob, item_1, item[4])\n",
    "                loss += es_loss\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(predictions[-1], dim=1)\n",
    "                correct = float(torch.sum((pred == item_2) * src_mask).item())\n",
    "                total = float(torch.sum(src_mask).item())\n",
    "                print(f\"Training:: Epoch {epoch}, Iteration {i}, Current loss {loss.item()}\" +\n",
    "                      f\" Accuracy {correct * 100.0 / total}\")\n",
    "\n",
    "    # Calculating Expectation Step\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-last-model.wt\")\n",
    "    print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")\n",
    "\n",
    "    if (epoch == initialize_epoch) or ((epoch > initialize_epoch) and ((epoch % (3 * expectation_cal_gap)) == 0)):\n",
    "        torch.save(model.state_dict(), config.output_dir + f\"ms-tcn-initial-{initialize_epoch}-epochs.wt\")\n",
    "        selected_frames_dict = change_selected_frames(model)\n",
    "        get_new_selected_frame_acc(selected_frames_dict)\n",
    "\n",
    "    if (epoch == initialize_epoch) or ((epoch > initialize_epoch) and (epoch % expectation_cal_gap == 0)):\n",
    "        print(\"Calculating Expectation\")\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, item in enumerate(trainloader):\n",
    "            with torch.no_grad():\n",
    "                item_0 = item[0].to(device)\n",
    "                item_1 = item[1].to(device)\n",
    "                item_2 = item[2].to(device)\n",
    "                src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "                src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "                middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "                prob = torch.softmax(predictions[-1], dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                calculate_element_probb(prob, item_1, item[4])\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Epoch {epoch} iter {i}\")\n",
    "                    \n",
    "        get_boundary_err()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 130, Probability Accuracy 51.43919338691232\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.61000906173455"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-emmax-best-model.wt\"))\n",
    "# model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-initial-15-epochs.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.625639564561894\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Validation Data Accuracy\")\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "        pred = torch.argmax(predictions[-1], dim=1)\n",
    "        correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "        total += float(torch.sum(src_mask).item())\n",
    "\n",
    "print(f\"Validation:: Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration done\n",
      "11 iteration done\n",
      "21 iteration done\n",
      "31 iteration done\n",
      "41 iteration done\n",
      "51 iteration done\n",
      "61 iteration done\n",
      "71 iteration done\n",
      "81 iteration done\n",
      "91 iteration done\n",
      "101 iteration done\n",
      "111 iteration done\n",
      "121 iteration done\n",
      "131 iteration done\n",
      "141 iteration done\n",
      "151 iteration done\n",
      "161 iteration done\n",
      "171 iteration done\n",
      "181 iteration done\n",
      "Train Boundary avergage error = 307.224\n",
      "Train From boundary avergage accuracy = 57.704\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        prob = torch.softmax(predictions[-1], dim=1)\n",
    "        prob = prob.permute(0, 2, 1)\n",
    "        calculate_element_probb(prob, item_1, item[4])\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f'{i+1} iteration done')\n",
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    idx = 1\n",
    "\n",
    "    cur_vid_feat = torch.softmax(predictions[-1], dim=1).permute(0, 2, 1)[idx]\n",
    "    cur_vidid = item[4][idx]\n",
    "\n",
    "    selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "    selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "    selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "    \n",
    "    cumsum_feat = torch.cumsum(cur_vid_feat, dim=0)\n",
    "    prob_each_segment = prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 228, 481, 735, 1578, 2388, 2567, 2745]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_frames_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[88, 229, 578, 1128, 2241, 2479, 2720, 2810]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_frames_dict[cur_vidid + \".txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min prob 0 = 0.0\n",
      "Min prob 1 = 0.0\n",
      "Min prob 2 = 0.0\n",
      "Min prob 3 = 0.0\n",
      "Min prob 4 = 0.0\n",
      "Min prob 5 = 7.224189870987231e-126\n",
      "Min prob 6 = 4.631831900603335e-244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 2811)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ymax = 1\n",
    "\n",
    "plt.plot([0, item[1][idx].item()], [0, 0])\n",
    "\n",
    "for pivot in selected_frames_indices:\n",
    "    plt.plot([pivot, pivot], [0, ymax], '--')\n",
    "    \n",
    "for pivot in boundary_frames_dict[cur_vidid + \".txt\"]:\n",
    "    plt.plot([pivot, pivot], [0, ymax])\n",
    "    \n",
    "all_prob = []\n",
    "for i, segment in enumerate(prob_each_segment):\n",
    "    segment = segment.cpu().numpy()\n",
    "    print(f\"Min prob {i} = {np.min(segment).item()}\")\n",
    "    xs = np.arange(selected_frames_indices[i], \n",
    "                   selected_frames_indices[i+1])\n",
    "    plt.plot(xs, segment, '*')\n",
    "\n",
    "    \n",
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "\n",
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]])\n",
    "loss_arr = -loss_arr[0].detach().cpu().numpy()\n",
    "plt.plot(np.arange(selected_frames_indices[0] - 1, selected_frames_indices[-1] + 1), loss_arr/np.max(loss_arr), 'k+')\n",
    "\n",
    "plt.ylim([0, ymax])\n",
    "plt.xlim([0, item[1][idx].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1895, 48])\n"
     ]
    }
   ],
   "source": [
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "print(loss_prob.shape)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]], item_2[idx].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1387])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faf5b8ecb00>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "plt.plot(np.arange(selected_frames[0] - 1, selected_frames[-1] + 1), loss_arr[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3987, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([75, 345, 1305, 1415, 1440, 1519],\n",
       " [73, 282, 455, 1312, 1434, 1458],\n",
       " tensor(1520, device='cuda:0', dtype=torch.int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid], loaded_vidid_selected_frames[cur_vidid + \".txt\"], item_1[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_features_shortened = cur_vid_feat[:item[1][idx]]\n",
    "cur_features_shortened[:, item[2][idx][:item[1][idx]]].shape\n",
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47, 47, 47, 47, 47, 47, 47,  4,  4,  4,  4,  4,  4,  4,  4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[2][idx][video_id_boundary_frames[cur_vidid][1]-6:video_id_boundary_frames[cur_vidid][1]+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid][0]-6,video_id_boundary_frames[cur_vidid][0]+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0794, 13.3350],\n",
       "        [ 1.0831, 13.5102],\n",
       "        [ 1.1767, 13.7662],\n",
       "        [ 1.3750, 14.0177],\n",
       "        [ 1.7298, 14.1727],\n",
       "        [ 2.1706, 14.0367],\n",
       "        [ 2.7338, 13.4563],\n",
       "        [ 4.5600, 12.1745],\n",
       "        [ 7.8450, 10.3246],\n",
       "        [11.0151,  8.3563],\n",
       "        [13.4775,  6.6546],\n",
       "        [14.1836,  5.2898],\n",
       "        [11.2142,  4.2791],\n",
       "        [ 5.9829,  3.5694],\n",
       "        [ 2.3440,  2.9389],\n",
       "        [ 0.7406,  2.3515]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_vid_feat[video_id_boundary_frames[cur_vidid][1]-7:video_id_boundary_frames[cur_vidid][1]+9][:,[47,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frames_and_get_classification_value(model_output, count_list, video_ids_list, labels_all, p_criterion):\n",
    "    new_selected_frames = {}\n",
    "#     new_selected_frames_probs_values = {}\n",
    "#     new_selected_frames_labels = {}\n",
    "    \n",
    "    labels_arr = []\n",
    "    probs_arr = []\n",
    "    \n",
    "    for i, video_id in enumerate(video_ids_list):\n",
    "        current_boundary_frames = boundaries_dict[video_id]\n",
    "        current_video_logits = model_output[i].T\n",
    "        current_video_count = count_list[i]\n",
    "        current_selected_frames = loaded_vidid_selected_frames[video_id]\n",
    "        labels = labels_all[i]\n",
    "        cur_seg_start = 0\n",
    "        for seg_num, ele in enumerate(current_boundary_frames):\n",
    "            cur_seg_end = ele + 1\n",
    "            total_seg_len = cur_seg_end - cur_seg_start\n",
    "            per_frames_far_from_boundary = int(0.3 * total_seg_len)\n",
    "            new_frames_start = cur_seg_start + per_frames_far_from_boundary\n",
    "            new_frames_end = cur_seg_end - per_frames_far_from_boundary\n",
    "            \n",
    "            frames_added = list(range(new_frames_start, new_frames_end))\n",
    "            frames_added.append(current_selected_frames[seg_num])\n",
    "            frames_added = list(set(frames_added))\n",
    "            frames_added.sort()\n",
    "            new_selected_frames[video_id] = frames_added\n",
    "\n",
    "            \n",
    "            labels_seg = torch.stack([labels[current_selected_frames[seg_num]]] * len(frames_added))\n",
    "            frames_added = torch.tensor(np.array(frames_added), dtype=torch.long, device=current_video_logits.device)\n",
    "            prob_seg = current_video_logits[frames_added, :]\n",
    "            \n",
    "            labels_arr.append(labels_seg)\n",
    "            probs_arr.append(prob_seg)\n",
    "            \n",
    "            cur_seg_start = cur_seg_end\n",
    "            \n",
    "    labels_arr = torch.cat(labels_arr)\n",
    "    probs_arr = torch.cat(probs_arr)\n",
    "    loss = p_criterion(probs_arr, labels_arr)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mask_for_this_class(video_len, weakly_labels_video, old_index_label_pair_list, \n",
    "                             cur_ele_searched, cur_index_searched):\n",
    "    searched_label_index = np.where(cur_ele_searched == np.array(weakly_labels_video))[0]\n",
    "    if len(searched_label_index) <= 1:\n",
    "        mask = torch.ones(video_len)\n",
    "        return mask\n",
    "    else:\n",
    "        start = 0\n",
    "        for i, index in enumerate(searched_label_index[:-1]):\n",
    "            cur_index_frame_selected = old_index_label_pair_list[index][0]\n",
    "            next_index = searched_label_index[i + 1]\n",
    "            next_index_frame_selected = old_index_label_pair_list[next_index][0]\n",
    "            \n",
    "            mid_select = (cur_index_frame_selected + next_index_frame_selected) // 2\n",
    "            \n",
    "            if index == cur_index_searched:\n",
    "                mask = torch.zeros(video_len)\n",
    "                mask[start: mid_select + 1] = 1\n",
    "                return mask\n",
    "            \n",
    "            start = mid_select\n",
    "        if searched_label_index[-1] == cur_index_searched:\n",
    "            mask = torch.zeros(video_len)\n",
    "            mask[start: video_len] = 1\n",
    "            return mask\n",
    "        else:\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "            return \"Error 1\"\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2, 2, 2, 2, 3, 3, 4, 4, 3, 3, 2, 2, 2, 2]\n",
    "find_mask_for_this_class(12, [2, 3, 4, 3,  2], [3, 5, 7, 8, 10], 4, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
