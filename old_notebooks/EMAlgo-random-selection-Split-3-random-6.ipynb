{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from time import time\n",
    "from utils import get_all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utility.adaptive_data_loader import BreakfastWithWeights, collate_fn_override_wtd\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='5'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temp': 1, 'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 3, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select6-temp1-exp4/split3/', 'project_name': 'breakfast-split-1', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split3.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split3.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split3_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    temp=1,\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=3,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select6-temp1-exp4/\",\n",
    "    project_name=\"breakfast-split-1\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "config.output_dir = config.output_dir + f\"split{config.split}\"\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "config.output_dir = config.output_dir + \"/\"\n",
    "if not os.path.exists(os.path.join(config.output_dir, \"posterior_weights\")):\n",
    "    os.mkdir(os.path.join(config.output_dir, \"posterior_weights\"))\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1279\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 433\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = BreakfastWithWeights(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override_wtd(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "\n",
    "trainloder_expectation = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=20,\n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override_wtd(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_frames_dict = pickle.load(open(\"data/breakfast_len_assum_annotations.pkl\", 'rb'))\n",
    "# loaded_vidid_selected_frames\n",
    "boundary_frames_dict = pickle.load(open(\"data/breakfast_boundary_annotations.pkl\", \"rb\"))\n",
    "num_boundary = 0\n",
    "for key in boundary_frames_dict.keys():\n",
    "    num_boundary += len(boundary_frames_dict[key])\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frames_dict = pickle.load(open(\"data/breakfast_random6frame_selection.pkl\", \"rb\"))\n",
    "# print(selected_frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"data/breakfast_meanvar_actions.pkl\", \"rb\"))\n",
    "mat_poisson = pickle.load(open(\"data/breakfast_possion_class_dict.pkl\", \"rb\"))\n",
    "\n",
    "def get_possion_prob(minlen, maxlen, cur_class):\n",
    "    prob = mat_poisson[label_id_to_label_name[cur_class]][minlen:maxlen]\n",
    "    return torch.tensor(prob)\n",
    "\n",
    "def get_poisson_logcdf(minlen, cur_class):\n",
    "    return np.log(np.sum(np.exp(mat_poisson[label_id_to_label_name[cur_class]][minlen:])) + 1e-20)\n",
    "\n",
    "def get_possion_prob_for_all_class(minlen, maxlen):\n",
    "    ele_list = []\n",
    "    for i in range(config.num_class):\n",
    "        prob = mat_poisson[label_id_to_label_name[i]][minlen:maxlen]\n",
    "        ele_list.append(torch.tensor(prob))\n",
    "    return torch.stack(ele_list, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, best_val_acc=None):\n",
    "    model.eval()\n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    vidcount = 0\n",
    "    all_scores = []\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "            for p, l, c in zip(pred, item_2, item_1):\n",
    "                all_scores.append(get_all_scores(p[:c].detach().cpu().numpy(), \n",
    "                                                 l[:c].detach().cpu().numpy(), ['SIL']))\n",
    "            \n",
    "    final_scores = np.mean(np.array(all_scores), axis=0)\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if best_val_acc is not None and val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-last-model.wt\")\n",
    "    print(f\"Validation:: Probability Accuracy {val_acc}\")\n",
    "    print(f\"Other scores:: Edit {final_scores[3]}, F1@[10:25:50] {final_scores[:3]}\")\n",
    "    _ = model.train()\n",
    "    return val_acc, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels, first_ele_flag, last_ele_flag, vidid, gt_labels):\n",
    "    prob_each_segment = []\n",
    "    LOW_VAL = -10000000\n",
    "    num_frames = len(cur_vid_feat)\n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    prev_boundary = 0\n",
    "    per_frame_weights = torch.zeros((num_frames, config.num_class))\n",
    "    start_time = time()\n",
    "    boundary_error = 0\n",
    "    current_boundary = 0\n",
    "    labels = [config.num_class-1] + labels if selected_frames[0] != 0 else labels\n",
    "    labels = labels + [config.num_class-1] if selected_frames[-1] != num_frames-1 else labels\n",
    "    selected_frames = [0] + selected_frames if selected_frames[0] != 0 else selected_frames\n",
    "    selected_frames = selected_frames + [num_frames-1] if selected_frames[-1] != num_frames-1 else selected_frames\n",
    "\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[i]\n",
    "        label_next_ele = labels[i + 1]\n",
    "        if cur_ele == next_ele-1:\n",
    "            per_frame_weights[cur_ele, label_cur_ele] = 1.0\n",
    "            if label_cur_ele != label_next_ele:\n",
    "                prev_boundary = cur_ele\n",
    "            continue\n",
    "        \n",
    "        seg_len = next_ele - cur_ele\n",
    "        mat_b1_b2_c_prob = LOW_VAL * torch.ones((seg_len, seg_len, config.num_class), dtype=cumsum_feat.dtype)\n",
    "        b1_prior = get_possion_prob(cur_ele-prev_boundary, next_ele-prev_boundary, label_cur_ele)\n",
    "        \n",
    "        # find dummy label where we will keep the diagonal (b1=b2) probabilities, later we will distribute among\n",
    "        # rest of the classes after the softmax by dividing by (num_class - 2)\n",
    "        dummy_label = 0\n",
    "        while True:\n",
    "            if dummy_label != label_cur_ele and dummy_label != label_next_ele:\n",
    "                break\n",
    "            else:\n",
    "                dummy_label += 1\n",
    "        \n",
    "        for b1 in range(cur_ele, next_ele - 1):\n",
    "\n",
    "            cur_boundary_len = b1 - prev_boundary\n",
    "            strt_index = cumsum_feat[cur_ele - 1, label_cur_ele] if cur_ele > 0 else 0\n",
    "            left_sum = (cumsum_feat[b1, label_cur_ele] - strt_index)\n",
    "            right_sum = cumsum_feat[next_ele-1, label_next_ele] - cumsum_feat[b1+1:next_ele, label_next_ele] # mid_seg_len\n",
    "            mid_sum = (cumsum_feat[b1+1:next_ele, :] - cumsum_feat[b1, :])  # mid_seg_len\n",
    "            b2_prior = get_possion_prob_for_all_class(1, next_ele-b1)  # mid_seg_len x num_class\n",
    "            \n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1+1-cur_ele:next_ele-cur_ele] = (left_sum + right_sum[:,None] + mid_sum) / config.temp \\\n",
    "                                                                            + b1_prior[b1-cur_ele] + b2_prior\n",
    "            # when mid segment is absent but right and left is not the same\n",
    "            # we assign the probability to a dummy label for now and then later \n",
    "            # re-distribute among other classes after the softmax\n",
    "            if label_cur_ele != label_next_ele:\n",
    "                rightsum_wo_midseg = cumsum_feat[next_ele-1, label_next_ele] - cumsum_feat[b1, label_next_ele]\n",
    "                mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = (left_sum + rightsum_wo_midseg) / config.temp \\\n",
    "                                                                        + b1_prior[b1-cur_ele]\n",
    "        \n",
    "#         if vidid=='P39_cam02_P39_scrambledegg' and cur_ele==574:\n",
    "#             import pdb\n",
    "#             pdb.set_trace()\n",
    "        # when mid segment is absent b1 can also be next_ele-1\n",
    "        b1 = next_ele - 1\n",
    "        if label_cur_ele != label_next_ele:\n",
    "            left_sum = (cumsum_feat[b1, label_cur_ele] - strt_index)\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = left_sum / config.temp + b1_prior[b1-cur_ele]\n",
    "        else:\n",
    "            # returns prob that the left class length >= seg len\n",
    "            b1_prior_ = get_poisson_logcdf(next_ele - prev_boundary, label_cur_ele) \n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label] = left_sum  / config.temp + b1_prior_\n",
    "        \n",
    "        mat_b1_b2_c_prob[:, :, label_cur_ele] = LOW_VAL\n",
    "        mat_b1_b2_c_prob[:, :, label_next_ele] = LOW_VAL\n",
    "        mat_b1_b2_c_prob = torch.softmax(mat_b1_b2_c_prob.flatten(), dim=0).reshape((seg_len, seg_len, config.num_class))\n",
    "        \n",
    "        # re-distribute the dummy class probability among the left-over classes\n",
    "        left_over_classes = config.num_class - 2 + (label_cur_ele==label_next_ele)\n",
    "        for b1 in range(cur_ele, next_ele):\n",
    "            assigned_prob = mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, dummy_label]\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, :] = assigned_prob/left_over_classes\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, label_cur_ele] = 0\n",
    "            mat_b1_b2_c_prob[b1-cur_ele, b1-cur_ele, label_next_ele] = 0\n",
    "        \n",
    "        marginal_b1 = torch.sum(mat_b1_b2_c_prob, axis=(1,2))\n",
    "        mean_b1 = round(torch.sum(marginal_b1.squeeze() * torch.arange(cur_ele, next_ele, 1)).item())\n",
    "        cumm_b1_prob = torch.cumsum(marginal_b1, dim=0)\n",
    "        cumm_b1_c_prob = torch.cumsum(torch.sum(mat_b1_b2_c_prob, dim=1), dim=0)\n",
    "        cumm_b2_c_prob = torch.cumsum(torch.sum(mat_b1_b2_c_prob, dim=0), dim=0)\n",
    "\n",
    "        per_frame_weights[cur_ele, label_cur_ele] = 1.0\n",
    "        per_frame_weights[cur_ele+1:next_ele, :] = cumm_b1_c_prob[:-1] - cumm_b2_c_prob[:-1]\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_cur_ele] = 1 - cumm_b1_prob[:-1]\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_next_ele] = 0\n",
    "        remaining_probability = 1 - torch.sum(per_frame_weights[cur_ele+1:next_ele, :], dim=-1)\n",
    "        # we use \"+=\" in the next line because left and right label might be the same\n",
    "        # in that case using \"=\" would just overwrite the previous probability\n",
    "        per_frame_weights[cur_ele+1:next_ele, label_next_ele] += remaining_probability\n",
    "        \n",
    "        expected_boundary = round(torch.sum(torch.sum(mat_b1_b2_c_prob, axis=(0,2)).squeeze() * \\\n",
    "                            torch.arange(cur_ele, next_ele, 1)).item())\n",
    "        if not (label_cur_ele == label_next_ele and expected_boundary >= next_ele-2):\n",
    "            prev_boundary = expected_boundary\n",
    "        if expected_boundary == 0 and i > 0:\n",
    "            print(f'Estimated boundary has become zero! for {vidid} and cur_ele, next_ele {cur_ele, next_ele}')\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        # boundary_error += (boundary_frames_dict[vidid + '.txt'][current_boundary] - mean_b1)**2\n",
    "        # boundary_error += (boundary_frames_dict[vidid + '.txt'][current_boundary+1] - prev_boundary)**2\n",
    "        # current_boundary += 2\n",
    "        # prob_each_segment.append(mat_b1_b2_c_prob)\n",
    "        \n",
    "    posterior_prediction = torch.argmax(per_frame_weights, dim=1)\n",
    "    correct = torch.sum(posterior_prediction == gt_labels[:num_frames]).item()\n",
    "    \n",
    "    return (vidid, per_frame_weights, [correct, num_frames, boundary_error]) #, prob_each_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_acc_correct, posterior_acc_total = 0, 0\n",
    "posterior_boundary_total_mse = 0\n",
    "results = []\n",
    "\n",
    "# Step 2: Define callback function to collect the output in `results`\n",
    "def collect_result(result):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    fname = os.path.join(config.output_dir, 'posterior_weights', result[0] + '.wt')\n",
    "    torch.save(result[1], fname)\n",
    "    correct, total, boundary_err = result[2]\n",
    "    posterior_acc_correct += correct\n",
    "    posterior_acc_total += total\n",
    "    posterior_boundary_total_mse += boundary_err\n",
    "    # print(f'Dumped in file {fname} at time {time()}')\n",
    "    return\n",
    "\n",
    "def calculate_element_probb(data_feat, data_count, video_ids, gt_labels): # loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    pool = mp.Pool(20)\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "#         if cur_vidid!='P39_cam02_P39_scrambledegg':\n",
    "#             continue\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num][:cur_vid_count].detach().cpu()\n",
    "        cur_gt_labels = gt_labels[iter_num].detach().cpu()\n",
    "        \n",
    "        cur_video_select_frames = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices_and_labels = cur_video_select_frames\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "        with torch.no_grad():\n",
    "            # Multi-processing\n",
    "            pool.apply_async(prob_vals_per_segment,\n",
    "                             args=(selected_frames_indices, cur_vid_feat, selected_frames_labels,\n",
    "                                   cur_video_select_frames[1], cur_video_select_frames[2], cur_vidid, cur_gt_labels),\n",
    "                             callback=collect_result)\n",
    "#             results.append(prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels,\n",
    "#                                    cur_video_select_frames[1], cur_video_select_frames[2], cur_vidid, cur_gt_labels))\n",
    "    # Step 4: Close Pool and let all the processes complete\n",
    "    pool.close()\n",
    "    pool.join()  # postpones the execution of next line of code until all processes in the queue are done.\n",
    "    return results\n",
    "\n",
    "def perform_expectation(model, dataloader):\n",
    "    global posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse\n",
    "    posterior_acc_correct, posterior_acc_total, posterior_boundary_total_mse = 0, 0, 0\n",
    "    model.eval()\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    curtime = time()\n",
    "    print(f'Calculating expectation')\n",
    "\n",
    "    for i, item in enumerate(dataloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device) # features\n",
    "            item_1 = item[1].to(device) # count\n",
    "            item_2 = item[2].to(device) # gt frame-wise labels\n",
    "            item_4 = item[4] # video-ids\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            prob = torch.softmax(predictions[-1], dim=1)\n",
    "            prob = prob.permute(0, 2, 1)\n",
    "            \n",
    "            calculate_element_probb(prob, item_1, item_4, item_2)\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(f\"iter {i+1} of Expectation completed in a total of {(time() - curtime)/60.: .1f} minutes\")\n",
    "    _ = model.train()\n",
    "    print(f'Expectation step finished, '\n",
    "          f'posterior frame-wise accuracy {100*posterior_acc_correct/posterior_acc_total: .2f}%, '\n",
    "          f'boundary mse {(posterior_boundary_total_mse/num_boundary)**0.5: .2f}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loaded_file=torch.load(os.path.join(config.output_dir, \"ms-tcn-initial-30-epochs.wt\"))\n",
    "# model.load_state_dict(loaded_file)\n",
    "# # loaded_file=torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcnnew-full-supervised-split1/ms-tcn-best-model.wt')\n",
    "# # model.load_state_dict(loaded_file)\n",
    "# loaded_file=torch.load(os.path.join(config.output_dir, \"ms-tcn-emmax-best-model.wt\"))\n",
    "# loaded_file=torch.load(\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/ms-tcn-emmax-last-model.wt\")\n",
    "# model.load_state_dict(loaded_file)\n",
    "# _ = validate(model, testloader)\n",
    "loaded_file = torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-random-select6/split3/ms-tcn-initial-30-epochs.wt')\n",
    "model.load_state_dict(loaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = next(iter(trainloader))\n",
    "    \n",
    "# with torch.no_grad():\n",
    "#     item_0 = item[0].to(device) # features\n",
    "#     item_1 = item[1].to(device) # count\n",
    "#     item_2 = item[2].to(device) # gt frame-wise labels\n",
    "#     item_4 = item[4] # video-ids\n",
    "#     src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "#     src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "#     middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "#     prob = torch.softmax(predictions[-1], dim=1)\n",
    "#     prob = prob.permute(0, 2, 1)\n",
    "\n",
    "#     res = calculate_element_probb(prob, item_1, item_4, item_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 2\n",
    "# vidid = res[idx][0]\n",
    "# mat = res[idx][1]\n",
    "# mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace(0, 5281, 4 + 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundary_frames_dict[f'{vidid}.txt'], selected_frames_dict[f'{vidid}.txt'], weakly_labels[f'{vidid}.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20, 5))\n",
    "# for i in range(48):\n",
    "#     plt.plot(mat[:,i])\n",
    "    \n",
    "# for bd in boundary_frames_dict[f'{vidid}.txt']:\n",
    "#     plt.plot([bd, bd], [0, 2])\n",
    "    \n",
    "# for bd in selected_frames_dict[f'{vidid}.txt']:\n",
    "#     plt.plot([bd[0], bd[0]], [0, 2], '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculating Expectation Step\n",
    "# perform_expectation(model, trainloder_expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_random(video_ids, len_frames, device):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((len(video_ids), len_frames), dtype=torch.long, device=device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "\n",
    "        frame_idx_tensor = torch.from_numpy(np.array(selected_frames_indices))\n",
    "        frame_labels = torch.from_numpy(np.array(selected_frames_labels)).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = frame_labels\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labels = pickle.load(open(\"data/breakfast_weaklysupervised_labels.pkl\", \"rb\"))\n",
    "prior_probs = pickle.load(open('data/breakfast_lengthmodel_multinomial_prior.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Epoch 31: Iteration 20 with loss 1.095117449760437\n",
      "Epoch 31: Iteration 40 with loss 0.5408681631088257\n",
      "Epoch 31: Iteration 60 with loss 0.8621843457221985\n",
      "Epoch 31: Iteration 80 with loss 0.7179521322250366\n",
      "Epoch 31: Iteration 100 with loss 0.9199670553207397\n",
      "Epoch 31: Iteration 120 with loss 1.202401041984558\n",
      "Epoch 31: Iteration 140 with loss 1.0838334560394287\n",
      "Epoch 31: Iteration 160 with loss 0.5967729687690735\n",
      "Epoch 31 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.912600934146575\n",
      "Other scores:: Edit 44.225053106602, F1@[10:25:50] [47.35058147 43.23498694 34.24252605]\n",
      "Starting Training\n",
      "Epoch 32: Iteration 20 with loss 0.0\n",
      "Epoch 32: Iteration 40 with loss 0.0\n",
      "Epoch 32: Iteration 60 with loss 0.0\n",
      "Epoch 32: Iteration 80 with loss 0.0\n",
      "Epoch 32: Iteration 100 with loss 0.0\n",
      "Epoch 32: Iteration 120 with loss 0.0\n",
      "Epoch 32: Iteration 140 with loss 0.0\n",
      "Epoch 32: Iteration 160 with loss 0.0\n",
      "Epoch 32 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.48104084240601\n",
      "Other scores:: Edit 40.44390186448062, F1@[10:25:50] [42.68951206 38.5313692  29.8439543 ]\n",
      "Starting Training\n",
      "Epoch 33: Iteration 20 with loss 0.0\n",
      "Epoch 33: Iteration 40 with loss 0.0\n",
      "Epoch 33: Iteration 60 with loss 0.0\n",
      "Epoch 33: Iteration 80 with loss 0.0\n",
      "Epoch 33: Iteration 100 with loss 0.0\n",
      "Epoch 33: Iteration 120 with loss 0.0\n",
      "Epoch 33: Iteration 140 with loss 0.0\n",
      "Epoch 33: Iteration 160 with loss 0.0\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.1 minutes\n",
      "iter 20 of Expectation completed in a total of  6.3 minutes\n",
      "iter 30 of Expectation completed in a total of  9.0 minutes\n",
      "iter 40 of Expectation completed in a total of  12.2 minutes\n",
      "iter 50 of Expectation completed in a total of  15.2 minutes\n",
      "iter 60 of Expectation completed in a total of  18.6 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  75.83%, boundary mse  0.00\n",
      "Epoch 33 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.48104084240601\n",
      "Other scores:: Edit 40.44390186448062, F1@[10:25:50] [42.68951206 38.5313692  29.8439543 ]\n",
      "Starting Training\n",
      "Epoch 34: Iteration 20 with loss 4.274847984313965\n",
      "Epoch 34: Iteration 40 with loss 7.345154762268066\n",
      "Epoch 34: Iteration 60 with loss 3.3247580528259277\n",
      "Epoch 34: Iteration 80 with loss 2.1185545921325684\n",
      "Epoch 34: Iteration 100 with loss 3.035097599029541\n",
      "Epoch 34: Iteration 120 with loss 2.7743074893951416\n",
      "Epoch 34: Iteration 140 with loss 2.7151451110839844\n",
      "Epoch 34: Iteration 160 with loss 1.5461714267730713\n",
      "Epoch 34 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.61495192549149\n",
      "Other scores:: Edit 55.63067913191029, F1@[10:25:50] [54.21664444 51.01166532 41.49508806]\n",
      "Starting Training\n",
      "Epoch 35: Iteration 20 with loss 1.1566369533538818\n",
      "Epoch 35: Iteration 40 with loss 4.422140121459961\n",
      "Epoch 35: Iteration 60 with loss 1.797621250152588\n",
      "Epoch 35: Iteration 80 with loss 5.329331874847412\n",
      "Epoch 35: Iteration 100 with loss 2.1386585235595703\n",
      "Epoch 35: Iteration 120 with loss 3.805525541305542\n",
      "Epoch 35: Iteration 140 with loss 4.191629886627197\n",
      "Epoch 35: Iteration 160 with loss 2.8699288368225098\n",
      "Epoch 35 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 55.24466939358597\n",
      "Other scores:: Edit 52.68605237154729, F1@[10:25:50] [49.40406005 45.63666566 36.72439192]\n",
      "Starting Training\n",
      "Epoch 36: Iteration 20 with loss 2.156543254852295\n",
      "Epoch 36: Iteration 40 with loss 1.7309424877166748\n",
      "Epoch 36: Iteration 60 with loss 1.7403144836425781\n",
      "Epoch 36: Iteration 80 with loss 2.2412099838256836\n",
      "Epoch 36: Iteration 100 with loss 2.049436569213867\n",
      "Epoch 36: Iteration 120 with loss 3.44378399848938\n",
      "Epoch 36: Iteration 140 with loss 2.747450113296509\n",
      "Epoch 36: Iteration 160 with loss 1.7248408794403076\n",
      "Epoch 36 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.74586079318754\n",
      "Other scores:: Edit 58.73721572776186, F1@[10:25:50] [57.02821758 53.18520812 43.2307963 ]\n",
      "Starting Training\n",
      "Epoch 37: Iteration 20 with loss 1.0407651662826538\n",
      "Epoch 37: Iteration 40 with loss 4.415771484375\n",
      "Epoch 37: Iteration 60 with loss 2.25838565826416\n",
      "Epoch 37: Iteration 80 with loss 1.4259676933288574\n",
      "Epoch 37: Iteration 100 with loss 1.3561317920684814\n",
      "Epoch 37: Iteration 120 with loss 2.511195182800293\n",
      "Epoch 37: Iteration 140 with loss 1.0183262825012207\n",
      "Epoch 37: Iteration 160 with loss 2.908682346343994\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.3 minutes\n",
      "iter 20 of Expectation completed in a total of  5.9 minutes\n",
      "iter 30 of Expectation completed in a total of  9.4 minutes\n",
      "iter 40 of Expectation completed in a total of  12.9 minutes\n",
      "iter 50 of Expectation completed in a total of  15.4 minutes\n",
      "iter 60 of Expectation completed in a total of  18.2 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  74.35%, boundary mse  0.00\n",
      "Epoch 37 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 56.26743154335076\n",
      "Other scores:: Edit 55.517863918491855, F1@[10:25:50] [53.68555357 49.82864315 41.29009099]\n",
      "Starting Training\n",
      "Epoch 38: Iteration 20 with loss 1.3458572626113892\n",
      "Epoch 38: Iteration 40 with loss 1.3890012502670288\n",
      "Epoch 38: Iteration 60 with loss 2.43341326713562\n",
      "Epoch 38: Iteration 80 with loss 1.8091412782669067\n",
      "Epoch 38: Iteration 100 with loss 2.360182285308838\n",
      "Epoch 38: Iteration 120 with loss 1.4597805738449097\n",
      "Epoch 38: Iteration 140 with loss 4.162890434265137\n",
      "Epoch 38: Iteration 160 with loss 3.400157928466797\n",
      "Epoch 38 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.53393117225908\n",
      "Other scores:: Edit 61.41247252443105, F1@[10:25:50] [58.17143034 54.79236214 45.66104282]\n",
      "Starting Training\n",
      "Epoch 39: Iteration 20 with loss 2.6509666442871094\n",
      "Epoch 39: Iteration 40 with loss 1.9688421487808228\n",
      "Epoch 39: Iteration 60 with loss 2.1675057411193848\n",
      "Epoch 39: Iteration 80 with loss 2.8815836906433105\n",
      "Epoch 39: Iteration 100 with loss 2.4874026775360107\n",
      "Epoch 39: Iteration 120 with loss 2.0456271171569824\n",
      "Epoch 39: Iteration 140 with loss 1.0490672588348389\n",
      "Epoch 39: Iteration 160 with loss 2.553238868713379\n",
      "Epoch 39 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.117075239535495\n",
      "Other scores:: Edit 63.55931543092456, F1@[10:25:50] [59.95530929 56.36639426 47.74316829]\n",
      "Starting Training\n",
      "Epoch 40: Iteration 20 with loss 1.3528269529342651\n",
      "Epoch 40: Iteration 40 with loss 0.908051073551178\n",
      "Epoch 40: Iteration 60 with loss 2.1228699684143066\n",
      "Epoch 40: Iteration 80 with loss 2.9005556106567383\n",
      "Epoch 40: Iteration 100 with loss 1.6613792181015015\n",
      "Epoch 40: Iteration 120 with loss 2.4228248596191406\n",
      "Epoch 40: Iteration 140 with loss 1.327498435974121\n",
      "Epoch 40: Iteration 160 with loss 0.6921800374984741\n",
      "Epoch 40 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.66194385075976\n",
      "Other scores:: Edit 63.06969856503429, F1@[10:25:50] [59.61711895 56.44433012 48.12516625]\n",
      "Starting Training\n",
      "Epoch 41: Iteration 20 with loss 1.4602359533309937\n",
      "Epoch 41: Iteration 40 with loss 2.3066611289978027\n",
      "Epoch 41: Iteration 60 with loss 1.1972711086273193\n",
      "Epoch 41: Iteration 80 with loss 0.8071955442428589\n",
      "Epoch 41: Iteration 100 with loss 1.5859475135803223\n",
      "Epoch 41: Iteration 120 with loss 1.072849988937378\n",
      "Epoch 41: Iteration 140 with loss 2.8116636276245117\n",
      "Epoch 41: Iteration 160 with loss 1.1340837478637695\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.4 minutes\n",
      "iter 20 of Expectation completed in a total of  6.5 minutes\n",
      "iter 30 of Expectation completed in a total of  9.4 minutes\n",
      "iter 40 of Expectation completed in a total of  12.2 minutes\n",
      "iter 50 of Expectation completed in a total of  15.8 minutes\n",
      "iter 60 of Expectation completed in a total of  18.8 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  75.12%, boundary mse  0.00\n",
      "Epoch 41 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Probability Accuracy 59.51172147476856\n",
      "Other scores:: Edit 63.19143073578516, F1@[10:25:50] [60.87216927 57.26812283 47.73638804]\n",
      "Starting Training\n",
      "Epoch 42: Iteration 20 with loss 1.1342337131500244\n",
      "Epoch 42: Iteration 40 with loss 0.8986411690711975\n",
      "Epoch 42: Iteration 60 with loss 1.701650619506836\n",
      "Epoch 42: Iteration 80 with loss 2.123737096786499\n",
      "Epoch 42: Iteration 100 with loss 1.2069036960601807\n",
      "Epoch 42: Iteration 120 with loss 1.1728521585464478\n",
      "Epoch 42: Iteration 140 with loss 1.7871774435043335\n",
      "Epoch 42: Iteration 160 with loss 0.9669917821884155\n",
      "Epoch 42 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.09609321376555\n",
      "Other scores:: Edit 64.70551054576148, F1@[10:25:50] [61.56433688 58.29643166 48.89552747]\n",
      "Starting Training\n",
      "Epoch 43: Iteration 20 with loss 1.289873719215393\n",
      "Epoch 43: Iteration 40 with loss 0.9306312203407288\n",
      "Epoch 43: Iteration 60 with loss 0.9443725943565369\n",
      "Epoch 43: Iteration 80 with loss 1.216572880744934\n",
      "Epoch 43: Iteration 100 with loss 1.233219861984253\n",
      "Epoch 43: Iteration 120 with loss 1.1095385551452637\n",
      "Epoch 43: Iteration 140 with loss 1.6871604919433594\n",
      "Epoch 43: Iteration 160 with loss 1.3787471055984497\n",
      "Epoch 43 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.18171215562413\n",
      "Other scores:: Edit 65.21072511112656, F1@[10:25:50] [60.89831505 57.55810465 48.64747763]\n",
      "Starting Training\n",
      "Epoch 44: Iteration 20 with loss 0.6540277600288391\n",
      "Epoch 44: Iteration 40 with loss 1.0399303436279297\n",
      "Epoch 44: Iteration 60 with loss 1.78565514087677\n",
      "Epoch 44: Iteration 80 with loss 0.7783930897712708\n",
      "Epoch 44: Iteration 100 with loss 0.9132235050201416\n",
      "Epoch 44: Iteration 120 with loss 1.7314069271087646\n",
      "Epoch 44: Iteration 140 with loss 1.4227800369262695\n",
      "Epoch 44: Iteration 160 with loss 2.017583131790161\n",
      "Epoch 44 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.143648751960086\n",
      "Other scores:: Edit 63.76430542610734, F1@[10:25:50] [61.19102918 57.4457197  48.59573273]\n",
      "Starting Training\n",
      "Epoch 45: Iteration 20 with loss 1.5716922283172607\n",
      "Epoch 45: Iteration 40 with loss 0.9331834316253662\n",
      "Epoch 45: Iteration 60 with loss 0.9270830154418945\n",
      "Epoch 45: Iteration 80 with loss 0.7484202980995178\n",
      "Epoch 45: Iteration 100 with loss 1.1348320245742798\n",
      "Epoch 45: Iteration 120 with loss 0.7552127242088318\n",
      "Epoch 45: Iteration 140 with loss 0.944388747215271\n",
      "Epoch 45: Iteration 160 with loss 0.48130229115486145\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.3 minutes\n",
      "iter 20 of Expectation completed in a total of  6.4 minutes\n",
      "iter 30 of Expectation completed in a total of  9.7 minutes\n",
      "iter 40 of Expectation completed in a total of  13.1 minutes\n",
      "iter 50 of Expectation completed in a total of  16.0 minutes\n",
      "iter 60 of Expectation completed in a total of  19.0 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  74.34%, boundary mse  0.00\n",
      "Epoch 45 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.43047192817004\n",
      "Other scores:: Edit 65.33798227814104, F1@[10:25:50] [62.17197438 59.16880381 49.88819402]\n",
      "Starting Training\n",
      "Epoch 46: Iteration 20 with loss 0.8152996301651001\n",
      "Epoch 46: Iteration 40 with loss 1.3919978141784668\n",
      "Epoch 46: Iteration 60 with loss 3.357963800430298\n",
      "Epoch 46: Iteration 80 with loss 2.1805624961853027\n",
      "Epoch 46: Iteration 100 with loss 0.9737311005592346\n",
      "Epoch 46: Iteration 120 with loss 1.9346261024475098\n",
      "Epoch 46: Iteration 140 with loss 1.4236037731170654\n",
      "Epoch 46: Iteration 160 with loss 1.2551462650299072\n",
      "Epoch 46 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.81640169418697\n",
      "Other scores:: Edit 64.88434737997316, F1@[10:25:50] [62.06080252 59.0295651  49.12951202]\n",
      "Starting Training\n",
      "Epoch 47: Iteration 20 with loss 1.54836106300354\n",
      "Epoch 47: Iteration 40 with loss 1.3978157043457031\n",
      "Epoch 47: Iteration 60 with loss 0.9876855611801147\n",
      "Epoch 47: Iteration 80 with loss 0.9523720145225525\n",
      "Epoch 47: Iteration 100 with loss 1.7449085712432861\n",
      "Epoch 47: Iteration 120 with loss 1.529485821723938\n",
      "Epoch 47: Iteration 140 with loss 2.7427783012390137\n",
      "Epoch 47: Iteration 160 with loss 1.4352285861968994\n",
      "Epoch 47 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.07243263151433\n",
      "Other scores:: Edit 66.54923610474691, F1@[10:25:50] [63.5127276  60.35050681 50.44937388]\n",
      "Starting Training\n",
      "Epoch 48: Iteration 20 with loss 1.2418853044509888\n",
      "Epoch 48: Iteration 40 with loss 0.5728824734687805\n",
      "Epoch 48: Iteration 60 with loss 0.6155160665512085\n",
      "Epoch 48: Iteration 80 with loss 1.1705394983291626\n",
      "Epoch 48: Iteration 100 with loss 1.2261428833007812\n",
      "Epoch 48: Iteration 120 with loss 1.0391275882720947\n",
      "Epoch 48: Iteration 140 with loss 1.3334035873413086\n",
      "Epoch 48: Iteration 160 with loss 0.8139231204986572\n",
      "Epoch 48 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.82365611799041\n",
      "Other scores:: Edit 66.26595692876674, F1@[10:25:50] [62.89774255 60.3574982  50.35565535]\n",
      "Starting Training\n",
      "Epoch 49: Iteration 20 with loss 1.5612891912460327\n",
      "Epoch 49: Iteration 40 with loss 0.5451861619949341\n",
      "Epoch 49: Iteration 60 with loss 1.2623730897903442\n",
      "Epoch 49: Iteration 80 with loss 1.1144709587097168\n",
      "Epoch 49: Iteration 100 with loss 0.6314496397972107\n",
      "Epoch 49: Iteration 120 with loss 0.7318554520606995\n",
      "Epoch 49: Iteration 140 with loss 0.9196906089782715\n",
      "Epoch 49: Iteration 160 with loss 1.22309410572052\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  2.9 minutes\n",
      "iter 20 of Expectation completed in a total of  6.1 minutes\n",
      "iter 30 of Expectation completed in a total of  9.4 minutes\n",
      "iter 40 of Expectation completed in a total of  12.5 minutes\n",
      "iter 50 of Expectation completed in a total of  15.8 minutes\n",
      "iter 60 of Expectation completed in a total of  19.4 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  74.68%, boundary mse  0.00\n",
      "Epoch 49 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.35491431409423\n",
      "Other scores:: Edit 66.24016237217072, F1@[10:25:50] [63.45225697 59.626748   49.38918735]\n",
      "Starting Training\n",
      "Epoch 50: Iteration 20 with loss 0.8169535994529724\n",
      "Epoch 50: Iteration 40 with loss 1.2104098796844482\n",
      "Epoch 50: Iteration 60 with loss 0.7612971663475037\n",
      "Epoch 50: Iteration 80 with loss 1.367461919784546\n",
      "Epoch 50: Iteration 100 with loss 1.1080862283706665\n",
      "Epoch 50: Iteration 120 with loss 0.9358930587768555\n",
      "Epoch 50: Iteration 140 with loss 0.7702670097351074\n",
      "Epoch 50: Iteration 160 with loss 1.912324070930481\n",
      "Epoch 50 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.071428172833855\n",
      "Other scores:: Edit 66.60369117121807, F1@[10:25:50] [63.64133182 60.76968593 50.19534824]\n",
      "Starting Training\n",
      "Epoch 51: Iteration 20 with loss 0.7876735925674438\n",
      "Epoch 51: Iteration 40 with loss 0.6221211552619934\n",
      "Epoch 51: Iteration 60 with loss 0.655647873878479\n",
      "Epoch 51: Iteration 80 with loss 0.6856958866119385\n",
      "Epoch 51: Iteration 100 with loss 0.8464158773422241\n",
      "Epoch 51: Iteration 120 with loss 0.6818300485610962\n",
      "Epoch 51: Iteration 140 with loss 1.9422670602798462\n",
      "Epoch 51: Iteration 160 with loss 0.6623860001564026\n",
      "Epoch 51 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.12444685018499\n",
      "Other scores:: Edit 66.84677824122117, F1@[10:25:50] [64.67334436 61.63002248 50.92623328]\n",
      "Starting Training\n",
      "Epoch 52: Iteration 20 with loss 0.6645691394805908\n",
      "Epoch 52: Iteration 40 with loss 1.9855760335922241\n",
      "Epoch 52: Iteration 60 with loss 1.466192603111267\n",
      "Epoch 52: Iteration 80 with loss 1.2333266735076904\n",
      "Epoch 52: Iteration 100 with loss 1.0312047004699707\n",
      "Epoch 52: Iteration 120 with loss 0.46265101432800293\n",
      "Epoch 52: Iteration 140 with loss 0.5499485731124878\n",
      "Epoch 52: Iteration 160 with loss 0.5375239849090576\n",
      "Epoch 52 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.6137186734449\n",
      "Other scores:: Edit 67.76567797959167, F1@[10:25:50] [64.83940051 61.39460286 51.7705161 ]\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Iteration 20 with loss 0.9818872213363647\n",
      "Epoch 53: Iteration 40 with loss 0.5141730308532715\n",
      "Epoch 53: Iteration 60 with loss 0.8006748557090759\n",
      "Epoch 53: Iteration 80 with loss 0.6649131178855896\n",
      "Epoch 53: Iteration 100 with loss 0.6640751957893372\n",
      "Epoch 53: Iteration 120 with loss 0.8865376114845276\n",
      "Epoch 53: Iteration 140 with loss 0.7819311022758484\n",
      "Epoch 53: Iteration 160 with loss 1.5470516681671143\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.7 minutes\n",
      "iter 20 of Expectation completed in a total of  6.3 minutes\n",
      "iter 30 of Expectation completed in a total of  9.5 minutes\n",
      "iter 40 of Expectation completed in a total of  13.2 minutes\n",
      "iter 50 of Expectation completed in a total of  16.3 minutes\n",
      "iter 60 of Expectation completed in a total of  19.3 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  74.29%, boundary mse  0.00\n",
      "Epoch 53 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.32310087555315\n",
      "Other scores:: Edit 65.97585705654281, F1@[10:25:50] [63.15310856 59.87776874 48.95674254]\n",
      "Starting Training\n",
      "Epoch 54: Iteration 20 with loss 0.7705525755882263\n",
      "Epoch 54: Iteration 40 with loss 0.8359407186508179\n",
      "Epoch 54: Iteration 60 with loss 1.1861555576324463\n",
      "Epoch 54: Iteration 80 with loss 1.0596271753311157\n",
      "Epoch 54: Iteration 100 with loss 1.1143715381622314\n",
      "Epoch 54: Iteration 120 with loss 1.247666835784912\n",
      "Epoch 54: Iteration 140 with loss 1.2661895751953125\n",
      "Epoch 54: Iteration 160 with loss 0.6122341752052307\n",
      "Epoch 54 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.036489751731295\n",
      "Other scores:: Edit 66.3319183516292, F1@[10:25:50] [63.49799551 60.72316369 49.73098722]\n",
      "Starting Training\n",
      "Epoch 55: Iteration 20 with loss 0.41067907214164734\n",
      "Epoch 55: Iteration 40 with loss 1.1139163970947266\n",
      "Epoch 55: Iteration 60 with loss 0.7022181153297424\n",
      "Epoch 55: Iteration 80 with loss 0.7230644226074219\n",
      "Epoch 55: Iteration 100 with loss 1.3079942464828491\n",
      "Epoch 55: Iteration 120 with loss 3.866429328918457\n",
      "Epoch 55: Iteration 140 with loss 1.508768081665039\n",
      "Epoch 55: Iteration 160 with loss 0.8710460662841797\n",
      "Epoch 55 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.405477648004194\n",
      "Other scores:: Edit 62.794928310953836, F1@[10:25:50] [59.49216349 55.74675115 45.52214112]\n",
      "Starting Training\n",
      "Epoch 56: Iteration 20 with loss 1.3172880411148071\n",
      "Epoch 56: Iteration 40 with loss 1.1513913869857788\n",
      "Epoch 56: Iteration 60 with loss 0.603004515171051\n",
      "Epoch 56: Iteration 80 with loss 0.5135126113891602\n",
      "Epoch 56: Iteration 100 with loss 0.4927322268486023\n",
      "Epoch 56: Iteration 120 with loss 0.5202292799949646\n",
      "Epoch 56: Iteration 140 with loss 0.6687201857566833\n",
      "Epoch 56: Iteration 160 with loss 0.8706633448600769\n",
      "Epoch 56 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.9808036785509\n",
      "Other scores:: Edit 65.7530107602733, F1@[10:25:50] [63.17828943 59.99974678 50.5076772 ]\n",
      "Starting Training\n",
      "Epoch 57: Iteration 20 with loss 0.4405612647533417\n",
      "Epoch 57: Iteration 40 with loss 0.7756571769714355\n",
      "Epoch 57: Iteration 60 with loss 0.4190210998058319\n",
      "Epoch 57: Iteration 80 with loss 0.5790478587150574\n",
      "Epoch 57: Iteration 100 with loss 1.1384515762329102\n",
      "Epoch 57: Iteration 120 with loss 0.5911309719085693\n",
      "Epoch 57: Iteration 140 with loss 0.8239522576332092\n",
      "Epoch 57: Iteration 160 with loss 0.6709297895431519\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.0 minutes\n",
      "iter 20 of Expectation completed in a total of  6.4 minutes\n",
      "iter 30 of Expectation completed in a total of  9.5 minutes\n",
      "iter 40 of Expectation completed in a total of  12.9 minutes\n",
      "iter 50 of Expectation completed in a total of  16.1 minutes\n",
      "iter 60 of Expectation completed in a total of  18.6 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  73.68%, boundary mse  0.00\n",
      "Epoch 57 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 57.67300405689701\n",
      "Other scores:: Edit 64.80512838669709, F1@[10:25:50] [61.86971631 58.93191055 47.70870444]\n",
      "Starting Training\n",
      "Epoch 58: Iteration 20 with loss 1.4147862195968628\n",
      "Epoch 58: Iteration 40 with loss 0.7012073993682861\n",
      "Epoch 58: Iteration 60 with loss 0.595801830291748\n",
      "Epoch 58: Iteration 80 with loss 0.777321994304657\n",
      "Epoch 58: Iteration 100 with loss 0.6353825926780701\n",
      "Epoch 58: Iteration 120 with loss 0.5781421661376953\n",
      "Epoch 58: Iteration 140 with loss 1.4536632299423218\n",
      "Epoch 58: Iteration 160 with loss 4.349393844604492\n",
      "Epoch 58 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 55.04087588796938\n",
      "Other scores:: Edit 61.51040281626386, F1@[10:25:50] [58.49452967 55.92189233 46.59028312]\n",
      "Starting Training\n",
      "Epoch 59: Iteration 20 with loss 0.3341488838195801\n",
      "Epoch 59: Iteration 40 with loss 0.6767687797546387\n",
      "Epoch 59: Iteration 60 with loss 0.6827011108398438\n",
      "Epoch 59: Iteration 80 with loss 0.9015276432037354\n",
      "Epoch 59: Iteration 100 with loss 1.596143364906311\n",
      "Epoch 59: Iteration 120 with loss 1.074882984161377\n",
      "Epoch 59: Iteration 140 with loss 1.0758347511291504\n",
      "Epoch 59: Iteration 160 with loss 0.5967029333114624\n",
      "Epoch 59 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.44575644109129\n",
      "Other scores:: Edit 66.1384457127796, F1@[10:25:50] [63.93226547 60.83654965 50.80526128]\n",
      "Starting Training\n",
      "Epoch 60: Iteration 20 with loss 1.436180591583252\n",
      "Epoch 60: Iteration 40 with loss 0.635638952255249\n",
      "Epoch 60: Iteration 60 with loss 1.033818244934082\n",
      "Epoch 60: Iteration 80 with loss 0.5765053033828735\n",
      "Epoch 60: Iteration 100 with loss 0.8172813057899475\n",
      "Epoch 60: Iteration 120 with loss 1.4870034456253052\n",
      "Epoch 60: Iteration 140 with loss 1.2879774570465088\n",
      "Epoch 60: Iteration 160 with loss 0.9408679604530334\n",
      "Epoch 60 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.89498384495622\n",
      "Other scores:: Edit 64.30378806132212, F1@[10:25:50] [61.21490396 57.70324295 47.56470682]\n",
      "Starting Training\n",
      "Epoch 61: Iteration 20 with loss 0.5732373595237732\n",
      "Epoch 61: Iteration 40 with loss 0.7397380471229553\n",
      "Epoch 61: Iteration 60 with loss 0.5921382904052734\n",
      "Epoch 61: Iteration 80 with loss 0.9962592124938965\n",
      "Epoch 61: Iteration 100 with loss 0.6188775300979614\n",
      "Epoch 61: Iteration 120 with loss 0.49540793895721436\n",
      "Epoch 61: Iteration 140 with loss 1.128868818283081\n",
      "Epoch 61: Iteration 160 with loss 0.6173047423362732\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.0 minutes\n",
      "iter 20 of Expectation completed in a total of  6.2 minutes\n",
      "iter 30 of Expectation completed in a total of  9.5 minutes\n",
      "iter 40 of Expectation completed in a total of  12.7 minutes\n",
      "iter 50 of Expectation completed in a total of  15.7 minutes\n",
      "iter 60 of Expectation completed in a total of  19.1 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  73.47%, boundary mse  0.00\n",
      "Epoch 61 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.391627278865634\n",
      "Other scores:: Edit 66.72297699089408, F1@[10:25:50] [65.18862167 62.07532188 51.23054909]\n",
      "Starting Training\n",
      "Epoch 62: Iteration 20 with loss 0.48975417017936707\n",
      "Epoch 62: Iteration 40 with loss 0.39514583349227905\n",
      "Epoch 62: Iteration 60 with loss 1.239766001701355\n",
      "Epoch 62: Iteration 80 with loss 0.41896867752075195\n",
      "Epoch 62: Iteration 100 with loss 0.4547403156757355\n",
      "Epoch 62: Iteration 120 with loss 0.4667976498603821\n",
      "Epoch 62: Iteration 140 with loss 0.7072362303733826\n",
      "Epoch 62: Iteration 160 with loss 0.6733454465866089\n",
      "Epoch 62 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.37913292894571\n",
      "Other scores:: Edit 66.20232550061198, F1@[10:25:50] [64.00191282 61.22012236 51.63792579]\n",
      "Starting Training\n",
      "Epoch 63: Iteration 20 with loss 0.5740417242050171\n",
      "Epoch 63: Iteration 40 with loss 0.60222989320755\n",
      "Epoch 63: Iteration 60 with loss 0.5596438646316528\n",
      "Epoch 63: Iteration 80 with loss 0.6312769651412964\n",
      "Epoch 63: Iteration 100 with loss 0.4162280559539795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Iteration 120 with loss 0.43833646178245544\n",
      "Epoch 63: Iteration 140 with loss 0.6618415117263794\n",
      "Epoch 63: Iteration 160 with loss 0.4658391773700714\n",
      "Epoch 63 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.6251081188163\n",
      "Other scores:: Edit 66.32701047054704, F1@[10:25:50] [64.3364088  61.03589158 51.08776554]\n",
      "Starting Training\n",
      "Epoch 64: Iteration 20 with loss 0.9479846954345703\n",
      "Epoch 64: Iteration 40 with loss 0.6926282644271851\n",
      "Epoch 64: Iteration 60 with loss 0.5544252395629883\n",
      "Epoch 64: Iteration 80 with loss 0.8459177017211914\n",
      "Epoch 64: Iteration 100 with loss 0.7123618721961975\n",
      "Epoch 64: Iteration 120 with loss 0.8010169863700867\n",
      "Epoch 64: Iteration 140 with loss 0.6451548933982849\n",
      "Epoch 64: Iteration 160 with loss 0.40961354970932007\n",
      "Epoch 64 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.654019787836006\n",
      "Other scores:: Edit 67.18464446115193, F1@[10:25:50] [64.93709011 61.93786453 52.00282508]\n",
      "Starting Training\n",
      "Epoch 65: Iteration 20 with loss 0.5299153923988342\n",
      "Epoch 65: Iteration 40 with loss 0.38788363337516785\n",
      "Epoch 65: Iteration 60 with loss 0.36496293544769287\n",
      "Epoch 65: Iteration 80 with loss 0.5413020849227905\n",
      "Epoch 65: Iteration 100 with loss 0.7614240050315857\n",
      "Epoch 65: Iteration 120 with loss 0.8786223530769348\n",
      "Epoch 65: Iteration 140 with loss 0.43514296412467957\n",
      "Epoch 65: Iteration 160 with loss 0.6293056607246399\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.1 minutes\n",
      "iter 20 of Expectation completed in a total of  6.3 minutes\n",
      "iter 30 of Expectation completed in a total of  9.3 minutes\n",
      "iter 40 of Expectation completed in a total of  12.5 minutes\n",
      "iter 50 of Expectation completed in a total of  15.3 minutes\n",
      "iter 60 of Expectation completed in a total of  18.5 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  73.65%, boundary mse  0.00\n",
      "Epoch 65 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.546313915658956\n",
      "Other scores:: Edit 66.7479913877622, F1@[10:25:50] [64.87878046 62.0785568  50.72682197]\n",
      "Starting Training\n",
      "Epoch 66: Iteration 20 with loss 0.47588062286376953\n",
      "Epoch 66: Iteration 40 with loss 0.4349859356880188\n",
      "Epoch 66: Iteration 60 with loss 0.38333359360694885\n",
      "Epoch 66: Iteration 80 with loss 0.3275688588619232\n",
      "Epoch 66: Iteration 100 with loss 0.7592105269432068\n",
      "Epoch 66: Iteration 120 with loss 0.3855385184288025\n",
      "Epoch 66: Iteration 140 with loss 0.2708727717399597\n",
      "Epoch 66: Iteration 160 with loss 0.42503127455711365\n",
      "Epoch 66 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.74419785603875\n",
      "Other scores:: Edit 66.19434461589019, F1@[10:25:50] [64.52974738 61.73991579 50.45028406]\n",
      "Starting Training\n",
      "Epoch 67: Iteration 20 with loss 0.5843585729598999\n",
      "Epoch 67: Iteration 40 with loss 0.4038856625556946\n",
      "Epoch 67: Iteration 60 with loss 0.49390268325805664\n",
      "Epoch 67: Iteration 80 with loss 0.5751124620437622\n",
      "Epoch 67: Iteration 100 with loss 0.29946520924568176\n",
      "Epoch 67: Iteration 120 with loss 0.4043673574924469\n",
      "Epoch 67: Iteration 140 with loss 0.44078391790390015\n",
      "Epoch 67: Iteration 160 with loss 0.6529025435447693\n",
      "Epoch 67 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.438390410767795\n",
      "Other scores:: Edit 66.26726655659543, F1@[10:25:50] [64.9455054  61.99942113 52.01003072]\n",
      "Starting Training\n",
      "Epoch 68: Iteration 20 with loss 0.496986448764801\n",
      "Epoch 68: Iteration 40 with loss 0.40422356128692627\n",
      "Epoch 68: Iteration 60 with loss 0.4476569890975952\n",
      "Epoch 68: Iteration 80 with loss 0.3305337429046631\n",
      "Epoch 68: Iteration 100 with loss 0.31256377696990967\n",
      "Epoch 68: Iteration 120 with loss 0.40462377667427063\n",
      "Epoch 68: Iteration 140 with loss 0.7892186641693115\n",
      "Epoch 68: Iteration 160 with loss 0.32585328817367554\n",
      "Epoch 68 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.63905335349691\n",
      "Other scores:: Edit 67.09831636409193, F1@[10:25:50] [66.07515641 62.98041512 52.40827426]\n",
      "Starting Training\n",
      "Epoch 69: Iteration 20 with loss 0.3168267607688904\n",
      "Epoch 69: Iteration 40 with loss 0.38783296942710876\n",
      "Epoch 69: Iteration 60 with loss 0.2693028450012207\n",
      "Epoch 69: Iteration 80 with loss 0.33376824855804443\n",
      "Epoch 69: Iteration 100 with loss 0.2942976653575897\n",
      "Epoch 69: Iteration 120 with loss 0.4443665146827698\n",
      "Epoch 69: Iteration 140 with loss 0.362341046333313\n",
      "Epoch 69: Iteration 160 with loss 0.42630720138549805\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.4 minutes\n",
      "iter 20 of Expectation completed in a total of  6.3 minutes\n",
      "iter 30 of Expectation completed in a total of  8.5 minutes\n",
      "iter 40 of Expectation completed in a total of  12.1 minutes\n",
      "iter 50 of Expectation completed in a total of  15.1 minutes\n",
      "iter 60 of Expectation completed in a total of  18.0 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  73.66%, boundary mse  0.00\n",
      "Epoch 69 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.39486944827317\n",
      "Other scores:: Edit 66.73388511588587, F1@[10:25:50] [64.76485991 61.38618929 50.41659321]\n",
      "Starting Training\n",
      "Epoch 70: Iteration 20 with loss 0.7284088134765625\n",
      "Epoch 70: Iteration 40 with loss 1.0367919206619263\n",
      "Epoch 70: Iteration 60 with loss 0.5129741430282593\n",
      "Epoch 70: Iteration 80 with loss 0.5244385004043579\n",
      "Epoch 70: Iteration 100 with loss 0.22547030448913574\n",
      "Epoch 70: Iteration 120 with loss 0.6049575209617615\n",
      "Epoch 70: Iteration 140 with loss 0.7467789649963379\n",
      "Epoch 70: Iteration 160 with loss 1.037940263748169\n",
      "Epoch 70 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.09096489416912\n",
      "Other scores:: Edit 63.47361475115978, F1@[10:25:50] [60.50445276 57.45638077 45.91307369]\n",
      "Starting Training\n",
      "Epoch 71: Iteration 20 with loss 0.8963347673416138\n",
      "Epoch 71: Iteration 40 with loss 0.4975287914276123\n",
      "Epoch 71: Iteration 60 with loss 0.8178754448890686\n",
      "Epoch 71: Iteration 80 with loss 0.5309603214263916\n",
      "Epoch 71: Iteration 100 with loss 0.6155614256858826\n",
      "Epoch 71: Iteration 120 with loss 0.5718201994895935\n",
      "Epoch 71: Iteration 140 with loss 0.9931128025054932\n",
      "Epoch 71: Iteration 160 with loss 0.5813199877738953\n",
      "Epoch 71 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.06172398591526\n",
      "Other scores:: Edit 66.03771951635984, F1@[10:25:50] [63.04760467 59.825433   49.25878056]\n",
      "Starting Training\n",
      "Epoch 72: Iteration 20 with loss 1.8197827339172363\n",
      "Epoch 72: Iteration 40 with loss 0.7935134172439575\n",
      "Epoch 72: Iteration 60 with loss 1.3802123069763184\n",
      "Epoch 72: Iteration 80 with loss 0.7241494655609131\n",
      "Epoch 72: Iteration 100 with loss 0.9544132351875305\n",
      "Epoch 72: Iteration 120 with loss 1.0284961462020874\n",
      "Epoch 72: Iteration 140 with loss 1.0849151611328125\n",
      "Epoch 72: Iteration 160 with loss 1.9588226079940796\n",
      "Epoch 72 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.520197989966576\n",
      "Other scores:: Edit 65.25398122522425, F1@[10:25:50] [62.91227313 59.62614685 49.3362436 ]\n",
      "Starting Training\n",
      "Epoch 73: Iteration 20 with loss 0.6696469783782959\n",
      "Epoch 73: Iteration 40 with loss 0.7225005030632019\n",
      "Epoch 73: Iteration 60 with loss 0.6879256367683411\n",
      "Epoch 73: Iteration 80 with loss 1.126395583152771\n",
      "Epoch 73: Iteration 100 with loss 0.5431469678878784\n",
      "Epoch 73: Iteration 120 with loss 0.36914658546447754\n",
      "Epoch 73: Iteration 140 with loss 0.4465346932411194\n",
      "Epoch 73: Iteration 160 with loss 0.6432192921638489\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.1 minutes\n",
      "iter 20 of Expectation completed in a total of  6.0 minutes\n",
      "iter 30 of Expectation completed in a total of  8.9 minutes\n",
      "iter 40 of Expectation completed in a total of  11.9 minutes\n",
      "iter 50 of Expectation completed in a total of  14.8 minutes\n",
      "iter 60 of Expectation completed in a total of  17.6 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  73.87%, boundary mse  0.00\n",
      "Epoch 73 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Probability Accuracy 60.6153983515717\n",
      "Other scores:: Edit 65.93330080773825, F1@[10:25:50] [64.25532933 60.78374968 50.08733716]\n",
      "Starting Training\n",
      "Epoch 74: Iteration 20 with loss 0.37662214040756226\n",
      "Epoch 74: Iteration 40 with loss 0.46538692712783813\n",
      "Epoch 74: Iteration 60 with loss 0.6805916428565979\n",
      "Epoch 74: Iteration 80 with loss 1.4491453170776367\n",
      "Epoch 74: Iteration 100 with loss 0.750613272190094\n",
      "Epoch 74: Iteration 120 with loss 2.355565309524536\n",
      "Epoch 74: Iteration 140 with loss 1.2277954816818237\n",
      "Epoch 74: Iteration 160 with loss 0.5008724927902222\n",
      "Epoch 74 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.82589940904348\n",
      "Other scores:: Edit 64.6865640949597, F1@[10:25:50] [62.22923144 59.52696854 49.13423997]\n",
      "Starting Training\n",
      "Epoch 75: Iteration 20 with loss 0.7748159766197205\n",
      "Epoch 75: Iteration 40 with loss 0.3427307605743408\n",
      "Epoch 75: Iteration 60 with loss 0.6765397787094116\n",
      "Epoch 75: Iteration 80 with loss 0.4537811875343323\n",
      "Epoch 75: Iteration 100 with loss 0.6006370782852173\n",
      "Epoch 75: Iteration 120 with loss 0.9873471856117249\n",
      "Epoch 75: Iteration 140 with loss 0.583743691444397\n",
      "Epoch 75: Iteration 160 with loss 0.6658549904823303\n",
      "Epoch 75 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.99151790447598\n",
      "Other scores:: Edit 66.03894128006984, F1@[10:25:50] [63.72710349 61.0730979  51.14574305]\n",
      "Starting Training\n",
      "Epoch 76: Iteration 20 with loss 0.4985021948814392\n",
      "Epoch 76: Iteration 40 with loss 0.5285194516181946\n",
      "Epoch 76: Iteration 60 with loss 0.6055288314819336\n",
      "Epoch 76: Iteration 80 with loss 0.7832726836204529\n",
      "Epoch 76: Iteration 100 with loss 1.5381669998168945\n",
      "Epoch 76: Iteration 120 with loss 0.833995521068573\n",
      "Epoch 76: Iteration 140 with loss 0.40023860335350037\n",
      "Epoch 76: Iteration 160 with loss 1.2885825634002686\n",
      "Epoch 76 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 58.484271851161544\n",
      "Other scores:: Edit 64.1382850693836, F1@[10:25:50] [63.18604249 59.93847804 48.80510785]\n",
      "Starting Training\n",
      "Epoch 77: Iteration 20 with loss 0.5094269514083862\n",
      "Epoch 77: Iteration 40 with loss 0.6341437697410583\n",
      "Epoch 77: Iteration 60 with loss 0.5627272725105286\n",
      "Epoch 77: Iteration 80 with loss 0.40049490332603455\n",
      "Epoch 77: Iteration 100 with loss 0.43228113651275635\n",
      "Epoch 77: Iteration 120 with loss 0.8683909177780151\n",
      "Epoch 77: Iteration 140 with loss 0.3774005174636841\n",
      "Epoch 77: Iteration 160 with loss 0.43079131841659546\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  2.5 minutes\n",
      "iter 20 of Expectation completed in a total of  5.6 minutes\n",
      "iter 30 of Expectation completed in a total of  9.1 minutes\n",
      "iter 40 of Expectation completed in a total of  11.6 minutes\n",
      "iter 50 of Expectation completed in a total of  14.5 minutes\n",
      "iter 60 of Expectation completed in a total of  17.9 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  74.13%, boundary mse  0.00\n",
      "Epoch 77 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.18337509277292\n",
      "Other scores:: Edit 65.47724774357839, F1@[10:25:50] [64.04911032 61.06691781 49.76744469]\n",
      "Starting Training\n",
      "Epoch 78: Iteration 20 with loss 0.46931424736976624\n",
      "Epoch 78: Iteration 40 with loss 0.27069175243377686\n",
      "Epoch 78: Iteration 60 with loss 0.4215288758277893\n",
      "Epoch 78: Iteration 80 with loss 0.3552052974700928\n",
      "Epoch 78: Iteration 100 with loss 0.28167861700057983\n",
      "Epoch 78: Iteration 120 with loss 0.3974838852882385\n",
      "Epoch 78: Iteration 140 with loss 0.3273943364620209\n",
      "Epoch 78: Iteration 160 with loss 0.37397003173828125\n",
      "Epoch 78 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.59230138224675\n",
      "Other scores:: Edit 65.81270840777573, F1@[10:25:50] [64.68046009 61.46128609 50.9702635 ]\n",
      "Starting Training\n",
      "Epoch 79: Iteration 20 with loss 0.31310606002807617\n",
      "Epoch 79: Iteration 40 with loss 0.30800682306289673\n",
      "Epoch 79: Iteration 60 with loss 0.5320839881896973\n",
      "Epoch 79: Iteration 80 with loss 0.33320266008377075\n",
      "Epoch 79: Iteration 100 with loss 0.9497346878051758\n",
      "Epoch 79: Iteration 120 with loss 0.5185741186141968\n",
      "Epoch 79: Iteration 140 with loss 0.5283151268959045\n",
      "Epoch 79: Iteration 160 with loss 0.5511834621429443\n",
      "Epoch 79 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 59.61306019497659\n",
      "Other scores:: Edit 65.1637088542914, F1@[10:25:50] [63.52720675 60.21907984 49.86660656]\n",
      "Starting Training\n",
      "Epoch 80: Iteration 20 with loss 0.4717254936695099\n",
      "Epoch 80: Iteration 40 with loss 1.5434426069259644\n",
      "Epoch 80: Iteration 60 with loss 0.9787877798080444\n",
      "Epoch 80: Iteration 80 with loss 0.3510180711746216\n",
      "Epoch 80: Iteration 100 with loss 0.5200275182723999\n",
      "Epoch 80: Iteration 120 with loss 0.35030123591423035\n",
      "Epoch 80: Iteration 140 with loss 0.4479103684425354\n",
      "Epoch 80: Iteration 160 with loss 0.3093918263912201\n",
      "Epoch 80 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.53928270489562\n",
      "Other scores:: Edit 66.56907228921301, F1@[10:25:50] [65.29769087 61.83809342 50.97018803]\n",
      "Starting Training\n",
      "Epoch 81: Iteration 20 with loss 0.5609377026557922\n",
      "Epoch 81: Iteration 40 with loss 0.2653995454311371\n",
      "Epoch 81: Iteration 60 with loss 0.3466591238975525\n",
      "Epoch 81: Iteration 80 with loss 0.37219664454460144\n",
      "Epoch 81: Iteration 100 with loss 0.30710047483444214\n",
      "Epoch 81: Iteration 120 with loss 0.22427642345428467\n",
      "Epoch 81: Iteration 140 with loss 0.489939421415329\n",
      "Epoch 81: Iteration 160 with loss 0.2854754626750946\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.3 minutes\n",
      "iter 20 of Expectation completed in a total of  5.9 minutes\n",
      "iter 30 of Expectation completed in a total of  8.8 minutes\n",
      "iter 40 of Expectation completed in a total of  11.9 minutes\n",
      "iter 50 of Expectation completed in a total of  15.2 minutes\n",
      "iter 60 of Expectation completed in a total of  18.4 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  74.21%, boundary mse  0.00\n",
      "Epoch 81 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.36584617273341\n",
      "Other scores:: Edit 65.8132079097873, F1@[10:25:50] [65.07180938 61.59879235 50.51244228]\n",
      "Starting Training\n",
      "Epoch 82: Iteration 20 with loss 0.2750968635082245\n",
      "Epoch 82: Iteration 40 with loss 0.3088194727897644\n",
      "Epoch 82: Iteration 60 with loss 0.21833983063697815\n",
      "Epoch 82: Iteration 80 with loss 0.3483738601207733\n",
      "Epoch 82: Iteration 100 with loss 0.31939011812210083\n",
      "Epoch 82: Iteration 120 with loss 0.2053372710943222\n",
      "Epoch 82: Iteration 140 with loss 0.2794007956981659\n",
      "Epoch 82: Iteration 160 with loss 0.20595455169677734\n",
      "Epoch 82 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 60.097990524606445\n",
      "Other scores:: Edit 65.38286817474071, F1@[10:25:50] [64.44934849 61.45562549 50.56265505]\n",
      "Starting Training\n",
      "Epoch 83: Iteration 20 with loss 0.4208526611328125\n",
      "Epoch 83: Iteration 40 with loss 0.3014496862888336\n",
      "Epoch 83: Iteration 60 with loss 0.36925989389419556\n",
      "Epoch 83: Iteration 80 with loss 0.29534992575645447\n",
      "Epoch 83: Iteration 100 with loss 0.35263025760650635\n",
      "Epoch 83: Iteration 120 with loss 0.4592163562774658\n",
      "Epoch 83: Iteration 140 with loss 0.5834513902664185\n",
      "Epoch 83: Iteration 160 with loss 0.3835960328578949\n",
      "Epoch 83 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 61.04151204513368\n",
      "Other scores:: Edit 65.54867269976326, F1@[10:25:50] [64.41837544 61.24173159 50.32795613]\n",
      "Starting Training\n",
      "Epoch 84: Iteration 20 with loss 0.2238069325685501\n",
      "Epoch 84: Iteration 40 with loss 0.33913394808769226\n",
      "Epoch 84: Iteration 60 with loss 0.4034794569015503\n",
      "Epoch 84: Iteration 80 with loss 0.3710840046405792\n",
      "Epoch 84: Iteration 100 with loss 0.16906075179576874\n",
      "Epoch 84: Iteration 120 with loss 0.28760266304016113\n",
      "Epoch 84: Iteration 140 with loss 0.3289198577404022\n",
      "Epoch 84: Iteration 160 with loss 3.7069389820098877\n",
      "Epoch 84 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 48.61468406984336\n",
      "Other scores:: Edit 54.10088777235635, F1@[10:25:50] [47.66018998 44.14824384 34.18758083]\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Iteration 20 with loss 1.5980749130249023\n",
      "Epoch 85: Iteration 40 with loss 1.4890985488891602\n",
      "Epoch 85: Iteration 60 with loss 0.7232102751731873\n",
      "Epoch 85: Iteration 80 with loss 0.6263508796691895\n",
      "Epoch 85: Iteration 100 with loss 2.126077175140381\n",
      "Epoch 85: Iteration 120 with loss 1.1074270009994507\n",
      "Epoch 85: Iteration 140 with loss 0.6739345192909241\n",
      "Epoch 85: Iteration 160 with loss 1.6380910873413086\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.2 minutes\n",
      "iter 20 of Expectation completed in a total of  6.2 minutes\n",
      "iter 30 of Expectation completed in a total of  8.9 minutes\n",
      "iter 40 of Expectation completed in a total of  12.0 minutes\n",
      "iter 50 of Expectation completed in a total of  15.0 minutes\n",
      "iter 60 of Expectation completed in a total of  18.1 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  69.17%, boundary mse  0.00\n",
      "Epoch 85 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 53.40014843667167\n",
      "Other scores:: Edit 57.54329948805902, F1@[10:25:50] [52.98559727 50.48636237 40.30074544]\n",
      "Starting Training\n",
      "Epoch 86: Iteration 20 with loss 1.7972135543823242\n",
      "Epoch 86: Iteration 40 with loss 3.370809316635132\n",
      "Epoch 86: Iteration 60 with loss 1.3756165504455566\n",
      "Epoch 86: Iteration 80 with loss 1.586927890777588\n",
      "Epoch 86: Iteration 100 with loss 2.5260276794433594\n",
      "Epoch 86: Iteration 120 with loss 1.3317017555236816\n",
      "Epoch 86: Iteration 140 with loss 2.686396598815918\n",
      "Epoch 86: Iteration 160 with loss 0.9423964023590088\n",
      "Epoch 86 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 55.43953437759834\n",
      "Other scores:: Edit 57.40560918455673, F1@[10:25:50] [54.474115   51.0756046  41.36570739]\n",
      "Starting Training\n",
      "Epoch 87: Iteration 20 with loss 3.414712429046631\n",
      "Epoch 87: Iteration 40 with loss 1.7299418449401855\n",
      "Epoch 87: Iteration 60 with loss 0.5046930909156799\n",
      "Epoch 87: Iteration 80 with loss 2.140058994293213\n",
      "Epoch 87: Iteration 100 with loss 1.163346529006958\n",
      "Epoch 87: Iteration 120 with loss 1.3931572437286377\n",
      "Epoch 87: Iteration 140 with loss 0.6292991638183594\n",
      "Epoch 87: Iteration 160 with loss 0.840728759765625\n",
      "Epoch 87 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 51.963884130110884\n",
      "Other scores:: Edit 57.697329322567015, F1@[10:25:50] [53.33391293 50.46007455 40.54418093]\n",
      "Starting Training\n",
      "Epoch 88: Iteration 20 with loss 0.9384908676147461\n",
      "Epoch 88: Iteration 40 with loss 1.3092310428619385\n",
      "Epoch 88: Iteration 60 with loss 1.686638355255127\n",
      "Epoch 88: Iteration 80 with loss 1.2836867570877075\n",
      "Epoch 88: Iteration 100 with loss 0.7106762528419495\n",
      "Epoch 88: Iteration 120 with loss 0.437025785446167\n",
      "Epoch 88: Iteration 140 with loss 1.1948552131652832\n",
      "Epoch 88: Iteration 160 with loss 2.6188604831695557\n",
      "Epoch 88 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 53.36197900681358\n",
      "Other scores:: Edit 58.4549624297779, F1@[10:25:50] [53.78697572 50.77373787 41.69450799]\n",
      "Starting Training\n",
      "Epoch 89: Iteration 20 with loss 0.8398301005363464\n",
      "Epoch 89: Iteration 40 with loss 0.5005207657814026\n",
      "Epoch 89: Iteration 60 with loss 0.5472909808158875\n",
      "Epoch 89: Iteration 80 with loss 1.8062615394592285\n",
      "Epoch 89: Iteration 100 with loss 0.9057172536849976\n",
      "Epoch 89: Iteration 120 with loss 0.5256332159042358\n",
      "Epoch 89: Iteration 140 with loss 1.1798783540725708\n",
      "Epoch 89: Iteration 160 with loss 1.0815703868865967\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.6 minutes\n",
      "iter 20 of Expectation completed in a total of  6.4 minutes\n",
      "iter 30 of Expectation completed in a total of  9.7 minutes\n",
      "iter 40 of Expectation completed in a total of  12.6 minutes\n",
      "iter 50 of Expectation completed in a total of  16.1 minutes\n",
      "iter 60 of Expectation completed in a total of  18.7 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  69.16%, boundary mse  0.00\n",
      "Epoch 89 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 53.76733388764572\n",
      "Other scores:: Edit 59.848293107844576, F1@[10:25:50] [55.23996693 52.21609848 41.95474578]\n",
      "Starting Training\n",
      "Epoch 90: Iteration 20 with loss 0.4964550733566284\n",
      "Epoch 90: Iteration 40 with loss 0.6659524440765381\n",
      "Epoch 90: Iteration 60 with loss 0.5361630916595459\n",
      "Epoch 90: Iteration 80 with loss 0.5378469228744507\n",
      "Epoch 90: Iteration 100 with loss 0.7451132535934448\n",
      "Epoch 90: Iteration 120 with loss 1.249385118484497\n",
      "Epoch 90: Iteration 140 with loss 1.401450276374817\n",
      "Epoch 90: Iteration 160 with loss 2.948268175125122\n",
      "Epoch 90 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.304830888220486\n",
      "Other scores:: Edit 60.16365751373327, F1@[10:25:50] [56.24607242 52.84126919 41.28568993]\n",
      "Starting Training\n",
      "Epoch 91: Iteration 20 with loss 0.4735402464866638\n",
      "Epoch 91: Iteration 40 with loss 0.5932280421257019\n",
      "Epoch 91: Iteration 60 with loss 0.6632572412490845\n",
      "Epoch 91: Iteration 80 with loss 4.193451881408691\n",
      "Epoch 91: Iteration 100 with loss 1.9533010721206665\n",
      "Epoch 91: Iteration 120 with loss 0.7700245380401611\n",
      "Epoch 91: Iteration 140 with loss 1.7526072263717651\n",
      "Epoch 91: Iteration 160 with loss 0.5591185092926025\n",
      "Epoch 91 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.96509506085346\n",
      "Other scores:: Edit 60.52605854094005, F1@[10:25:50] [56.0892244  52.98674931 42.05647124]\n",
      "Starting Training\n",
      "Epoch 92: Iteration 20 with loss 0.707017719745636\n",
      "Epoch 92: Iteration 40 with loss 0.7849321961402893\n",
      "Epoch 92: Iteration 60 with loss 0.8318514823913574\n",
      "Epoch 92: Iteration 80 with loss 0.758643627166748\n",
      "Epoch 92: Iteration 100 with loss 0.6470106840133667\n",
      "Epoch 92: Iteration 120 with loss 0.46944332122802734\n",
      "Epoch 92: Iteration 140 with loss 1.4903571605682373\n",
      "Epoch 92: Iteration 160 with loss 0.7893306612968445\n",
      "Epoch 92 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 53.098364406448624\n",
      "Other scores:: Edit 59.07206315318768, F1@[10:25:50] [54.56073469 51.34436459 41.80116491]\n",
      "Starting Training\n",
      "Epoch 93: Iteration 20 with loss 0.33424168825149536\n",
      "Epoch 93: Iteration 40 with loss 0.867337703704834\n",
      "Epoch 93: Iteration 60 with loss 0.3278675675392151\n",
      "Epoch 93: Iteration 80 with loss 0.5442633628845215\n",
      "Epoch 93: Iteration 100 with loss 0.45706790685653687\n",
      "Epoch 93: Iteration 120 with loss 0.33450329303741455\n",
      "Epoch 93: Iteration 140 with loss 0.4417349100112915\n",
      "Epoch 93: Iteration 160 with loss 0.6316094398498535\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.4 minutes\n",
      "iter 20 of Expectation completed in a total of  6.2 minutes\n",
      "iter 30 of Expectation completed in a total of  8.9 minutes\n",
      "iter 40 of Expectation completed in a total of  12.0 minutes\n",
      "iter 50 of Expectation completed in a total of  15.0 minutes\n",
      "iter 60 of Expectation completed in a total of  18.5 minutes\n",
      "Expectation step finished, posterior frame-wise accuracy  69.57%, boundary mse  0.00\n",
      "Epoch 93 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.705498295210404\n",
      "Other scores:: Edit 61.90073996348357, F1@[10:25:50] [57.52329247 54.58087207 44.18254867]\n",
      "Starting Training\n",
      "Epoch 94: Iteration 20 with loss 0.29149776697158813\n",
      "Epoch 94: Iteration 40 with loss 0.398108571767807\n",
      "Epoch 94: Iteration 60 with loss 0.9446010589599609\n",
      "Epoch 94: Iteration 80 with loss 1.0225433111190796\n",
      "Epoch 94: Iteration 100 with loss 0.5697136521339417\n",
      "Epoch 94: Iteration 120 with loss 0.362163245677948\n",
      "Epoch 94: Iteration 140 with loss 0.514337420463562\n",
      "Epoch 94: Iteration 160 with loss 0.4781529903411865\n",
      "Epoch 94 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 56.03171857299903\n",
      "Other scores:: Edit 60.707832065686624, F1@[10:25:50] [57.38381685 54.07640717 43.56303161]\n",
      "Starting Training\n",
      "Epoch 95: Iteration 20 with loss 0.42811399698257446\n",
      "Epoch 95: Iteration 40 with loss 0.307843416929245\n",
      "Epoch 95: Iteration 60 with loss 0.5705506205558777\n",
      "Epoch 95: Iteration 80 with loss 0.4063071012496948\n",
      "Epoch 95: Iteration 100 with loss 0.5893059968948364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Iteration 120 with loss 0.8878644108772278\n",
      "Epoch 95: Iteration 140 with loss 0.33748066425323486\n",
      "Epoch 95: Iteration 160 with loss 0.504066526889801\n",
      "Epoch 95 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 55.80805910681302\n",
      "Other scores:: Edit 62.05488673879516, F1@[10:25:50] [58.49468231 55.31552874 44.09986683]\n",
      "Starting Training\n",
      "Epoch 96: Iteration 20 with loss 0.21670183539390564\n",
      "Epoch 96: Iteration 40 with loss 0.24132494628429413\n",
      "Epoch 96: Iteration 60 with loss 0.9693946242332458\n",
      "Epoch 96: Iteration 80 with loss 0.3011978268623352\n",
      "Epoch 96: Iteration 100 with loss 0.8201950788497925\n",
      "Epoch 96: Iteration 120 with loss 0.8115737438201904\n",
      "Epoch 96: Iteration 140 with loss 0.2786802053451538\n",
      "Epoch 96: Iteration 160 with loss 0.4960501492023468\n",
      "Epoch 96 finished, starting validation\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 56.01352671023041\n",
      "Other scores:: Edit 61.63859734349824, F1@[10:25:50] [58.40496877 55.12874628 44.88440042]\n",
      "Starting Training\n",
      "Epoch 97: Iteration 20 with loss 0.6496497988700867\n",
      "Epoch 97: Iteration 40 with loss 0.4404562711715698\n",
      "Epoch 97: Iteration 60 with loss 0.28798720240592957\n",
      "Epoch 97: Iteration 80 with loss 0.3523455560207367\n",
      "Epoch 97: Iteration 100 with loss 0.4565427899360657\n",
      "Epoch 97: Iteration 120 with loss 0.3333939015865326\n",
      "Epoch 97: Iteration 140 with loss 0.9665653705596924\n",
      "Epoch 97: Iteration 160 with loss 0.41736090183258057\n",
      "Calculating expectation\n",
      "iter 10 of Expectation completed in a total of  3.2 minutes\n",
      "iter 20 of Expectation completed in a total of  6.4 minutes\n",
      "iter 30 of Expectation completed in a total of  9.4 minutes\n",
      "iter 40 of Expectation completed in a total of  12.3 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-22013:\n",
      "Process ForkPoolWorker-22005:\n",
      "Process ForkPoolWorker-22002:\n",
      "Process ForkPoolWorker-22019:\n",
      "Process ForkPoolWorker-22012:\n",
      "Process ForkPoolWorker-22014:\n",
      "Process ForkPoolWorker-22009:\n",
      "Process ForkPoolWorker-22020:\n",
      "Process ForkPoolWorker-22018:\n",
      "Process ForkPoolWorker-22007:\n",
      "Process ForkPoolWorker-22011:\n",
      "Process ForkPoolWorker-22006:\n",
      "Process ForkPoolWorker-22016:\n",
      "Process ForkPoolWorker-22010:\n",
      "Process ForkPoolWorker-22003:\n",
      "Process ForkPoolWorker-22008:\n",
      "Process ForkPoolWorker-22015:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-22001:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"<ipython-input-14-e945e03708c3>\", line 47, in prob_vals_per_segment\n",
      "    b2_prior = get_possion_prob_for_all_class(1, next_ele-b1)  # mid_seg_len x num_class\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-14-e945e03708c3>\", line 99, in prob_vals_per_segment\n",
      "    expected_boundary = round(torch.sum(torch.sum(mat_b1_b2_c_prob, axis=(0,2)).squeeze() * \\\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"<ipython-input-12-748e515e4c49>\", line 15, in get_possion_prob_for_all_class\n",
      "    ele_list.append(torch.tensor(prob))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"<ipython-input-14-e945e03708c3>\", line 50, in prob_vals_per_segment\n",
      "    + b1_prior[b1-cur_ele] + b2_prior\n",
      "  File \"<ipython-input-14-e945e03708c3>\", line 46, in prob_vals_per_segment\n",
      "    mid_sum = (cumsum_feat[b1+1:next_ele, :] - cumsum_feat[b1, :])  # mid_seg_len\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-27-8ffe18a7b6ba>\", line 42, in <module>\n",
      "    perform_expectation(model, trainloder_expectation)\n",
      "  File \"<ipython-input-15-e151fbc59213>\", line 66, in perform_expectation\n",
      "    calculate_element_probb(prob, item_1, item_4, item_2)\n",
      "  File \"<ipython-input-15-e151fbc59213>\", line 42, in calculate_element_probb\n",
      "    pool.join()  # postpones the execution of next line of code until all processes in the queue are done.\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/pool.py\", line 556, in join\n",
      "    self._worker_handler.join()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/threading.py\", line 1032, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/threading.py\", line 1048, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-22017:\n",
      "Process ForkPoolWorker-22004:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "initialize_epoch = 30\n",
    "expectation_cal_gap = 4\n",
    "best_val_acc = 0\n",
    "for epoch in range(30, 150):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)  # features\n",
    "        item_1 = item[1].to(device)  # count\n",
    "        item_2 = item[2].to(device)  # target\n",
    "        weights = item[5].to(device)  # posterior weight\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        boundary_target_tensor = get_single_random(item[4], item_2.shape[1], item_2.device)\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, boundary_target_tensor)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                            max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                total_count = torch.sum(src_mask)\n",
    "                weighted_loss_sum = -torch.sum(torch.sum(torch.log(prob + 1e-8) * weights, dim=-1) * src_mask)\n",
    "                loss += weighted_loss_sum/total_count\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1)%20 == 0:\n",
    "            print(f'Epoch {epoch+1}: Iteration {i+1} with loss {loss.item()}')\n",
    "\n",
    "    if (epoch >= initialize_epoch) and ((epoch % (3 * expectation_cal_gap)) == 0):\n",
    "        torch.save(model.state_dict(), config.output_dir + f\"ms-tcn-initial-{epoch}-epochs.wt\")\n",
    "\n",
    "    if epoch >= initialize_epoch and (epoch % expectation_cal_gap == 0):\n",
    "        perform_expectation(model, trainloder_expectation)\n",
    "    \n",
    "    print(f'Epoch {epoch+1} finished, starting validation')\n",
    "    val_acc, best_val_acc = validate(model, testloader, best_val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 105, Probability Accuracy 61.02425300046298\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 64, Probability Accuracy 66.57663740715732\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {best_val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-emmax-best-model.wt\"))\n",
    "# model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-initial-15-epochs.wt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
