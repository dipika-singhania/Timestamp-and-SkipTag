{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 1, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split1/', 'project_name': 'breakfast-split-1', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split1.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split1.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split1_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=1,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split1/\",\n",
    "    project_name=\"breakfast-split-1\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1460\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 252\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = Breakfast(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels_dir = \"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/length_segmentation_output/\"\n",
    "def get_single_random(output_p, video_ids):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((output_p.shape[0], output_p.shape[2]), dtype=torch.long, \n",
    "                                        device=output_p.device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        pseudo_l = open(pseudo_labels_dir + cur_vidid + \".txt\").read().split(\"\\n\")[0:-1]\n",
    "        pseudo_l = [label_name_to_label_id_dict[ele] for ele in pseudo_l]\n",
    "        abc = torch.tensor(pseudo_l).to(torch.long).to(boundary_target_tensor.device)\n",
    "        frame_idx_tensor = torch.arange(0, len(pseudo_l), 1).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = abc\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Training:: Epoch 0, Iteration 0, Current loss 15.688101768493652 Accuracy 1.7120043307619435\n",
      "Training:: Epoch 0, Iteration 10, Current loss 14.867568969726562 Accuracy 3.1712991306477285\n",
      "Training:: Epoch 0, Iteration 20, Current loss 12.627345085144043 Accuracy 8.095451921226505\n",
      "Training:: Epoch 0, Iteration 30, Current loss 13.397523880004883 Accuracy 10.806481142438667\n",
      "Training:: Epoch 0, Iteration 40, Current loss 12.8862886428833 Accuracy 25.437440076701822\n",
      "Training:: Epoch 0, Iteration 50, Current loss 13.115045547485352 Accuracy 14.34950178605001\n",
      "Training:: Epoch 0, Iteration 60, Current loss 13.697102546691895 Accuracy 5.139224639627541\n",
      "Training:: Epoch 0, Iteration 70, Current loss 10.90279769897461 Accuracy 31.25250501002004\n",
      "Training:: Epoch 0, Iteration 80, Current loss 12.055412292480469 Accuracy 14.958582743817644\n",
      "Training:: Epoch 0, Iteration 90, Current loss 12.215043067932129 Accuracy 9.596265237313046\n",
      "Training:: Epoch 0, Iteration 100, Current loss 11.243647575378418 Accuracy 9.561526116891857\n",
      "Training:: Epoch 0, Iteration 110, Current loss 9.330362319946289 Accuracy 32.140554480980015\n",
      "Training:: Epoch 0, Iteration 120, Current loss 10.558212280273438 Accuracy 14.313053988718774\n",
      "Training:: Epoch 0, Iteration 130, Current loss 9.601592063903809 Accuracy 18.04804804804805\n",
      "Training:: Epoch 0, Iteration 140, Current loss 10.074091911315918 Accuracy 15.34612935504412\n",
      "Training:: Epoch 0, Iteration 150, Current loss 11.148886680603027 Accuracy 17.170980678089684\n",
      "Training:: Epoch 0, Iteration 160, Current loss 10.226292610168457 Accuracy 22.200047896543467\n",
      "Training:: Epoch 0, Iteration 170, Current loss 9.365734100341797 Accuracy 19.968930027833515\n",
      "Training:: Epoch 0, Iteration 180, Current loss 8.992399215698242 Accuracy 26.47752808988764\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 0, Probability Accuracy 20.99156744265188\n",
      "Starting Training\n",
      "Training:: Epoch 1, Iteration 0, Current loss 8.05727481842041 Accuracy 34.34805105208692\n",
      "Training:: Epoch 1, Iteration 10, Current loss 10.004932403564453 Accuracy 13.35328578706062\n",
      "Training:: Epoch 1, Iteration 20, Current loss 8.617807388305664 Accuracy 24.365034852976525\n",
      "Training:: Epoch 1, Iteration 30, Current loss 10.051569938659668 Accuracy 25.629967047877496\n",
      "Training:: Epoch 1, Iteration 40, Current loss 9.949522972106934 Accuracy 17.11468108795928\n",
      "Training:: Epoch 1, Iteration 50, Current loss 10.192352294921875 Accuracy 14.80104940970704\n",
      "Training:: Epoch 1, Iteration 60, Current loss 8.234490394592285 Accuracy 24.763805721889554\n",
      "Training:: Epoch 1, Iteration 70, Current loss 10.401637077331543 Accuracy 18.116420503909644\n",
      "Training:: Epoch 1, Iteration 80, Current loss 9.600810050964355 Accuracy 28.64483923065629\n",
      "Training:: Epoch 1, Iteration 90, Current loss 9.90942096710205 Accuracy 19.23607915324436\n",
      "Training:: Epoch 1, Iteration 100, Current loss 8.549787521362305 Accuracy 21.73313534153585\n",
      "Training:: Epoch 1, Iteration 110, Current loss 9.416618347167969 Accuracy 17.144886363636363\n",
      "Training:: Epoch 1, Iteration 120, Current loss 8.157992362976074 Accuracy 36.855730760178865\n",
      "Training:: Epoch 1, Iteration 130, Current loss 8.339263916015625 Accuracy 28.083560399636696\n",
      "Training:: Epoch 1, Iteration 140, Current loss 9.159346580505371 Accuracy 23.335216439516984\n",
      "Training:: Epoch 1, Iteration 150, Current loss 7.8602399826049805 Accuracy 24.189058339385138\n",
      "Training:: Epoch 1, Iteration 160, Current loss 8.273746490478516 Accuracy 26.051370416240374\n",
      "Training:: Epoch 1, Iteration 170, Current loss 8.106002807617188 Accuracy 29.194944527979843\n",
      "Training:: Epoch 1, Iteration 180, Current loss 8.417619705200195 Accuracy 28.677372885877393\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 1, Probability Accuracy 37.45108048323975\n",
      "Starting Training\n",
      "Training:: Epoch 2, Iteration 0, Current loss 7.357198715209961 Accuracy 35.63343328335832\n",
      "Training:: Epoch 2, Iteration 10, Current loss 8.112380981445312 Accuracy 29.723322530308486\n",
      "Training:: Epoch 2, Iteration 20, Current loss 6.656579494476318 Accuracy 31.97553516819572\n",
      "Training:: Epoch 2, Iteration 30, Current loss 6.5834808349609375 Accuracy 33.65495264229441\n",
      "Training:: Epoch 2, Iteration 40, Current loss 7.823265075683594 Accuracy 19.89634321911892\n",
      "Training:: Epoch 2, Iteration 50, Current loss 6.805909633636475 Accuracy 30.01612036539495\n",
      "Training:: Epoch 2, Iteration 60, Current loss 6.312103748321533 Accuracy 30.80754622999813\n",
      "Training:: Epoch 2, Iteration 70, Current loss 7.3204169273376465 Accuracy 34.80678538748504\n",
      "Training:: Epoch 2, Iteration 80, Current loss 5.245928764343262 Accuracy 41.06476048223621\n",
      "Training:: Epoch 2, Iteration 90, Current loss 9.081082344055176 Accuracy 29.847892220773577\n",
      "Training:: Epoch 2, Iteration 100, Current loss 8.458741188049316 Accuracy 28.738983500099398\n",
      "Training:: Epoch 2, Iteration 110, Current loss 7.504465103149414 Accuracy 37.13382070824908\n",
      "Training:: Epoch 2, Iteration 120, Current loss 9.356874465942383 Accuracy 40.913668406115534\n",
      "Training:: Epoch 2, Iteration 130, Current loss 7.692050933837891 Accuracy 23.92882103112736\n",
      "Training:: Epoch 2, Iteration 140, Current loss 8.441701889038086 Accuracy 25.935966004835517\n",
      "Training:: Epoch 2, Iteration 150, Current loss 6.919122219085693 Accuracy 36.47244249618283\n",
      "Training:: Epoch 2, Iteration 160, Current loss 7.917263984680176 Accuracy 35.4008729611762\n",
      "Training:: Epoch 2, Iteration 170, Current loss 7.643721103668213 Accuracy 33.24245644840811\n",
      "Training:: Epoch 2, Iteration 180, Current loss 6.456663608551025 Accuracy 39.3386447357149\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 2, Probability Accuracy 33.66355243736917\n",
      "Starting Training\n",
      "Training:: Epoch 3, Iteration 0, Current loss 6.474941253662109 Accuracy 36.157151626764886\n",
      "Training:: Epoch 3, Iteration 10, Current loss 7.535764217376709 Accuracy 28.952224728316587\n",
      "Training:: Epoch 3, Iteration 20, Current loss 8.041070938110352 Accuracy 40.03364695619665\n",
      "Training:: Epoch 3, Iteration 30, Current loss 6.377602577209473 Accuracy 49.68676040651538\n",
      "Training:: Epoch 3, Iteration 40, Current loss 7.5966644287109375 Accuracy 40.24717378808201\n",
      "Training:: Epoch 3, Iteration 50, Current loss 6.80863618850708 Accuracy 45.7926653190875\n",
      "Training:: Epoch 3, Iteration 60, Current loss 7.823949813842773 Accuracy 38.10082063305979\n",
      "Training:: Epoch 3, Iteration 70, Current loss 6.726225852966309 Accuracy 46.67567567567568\n",
      "Training:: Epoch 3, Iteration 80, Current loss 6.780111789703369 Accuracy 33.0854617954521\n",
      "Training:: Epoch 3, Iteration 90, Current loss 6.998040199279785 Accuracy 41.081562778481306\n",
      "Training:: Epoch 3, Iteration 100, Current loss 7.414593696594238 Accuracy 28.495499357051006\n",
      "Training:: Epoch 3, Iteration 110, Current loss 6.951094627380371 Accuracy 25.95808383233533\n",
      "Training:: Epoch 3, Iteration 120, Current loss 6.925449848175049 Accuracy 43.936352509179926\n",
      "Training:: Epoch 3, Iteration 130, Current loss 6.388370037078857 Accuracy 46.13980582524272\n",
      "Training:: Epoch 3, Iteration 140, Current loss 7.436987400054932 Accuracy 37.65599565925122\n",
      "Training:: Epoch 3, Iteration 150, Current loss 6.523197174072266 Accuracy 38.157303370786515\n",
      "Training:: Epoch 3, Iteration 160, Current loss 8.038005828857422 Accuracy 28.69441694287805\n",
      "Training:: Epoch 3, Iteration 170, Current loss 8.091632843017578 Accuracy 40.94282341035588\n",
      "Training:: Epoch 3, Iteration 180, Current loss 5.812917709350586 Accuracy 53.95046691027203\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 3, Probability Accuracy 40.580148865700345\n",
      "Starting Training\n",
      "Training:: Epoch 4, Iteration 0, Current loss 6.885035991668701 Accuracy 26.73826571201273\n",
      "Training:: Epoch 4, Iteration 10, Current loss 5.375127792358398 Accuracy 41.6613301619248\n",
      "Training:: Epoch 4, Iteration 20, Current loss 6.516550064086914 Accuracy 46.25550660792952\n",
      "Training:: Epoch 4, Iteration 30, Current loss 6.531889915466309 Accuracy 42.45464247598719\n",
      "Training:: Epoch 4, Iteration 40, Current loss 6.402658939361572 Accuracy 46.60932683702894\n",
      "Training:: Epoch 4, Iteration 50, Current loss 5.274881362915039 Accuracy 52.398753894081\n",
      "Training:: Epoch 4, Iteration 60, Current loss 5.622676372528076 Accuracy 57.76815957847196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 4, Iteration 70, Current loss 6.280013084411621 Accuracy 36.54118313048401\n",
      "Training:: Epoch 4, Iteration 80, Current loss 7.169579982757568 Accuracy 36.03206765923707\n",
      "Training:: Epoch 4, Iteration 90, Current loss 6.607783317565918 Accuracy 34.43472446648465\n",
      "Training:: Epoch 4, Iteration 100, Current loss 5.889108657836914 Accuracy 51.48262813897489\n",
      "Training:: Epoch 4, Iteration 110, Current loss 6.916120529174805 Accuracy 31.214701927386823\n",
      "Training:: Epoch 4, Iteration 120, Current loss 5.950628757476807 Accuracy 50.024175027196904\n",
      "Training:: Epoch 4, Iteration 130, Current loss 6.824543476104736 Accuracy 44.49109915584132\n",
      "Training:: Epoch 4, Iteration 140, Current loss 5.868003845214844 Accuracy 43.218733080671356\n",
      "Training:: Epoch 4, Iteration 150, Current loss 5.4972429275512695 Accuracy 52.68215081132676\n",
      "Training:: Epoch 4, Iteration 160, Current loss 7.453354835510254 Accuracy 36.96352333158565\n",
      "Training:: Epoch 4, Iteration 170, Current loss 5.6124420166015625 Accuracy 53.567373202119605\n",
      "Training:: Epoch 4, Iteration 180, Current loss 6.486903667449951 Accuracy 43.48277293482773\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 4, Probability Accuracy 46.64893890649794\n",
      "Starting Training\n",
      "Training:: Epoch 5, Iteration 0, Current loss 5.3833417892456055 Accuracy 50.22416737830914\n",
      "Training:: Epoch 5, Iteration 10, Current loss 4.685949325561523 Accuracy 53.75138360845084\n",
      "Training:: Epoch 5, Iteration 20, Current loss 6.69047212600708 Accuracy 46.011168727562826\n",
      "Training:: Epoch 5, Iteration 30, Current loss 5.119693756103516 Accuracy 58.73171740141609\n",
      "Training:: Epoch 5, Iteration 40, Current loss 6.294136047363281 Accuracy 48.92521271831617\n",
      "Training:: Epoch 5, Iteration 50, Current loss 5.67277717590332 Accuracy 44.81924560371315\n",
      "Training:: Epoch 5, Iteration 60, Current loss 6.296163082122803 Accuracy 35.59159543021491\n",
      "Training:: Epoch 5, Iteration 70, Current loss 5.9030585289001465 Accuracy 53.88086642599278\n",
      "Training:: Epoch 5, Iteration 80, Current loss 5.510390758514404 Accuracy 50.03877587543996\n",
      "Training:: Epoch 5, Iteration 90, Current loss 6.521420955657959 Accuracy 36.02242923035181\n",
      "Training:: Epoch 5, Iteration 100, Current loss 5.476321220397949 Accuracy 51.7302195463115\n",
      "Training:: Epoch 5, Iteration 110, Current loss 4.843090057373047 Accuracy 54.62244177840508\n",
      "Training:: Epoch 5, Iteration 120, Current loss 5.943709373474121 Accuracy 46.854391290694025\n",
      "Training:: Epoch 5, Iteration 130, Current loss 7.970916748046875 Accuracy 39.547540283854445\n",
      "Training:: Epoch 5, Iteration 140, Current loss 4.534069061279297 Accuracy 60.15493432132031\n",
      "Training:: Epoch 5, Iteration 150, Current loss 6.697222709655762 Accuracy 44.16178746887408\n",
      "Training:: Epoch 5, Iteration 160, Current loss 5.760191440582275 Accuracy 58.47075535791489\n",
      "Training:: Epoch 5, Iteration 170, Current loss 5.088237762451172 Accuracy 49.85758760018547\n",
      "Training:: Epoch 5, Iteration 180, Current loss 6.198019981384277 Accuracy 42.72255335512401\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 5, Probability Accuracy 52.02147908084729\n",
      "Starting Training\n",
      "Training:: Epoch 6, Iteration 0, Current loss 4.975122451782227 Accuracy 56.38848747591522\n",
      "Training:: Epoch 6, Iteration 10, Current loss 5.2581281661987305 Accuracy 43.38101523204794\n",
      "Training:: Epoch 6, Iteration 20, Current loss 8.982439041137695 Accuracy 35.936069258303505\n",
      "Training:: Epoch 6, Iteration 30, Current loss 5.226809978485107 Accuracy 57.1613529697362\n",
      "Training:: Epoch 6, Iteration 40, Current loss 5.436341762542725 Accuracy 47.93980416639285\n",
      "Training:: Epoch 6, Iteration 50, Current loss 6.660220623016357 Accuracy 43.82022471910113\n",
      "Training:: Epoch 6, Iteration 60, Current loss 6.529219150543213 Accuracy 43.983018559843245\n",
      "Training:: Epoch 6, Iteration 70, Current loss 6.261469841003418 Accuracy 62.293555501102674\n",
      "Training:: Epoch 6, Iteration 80, Current loss 5.314724445343018 Accuracy 55.07914419899113\n",
      "Training:: Epoch 6, Iteration 90, Current loss 6.433204650878906 Accuracy 44.64310954063604\n",
      "Training:: Epoch 6, Iteration 100, Current loss 7.069818019866943 Accuracy 40.8830443726124\n",
      "Training:: Epoch 6, Iteration 110, Current loss 5.311341762542725 Accuracy 47.62241544285892\n",
      "Training:: Epoch 6, Iteration 120, Current loss 6.631687641143799 Accuracy 37.701377013770134\n",
      "Training:: Epoch 6, Iteration 130, Current loss 4.559247970581055 Accuracy 61.73199635369188\n",
      "Training:: Epoch 6, Iteration 140, Current loss 5.3939738273620605 Accuracy 53.25783097985808\n",
      "Training:: Epoch 6, Iteration 150, Current loss 5.889377593994141 Accuracy 51.83625177472788\n",
      "Training:: Epoch 6, Iteration 160, Current loss 4.971004486083984 Accuracy 57.2285754623747\n",
      "Training:: Epoch 6, Iteration 170, Current loss 6.0074543952941895 Accuracy 48.3609061940722\n",
      "Training:: Epoch 6, Iteration 180, Current loss 5.099850177764893 Accuracy 48.91352549889135\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 6, Probability Accuracy 47.37704334199936\n",
      "Starting Training\n",
      "Training:: Epoch 7, Iteration 0, Current loss 7.151811599731445 Accuracy 40.73287900793208\n",
      "Training:: Epoch 7, Iteration 10, Current loss 6.05611515045166 Accuracy 41.12453203362294\n",
      "Training:: Epoch 7, Iteration 20, Current loss 6.11543607711792 Accuracy 49.955969955969955\n",
      "Training:: Epoch 7, Iteration 30, Current loss 5.993200778961182 Accuracy 64.67875806947433\n",
      "Training:: Epoch 7, Iteration 40, Current loss 6.125125885009766 Accuracy 45.599523064311796\n",
      "Training:: Epoch 7, Iteration 50, Current loss 5.283883094787598 Accuracy 61.15472927931264\n",
      "Training:: Epoch 7, Iteration 60, Current loss 5.130862712860107 Accuracy 48.77409967260822\n",
      "Training:: Epoch 7, Iteration 70, Current loss 4.791347503662109 Accuracy 65.43222250062641\n",
      "Training:: Epoch 7, Iteration 80, Current loss 4.305079460144043 Accuracy 62.662160688978524\n",
      "Training:: Epoch 7, Iteration 90, Current loss 4.504557132720947 Accuracy 64.9812473954716\n",
      "Training:: Epoch 7, Iteration 100, Current loss 6.350220203399658 Accuracy 56.203007518796994\n",
      "Training:: Epoch 7, Iteration 110, Current loss 5.243225574493408 Accuracy 58.423428151569226\n",
      "Training:: Epoch 7, Iteration 120, Current loss 5.985276222229004 Accuracy 56.91717445271948\n",
      "Training:: Epoch 7, Iteration 130, Current loss 5.414712905883789 Accuracy 48.18731117824773\n",
      "Training:: Epoch 7, Iteration 140, Current loss 5.649481773376465 Accuracy 47.36447195648096\n",
      "Training:: Epoch 7, Iteration 150, Current loss 6.133406639099121 Accuracy 44.7550849394378\n",
      "Training:: Epoch 7, Iteration 160, Current loss 5.516063690185547 Accuracy 62.23218287763335\n",
      "Training:: Epoch 7, Iteration 170, Current loss 6.890292644500732 Accuracy 50.86056720786008\n",
      "Training:: Epoch 7, Iteration 180, Current loss 6.498950958251953 Accuracy 44.97486017739111\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 7, Probability Accuracy 46.58186624246669\n",
      "Starting Training\n",
      "Training:: Epoch 8, Iteration 0, Current loss 4.739704608917236 Accuracy 55.86067472518216\n",
      "Training:: Epoch 8, Iteration 10, Current loss 5.070976734161377 Accuracy 53.928909544711246\n",
      "Training:: Epoch 8, Iteration 20, Current loss 5.465886116027832 Accuracy 45.19234457101216\n",
      "Training:: Epoch 8, Iteration 30, Current loss 4.168686389923096 Accuracy 57.58280069726903\n",
      "Training:: Epoch 8, Iteration 40, Current loss 5.51230525970459 Accuracy 44.41364014416413\n",
      "Training:: Epoch 8, Iteration 50, Current loss 4.527568817138672 Accuracy 59.25739838215345\n",
      "Training:: Epoch 8, Iteration 60, Current loss 5.5705156326293945 Accuracy 42.13637836086816\n",
      "Training:: Epoch 8, Iteration 70, Current loss 5.806458473205566 Accuracy 51.150138398396486\n",
      "Training:: Epoch 8, Iteration 80, Current loss 5.23669958114624 Accuracy 44.183673469387756\n",
      "Training:: Epoch 8, Iteration 90, Current loss 4.808967113494873 Accuracy 51.18085057786305\n",
      "Training:: Epoch 8, Iteration 100, Current loss 3.9505107402801514 Accuracy 56.510223048327134\n",
      "Training:: Epoch 8, Iteration 110, Current loss 4.5370965003967285 Accuracy 47.434402332361515\n",
      "Training:: Epoch 8, Iteration 120, Current loss 4.242543697357178 Accuracy 56.53393157599551\n",
      "Training:: Epoch 8, Iteration 130, Current loss 5.865342140197754 Accuracy 46.62058882169203\n",
      "Training:: Epoch 8, Iteration 140, Current loss 5.792014122009277 Accuracy 46.99437370447142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 8, Iteration 150, Current loss 5.290956497192383 Accuracy 57.1322505800464\n",
      "Training:: Epoch 8, Iteration 160, Current loss 4.486000061035156 Accuracy 50.41947005565246\n",
      "Training:: Epoch 8, Iteration 170, Current loss 4.723947525024414 Accuracy 58.09263061829797\n",
      "Training:: Epoch 8, Iteration 180, Current loss 7.25172233581543 Accuracy 34.866059099696216\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 8, Probability Accuracy 51.56285242826786\n",
      "Starting Training\n",
      "Training:: Epoch 9, Iteration 0, Current loss 5.134907245635986 Accuracy 44.44444444444444\n",
      "Training:: Epoch 9, Iteration 10, Current loss 5.608646869659424 Accuracy 55.45439288411513\n",
      "Training:: Epoch 9, Iteration 20, Current loss 6.688746929168701 Accuracy 49.37062416207359\n",
      "Training:: Epoch 9, Iteration 30, Current loss 6.824410438537598 Accuracy 37.94405879951\n",
      "Training:: Epoch 9, Iteration 40, Current loss 6.757987976074219 Accuracy 43.35959307735252\n",
      "Training:: Epoch 9, Iteration 50, Current loss 6.34982967376709 Accuracy 51.600455465587046\n",
      "Training:: Epoch 9, Iteration 60, Current loss 6.3237833976745605 Accuracy 44.29590017825312\n",
      "Training:: Epoch 9, Iteration 70, Current loss 4.8743720054626465 Accuracy 46.8321862738792\n",
      "Training:: Epoch 9, Iteration 80, Current loss 4.421104431152344 Accuracy 58.026189715745765\n",
      "Training:: Epoch 9, Iteration 90, Current loss 8.41258716583252 Accuracy 37.86147272185233\n",
      "Training:: Epoch 9, Iteration 100, Current loss 5.373716354370117 Accuracy 33.64705882352941\n",
      "Training:: Epoch 9, Iteration 110, Current loss 4.895041465759277 Accuracy 65.03431429568454\n",
      "Training:: Epoch 9, Iteration 120, Current loss 4.718883991241455 Accuracy 53.92334265504195\n",
      "Training:: Epoch 9, Iteration 130, Current loss 3.403109073638916 Accuracy 65.68117757594739\n",
      "Training:: Epoch 9, Iteration 140, Current loss 4.505433559417725 Accuracy 49.59310344827586\n",
      "Training:: Epoch 9, Iteration 150, Current loss 5.615799427032471 Accuracy 57.14049859666502\n",
      "Training:: Epoch 9, Iteration 160, Current loss 4.979366779327393 Accuracy 53.54741216471477\n",
      "Training:: Epoch 9, Iteration 170, Current loss 5.358459949493408 Accuracy 55.70647047726844\n",
      "Training:: Epoch 9, Iteration 180, Current loss 4.285864353179932 Accuracy 55.50702620584884\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 9, Probability Accuracy 51.25044022618722\n",
      "Starting Training\n",
      "Training:: Epoch 10, Iteration 0, Current loss 5.8285722732543945 Accuracy 38.13532733737712\n",
      "Training:: Epoch 10, Iteration 10, Current loss 3.947145462036133 Accuracy 66.70073399609774\n",
      "Training:: Epoch 10, Iteration 20, Current loss 5.67022180557251 Accuracy 50.975839558516725\n",
      "Training:: Epoch 10, Iteration 30, Current loss 3.624389171600342 Accuracy 56.42649622312609\n",
      "Training:: Epoch 10, Iteration 40, Current loss 3.795344114303589 Accuracy 60.29723991507431\n",
      "Training:: Epoch 10, Iteration 50, Current loss 3.8364381790161133 Accuracy 72.63224294854466\n",
      "Training:: Epoch 10, Iteration 60, Current loss 6.759252071380615 Accuracy 44.02206320810972\n",
      "Training:: Epoch 10, Iteration 70, Current loss 3.7683351039886475 Accuracy 64.51241671714112\n",
      "Training:: Epoch 10, Iteration 80, Current loss 4.968536376953125 Accuracy 62.29798412426475\n",
      "Training:: Epoch 10, Iteration 90, Current loss 4.283366680145264 Accuracy 51.946386946386944\n",
      "Training:: Epoch 10, Iteration 100, Current loss 7.30983304977417 Accuracy 39.41669252249457\n",
      "Training:: Epoch 10, Iteration 110, Current loss 3.9249215126037598 Accuracy 61.287547968770674\n",
      "Training:: Epoch 10, Iteration 120, Current loss 2.885734796524048 Accuracy 65.50973654066438\n",
      "Training:: Epoch 10, Iteration 130, Current loss 5.215476036071777 Accuracy 54.95675587467363\n",
      "Training:: Epoch 10, Iteration 140, Current loss 4.24983549118042 Accuracy 52.442067736185386\n",
      "Training:: Epoch 10, Iteration 150, Current loss 4.082457542419434 Accuracy 65.71061643835617\n",
      "Training:: Epoch 10, Iteration 160, Current loss 4.753513336181641 Accuracy 53.12354312354312\n",
      "Training:: Epoch 10, Iteration 170, Current loss 4.975809097290039 Accuracy 52.392414296134206\n",
      "Training:: Epoch 10, Iteration 180, Current loss 4.243070602416992 Accuracy 67.96433713589545\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 10, Probability Accuracy 52.406108163079566\n",
      "Starting Training\n",
      "Training:: Epoch 11, Iteration 0, Current loss 3.333873987197876 Accuracy 67.44395066660009\n",
      "Training:: Epoch 11, Iteration 10, Current loss 5.592169761657715 Accuracy 60.9254240690555\n",
      "Training:: Epoch 11, Iteration 20, Current loss 4.478793144226074 Accuracy 58.33932422717469\n",
      "Training:: Epoch 11, Iteration 30, Current loss 4.536716938018799 Accuracy 58.902877697841724\n",
      "Training:: Epoch 11, Iteration 40, Current loss 6.378317832946777 Accuracy 47.42364042711696\n",
      "Training:: Epoch 11, Iteration 50, Current loss 3.592210531234741 Accuracy 53.01204819277108\n",
      "Training:: Epoch 11, Iteration 60, Current loss 4.133901119232178 Accuracy 71.5583465431045\n",
      "Training:: Epoch 11, Iteration 70, Current loss 4.241559028625488 Accuracy 59.10118219749652\n",
      "Training:: Epoch 11, Iteration 80, Current loss 3.948984384536743 Accuracy 55.70265398719622\n",
      "Training:: Epoch 11, Iteration 90, Current loss 4.754065990447998 Accuracy 49.244120940649495\n",
      "Training:: Epoch 11, Iteration 100, Current loss 3.6354663372039795 Accuracy 57.2583273580601\n",
      "Training:: Epoch 11, Iteration 110, Current loss 3.7692549228668213 Accuracy 66.3589183283256\n",
      "Training:: Epoch 11, Iteration 120, Current loss 4.126593112945557 Accuracy 62.16424624084308\n",
      "Training:: Epoch 11, Iteration 130, Current loss 3.823838472366333 Accuracy 54.05931828242585\n",
      "Training:: Epoch 11, Iteration 140, Current loss 4.956901550292969 Accuracy 56.82123475364032\n",
      "Training:: Epoch 11, Iteration 150, Current loss 2.6144323348999023 Accuracy 67.12525078819147\n",
      "Training:: Epoch 11, Iteration 160, Current loss 3.136547565460205 Accuracy 68.21500058872012\n",
      "Training:: Epoch 11, Iteration 170, Current loss 4.166100025177002 Accuracy 57.32714138286894\n",
      "Training:: Epoch 11, Iteration 180, Current loss 4.234417915344238 Accuracy 59.548655923891\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 11, Probability Accuracy 52.354072438477154\n",
      "Starting Training\n",
      "Training:: Epoch 12, Iteration 0, Current loss 4.515839099884033 Accuracy 67.57804797896813\n",
      "Training:: Epoch 12, Iteration 10, Current loss 4.262605667114258 Accuracy 54.33112383247966\n",
      "Training:: Epoch 12, Iteration 20, Current loss 3.715444326400757 Accuracy 63.60718870346598\n",
      "Training:: Epoch 12, Iteration 30, Current loss 4.179905891418457 Accuracy 45.30677990921072\n",
      "Training:: Epoch 12, Iteration 40, Current loss 5.050488471984863 Accuracy 66.23196234277336\n",
      "Training:: Epoch 12, Iteration 50, Current loss 4.1132073402404785 Accuracy 45.77914110429448\n",
      "Training:: Epoch 12, Iteration 60, Current loss 5.493136405944824 Accuracy 48.4017883257427\n",
      "Training:: Epoch 12, Iteration 70, Current loss 3.948289632797241 Accuracy 60.4182287761393\n",
      "Training:: Epoch 12, Iteration 80, Current loss 4.004966735839844 Accuracy 66.61246612466125\n",
      "Training:: Epoch 12, Iteration 90, Current loss 3.907897472381592 Accuracy 66.55716762478329\n",
      "Training:: Epoch 12, Iteration 100, Current loss 3.206774950027466 Accuracy 62.22167648984938\n",
      "Training:: Epoch 12, Iteration 110, Current loss 3.4178428649902344 Accuracy 60.10474016382436\n",
      "Training:: Epoch 12, Iteration 120, Current loss 3.8717596530914307 Accuracy 55.46903665049533\n",
      "Training:: Epoch 12, Iteration 130, Current loss 4.490696430206299 Accuracy 59.5405391937011\n",
      "Training:: Epoch 12, Iteration 140, Current loss 4.0798563957214355 Accuracy 55.660607539343665\n",
      "Training:: Epoch 12, Iteration 150, Current loss 3.1417856216430664 Accuracy 68.06673064147044\n",
      "Training:: Epoch 12, Iteration 160, Current loss 4.278685092926025 Accuracy 62.40750966316952\n",
      "Training:: Epoch 12, Iteration 170, Current loss 4.857606410980225 Accuracy 58.825978351373855\n",
      "Training:: Epoch 12, Iteration 180, Current loss 9.193070411682129 Accuracy 50.62856730005058\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 12, Probability Accuracy 45.90797393069554\n",
      "Starting Training\n",
      "Training:: Epoch 13, Iteration 0, Current loss 6.3682332038879395 Accuracy 42.12798374809548\n",
      "Training:: Epoch 13, Iteration 10, Current loss 4.194666862487793 Accuracy 63.661488611455255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 13, Iteration 20, Current loss 3.784616231918335 Accuracy 57.015669515669515\n",
      "Training:: Epoch 13, Iteration 30, Current loss 5.065441131591797 Accuracy 47.51049402647724\n",
      "Training:: Epoch 13, Iteration 40, Current loss 6.399113655090332 Accuracy 57.605335936229054\n",
      "Training:: Epoch 13, Iteration 50, Current loss 3.8770017623901367 Accuracy 51.5831894070236\n",
      "Training:: Epoch 13, Iteration 60, Current loss 4.6334686279296875 Accuracy 64.90309062336301\n",
      "Training:: Epoch 13, Iteration 70, Current loss 3.9832348823547363 Accuracy 54.59950734732014\n",
      "Training:: Epoch 13, Iteration 80, Current loss 4.956575393676758 Accuracy 65.93398487921814\n",
      "Training:: Epoch 13, Iteration 90, Current loss 4.285998344421387 Accuracy 61.68397812233429\n",
      "Training:: Epoch 13, Iteration 100, Current loss 5.584327697753906 Accuracy 57.11390191558699\n",
      "Training:: Epoch 13, Iteration 110, Current loss 3.568197011947632 Accuracy 67.48174284073193\n",
      "Training:: Epoch 13, Iteration 120, Current loss 4.321170806884766 Accuracy 52.901419329921794\n",
      "Training:: Epoch 13, Iteration 130, Current loss 4.491145133972168 Accuracy 59.97191011235955\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-95645851addf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmiddle_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpsuedo_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_single_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_stages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mmiddle_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmiddle_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mfinal_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dilated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    258\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 259\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_epoch = -1\n",
    "for epoch in range(100):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        psuedo_l = get_single_random(predictions[-1], item[4])\n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            loss += ce_criterion(p, psuedo_l)\n",
    "            loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                        max=16) * src_mask_mse[:, :, 1:])\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(predictions[-1], dim=1)\n",
    "                correct = float(torch.sum((pred == item_2) * src_mask).item())\n",
    "                total = float(torch.sum(src_mask).item())\n",
    "                print(f\"Training:: Epoch {epoch}, Iteration {i}, Current loss {loss.item()}\" +\n",
    "                      f\" Accuracy {correct * 100.0 / total}\")\n",
    "    # Calculating Expectation Step\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-last-model.wt\")\n",
    "    print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split1/ms-tcn-best-model.wt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir + \"ms-tcn-best-model.wt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split3/ms-tcn-initial-15-epochs.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 15, Probability Accuracy 57.770101729343025\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Validation Data Accuracy\")\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "        pred = torch.argmax(predictions[-1], dim=1)\n",
    "        correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "        total += float(torch.sum(src_mask).item())\n",
    "\n",
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(video_id_boundary_frames, open(\"dump_dir/video_id_boundary_frames_dict.pkl\", \"wb\"))\n",
    "# pickle.dump(loaded_vidid_selected_frames, open(\"dump_dir/loaded_vidid_selected_frames_dict.pkl\", \"wb\"))\n",
    "pickle.dump(boundary_dict, open(\"dump_dir/chunk_1_video_id_boundary_frames_dict.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
