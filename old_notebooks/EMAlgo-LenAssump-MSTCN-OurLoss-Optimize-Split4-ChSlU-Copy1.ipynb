{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 4, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split4-slup15/', 'project_name': 'breakfast-split-4', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split4.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split4.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split4_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=4,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split4-slup15/\",\n",
    "    project_name=\"breakfast-split-4\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1136\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 576\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = Breakfast(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = iter(trainloader).next()\n",
    "# print(item[0]) # -- data feature\n",
    "# print(item[1]) # -- valid count\n",
    "# item[2] # -- Actual labels\n",
    "# print(item[5]) # video names\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_frames_dict = pickle.load(open(\"data/breakfast_len_assum_annotations.pkl\", 'rb'))\n",
    "# loaded_vidid_selected_frames\n",
    "boundary_frames_dict = pickle.load(open(\"data/breakfast_boundary_annotations.pkl\", \"rb\"))\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"data/breakfast_meanvar_actions.pkl\", \"rb\"))\n",
    "def get_possion_prob(cur_len, cur_class):\n",
    "    mean_class, std_class = loaded_mean_var_actions[label_id_to_label_name[cur_class]]\n",
    "    mean_class = mean_class\n",
    "    prob = cur_len * torch.log(torch.tensor(mean_class, device=device) + 1e-5)\n",
    "    prob = prob - mean_class\n",
    "    factorials = torch.cumsum(torch.log(torch.arange(1, torch.max(cur_len)+1, 1).type(torch.float).to(device)), \n",
    "                              dim=0)[min(cur_len)-1:]\n",
    "    prob = prob - factorials\n",
    "    return prob\n",
    "\n",
    "# get_possion_prob(torch.arange(10, 21), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_video_each_segment_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels):\n",
    "    prob_each_segment = []\n",
    "    \n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    cur_boundary = 0\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[i]\n",
    "        label_next_ele = labels[i + 1]\n",
    "\n",
    "        indices = torch.arange(cur_ele, next_ele).to(cumsum_feat.device)\n",
    "        strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "        end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "        left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "        right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "\n",
    "        cur_boundary_len = indices - cur_boundary\n",
    "        len_prob = get_possion_prob(cur_boundary_len, label_cur_ele)\n",
    "\n",
    "        prob = torch.softmax((left_sum + right_sum + len_prob), dim=0)\n",
    "#         prob = torch.softmax((left_sum + right_sum), dim=0)\n",
    "\n",
    "        cur_boundary = round(np.sum(np.arange(cur_ele, next_ele, 1) * prob.detach().cpu().numpy()).item())\n",
    "        prob_each_segment.append(prob)\n",
    "    \n",
    "    return prob_each_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_element_probb(data_feat, data_count, video_ids): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "        prob_video = prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels)\n",
    "        prob_video_each_segment_dict[cur_vidid] = prob_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_loss(data_feat, data_count, video_ids): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "#     global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    loss_arr = []\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "\n",
    "        prob_each_video = prob_video_each_segment_dict[cur_vidid]\n",
    "        \n",
    "        log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "        cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "        \n",
    "        \n",
    "        current_vid_prob_arr = []\n",
    "        # Start segment log probability\n",
    "        start_ele_idx = selected_frames_indices[0]\n",
    "        if start_ele_idx > 0:\n",
    "            start_ele_label_idx = selected_frames_labels[0]\n",
    "            first_segment_prob = (cumsum_feat[start_ele_idx - 1, :])[start_ele_label_idx]\n",
    "            current_vid_prob_arr.append(first_segment_prob.unsqueeze(0))\n",
    "        \n",
    "        for i, cur_ele in enumerate(selected_frames_indices[:-1]):\n",
    "            next_ele = selected_frames_indices[i + 1]\n",
    "            label_cur_ele = selected_frames_labels[i]\n",
    "            label_next_ele = selected_frames_labels[i + 1]\n",
    "\n",
    "            indices = torch.arange(cur_ele, next_ele)\n",
    "            strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "            end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "            left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "            right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "            current_vid_prob_arr.append((left_sum + right_sum)  * (prob_each_video[i]))\n",
    "        \n",
    "        # End segment log probability\n",
    "        end_index = cur_vid_count.item() - 1\n",
    "        last_ele_label_idx = selected_frames_labels[-1]\n",
    "        last_segment_sum_prob = (cumsum_feat[end_index, :] - cumsum_feat[selected_frames_indices[-1] - 1, \\\n",
    "                                                                         :])[last_ele_label_idx]\n",
    "        current_vid_prob_arr.append(last_segment_sum_prob.unsqueeze(0))\n",
    "            \n",
    "        loss_arr.append(torch.cat(current_vid_prob_arr))\n",
    "    return -torch.mean(torch.cat(loss_arr)), loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_file_list = set(open(config.train_split_file).read().split(\"\\n\")[0:-1])\n",
    "\n",
    "def get_estimated_boundaries():\n",
    "    estimated_boundary_dict = {}\n",
    "    for video_id in train_split_file_list:\n",
    "        ele = video_id.split(\".txt\")[0]\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[video_id]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        \n",
    "        boundary_list = []\n",
    "        for i, segment in enumerate(estimated_boundary_probs):\n",
    "            estimated_boundary = np.sum(np.arange(selected_frames_indices[i], selected_frames_indices[i + 1], 1) \\\n",
    "                                        * segment.detach().cpu().numpy())\n",
    "            estimated_boundary = round(estimated_boundary.item())\n",
    "            \n",
    "            if (estimated_boundary < selected_frames_indices[i]) or (estimated_boundary > selected_frames_indices[i + 1]):\n",
    "                print(\"Estimated value wrong\")\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "            boundary_list.append(estimated_boundary)\n",
    "\n",
    "        estimated_boundary_dict[ele] = boundary_list\n",
    "    return estimated_boundary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_err():\n",
    "    err_list = []\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    estimated_boundar_dict = get_estimated_boundaries()\n",
    "    for video_id in train_split_file_list:\n",
    "        ele = video_id.split(\".txt\")[0]\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        estimated_boundary_list = estimated_boundar_dict[ele]\n",
    "        \n",
    "        estimated = np.array(estimated_boundary_list) #.detach().cpu().numpy()\n",
    "        actual = np.array(boundary_frames_dict[video_id][:-1])\n",
    "        if len(actual) != len(estimated):\n",
    "            print(ele)\n",
    "            continue\n",
    "        \n",
    "        mse_err = (actual - estimated)**2\n",
    "        err_list.append(mse_err)\n",
    "        \n",
    "        estimated_labels = []\n",
    "        actual_labels = []\n",
    "        start_v1 = 0\n",
    "        start_v2 = 0\n",
    "        for i, v1 in enumerate(estimated):\n",
    "            estimated_labels.extend([i] * (v1 - start_v1))\n",
    "            start_v1 = v1\n",
    "            v2 = actual[i]\n",
    "            actual_labels.extend([i] * (v2 - start_v2))\n",
    "            start_v2 = v2\n",
    "            \n",
    "        last_ele = boundary_frames_dict[video_id][-1]\n",
    "        estimated_labels.extend([i+1] * (last_ele - start_v1))\n",
    "        actual_labels.extend([i+1] * (last_ele - start_v2))\n",
    "        \n",
    "        correct += np.sum(np.array(actual_labels) == np.array(estimated_labels))\n",
    "        total += len(actual_labels)\n",
    "        \n",
    "    print(f\"Train Boundary avergage error = {np.sqrt(np.mean(np.concatenate(err_list))):.3f}\")\n",
    "    print(f\"Train From boundary avergage accuracy = {correct * 100.0 / total:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_file=torch.load(\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split1/ms-tcn-best-model.wt\")\n",
    "# model.load_state_dict(loaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels_dir = \"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/length_segmentation_output/\"\n",
    "def get_single_random(output_p, video_ids):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((output_p.shape[0], output_p.shape[2]), dtype=torch.long, \n",
    "                                        device=output_p.device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        pseudo_l = open(pseudo_labels_dir + cur_vidid + \".txt\").read().split(\"\\n\")[0:-1]\n",
    "        pseudo_l = [label_name_to_label_id_dict[ele] for ele in pseudo_l]\n",
    "        abc = torch.tensor(pseudo_l).to(torch.long).to(boundary_target_tensor.device)\n",
    "        frame_idx_tensor = torch.arange(0, len(pseudo_l), 1).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = abc\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labels = pickle.load(open(\"data/breakfast_weaklysupervised_labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = pickle.load(open('data/breakfast_lengthmodel_multinomial_prior.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def change_selected_frames(model):\n",
    "    global selected_frames_dict\n",
    "    new_selected_frame_dict = {}\n",
    "    with torch.no_grad():\n",
    "        for train_idx, item in enumerate(trainloader):\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            if train_idx % 10 == 0:\n",
    "                print(f\"Completed {train_idx} videos selected frames calculation\")\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            for idx, video_id in enumerate(item[4]):\n",
    "                start = 0\n",
    "                new_index_label_pair_list = []\n",
    "                weakly_labels_video = [label_name_to_label_id_dict[wl] for wl in weakly_labels[video_id + \".txt\"]]\n",
    "                cur_video_predictions = predictions[-1][idx][:, :item_1[idx]]\n",
    "                cur_preds_for_weakly_labels = torch.softmax(cur_video_predictions[weakly_labels_video], dim=0)\n",
    "                prior_probs_cur_vid = prior_probs[video_id]\n",
    "                weakly_labels_masked = []\n",
    "                for i, prob_class in enumerate(cur_preds_for_weakly_labels):\n",
    "                    prob_class_masked = prob_class * torch.tensor(prior_probs_cur_vid[i], \n",
    "                                                                  dtype=prob_class.dtype, device=prob_class.device)\n",
    "                    weakly_labels_masked.append(prob_class_masked)\n",
    "                    \n",
    "                weakly_labels_masked = torch.stack(weakly_labels_masked)\n",
    "                weakly_labels_masked = weakly_labels_masked / torch.sum(weakly_labels_masked, dim=0)\n",
    "\n",
    "                for i in range(len(weakly_labels_video)):\n",
    "                    cur_l = weakly_labels_video[i]\n",
    "                    prob_class = weakly_labels_masked[i]\n",
    "                    expected_value_of_class = torch.argmax(prob_class)\n",
    "                    new_index_label_pair_list.append((int(expected_value_of_class.item()),\n",
    "                                                      weakly_labels_video[i])) \n",
    "                \n",
    "                back_list = copy.deepcopy(new_index_label_pair_list)\n",
    "                error_list = []\n",
    "                if new_index_label_pair_list[0][0] > new_index_label_pair_list[1][0]:\n",
    "                    error_list.append(1)\n",
    "                else:\n",
    "                    error_list.append(0)\n",
    "                for i in range(1, len(new_index_label_pair_list) - 1, 1):\n",
    "                    err = 0\n",
    "                    prev_ele = new_index_label_pair_list[i - 1]\n",
    "                    cur_ele = new_index_label_pair_list[i]\n",
    "                    next_ele = new_index_label_pair_list[i + 1]\n",
    "                    if not (prev_ele[0] < cur_ele[0]):\n",
    "                        err += 1\n",
    "                    if not (cur_ele[0] < next_ele[0]):\n",
    "                        err += 1\n",
    "                    error_list.append(err)\n",
    "\n",
    "                if new_index_label_pair_list[-1][0] < new_index_label_pair_list[-2][0]:\n",
    "                    error_list.append(1)\n",
    "                else:\n",
    "                    error_list.append(0)\n",
    "                    \n",
    "                if error_list[0] == 1 and error_list[1] == 1:\n",
    "                    new_index = new_index_label_pair_list[1][0] // 2\n",
    "                    new_index_label_pair_list[0] = (new_index, new_index_label_pair_list[0][1])\n",
    "                    error_list[0] = 0\n",
    "                    error_list[1] = 0\n",
    "                    \n",
    "                if error_list[-1] == 1 and error_list[-2] == 1:\n",
    "                    new_index = (new_index_label_pair_list[-2][0] + weakly_labels_masked.shape[1]) // 2\n",
    "                    new_index_label_pair_list[-1] = (new_index, new_index_label_pair_list[-1][1])\n",
    "                    error_list[-1] = 0\n",
    "                    error_list[-2] = 0\n",
    "                    \n",
    "                start_flag = False\n",
    "                start_index = -1\n",
    "                end_index = -1\n",
    "                for i in range(1, len(error_list) - 1):\n",
    "                    if error_list[i] == 1 and error_list[i + 1] == 2:\n",
    "                        start_flag = True\n",
    "                        start_index = i\n",
    "                        \n",
    "                    if (start_flag is True) and (error_list[i] == 2 or error_list[i + 1] == 1):\n",
    "                        start_flag = False\n",
    "                        end_index = i + 1\n",
    "                        \n",
    "                        num_div = end_index - start_index - 1\n",
    "                        increm = (new_index_label_pair_list[end_index][0] - \\\n",
    "                                  new_index_label_pair_list[start_index][0]) // num_div\n",
    "                        value = list(range(new_index_label_pair_list[start_index][0], \n",
    "                                           new_index_label_pair_list[end_index][0], increm))\n",
    "                        count = 0\n",
    "                        for ch_i in range(start_index + 1, end_index):\n",
    "                            old_ele = new_index_label_pair_list[ch_i]\n",
    "                            new_ele = (value[count], old_ele[1])\n",
    "                            new_index_label_pair_list[ch_i] = new_ele\n",
    "                            count += 1\n",
    "                    \n",
    "                final_list = new_index_label_pair_list\n",
    "                is_valid_list = True\n",
    "                for i in range(1, len(final_list) - 1, 1):\n",
    "                    cur_ele = final_list[i]\n",
    "                    \n",
    "                    if not (final_list[i - 1][0] < cur_ele[0] and cur_ele[0] < final_list[i + 1][0]):\n",
    "                        is_valid_list  = False\n",
    "\n",
    "                if is_valid_list == False:\n",
    "                    print(f\"Could not find expected solution for video {video_id}\")\n",
    "                    print(final_list)\n",
    "                    print(back_list)\n",
    "                    print(error_list)\n",
    "                    new_selected_frame_dict[video_id + \".txt\"] = selected_frames_dict[video_id + \".txt\"]\n",
    "                else:\n",
    "                \n",
    "                    label_name_final_list = []\n",
    "                    for ele in final_list:\n",
    "                        label_name_final_list.append((ele[0], label_id_to_label_name[ele[1]]))\n",
    "                    new_selected_frame_dict[video_id + \".txt\"] = label_name_final_list\n",
    "                \n",
    "        return new_selected_frame_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_selected_frame_acc(selected_frame_dict):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    for video_id in selected_frame_dict.keys():\n",
    "        ground_labels = open(config.ground_truth_files_dir + video_id).read().split(\"\\n\")[0:-1]\n",
    "        ground_labels = np.array(ground_labels)\n",
    "\n",
    "        selected_frames_index = [ele[0] for ele in selected_frame_dict[video_id]]\n",
    "        selected_frames_labels = np.array([ele[1] for ele in selected_frame_dict[video_id]])\n",
    "\n",
    "        ground_selected_labels = ground_labels[selected_frames_index]\n",
    "\n",
    "        correct += np.sum(ground_selected_labels == selected_frames_labels)\n",
    "        total += len(ground_selected_labels)\n",
    "\n",
    "    print(\"Total correct pivots labels selected = \", correct * 100.0 / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# selected_frames_dict = change_selected_frames(model)\n",
    "# get_new_selected_frame_acc(selected_frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Expection Boundaries\n",
    "# print(\"Calculating Expectation\")\n",
    "# correct = 0.0\n",
    "# total = 0.0\n",
    "# model.eval()\n",
    "# for i, item in enumerate(trainloader):\n",
    "#     with torch.no_grad():\n",
    "#         item_0 = item[0].to(device)\n",
    "#         item_1 = item[1].to(device)\n",
    "#         item_2 = item[2].to(device)\n",
    "#         src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "#         src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "#         middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "#         prob = torch.softmax(predictions[-1], dim=1)\n",
    "#         prob = prob.permute(0, 2, 1)\n",
    "#         calculate_element_probb(prob, item_1, item[4])\n",
    "\n",
    "#         if i % 10 == 0:\n",
    "#             print(f\"Completed iter {i}\")\n",
    "\n",
    "# get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split4-slup15/'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Training:: Epoch 25, Iteration 0, Current loss 3.0428950786590576 Accuracy 61.21641978408235\n",
      "Training:: Epoch 25, Iteration 10, Current loss 3.110691785812378 Accuracy 65.61863370908597\n",
      "Training:: Epoch 25, Iteration 20, Current loss 2.4662787914276123 Accuracy 63.68137649316086\n",
      "Training:: Epoch 25, Iteration 30, Current loss 3.0292460918426514 Accuracy 64.40338379341051\n",
      "Training:: Epoch 25, Iteration 40, Current loss 2.9688186645507812 Accuracy 62.53463883244042\n",
      "Training:: Epoch 25, Iteration 50, Current loss 2.638812780380249 Accuracy 58.48197135173701\n",
      "Training:: Epoch 25, Iteration 60, Current loss 2.882021188735962 Accuracy 69.50900567480879\n",
      "Training:: Epoch 25, Iteration 70, Current loss 2.7382493019104004 Accuracy 69.90426563257392\n",
      "Training:: Epoch 25, Iteration 80, Current loss 2.5315325260162354 Accuracy 61.35753945972924\n",
      "Training:: Epoch 25, Iteration 90, Current loss 3.127528190612793 Accuracy 58.7964039370689\n",
      "Training:: Epoch 25, Iteration 100, Current loss 3.6228227615356445 Accuracy 63.93748012176837\n",
      "Training:: Epoch 25, Iteration 110, Current loss 2.533386468887329 Accuracy 59.11943268200602\n",
      "Training:: Epoch 25, Iteration 120, Current loss 3.0581443309783936 Accuracy 64.2120381250816\n",
      "Training:: Epoch 25, Iteration 130, Current loss 3.601799488067627 Accuracy 48.27085377821393\n",
      "Training:: Epoch 25, Iteration 140, Current loss 2.4609804153442383 Accuracy 64.23190304618409\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 25, Probability Accuracy 50.612422303413744\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Total correct pivots labels selected =  63.21391484942887\n",
      "Calculating Expectation\n",
      "Epoch 25 iter 0\n",
      "Epoch 25 iter 10\n",
      "Epoch 25 iter 20\n",
      "Epoch 25 iter 30\n",
      "Epoch 25 iter 40\n",
      "Epoch 25 iter 50\n",
      "Epoch 25 iter 60\n",
      "Epoch 25 iter 70\n",
      "Epoch 25 iter 80\n",
      "Epoch 25 iter 90\n",
      "Epoch 25 iter 100\n",
      "Epoch 25 iter 110\n",
      "Epoch 25 iter 120\n",
      "Epoch 25 iter 130\n",
      "Epoch 25 iter 140\n",
      "Train Boundary avergage error = 291.313\n",
      "Train From boundary avergage accuracy = 61.478\n",
      "Starting Training\n",
      "Training:: Epoch 26, Iteration 0, Current loss 2.2015894326542487 Accuracy 50.24249127882243\n",
      "Training:: Epoch 26, Iteration 10, Current loss 2.1438753968173256 Accuracy 57.06271965396053\n",
      "Training:: Epoch 26, Iteration 20, Current loss 2.019686010839584 Accuracy 55.6913752596275\n",
      "Training:: Epoch 26, Iteration 30, Current loss 1.8502718001323073 Accuracy 60.388821385176186\n",
      "Training:: Epoch 26, Iteration 40, Current loss 1.8113965709554567 Accuracy 59.7796551553777\n",
      "Training:: Epoch 26, Iteration 50, Current loss 3.1333679009958795 Accuracy 70.96812209062519\n",
      "Training:: Epoch 26, Iteration 60, Current loss 3.8756940193639626 Accuracy 60.27346637102735\n",
      "Training:: Epoch 26, Iteration 70, Current loss 4.1018141089395375 Accuracy 54.10840171038946\n",
      "Training:: Epoch 26, Iteration 80, Current loss 4.908921962818077 Accuracy 47.100046104195485\n",
      "Training:: Epoch 26, Iteration 90, Current loss 3.6474367760992417 Accuracy 53.2843012934314\n",
      "Training:: Epoch 26, Iteration 100, Current loss 4.558980335821477 Accuracy 57.0562435500516\n",
      "Training:: Epoch 26, Iteration 110, Current loss 3.3130825959213093 Accuracy 66.88643565368497\n",
      "Training:: Epoch 26, Iteration 120, Current loss 2.8031752125715386 Accuracy 57.82465310186049\n",
      "Training:: Epoch 26, Iteration 130, Current loss 2.6173258673761546 Accuracy 62.28544074403337\n",
      "Training:: Epoch 26, Iteration 140, Current loss 1.9537432606564924 Accuracy 68.26664274179078\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 26, Probability Accuracy 51.836695011078504\n",
      "Starting Training\n",
      "Training:: Epoch 27, Iteration 0, Current loss 5.777726130073032 Accuracy 56.342724592857486\n",
      "Training:: Epoch 27, Iteration 10, Current loss 2.305286829473459 Accuracy 64.27940586109996\n",
      "Training:: Epoch 27, Iteration 20, Current loss 3.2037324670484626 Accuracy 69.62321553943366\n",
      "Training:: Epoch 27, Iteration 30, Current loss 2.106506159184415 Accuracy 71.31652366163078\n",
      "Training:: Epoch 27, Iteration 40, Current loss 2.212255208678457 Accuracy 59.858103061986554\n",
      "Training:: Epoch 27, Iteration 50, Current loss 4.3097787650891215 Accuracy 52.9065565307176\n",
      "Training:: Epoch 27, Iteration 60, Current loss 3.0271909750981014 Accuracy 54.36105476673428\n",
      "Training:: Epoch 27, Iteration 70, Current loss 2.03452929468169 Accuracy 64.09674616201603\n",
      "Training:: Epoch 27, Iteration 80, Current loss 2.4239042703099054 Accuracy 72.16712124969006\n",
      "Training:: Epoch 27, Iteration 90, Current loss 2.4096123494782455 Accuracy 63.996525921966864\n",
      "Training:: Epoch 27, Iteration 100, Current loss 1.561569060880125 Accuracy 68.2662692498758\n",
      "Training:: Epoch 27, Iteration 110, Current loss 2.1269454143053066 Accuracy 72.19928339873742\n",
      "Training:: Epoch 27, Iteration 120, Current loss 1.9674156350687355 Accuracy 63.5925836744522\n",
      "Training:: Epoch 27, Iteration 130, Current loss 4.559942374782714 Accuracy 53.6810551558753\n",
      "Training:: Epoch 27, Iteration 140, Current loss 2.4205683980903956 Accuracy 67.20366357280125\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 27, Probability Accuracy 52.32844659115419\n",
      "Starting Training\n",
      "Training:: Epoch 28, Iteration 0, Current loss 1.572516017166434 Accuracy 63.496979429532765\n",
      "Training:: Epoch 28, Iteration 10, Current loss 1.846650483877024 Accuracy 65.65953782115689\n",
      "Training:: Epoch 28, Iteration 20, Current loss 2.286404619777175 Accuracy 57.79962470425063\n",
      "Training:: Epoch 28, Iteration 30, Current loss 2.345798523314583 Accuracy 56.31475980001449\n",
      "Training:: Epoch 28, Iteration 40, Current loss 1.8312395218089292 Accuracy 61.549732804688844\n",
      "Training:: Epoch 28, Iteration 50, Current loss 1.7446473066395165 Accuracy 61.177383376976046\n",
      "Training:: Epoch 28, Iteration 60, Current loss 1.6847192247174134 Accuracy 63.64212049936675\n",
      "Training:: Epoch 28, Iteration 70, Current loss 2.49689568335078 Accuracy 57.06617462048142\n",
      "Training:: Epoch 28, Iteration 80, Current loss 1.1236417189556314 Accuracy 68.18755256518082\n",
      "Training:: Epoch 28, Iteration 90, Current loss 2.2047369592414423 Accuracy 48.55401964350673\n",
      "Training:: Epoch 28, Iteration 100, Current loss 0.9746156609542788 Accuracy 67.71138449521578\n",
      "Training:: Epoch 28, Iteration 110, Current loss 2.133106031105405 Accuracy 68.2006256938137\n",
      "Training:: Epoch 28, Iteration 120, Current loss 1.766294105299995 Accuracy 67.78973005885935\n",
      "Training:: Epoch 28, Iteration 130, Current loss 1.6896255971984122 Accuracy 61.29294022180146\n",
      "Training:: Epoch 28, Iteration 140, Current loss 1.9215387568190057 Accuracy 66.35585970915312\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 28, Probability Accuracy 51.28718161556611\n",
      "Starting Training\n",
      "Training:: Epoch 29, Iteration 0, Current loss 1.6235676232087397 Accuracy 56.08827006436359\n",
      "Training:: Epoch 29, Iteration 10, Current loss 1.2974254245245314 Accuracy 53.90961480133455\n",
      "Training:: Epoch 29, Iteration 20, Current loss 1.4456784085759409 Accuracy 68.69469026548673\n",
      "Training:: Epoch 29, Iteration 30, Current loss 1.5666605471543007 Accuracy 59.876398341547365\n",
      "Training:: Epoch 29, Iteration 40, Current loss 1.4207294244000572 Accuracy 66.09697334738745\n",
      "Training:: Epoch 29, Iteration 50, Current loss 1.3451851496525742 Accuracy 64.0577007459412\n",
      "Training:: Epoch 29, Iteration 60, Current loss 1.5576716969844293 Accuracy 48.967691095350666\n",
      "Training:: Epoch 29, Iteration 70, Current loss 1.6145023617614132 Accuracy 59.825599501712865\n",
      "Training:: Epoch 29, Iteration 80, Current loss 1.7969887770335804 Accuracy 65.00412801709484\n",
      "Training:: Epoch 29, Iteration 90, Current loss 1.8703179827451668 Accuracy 59.56554358204883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 29, Iteration 100, Current loss 1.43712967282873 Accuracy 68.59532460409955\n",
      "Training:: Epoch 29, Iteration 110, Current loss 1.124702450349028 Accuracy 60.402504951024994\n",
      "Training:: Epoch 29, Iteration 120, Current loss 1.2859740136769586 Accuracy 64.31553504724236\n",
      "Training:: Epoch 29, Iteration 130, Current loss 1.308723882441427 Accuracy 65.03937657197048\n",
      "Training:: Epoch 29, Iteration 140, Current loss 1.263368575771478 Accuracy 73.44435418359058\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 29, Probability Accuracy 51.86741416610566\n",
      "Starting Training\n",
      "Training:: Epoch 30, Iteration 0, Current loss 1.4358938803276415 Accuracy 56.33683016728097\n",
      "Training:: Epoch 30, Iteration 10, Current loss 1.1769631018549112 Accuracy 70.43090638930164\n",
      "Training:: Epoch 30, Iteration 20, Current loss 1.5772394463846267 Accuracy 64.17354578613937\n",
      "Training:: Epoch 30, Iteration 30, Current loss 0.8480536551132928 Accuracy 64.57824789802007\n",
      "Training:: Epoch 30, Iteration 40, Current loss 1.7001983598405153 Accuracy 63.65898158898656\n",
      "Training:: Epoch 30, Iteration 50, Current loss 1.5017429453241724 Accuracy 70.54258334458092\n",
      "Training:: Epoch 30, Iteration 60, Current loss 1.2887279094883488 Accuracy 72.26419899821717\n",
      "Training:: Epoch 30, Iteration 70, Current loss 2.049955183122501 Accuracy 54.58750963762529\n",
      "Training:: Epoch 30, Iteration 80, Current loss 1.4090167891434024 Accuracy 58.107277675357736\n",
      "Training:: Epoch 30, Iteration 90, Current loss 1.1242029468585086 Accuracy 74.19018404907976\n",
      "Training:: Epoch 30, Iteration 100, Current loss 1.4922158896731734 Accuracy 69.51093125400978\n",
      "Training:: Epoch 30, Iteration 110, Current loss 1.792479246326868 Accuracy 52.31187669990934\n",
      "Training:: Epoch 30, Iteration 120, Current loss 1.1698924337053298 Accuracy 70.07709750566893\n",
      "Training:: Epoch 30, Iteration 130, Current loss 3.3350896305835978 Accuracy 50.890574023454725\n",
      "Training:: Epoch 30, Iteration 140, Current loss 1.4263955326102111 Accuracy 64.82390991854336\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 30, Probability Accuracy 47.49998366002392\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Total correct pivots labels selected =  62.889408099688474\n",
      "Calculating Expectation\n",
      "Epoch 30 iter 0\n",
      "Epoch 30 iter 10\n",
      "Epoch 30 iter 20\n",
      "Epoch 30 iter 30\n",
      "Epoch 30 iter 40\n",
      "Epoch 30 iter 50\n",
      "Epoch 30 iter 60\n",
      "Epoch 30 iter 70\n",
      "Epoch 30 iter 80\n",
      "Epoch 30 iter 90\n",
      "Epoch 30 iter 100\n",
      "Epoch 30 iter 110\n",
      "Epoch 30 iter 120\n",
      "Epoch 30 iter 130\n",
      "Epoch 30 iter 140\n",
      "Train Boundary avergage error = 297.595\n",
      "Train From boundary avergage accuracy = 60.470\n",
      "Starting Training\n",
      "Training:: Epoch 31, Iteration 0, Current loss 1.8713549800863443 Accuracy 46.85404024273395\n",
      "Training:: Epoch 31, Iteration 10, Current loss 1.0364481842367432 Accuracy 59.31133428981349\n",
      "Training:: Epoch 31, Iteration 20, Current loss 1.5896314126891693 Accuracy 56.85787211176787\n",
      "Training:: Epoch 31, Iteration 30, Current loss 1.2627875447600565 Accuracy 59.35066199376947\n",
      "Training:: Epoch 31, Iteration 40, Current loss 0.9422853212844216 Accuracy 54.79124297164733\n",
      "Training:: Epoch 31, Iteration 50, Current loss 0.9033316340920615 Accuracy 72.51965158274909\n",
      "Training:: Epoch 31, Iteration 60, Current loss 1.2030179364665798 Accuracy 60.78954387836757\n",
      "Training:: Epoch 31, Iteration 70, Current loss 1.206352023763178 Accuracy 69.1035170413343\n",
      "Training:: Epoch 31, Iteration 80, Current loss 1.0735269373488303 Accuracy 62.860062281043206\n",
      "Training:: Epoch 31, Iteration 90, Current loss 1.264297718475164 Accuracy 50.951356005165735\n",
      "Training:: Epoch 31, Iteration 100, Current loss 1.4380974235765858 Accuracy 67.10498632442668\n",
      "Training:: Epoch 31, Iteration 110, Current loss 1.180301624721943 Accuracy 65.67975537543076\n",
      "Training:: Epoch 31, Iteration 120, Current loss 1.1337344008356798 Accuracy 61.70733840636753\n",
      "Training:: Epoch 31, Iteration 130, Current loss 1.5975464666349597 Accuracy 60.96759743168583\n",
      "Training:: Epoch 31, Iteration 140, Current loss 1.4969173001630935 Accuracy 60.875560151671834\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 31, Probability Accuracy 52.98106523572049\n",
      "Starting Training\n",
      "Training:: Epoch 32, Iteration 0, Current loss 0.9213251149707136 Accuracy 72.23364287233288\n",
      "Training:: Epoch 32, Iteration 10, Current loss 1.269919377208577 Accuracy 68.25059503570215\n",
      "Training:: Epoch 32, Iteration 20, Current loss 1.6106701668228371 Accuracy 57.090035126640785\n",
      "Training:: Epoch 32, Iteration 30, Current loss 1.234186910345699 Accuracy 66.51676206050695\n",
      "Training:: Epoch 32, Iteration 40, Current loss 1.6103634233465787 Accuracy 63.86977031938752\n",
      "Training:: Epoch 32, Iteration 50, Current loss 1.082190714993168 Accuracy 65.79547304999186\n",
      "Training:: Epoch 32, Iteration 60, Current loss 1.9077004164498064 Accuracy 58.71985841752083\n",
      "Training:: Epoch 32, Iteration 70, Current loss 1.4446101501022464 Accuracy 64.0327598828697\n",
      "Training:: Epoch 32, Iteration 80, Current loss 1.153705139887767 Accuracy 65.57640750670241\n",
      "Training:: Epoch 32, Iteration 90, Current loss 1.7706253570350146 Accuracy 54.37840577873527\n",
      "Training:: Epoch 32, Iteration 100, Current loss 2.0364673363568118 Accuracy 51.91318621192778\n",
      "Training:: Epoch 32, Iteration 110, Current loss 1.3515778123288384 Accuracy 51.50892513162964\n",
      "Training:: Epoch 32, Iteration 120, Current loss 0.9539115936212202 Accuracy 65.13116115480436\n",
      "Training:: Epoch 32, Iteration 130, Current loss 1.1445430895774953 Accuracy 66.64422300026932\n",
      "Training:: Epoch 32, Iteration 140, Current loss 0.9718480622462661 Accuracy 68.21163095758635\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 32, Probability Accuracy 53.235560363139626\n",
      "Starting Training\n",
      "Training:: Epoch 33, Iteration 0, Current loss 1.8186250823398566 Accuracy 62.59958071278826\n",
      "Training:: Epoch 33, Iteration 10, Current loss 1.1382616169601467 Accuracy 64.68909276248726\n",
      "Training:: Epoch 33, Iteration 20, Current loss 1.2130451316100828 Accuracy 61.49056236621911\n",
      "Training:: Epoch 33, Iteration 30, Current loss 1.4700249574530737 Accuracy 55.12123043857882\n",
      "Training:: Epoch 33, Iteration 40, Current loss 1.0551741854617607 Accuracy 62.1735034683566\n",
      "Training:: Epoch 33, Iteration 50, Current loss 1.2423554199375748 Accuracy 66.26734747316051\n",
      "Training:: Epoch 33, Iteration 60, Current loss 1.1738321589309808 Accuracy 63.64282892137495\n",
      "Training:: Epoch 33, Iteration 70, Current loss 1.5637174652298158 Accuracy 54.14082451659978\n",
      "Training:: Epoch 33, Iteration 80, Current loss 1.1605677941021182 Accuracy 65.24959493866214\n",
      "Training:: Epoch 33, Iteration 90, Current loss 1.220338411369917 Accuracy 60.36612262902514\n",
      "Training:: Epoch 33, Iteration 100, Current loss 1.205509133669627 Accuracy 67.99398241737578\n",
      "Training:: Epoch 33, Iteration 110, Current loss 1.0060575738949253 Accuracy 71.90326662604865\n",
      "Training:: Epoch 33, Iteration 120, Current loss 1.9206893202578466 Accuracy 54.53005030447445\n",
      "Training:: Epoch 33, Iteration 130, Current loss 0.9682439613500458 Accuracy 65.44278512318083\n",
      "Training:: Epoch 33, Iteration 140, Current loss 0.9841147008597164 Accuracy 59.94660194174757\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 33, Probability Accuracy 52.93139170844254\n",
      "Starting Training\n",
      "Training:: Epoch 34, Iteration 0, Current loss 1.0222131293352037 Accuracy 53.97679911086413\n",
      "Training:: Epoch 34, Iteration 10, Current loss 1.1415636485885359 Accuracy 66.21889650198341\n",
      "Training:: Epoch 34, Iteration 20, Current loss 1.2271048657247647 Accuracy 60.359338625917744\n",
      "Training:: Epoch 34, Iteration 30, Current loss 1.2786333614497782 Accuracy 68.29756795422031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 34, Iteration 40, Current loss 1.417468263047334 Accuracy 62.31616434742465\n",
      "Training:: Epoch 34, Iteration 50, Current loss 1.0820952587991464 Accuracy 59.27290421242875\n",
      "Training:: Epoch 34, Iteration 60, Current loss 1.060614377610683 Accuracy 59.97804610318332\n",
      "Training:: Epoch 34, Iteration 70, Current loss 1.4028008108801113 Accuracy 68.42962777290387\n",
      "Training:: Epoch 34, Iteration 80, Current loss 2.3918259153571237 Accuracy 53.518167028199564\n",
      "Training:: Epoch 34, Iteration 90, Current loss 1.415894065834411 Accuracy 65.3848391413113\n",
      "Training:: Epoch 34, Iteration 100, Current loss 1.002329310936785 Accuracy 63.16372556777716\n",
      "Training:: Epoch 34, Iteration 110, Current loss 1.0761304204129112 Accuracy 65.39709239456927\n",
      "Training:: Epoch 34, Iteration 120, Current loss 0.9855358510086375 Accuracy 66.56802947037865\n",
      "Training:: Epoch 34, Iteration 130, Current loss 0.971359298753274 Accuracy 74.74759020078486\n",
      "Training:: Epoch 34, Iteration 140, Current loss 1.5700590200610558 Accuracy 58.04951886690453\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 34, Probability Accuracy 52.14012836685207\n",
      "Starting Training\n",
      "Training:: Epoch 35, Iteration 0, Current loss 0.9744264400416017 Accuracy 71.10683517732977\n",
      "Training:: Epoch 35, Iteration 10, Current loss 1.5246379301933692 Accuracy 54.25778043137547\n",
      "Training:: Epoch 35, Iteration 20, Current loss 1.0257475237493379 Accuracy 64.16828260686283\n",
      "Training:: Epoch 35, Iteration 30, Current loss 1.827606705699414 Accuracy 50.38766931340495\n",
      "Training:: Epoch 35, Iteration 40, Current loss 4.839074188623288 Accuracy 57.534951539583155\n",
      "Training:: Epoch 35, Iteration 50, Current loss 2.053354411635424 Accuracy 64.81665014866203\n",
      "Training:: Epoch 35, Iteration 60, Current loss 4.773162170080436 Accuracy 58.24128686327078\n",
      "Training:: Epoch 35, Iteration 70, Current loss 2.537438244449801 Accuracy 52.4289048318783\n",
      "Training:: Epoch 35, Iteration 80, Current loss 2.0929856097735553 Accuracy 51.459751364122184\n",
      "Training:: Epoch 35, Iteration 90, Current loss 2.012860671203325 Accuracy 74.52546991179051\n",
      "Training:: Epoch 35, Iteration 100, Current loss 2.5971351324458753 Accuracy 59.220824905461264\n",
      "Training:: Epoch 35, Iteration 110, Current loss 2.1236900509854886 Accuracy 54.28114349307922\n",
      "Training:: Epoch 35, Iteration 120, Current loss 1.3357154624982401 Accuracy 69.04721322652122\n",
      "Training:: Epoch 35, Iteration 130, Current loss 1.3274691484906078 Accuracy 65.84210133572121\n",
      "Training:: Epoch 35, Iteration 140, Current loss 1.4825530153680193 Accuracy 64.99973314831617\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 35, Probability Accuracy 50.28970777586782\n",
      "Calculating Expectation\n",
      "Epoch 35 iter 0\n",
      "Epoch 35 iter 10\n",
      "Epoch 35 iter 20\n",
      "Epoch 35 iter 30\n",
      "Epoch 35 iter 40\n",
      "Epoch 35 iter 50\n",
      "Epoch 35 iter 60\n",
      "Epoch 35 iter 70\n",
      "Epoch 35 iter 80\n",
      "Epoch 35 iter 90\n",
      "Epoch 35 iter 100\n",
      "Epoch 35 iter 110\n",
      "Epoch 35 iter 120\n",
      "Epoch 35 iter 130\n",
      "Epoch 35 iter 140\n",
      "Train Boundary avergage error = 299.274\n",
      "Train From boundary avergage accuracy = 60.459\n",
      "Starting Training\n",
      "Training:: Epoch 36, Iteration 0, Current loss 0.9954834405787457 Accuracy 65.99164926931107\n",
      "Training:: Epoch 36, Iteration 10, Current loss 1.6104021632072505 Accuracy 68.05596321299286\n",
      "Training:: Epoch 36, Iteration 20, Current loss 1.1221278455008188 Accuracy 64.61732211345813\n",
      "Training:: Epoch 36, Iteration 30, Current loss 2.744093485837519 Accuracy 53.81346454931783\n",
      "Training:: Epoch 36, Iteration 40, Current loss 2.6444324050341934 Accuracy 53.40981788714974\n",
      "Training:: Epoch 36, Iteration 50, Current loss 1.4330472127170981 Accuracy 71.3809605195693\n",
      "Training:: Epoch 36, Iteration 60, Current loss 1.455838066400363 Accuracy 57.11157508784437\n",
      "Training:: Epoch 36, Iteration 70, Current loss 2.059853159404025 Accuracy 62.08147044212618\n",
      "Training:: Epoch 36, Iteration 80, Current loss 1.298393891686518 Accuracy 66.4562493930271\n",
      "Training:: Epoch 36, Iteration 90, Current loss 2.4467070636998036 Accuracy 41.318781264211005\n",
      "Training:: Epoch 36, Iteration 100, Current loss 1.4314170462839564 Accuracy 59.58882107292001\n",
      "Training:: Epoch 36, Iteration 110, Current loss 2.0911201272061803 Accuracy 62.723853868194844\n",
      "Training:: Epoch 36, Iteration 120, Current loss 1.6098852628061728 Accuracy 63.712846347607055\n",
      "Training:: Epoch 36, Iteration 130, Current loss 1.285347421101144 Accuracy 65.15205091937766\n",
      "Training:: Epoch 36, Iteration 140, Current loss 1.4376026957056554 Accuracy 63.310075355847054\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 36, Probability Accuracy 50.98628095608468\n",
      "Starting Training\n",
      "Training:: Epoch 37, Iteration 0, Current loss 0.9733008140522753 Accuracy 65.86693324447407\n",
      "Training:: Epoch 37, Iteration 10, Current loss 0.990321998768155 Accuracy 50.44279645762834\n",
      "Training:: Epoch 37, Iteration 20, Current loss 1.109681853610618 Accuracy 69.42372881355932\n",
      "Training:: Epoch 37, Iteration 30, Current loss 1.0207448422758036 Accuracy 66.65877057917801\n",
      "Training:: Epoch 37, Iteration 40, Current loss 1.0269686895475205 Accuracy 69.48673938320137\n",
      "Training:: Epoch 37, Iteration 50, Current loss 1.0640386639030344 Accuracy 60.22166552797388\n",
      "Training:: Epoch 37, Iteration 60, Current loss 2.4292312898983788 Accuracy 57.555624227441285\n",
      "Training:: Epoch 37, Iteration 70, Current loss 1.442939343864038 Accuracy 48.68387096774194\n",
      "Training:: Epoch 37, Iteration 80, Current loss 0.9106126910000414 Accuracy 60.66390578491006\n",
      "Training:: Epoch 37, Iteration 90, Current loss 1.16827372212433 Accuracy 64.16518992218198\n",
      "Training:: Epoch 37, Iteration 100, Current loss 1.4918068700152645 Accuracy 59.34449866903283\n",
      "Training:: Epoch 37, Iteration 110, Current loss 1.2353570592657568 Accuracy 58.63817285822593\n",
      "Training:: Epoch 37, Iteration 120, Current loss 0.823236593106021 Accuracy 75.52349646944242\n",
      "Training:: Epoch 37, Iteration 130, Current loss 1.3988950959591788 Accuracy 58.07274340208472\n",
      "Training:: Epoch 37, Iteration 140, Current loss 0.978487426094883 Accuracy 53.83841095155013\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 37, Probability Accuracy 52.662027202792174\n",
      "Starting Training\n",
      "Training:: Epoch 38, Iteration 0, Current loss 0.9139531641789981 Accuracy 72.13101229271513\n",
      "Training:: Epoch 38, Iteration 10, Current loss 1.185742968628719 Accuracy 70.16044187269858\n",
      "Training:: Epoch 38, Iteration 20, Current loss 1.0397631132100202 Accuracy 64.67775467775468\n",
      "Training:: Epoch 38, Iteration 30, Current loss 1.0550342794414107 Accuracy 72.25583928355319\n",
      "Training:: Epoch 38, Iteration 40, Current loss 0.8939669949874354 Accuracy 69.64478828716413\n",
      "Training:: Epoch 38, Iteration 50, Current loss 0.8409951984224541 Accuracy 71.41194724592708\n",
      "Training:: Epoch 38, Iteration 60, Current loss 1.6916486037460003 Accuracy 60.8955895589559\n",
      "Training:: Epoch 38, Iteration 70, Current loss 0.9881730593472535 Accuracy 52.58397249404919\n",
      "Training:: Epoch 38, Iteration 80, Current loss 0.8847034153661956 Accuracy 70.19245814426537\n",
      "Training:: Epoch 38, Iteration 90, Current loss 0.9837079839819116 Accuracy 73.09510567296996\n",
      "Training:: Epoch 38, Iteration 100, Current loss 1.3064491541512187 Accuracy 63.18504520149139\n",
      "Training:: Epoch 38, Iteration 110, Current loss 1.6457576560575866 Accuracy 57.649699514879444\n",
      "Training:: Epoch 38, Iteration 120, Current loss 1.2888668681138638 Accuracy 60.45865184155664\n",
      "Training:: Epoch 38, Iteration 130, Current loss 0.8918769073087316 Accuracy 66.02275478092471\n",
      "Training:: Epoch 38, Iteration 140, Current loss 1.1889626382857534 Accuracy 61.753877050094836\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 38, Probability Accuracy 52.64871012228838\n",
      "Starting Training\n",
      "Training:: Epoch 39, Iteration 0, Current loss 1.0854591966826472 Accuracy 56.08711611403402\n",
      "Training:: Epoch 39, Iteration 10, Current loss 0.8984413730265323 Accuracy 60.65592972181552\n",
      "Training:: Epoch 39, Iteration 20, Current loss 1.1274668128909613 Accuracy 64.11908247925817\n",
      "Training:: Epoch 39, Iteration 30, Current loss 1.1171494854118031 Accuracy 61.83928092299436\n",
      "Training:: Epoch 39, Iteration 40, Current loss 0.9343533878759173 Accuracy 70.82461280870658\n",
      "Training:: Epoch 39, Iteration 50, Current loss 0.8481067934152148 Accuracy 66.93145710394916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 39, Iteration 60, Current loss 0.8092590716074003 Accuracy 61.80832074694494\n",
      "Training:: Epoch 39, Iteration 70, Current loss 1.1334087595888964 Accuracy 71.73777777777778\n",
      "Training:: Epoch 39, Iteration 80, Current loss 0.9525849488817899 Accuracy 72.80785608759885\n",
      "Training:: Epoch 39, Iteration 90, Current loss 1.144666894487013 Accuracy 62.53919388860384\n",
      "Training:: Epoch 39, Iteration 100, Current loss 1.0747386467180229 Accuracy 74.677867609904\n",
      "Training:: Epoch 39, Iteration 110, Current loss 0.8897796989291247 Accuracy 72.63603500761035\n",
      "Training:: Epoch 39, Iteration 120, Current loss 1.1535284811864834 Accuracy 60.61441729634328\n",
      "Training:: Epoch 39, Iteration 130, Current loss 1.1600160885196453 Accuracy 54.73439917483239\n",
      "Training:: Epoch 39, Iteration 140, Current loss 0.9302030464280283 Accuracy 66.31226530335249\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 39, Probability Accuracy 52.41864325910627\n",
      "Starting Training\n",
      "Training:: Epoch 40, Iteration 0, Current loss 0.8627747835221803 Accuracy 69.83987716604518\n",
      "Training:: Epoch 40, Iteration 10, Current loss 1.137523948911287 Accuracy 58.24022346368715\n",
      "Training:: Epoch 40, Iteration 20, Current loss 0.8287574065235548 Accuracy 74.09056540367975\n",
      "Training:: Epoch 40, Iteration 30, Current loss 1.0025546354305706 Accuracy 59.85372207193668\n",
      "Training:: Epoch 40, Iteration 40, Current loss 0.8963426260804989 Accuracy 67.44114241605558\n",
      "Training:: Epoch 40, Iteration 50, Current loss 0.9594377105386662 Accuracy 59.041769041769044\n",
      "Training:: Epoch 40, Iteration 60, Current loss 0.7199767741942792 Accuracy 67.35501634830494\n",
      "Training:: Epoch 40, Iteration 70, Current loss 0.8700547126770934 Accuracy 62.87629902782434\n",
      "Training:: Epoch 40, Iteration 80, Current loss 1.22331554266576 Accuracy 58.05302252551483\n",
      "Training:: Epoch 40, Iteration 90, Current loss 0.973408163386396 Accuracy 71.97062423500611\n",
      "Training:: Epoch 40, Iteration 100, Current loss 1.39434122994319 Accuracy 59.96123006432285\n",
      "Training:: Epoch 40, Iteration 110, Current loss 1.0656049560204344 Accuracy 56.488308405308615\n",
      "Training:: Epoch 40, Iteration 120, Current loss 0.8078560797717332 Accuracy 71.76165803108809\n",
      "Training:: Epoch 40, Iteration 130, Current loss 0.9729863899275124 Accuracy 61.52883185979188\n",
      "Training:: Epoch 40, Iteration 140, Current loss 0.6075947232833884 Accuracy 78.87893672349033\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 40, Probability Accuracy 52.52240210720331\n",
      "Calculating Expectation\n",
      "Epoch 40 iter 0\n",
      "Epoch 40 iter 10\n",
      "Epoch 40 iter 20\n",
      "Epoch 40 iter 30\n",
      "Epoch 40 iter 40\n",
      "Epoch 40 iter 50\n",
      "Epoch 40 iter 60\n",
      "Epoch 40 iter 70\n",
      "Epoch 40 iter 80\n",
      "Epoch 40 iter 90\n",
      "Epoch 40 iter 100\n",
      "Epoch 40 iter 110\n",
      "Epoch 40 iter 120\n",
      "Epoch 40 iter 130\n",
      "Epoch 40 iter 140\n",
      "Train Boundary avergage error = 301.230\n",
      "Train From boundary avergage accuracy = 60.264\n",
      "Starting Training\n",
      "Training:: Epoch 41, Iteration 0, Current loss 0.82790948236385 Accuracy 60.49689440993789\n",
      "Training:: Epoch 41, Iteration 10, Current loss 0.8019100958934926 Accuracy 63.51729881141646\n",
      "Training:: Epoch 41, Iteration 20, Current loss 0.7106103805942534 Accuracy 66.50814359664997\n",
      "Training:: Epoch 41, Iteration 30, Current loss 0.7225993295709825 Accuracy 64.16002801365666\n",
      "Training:: Epoch 41, Iteration 40, Current loss 0.8524200134126897 Accuracy 62.53487170656105\n",
      "Training:: Epoch 41, Iteration 50, Current loss 0.7457210909880894 Accuracy 59.992031166991325\n",
      "Training:: Epoch 41, Iteration 60, Current loss 1.0041685113025798 Accuracy 55.43718207121605\n",
      "Training:: Epoch 41, Iteration 70, Current loss 0.9844311771796691 Accuracy 55.240145297995426\n",
      "Training:: Epoch 41, Iteration 80, Current loss 0.9316782936684544 Accuracy 66.4752080647052\n",
      "Training:: Epoch 41, Iteration 90, Current loss 0.8234006086628591 Accuracy 73.57397235468099\n",
      "Training:: Epoch 41, Iteration 100, Current loss 1.026983609550538 Accuracy 65.91997109565531\n",
      "Training:: Epoch 41, Iteration 110, Current loss 0.8648439895222064 Accuracy 68.48617955860296\n",
      "Training:: Epoch 41, Iteration 120, Current loss 1.1048779307007746 Accuracy 69.2245516544582\n",
      "Training:: Epoch 41, Iteration 130, Current loss 1.472697157609471 Accuracy 60.11783367323816\n",
      "Training:: Epoch 41, Iteration 140, Current loss 0.9135179088568124 Accuracy 54.960132174412756\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 41, Probability Accuracy 52.071010268040965\n",
      "Starting Training\n",
      "Training:: Epoch 42, Iteration 0, Current loss 0.9626622181906168 Accuracy 70.76379491805743\n",
      "Training:: Epoch 42, Iteration 10, Current loss 1.11708904631461 Accuracy 66.51438449191258\n",
      "Training:: Epoch 42, Iteration 20, Current loss 0.8540805421364125 Accuracy 66.05069888651978\n",
      "Training:: Epoch 42, Iteration 30, Current loss 0.9255058602825027 Accuracy 68.46321089369494\n",
      "Training:: Epoch 42, Iteration 40, Current loss 1.138403409986943 Accuracy 68.97556158973093\n",
      "Training:: Epoch 42, Iteration 50, Current loss 1.3477558703222412 Accuracy 67.03850603206082\n",
      "Training:: Epoch 42, Iteration 60, Current loss 0.8751229536379355 Accuracy 68.5147787773086\n",
      "Training:: Epoch 42, Iteration 70, Current loss 0.7958093349917703 Accuracy 69.7964414214599\n",
      "Training:: Epoch 42, Iteration 80, Current loss 0.903600894524786 Accuracy 62.81973572554249\n",
      "Training:: Epoch 42, Iteration 90, Current loss 0.9415571288268259 Accuracy 55.67744576340565\n",
      "Training:: Epoch 42, Iteration 100, Current loss 0.6465280254029724 Accuracy 62.73789649415693\n",
      "Training:: Epoch 42, Iteration 110, Current loss 0.8932668973933433 Accuracy 62.29917455204349\n",
      "Training:: Epoch 42, Iteration 120, Current loss 0.8679195034330822 Accuracy 63.440982488060044\n",
      "Training:: Epoch 42, Iteration 130, Current loss 0.6822835558226856 Accuracy 67.35438596491228\n",
      "Training:: Epoch 42, Iteration 140, Current loss 1.3403704817605095 Accuracy 50.62059711506206\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 42, Probability Accuracy 51.62100732684527\n",
      "Starting Training\n",
      "Training:: Epoch 43, Iteration 0, Current loss 0.9368926693835273 Accuracy 63.385026058217875\n",
      "Training:: Epoch 43, Iteration 10, Current loss 0.898089986520602 Accuracy 60.06159074015079\n",
      "Training:: Epoch 43, Iteration 20, Current loss 0.8140380707938757 Accuracy 68.77005995276448\n",
      "Training:: Epoch 43, Iteration 30, Current loss 0.8470125948254458 Accuracy 65.40936717912048\n",
      "Training:: Epoch 43, Iteration 40, Current loss 0.6672557057866145 Accuracy 67.45269894268225\n",
      "Training:: Epoch 43, Iteration 50, Current loss 0.7803248590713844 Accuracy 68.7850812407681\n",
      "Training:: Epoch 43, Iteration 60, Current loss 0.9271915107104732 Accuracy 54.264015305235084\n",
      "Training:: Epoch 43, Iteration 70, Current loss 1.0356945774378086 Accuracy 64.62626884035681\n",
      "Training:: Epoch 43, Iteration 80, Current loss 0.7388992416432313 Accuracy 66.1364249123753\n",
      "Training:: Epoch 43, Iteration 90, Current loss 0.6863166083220923 Accuracy 64.34045986284792\n",
      "Training:: Epoch 43, Iteration 100, Current loss 0.8360898667614896 Accuracy 66.56226374338482\n",
      "Training:: Epoch 43, Iteration 110, Current loss 0.9491392276941467 Accuracy 54.48791117567708\n",
      "Training:: Epoch 43, Iteration 120, Current loss 1.0171839333997397 Accuracy 63.42984168293212\n",
      "Training:: Epoch 43, Iteration 130, Current loss 0.6746435315350982 Accuracy 62.480493423497066\n",
      "Training:: Epoch 43, Iteration 140, Current loss 0.7859944097750233 Accuracy 56.02491199566748\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 43, Probability Accuracy 52.085144347348674\n",
      "Starting Training\n",
      "Training:: Epoch 44, Iteration 0, Current loss 0.7883250243461909 Accuracy 70.20055053086905\n",
      "Training:: Epoch 44, Iteration 10, Current loss 0.9276607451701234 Accuracy 50.78896174075942\n",
      "Training:: Epoch 44, Iteration 20, Current loss 0.6573428505030542 Accuracy 63.892463235294116\n",
      "Training:: Epoch 44, Iteration 30, Current loss 0.7252092787837714 Accuracy 74.13586097946288\n",
      "Training:: Epoch 44, Iteration 40, Current loss 0.7200005787965192 Accuracy 65.31387445021991\n",
      "Training:: Epoch 44, Iteration 50, Current loss 0.6416225684884751 Accuracy 68.64284238793638\n",
      "Training:: Epoch 44, Iteration 60, Current loss 0.7540097443854092 Accuracy 62.20802919708029\n",
      "Training:: Epoch 44, Iteration 70, Current loss 0.5523424690980141 Accuracy 61.9390389197776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 44, Iteration 80, Current loss 0.8539614390864158 Accuracy 59.27311598075895\n",
      "Training:: Epoch 44, Iteration 90, Current loss 0.8757115568661582 Accuracy 70.62956560530864\n",
      "Training:: Epoch 44, Iteration 100, Current loss 0.7336887353653817 Accuracy 76.78419349344234\n",
      "Training:: Epoch 44, Iteration 110, Current loss 1.15699139039174 Accuracy 60.42642346561499\n",
      "Training:: Epoch 44, Iteration 120, Current loss 2.816324909880256 Accuracy 53.69816411519737\n",
      "Training:: Epoch 44, Iteration 130, Current loss 5.325503915073375 Accuracy 46.52733987929015\n",
      "Training:: Epoch 44, Iteration 140, Current loss 4.41685271773998 Accuracy 44.77975632614808\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 44, Probability Accuracy 45.97946718606004\n",
      "Starting Training\n",
      "Training:: Epoch 45, Iteration 0, Current loss 4.804058923498326 Accuracy 44.082840236686394\n",
      "Training:: Epoch 45, Iteration 10, Current loss 9.531079844647518 Accuracy 34.54411282387668\n",
      "Training:: Epoch 45, Iteration 20, Current loss 2.3497269852368943 Accuracy 60.04857316332726\n",
      "Training:: Epoch 45, Iteration 30, Current loss 5.757432567696622 Accuracy 23.583394513782288\n",
      "Training:: Epoch 45, Iteration 40, Current loss 2.5511809783316166 Accuracy 61.76917575540855\n",
      "Training:: Epoch 45, Iteration 50, Current loss 2.616803826278231 Accuracy 53.49560316766264\n",
      "Training:: Epoch 45, Iteration 60, Current loss 1.9666734770928003 Accuracy 46.37938693913816\n",
      "Training:: Epoch 45, Iteration 70, Current loss 1.6927822074567476 Accuracy 72.27735209144579\n",
      "Training:: Epoch 45, Iteration 80, Current loss 1.5231531510405507 Accuracy 62.409577177789096\n",
      "Training:: Epoch 45, Iteration 90, Current loss 0.856254624886661 Accuracy 71.30037250253979\n",
      "Training:: Epoch 45, Iteration 100, Current loss 0.8527710111840988 Accuracy 78.02933433621662\n",
      "Training:: Epoch 45, Iteration 110, Current loss 1.3089297475481119 Accuracy 58.52086939796115\n",
      "Training:: Epoch 45, Iteration 120, Current loss 0.7041722841296244 Accuracy 72.4851783458062\n",
      "Training:: Epoch 45, Iteration 130, Current loss 1.2151364043606947 Accuracy 78.5532558619267\n",
      "Training:: Epoch 45, Iteration 140, Current loss 1.0746495912949703 Accuracy 64.26938839848675\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 45, Probability Accuracy 52.41986875731214\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Total correct pivots labels selected =  62.73364485981308\n",
      "Calculating Expectation\n",
      "Epoch 45 iter 0\n",
      "Epoch 45 iter 10\n",
      "Epoch 45 iter 20\n",
      "Epoch 45 iter 30\n",
      "Epoch 45 iter 40\n",
      "Epoch 45 iter 50\n",
      "Epoch 45 iter 60\n",
      "Epoch 45 iter 70\n",
      "Epoch 45 iter 80\n",
      "Epoch 45 iter 90\n",
      "Epoch 45 iter 100\n",
      "Epoch 45 iter 110\n",
      "Epoch 45 iter 120\n",
      "Epoch 45 iter 130\n",
      "Epoch 45 iter 140\n",
      "Train Boundary avergage error = 301.269\n",
      "Train From boundary avergage accuracy = 60.221\n",
      "Starting Training\n",
      "Training:: Epoch 46, Iteration 0, Current loss 0.798482440626827 Accuracy 57.73034551827742\n",
      "Training:: Epoch 46, Iteration 10, Current loss 0.7753917172809721 Accuracy 69.4743059657413\n",
      "Training:: Epoch 46, Iteration 20, Current loss 0.7519373419587526 Accuracy 56.991618879576535\n",
      "Training:: Epoch 46, Iteration 30, Current loss 0.7859114194549865 Accuracy 56.77285932345266\n",
      "Training:: Epoch 46, Iteration 40, Current loss 1.0229415257262808 Accuracy 59.015290952852894\n",
      "Training:: Epoch 46, Iteration 50, Current loss 0.8590238556483157 Accuracy 57.585585585585584\n",
      "Training:: Epoch 46, Iteration 60, Current loss 0.6543784146494975 Accuracy 60.37676112078518\n",
      "Training:: Epoch 46, Iteration 70, Current loss 1.0740562219503877 Accuracy 70.48860443334374\n",
      "Training:: Epoch 46, Iteration 80, Current loss 1.0781839573202663 Accuracy 69.8931599117408\n",
      "Training:: Epoch 46, Iteration 90, Current loss 0.8594029556418636 Accuracy 73.70894080449675\n",
      "Training:: Epoch 46, Iteration 100, Current loss 0.9402429337496694 Accuracy 64.82800732749847\n",
      "Training:: Epoch 46, Iteration 110, Current loss 0.8307714490224704 Accuracy 72.24203664985856\n",
      "Training:: Epoch 46, Iteration 120, Current loss 1.5696434188055157 Accuracy 68.23627751462803\n",
      "Training:: Epoch 46, Iteration 130, Current loss 1.6380890877999603 Accuracy 60.38793103448276\n",
      "Training:: Epoch 46, Iteration 140, Current loss 0.8733523110921575 Accuracy 66.29696054370399\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 46, Probability Accuracy 49.32940738174759\n",
      "Starting Training\n",
      "Training:: Epoch 47, Iteration 0, Current loss 1.392371902630927 Accuracy 58.315459495132814\n",
      "Training:: Epoch 47, Iteration 10, Current loss 0.7525228887983388 Accuracy 69.17568513433478\n",
      "Training:: Epoch 47, Iteration 20, Current loss 0.9134773597470774 Accuracy 54.174857734092086\n",
      "Training:: Epoch 47, Iteration 30, Current loss 0.7295229292479148 Accuracy 68.74628285952183\n",
      "Training:: Epoch 47, Iteration 40, Current loss 1.2128578301587112 Accuracy 60.5571314277402\n",
      "Training:: Epoch 47, Iteration 50, Current loss 0.9630196565495479 Accuracy 69.2234788652303\n",
      "Training:: Epoch 47, Iteration 60, Current loss 0.6888888092597505 Accuracy 67.05341628832464\n",
      "Training:: Epoch 47, Iteration 70, Current loss 1.1729894699244738 Accuracy 53.888368357649576\n",
      "Training:: Epoch 47, Iteration 80, Current loss 0.7240626543375944 Accuracy 67.2591743119266\n",
      "Training:: Epoch 47, Iteration 90, Current loss 1.0185208818108646 Accuracy 57.96229691181942\n",
      "Training:: Epoch 47, Iteration 100, Current loss 0.7792721042789539 Accuracy 69.55062465038225\n",
      "Training:: Epoch 47, Iteration 110, Current loss 1.006101036953877 Accuracy 60.684647302904565\n",
      "Training:: Epoch 47, Iteration 120, Current loss 0.8141922630543227 Accuracy 52.034516626911746\n",
      "Training:: Epoch 47, Iteration 130, Current loss 0.7047282064831661 Accuracy 57.48776508972268\n",
      "Training:: Epoch 47, Iteration 140, Current loss 0.9896361002725562 Accuracy 54.63195595231731\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 47, Probability Accuracy 51.43064660553337\n",
      "Starting Training\n",
      "Training:: Epoch 48, Iteration 0, Current loss 0.9552575970790468 Accuracy 60.56112905968373\n",
      "Training:: Epoch 48, Iteration 10, Current loss 0.7802224890214471 Accuracy 70.17013232514178\n",
      "Training:: Epoch 48, Iteration 20, Current loss 0.7994952446577566 Accuracy 65.08074080832041\n",
      "Training:: Epoch 48, Iteration 30, Current loss 0.5941051051789445 Accuracy 70.49830450025864\n",
      "Training:: Epoch 48, Iteration 40, Current loss 0.6376595477934973 Accuracy 60.827894664780246\n",
      "Training:: Epoch 48, Iteration 50, Current loss 0.8060481166419964 Accuracy 62.83985814616508\n",
      "Training:: Epoch 48, Iteration 60, Current loss 1.0089029893493004 Accuracy 65.646911705596\n",
      "Training:: Epoch 48, Iteration 70, Current loss 1.0591852827418993 Accuracy 54.65065396022755\n",
      "Training:: Epoch 48, Iteration 80, Current loss 0.9896914254478895 Accuracy 52.88078591025754\n",
      "Training:: Epoch 48, Iteration 90, Current loss 0.5231267018684546 Accuracy 68.4857608832016\n",
      "Training:: Epoch 48, Iteration 100, Current loss 0.6218103594200222 Accuracy 71.36296539281614\n",
      "Training:: Epoch 48, Iteration 110, Current loss 0.9530743296071851 Accuracy 59.64642224088068\n",
      "Training:: Epoch 48, Iteration 120, Current loss 0.8715945953038111 Accuracy 55.582876237311645\n",
      "Training:: Epoch 48, Iteration 130, Current loss 0.9175000319182693 Accuracy 59.54068359199785\n",
      "Training:: Epoch 48, Iteration 140, Current loss 0.842374992890251 Accuracy 56.10567780494431\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 48, Probability Accuracy 52.543644076105075\n",
      "Starting Training\n",
      "Training:: Epoch 49, Iteration 0, Current loss 0.757747228516373 Accuracy 61.924316128624675\n",
      "Training:: Epoch 49, Iteration 10, Current loss 0.7214000264308088 Accuracy 67.95420057939026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 49, Iteration 20, Current loss 0.7491543985866588 Accuracy 64.61720049358871\n",
      "Training:: Epoch 49, Iteration 30, Current loss 0.796497611063592 Accuracy 63.13214827063525\n",
      "Training:: Epoch 49, Iteration 40, Current loss 0.5724919403039107 Accuracy 73.71950349550578\n",
      "Training:: Epoch 49, Iteration 50, Current loss 0.7031049282327845 Accuracy 70.0845665961945\n",
      "Training:: Epoch 49, Iteration 60, Current loss 0.6470882133183676 Accuracy 63.15170060021184\n",
      "Training:: Epoch 49, Iteration 70, Current loss 0.6895519477560731 Accuracy 50.947184635530334\n",
      "Training:: Epoch 49, Iteration 80, Current loss 0.65203572058401 Accuracy 56.142674677137045\n",
      "Training:: Epoch 49, Iteration 90, Current loss 0.6500759440939021 Accuracy 52.846820809248555\n",
      "Training:: Epoch 49, Iteration 100, Current loss 0.6193738677791725 Accuracy 65.89755011135857\n",
      "Training:: Epoch 49, Iteration 110, Current loss 2.022705270710021 Accuracy 55.511811023622045\n",
      "Training:: Epoch 49, Iteration 120, Current loss 1.4829057757510613 Accuracy 62.44131455399061\n",
      "Training:: Epoch 49, Iteration 130, Current loss 1.3030144197597056 Accuracy 59.467345747785025\n",
      "Training:: Epoch 49, Iteration 140, Current loss 1.4545295744795026 Accuracy 55.97691071167617\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 49, Probability Accuracy 52.26447558480774\n",
      "Starting Training\n",
      "Training:: Epoch 50, Iteration 0, Current loss 0.6782682403368457 Accuracy 57.06688484352628\n",
      "Training:: Epoch 50, Iteration 10, Current loss 0.7789618063085959 Accuracy 74.65324993200979\n",
      "Training:: Epoch 50, Iteration 20, Current loss 0.8405209401619136 Accuracy 73.45401530798202\n",
      "Training:: Epoch 50, Iteration 30, Current loss 1.1054215021171012 Accuracy 57.82410533423363\n",
      "Training:: Epoch 50, Iteration 40, Current loss 0.8415171551203778 Accuracy 65.95878136200717\n",
      "Training:: Epoch 50, Iteration 50, Current loss 0.6225749086888238 Accuracy 63.79033021099442\n",
      "Training:: Epoch 50, Iteration 60, Current loss 0.624141545422621 Accuracy 68.5605572036631\n",
      "Training:: Epoch 50, Iteration 70, Current loss 0.769663780356198 Accuracy 68.2911620885432\n",
      "Training:: Epoch 50, Iteration 80, Current loss 0.5706462243701045 Accuracy 63.05356043505028\n",
      "Training:: Epoch 50, Iteration 90, Current loss 0.6910599571382312 Accuracy 58.92155321490332\n",
      "Training:: Epoch 50, Iteration 100, Current loss 0.7982796962374951 Accuracy 64.93839014242279\n",
      "Training:: Epoch 50, Iteration 110, Current loss 0.6437168582616698 Accuracy 64.91915179320763\n",
      "Training:: Epoch 50, Iteration 120, Current loss 0.6901867361711246 Accuracy 57.40951215247421\n",
      "Training:: Epoch 50, Iteration 130, Current loss 0.7457274840017172 Accuracy 66.8348130212537\n",
      "Training:: Epoch 50, Iteration 140, Current loss 0.598720283393567 Accuracy 59.959514170040485\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 50, Probability Accuracy 52.40124118458291\n",
      "Calculating Expectation\n",
      "Epoch 50 iter 0\n",
      "Epoch 50 iter 10\n",
      "Epoch 50 iter 20\n",
      "Epoch 50 iter 30\n",
      "Epoch 50 iter 40\n",
      "Epoch 50 iter 50\n",
      "Epoch 50 iter 60\n",
      "Epoch 50 iter 70\n",
      "Epoch 50 iter 80\n",
      "Epoch 50 iter 90\n",
      "Epoch 50 iter 100\n",
      "Epoch 50 iter 110\n",
      "Epoch 50 iter 120\n",
      "Epoch 50 iter 130\n",
      "Epoch 50 iter 140\n",
      "Train Boundary avergage error = 300.787\n",
      "Train From boundary avergage accuracy = 60.186\n",
      "Starting Training\n",
      "Training:: Epoch 51, Iteration 0, Current loss 0.49469523161515827 Accuracy 65.79285784944109\n",
      "Training:: Epoch 51, Iteration 10, Current loss 0.7419761970230792 Accuracy 51.32841485777645\n",
      "Training:: Epoch 51, Iteration 20, Current loss 0.841635478343148 Accuracy 66.78460858027421\n",
      "Training:: Epoch 51, Iteration 30, Current loss 0.4873539547432158 Accuracy 57.141994322642994\n",
      "Training:: Epoch 51, Iteration 40, Current loss 0.7593525541541103 Accuracy 64.55072463768116\n",
      "Training:: Epoch 51, Iteration 50, Current loss 0.714595255449333 Accuracy 53.33142693737489\n",
      "Training:: Epoch 51, Iteration 60, Current loss 0.5490112283615123 Accuracy 60.79783113865221\n",
      "Training:: Epoch 51, Iteration 70, Current loss 0.7974032769356638 Accuracy 59.232109595625786\n",
      "Training:: Epoch 51, Iteration 80, Current loss 0.6704515824652759 Accuracy 67.13775587185033\n",
      "Training:: Epoch 51, Iteration 90, Current loss 0.8229972062938251 Accuracy 77.16104203670811\n",
      "Training:: Epoch 51, Iteration 100, Current loss 0.6155967323929079 Accuracy 68.8180337704637\n",
      "Training:: Epoch 51, Iteration 110, Current loss 0.65853692296436 Accuracy 55.59454191033139\n",
      "Training:: Epoch 51, Iteration 120, Current loss 0.7272759737776793 Accuracy 63.413611589882144\n",
      "Training:: Epoch 51, Iteration 130, Current loss 0.5292949361201742 Accuracy 60.81228846654517\n",
      "Training:: Epoch 51, Iteration 140, Current loss 0.7882188957733373 Accuracy 62.001790133206974\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 51, Probability Accuracy 51.897479722089685\n",
      "Starting Training\n",
      "Training:: Epoch 52, Iteration 0, Current loss 0.6035387919924907 Accuracy 60.10578382878691\n",
      "Training:: Epoch 52, Iteration 10, Current loss 0.6483291242134461 Accuracy 58.03113391119759\n",
      "Training:: Epoch 52, Iteration 20, Current loss 0.7311554315337077 Accuracy 64.79964740882212\n",
      "Training:: Epoch 52, Iteration 30, Current loss 0.6254431524594816 Accuracy 66.70755119453925\n",
      "Training:: Epoch 52, Iteration 40, Current loss 0.7138994660718436 Accuracy 59.452169464725856\n",
      "Training:: Epoch 52, Iteration 50, Current loss 0.8191242542326298 Accuracy 64.90606460118656\n",
      "Training:: Epoch 52, Iteration 60, Current loss 0.6471130985247945 Accuracy 64.66691477484183\n",
      "Training:: Epoch 52, Iteration 70, Current loss 0.7199916788455014 Accuracy 61.0062893081761\n",
      "Training:: Epoch 52, Iteration 80, Current loss 0.5255261297124396 Accuracy 67.79875049847135\n",
      "Training:: Epoch 52, Iteration 90, Current loss 0.5931373276033359 Accuracy 67.67390907431076\n",
      "Training:: Epoch 52, Iteration 100, Current loss 0.590959356637463 Accuracy 62.94654009492881\n",
      "Training:: Epoch 52, Iteration 110, Current loss 0.5863389710795412 Accuracy 59.24441250992701\n",
      "Training:: Epoch 52, Iteration 120, Current loss 0.6695995637158167 Accuracy 63.22689919076595\n",
      "Training:: Epoch 52, Iteration 130, Current loss 0.6442640005476814 Accuracy 63.24313648034762\n",
      "Training:: Epoch 52, Iteration 140, Current loss 0.7317730391775137 Accuracy 48.410054512416714\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 52, Probability Accuracy 52.66243570219413\n",
      "Starting Training\n",
      "Training:: Epoch 53, Iteration 0, Current loss 0.9181510299616404 Accuracy 60.256589039185606\n",
      "Training:: Epoch 53, Iteration 10, Current loss 0.6962517572856278 Accuracy 64.73638249099443\n",
      "Training:: Epoch 53, Iteration 20, Current loss 0.5704006750367949 Accuracy 71.70749814402376\n",
      "Training:: Epoch 53, Iteration 30, Current loss 0.5696471314858954 Accuracy 55.731267817761285\n",
      "Training:: Epoch 53, Iteration 40, Current loss 0.7566005326038804 Accuracy 65.67951054412913\n",
      "Training:: Epoch 53, Iteration 50, Current loss 0.8207934431762374 Accuracy 65.35186794092094\n",
      "Training:: Epoch 53, Iteration 60, Current loss 0.5426265941810398 Accuracy 75.31607099440798\n",
      "Training:: Epoch 53, Iteration 70, Current loss 0.8075442823870587 Accuracy 51.334584306667175\n",
      "Training:: Epoch 53, Iteration 80, Current loss 0.577711113545621 Accuracy 67.8446159242371\n",
      "Training:: Epoch 53, Iteration 90, Current loss 0.5924447908923657 Accuracy 66.57647297571535\n",
      "Training:: Epoch 53, Iteration 100, Current loss 0.7606479195179467 Accuracy 66.60048426150121\n",
      "Training:: Epoch 53, Iteration 110, Current loss 0.6147433286390633 Accuracy 61.54401628044377\n",
      "Training:: Epoch 53, Iteration 120, Current loss 0.933798265289913 Accuracy 57.28893662728249\n",
      "Training:: Epoch 53, Iteration 130, Current loss 0.560221209799038 Accuracy 77.37353600797408\n",
      "Training:: Epoch 53, Iteration 140, Current loss 0.7021103322681348 Accuracy 65.9709561828126\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 53, Probability Accuracy 53.06219321694913\n",
      "Starting Training\n",
      "Training:: Epoch 54, Iteration 0, Current loss 0.5961554038213721 Accuracy 56.29360980801829\n",
      "Training:: Epoch 54, Iteration 10, Current loss 0.6605841930924692 Accuracy 61.340294910780884\n",
      "Training:: Epoch 54, Iteration 20, Current loss 0.7392065103916432 Accuracy 57.67218596623699\n",
      "Training:: Epoch 54, Iteration 30, Current loss 0.5988571048442056 Accuracy 58.47919655667145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 54, Iteration 40, Current loss 0.5316116883871388 Accuracy 72.32527893764119\n",
      "Training:: Epoch 54, Iteration 50, Current loss 0.5429290178343152 Accuracy 73.29768049250669\n",
      "Training:: Epoch 54, Iteration 60, Current loss 0.5147085458207366 Accuracy 66.04156899515549\n",
      "Training:: Epoch 54, Iteration 70, Current loss 0.4911080336998107 Accuracy 65.28749259039715\n",
      "Training:: Epoch 54, Iteration 80, Current loss 0.4783997062626757 Accuracy 73.22202166064982\n",
      "Training:: Epoch 54, Iteration 90, Current loss 0.6191825938877554 Accuracy 59.44902016472593\n",
      "Training:: Epoch 54, Iteration 100, Current loss 0.6521096918188644 Accuracy 61.61616161616162\n",
      "Training:: Epoch 54, Iteration 110, Current loss 0.6345016841213077 Accuracy 65.89285714285714\n",
      "Training:: Epoch 54, Iteration 120, Current loss 0.5969523365853153 Accuracy 57.56477987421383\n",
      "Training:: Epoch 54, Iteration 130, Current loss 0.6593557635143587 Accuracy 65.19216085517944\n",
      "Training:: Epoch 54, Iteration 140, Current loss 0.6529970403607036 Accuracy 64.81609993060374\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 54, Probability Accuracy 52.512107922274005\n",
      "Starting Training\n",
      "Training:: Epoch 55, Iteration 0, Current loss 0.5669002790897293 Accuracy 62.84552451953333\n",
      "Training:: Epoch 55, Iteration 10, Current loss 0.6467780393023609 Accuracy 67.51274483498793\n",
      "Training:: Epoch 55, Iteration 20, Current loss 0.5442398547352328 Accuracy 66.430230368464\n",
      "Training:: Epoch 55, Iteration 30, Current loss 0.5981250270408186 Accuracy 71.22470289891105\n",
      "Training:: Epoch 55, Iteration 40, Current loss 0.6437057437449429 Accuracy 62.289378538781634\n",
      "Training:: Epoch 55, Iteration 50, Current loss 0.7273811945081515 Accuracy 66.79150211085387\n",
      "Training:: Epoch 55, Iteration 60, Current loss 1.1057945728035903 Accuracy 54.261589028675054\n",
      "Training:: Epoch 55, Iteration 70, Current loss 0.6460511331328205 Accuracy 63.436616012104466\n",
      "Training:: Epoch 55, Iteration 80, Current loss 0.5691638104875715 Accuracy 60.5079609408822\n",
      "Training:: Epoch 55, Iteration 90, Current loss 0.5378092979169232 Accuracy 61.55443725537184\n",
      "Training:: Epoch 55, Iteration 100, Current loss 0.6877932430470659 Accuracy 60.230179028132994\n",
      "Training:: Epoch 55, Iteration 110, Current loss 0.5437120141534331 Accuracy 69.63805713571294\n",
      "Training:: Epoch 55, Iteration 120, Current loss 0.6811148025963057 Accuracy 66.13649358074744\n",
      "Training:: Epoch 55, Iteration 130, Current loss 0.5423107405355057 Accuracy 54.21717823059066\n",
      "Training:: Epoch 55, Iteration 140, Current loss 0.6118331493022094 Accuracy 62.287861121906985\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 55, Probability Accuracy 52.00458826528278\n",
      "Calculating Expectation\n",
      "Epoch 55 iter 0\n",
      "Epoch 55 iter 10\n",
      "Epoch 55 iter 20\n",
      "Epoch 55 iter 30\n",
      "Epoch 55 iter 40\n",
      "Epoch 55 iter 50\n",
      "Epoch 55 iter 60\n",
      "Epoch 55 iter 70\n",
      "Epoch 55 iter 80\n",
      "Epoch 55 iter 90\n",
      "Epoch 55 iter 100\n",
      "Epoch 55 iter 110\n",
      "Epoch 55 iter 120\n",
      "Epoch 55 iter 130\n",
      "Epoch 55 iter 140\n",
      "Train Boundary avergage error = 301.051\n",
      "Train From boundary avergage accuracy = 60.170\n",
      "Starting Training\n",
      "Training:: Epoch 56, Iteration 0, Current loss 0.6700036103265521 Accuracy 69.9614807077104\n",
      "Training:: Epoch 56, Iteration 10, Current loss 0.5038109125851866 Accuracy 60.22596821944293\n",
      "Training:: Epoch 56, Iteration 20, Current loss 0.42178835766853123 Accuracy 66.39669136653455\n",
      "Training:: Epoch 56, Iteration 30, Current loss 0.5698317849511718 Accuracy 58.458436990649396\n",
      "Training:: Epoch 56, Iteration 40, Current loss 0.6630969582810375 Accuracy 51.34467357217523\n",
      "Training:: Epoch 56, Iteration 50, Current loss 0.45223606702404945 Accuracy 62.52912984214923\n",
      "Training:: Epoch 56, Iteration 60, Current loss 0.525482799954353 Accuracy 63.72226198997853\n",
      "Training:: Epoch 56, Iteration 70, Current loss 0.6055099467587387 Accuracy 62.07596169453011\n",
      "Training:: Epoch 56, Iteration 80, Current loss 0.604013705991982 Accuracy 60.47026415465591\n",
      "Training:: Epoch 56, Iteration 90, Current loss 0.6960876080893738 Accuracy 60.86309523809524\n",
      "Training:: Epoch 56, Iteration 100, Current loss 0.5423236762051047 Accuracy 68.90951276102088\n",
      "Training:: Epoch 56, Iteration 110, Current loss 0.7868218584205156 Accuracy 60.99330076059034\n",
      "Training:: Epoch 56, Iteration 120, Current loss 0.5199434248144689 Accuracy 66.9234204063407\n",
      "Training:: Epoch 56, Iteration 130, Current loss 0.9884052142921574 Accuracy 56.24169603142511\n",
      "Training:: Epoch 56, Iteration 140, Current loss 0.5605070699276041 Accuracy 59.589504548530186\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 56, Probability Accuracy 50.70065817423643\n",
      "Starting Training\n",
      "Training:: Epoch 57, Iteration 0, Current loss 0.5346863216894353 Accuracy 52.7812444285969\n",
      "Training:: Epoch 57, Iteration 10, Current loss 0.48116518826033616 Accuracy 79.79751068177596\n",
      "Training:: Epoch 57, Iteration 20, Current loss 0.6095353085797041 Accuracy 65.7967488665266\n",
      "Training:: Epoch 57, Iteration 30, Current loss 0.5868295720316925 Accuracy 73.17073170731707\n",
      "Training:: Epoch 57, Iteration 40, Current loss 0.9052246018831148 Accuracy 69.52175087814105\n",
      "Training:: Epoch 57, Iteration 50, Current loss 1.766051281111114 Accuracy 67.44866284622732\n",
      "Training:: Epoch 57, Iteration 60, Current loss 1.4734678824414478 Accuracy 57.83184644498513\n",
      "Training:: Epoch 57, Iteration 70, Current loss 4.950751280896411 Accuracy 45.89474804448465\n",
      "Training:: Epoch 57, Iteration 80, Current loss 2.3670414428152706 Accuracy 51.679697043733206\n",
      "Training:: Epoch 57, Iteration 90, Current loss 1.9705527125390294 Accuracy 53.54231366459627\n",
      "Training:: Epoch 57, Iteration 100, Current loss 1.1656662468852321 Accuracy 59.73157894736842\n",
      "Training:: Epoch 57, Iteration 110, Current loss 1.5606762823385392 Accuracy 70.08357496162374\n",
      "Training:: Epoch 57, Iteration 120, Current loss 1.2708165784239478 Accuracy 69.48753041362531\n",
      "Training:: Epoch 57, Iteration 130, Current loss 1.915895426489435 Accuracy 64.6179570328334\n",
      "Training:: Epoch 57, Iteration 140, Current loss 1.2103436455482204 Accuracy 60.098874262910236\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 57, Probability Accuracy 51.20360263792574\n",
      "Starting Training\n",
      "Training:: Epoch 58, Iteration 0, Current loss 1.3883094914001313 Accuracy 60.45204954667348\n",
      "Training:: Epoch 58, Iteration 10, Current loss 1.049152676010148 Accuracy 65.86660054549962\n",
      "Training:: Epoch 58, Iteration 20, Current loss 2.3053609514487863 Accuracy 49.226660040996336\n",
      "Training:: Epoch 58, Iteration 30, Current loss 1.3381330662171451 Accuracy 54.30721195679992\n",
      "Training:: Epoch 58, Iteration 40, Current loss 1.1680574356658318 Accuracy 56.9851504493943\n",
      "Training:: Epoch 58, Iteration 50, Current loss 1.1885888910690776 Accuracy 55.119617224880386\n",
      "Training:: Epoch 58, Iteration 60, Current loss 1.0673605877725567 Accuracy 56.588921282798836\n",
      "Training:: Epoch 58, Iteration 70, Current loss 0.9238069354428677 Accuracy 60.728212356119336\n",
      "Training:: Epoch 58, Iteration 80, Current loss 0.8298268129328163 Accuracy 64.04114414541355\n",
      "Training:: Epoch 58, Iteration 90, Current loss 0.9098161342830251 Accuracy 60.24902170046247\n",
      "Training:: Epoch 58, Iteration 100, Current loss 0.9051923240007496 Accuracy 60.634450044470796\n",
      "Training:: Epoch 58, Iteration 110, Current loss 0.6304305027712735 Accuracy 60.31259273914334\n",
      "Training:: Epoch 58, Iteration 120, Current loss 0.6846887102275419 Accuracy 58.555394365121785\n",
      "Training:: Epoch 58, Iteration 130, Current loss 0.5698397986325191 Accuracy 63.90107276858849\n",
      "Training:: Epoch 58, Iteration 140, Current loss 0.7317535115448142 Accuracy 49.375069746680055\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 58, Probability Accuracy 52.220602749037575\n",
      "Starting Training\n",
      "Training:: Epoch 59, Iteration 0, Current loss 0.9227118777355116 Accuracy 58.42266824085006\n",
      "Training:: Epoch 59, Iteration 10, Current loss 1.1978339480758904 Accuracy 51.71946467897679\n",
      "Training:: Epoch 59, Iteration 20, Current loss 1.016568179555199 Accuracy 68.2015524273122\n",
      "Training:: Epoch 59, Iteration 30, Current loss 1.959144011993601 Accuracy 61.48890914615618\n",
      "Training:: Epoch 59, Iteration 40, Current loss 1.4428691306908377 Accuracy 59.60030237172824\n",
      "Training:: Epoch 59, Iteration 50, Current loss 0.9243132540355959 Accuracy 69.73229453459082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 59, Iteration 60, Current loss 1.7247108153425912 Accuracy 55.101246105919\n",
      "Training:: Epoch 59, Iteration 70, Current loss 1.044303675975653 Accuracy 60.784109816971714\n",
      "Training:: Epoch 59, Iteration 80, Current loss 0.8035109493222665 Accuracy 56.539693241193326\n",
      "Training:: Epoch 59, Iteration 90, Current loss 0.6836758139876776 Accuracy 61.46161064193851\n",
      "Training:: Epoch 59, Iteration 100, Current loss 0.8240958646665775 Accuracy 57.851912123677785\n",
      "Training:: Epoch 59, Iteration 110, Current loss 0.7099527335188911 Accuracy 62.854186564788286\n",
      "Training:: Epoch 59, Iteration 120, Current loss 0.5048591656614896 Accuracy 59.420921815724064\n",
      "Training:: Epoch 59, Iteration 130, Current loss 0.5059043936193554 Accuracy 71.8111279333838\n",
      "Training:: Epoch 59, Iteration 140, Current loss 0.7846642171759473 Accuracy 56.537160768786606\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 59, Probability Accuracy 51.940698958816725\n",
      "Starting Training\n",
      "Training:: Epoch 60, Iteration 0, Current loss 0.8010604203400439 Accuracy 49.46831755280408\n",
      "Training:: Epoch 60, Iteration 10, Current loss 0.6742812534710899 Accuracy 62.036041732532404\n",
      "Training:: Epoch 60, Iteration 20, Current loss 0.6700014423074416 Accuracy 56.72654690618762\n",
      "Training:: Epoch 60, Iteration 30, Current loss 0.5345198853391809 Accuracy 61.996708721886996\n",
      "Training:: Epoch 60, Iteration 40, Current loss 0.615157328111537 Accuracy 62.69117647058823\n",
      "Training:: Epoch 60, Iteration 50, Current loss 0.5214897374119992 Accuracy 58.58796735623458\n",
      "Training:: Epoch 60, Iteration 60, Current loss 0.6195242279559814 Accuracy 68.06285052968931\n",
      "Training:: Epoch 60, Iteration 70, Current loss 0.4254648203180358 Accuracy 67.4742950218874\n",
      "Training:: Epoch 60, Iteration 80, Current loss 0.7680856549722959 Accuracy 71.25892466851231\n",
      "Training:: Epoch 60, Iteration 90, Current loss 0.46729080322348854 Accuracy 68.80592158776639\n",
      "Training:: Epoch 60, Iteration 100, Current loss 0.730327519802962 Accuracy 66.62726090554439\n",
      "Training:: Epoch 60, Iteration 110, Current loss 0.5261800544394917 Accuracy 63.7091556130702\n",
      "Training:: Epoch 60, Iteration 120, Current loss 0.49427501657441325 Accuracy 73.07979120059657\n",
      "Training:: Epoch 60, Iteration 130, Current loss 0.43001547904004844 Accuracy 69.96501419235594\n",
      "Training:: Epoch 60, Iteration 140, Current loss 0.6197752767716893 Accuracy 51.79150937148155\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 60, Probability Accuracy 52.29691043732312\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.94184839044652\n",
      "Calculating Expectation\n",
      "Epoch 60 iter 0\n",
      "Epoch 60 iter 10\n",
      "Epoch 60 iter 20\n",
      "Epoch 60 iter 30\n",
      "Epoch 60 iter 40\n",
      "Epoch 60 iter 50\n",
      "Epoch 60 iter 60\n",
      "Epoch 60 iter 70\n",
      "Epoch 60 iter 80\n",
      "Epoch 60 iter 90\n",
      "Epoch 60 iter 100\n",
      "Epoch 60 iter 110\n",
      "Epoch 60 iter 120\n",
      "Epoch 60 iter 130\n",
      "Epoch 60 iter 140\n",
      "Train Boundary avergage error = 302.262\n",
      "Train From boundary avergage accuracy = 59.948\n",
      "Starting Training\n",
      "Training:: Epoch 61, Iteration 0, Current loss 0.4335897658938937 Accuracy 46.291953093408814\n",
      "Training:: Epoch 61, Iteration 10, Current loss 0.4542785000263941 Accuracy 58.712223603827645\n",
      "Training:: Epoch 61, Iteration 20, Current loss 0.4838284642417651 Accuracy 50.851739569799335\n",
      "Training:: Epoch 61, Iteration 30, Current loss 0.44854738353406887 Accuracy 70.14821098857229\n",
      "Training:: Epoch 61, Iteration 40, Current loss 0.4277798166736569 Accuracy 62.656758012076175\n",
      "Training:: Epoch 61, Iteration 50, Current loss 0.5371700160875976 Accuracy 54.22586082350109\n",
      "Training:: Epoch 61, Iteration 60, Current loss 0.44008917409085235 Accuracy 63.96182872824799\n",
      "Training:: Epoch 61, Iteration 70, Current loss 0.46795648918262317 Accuracy 55.029077451757864\n",
      "Training:: Epoch 61, Iteration 80, Current loss 0.42396219205160035 Accuracy 54.770656864311974\n",
      "Training:: Epoch 61, Iteration 90, Current loss 0.4745412906637747 Accuracy 61.41728749663405\n",
      "Training:: Epoch 61, Iteration 100, Current loss 0.5085509651947664 Accuracy 52.24710303789539\n",
      "Training:: Epoch 61, Iteration 110, Current loss 0.5041825041195757 Accuracy 62.90216437554841\n",
      "Training:: Epoch 61, Iteration 120, Current loss 0.6151714287340364 Accuracy 68.45498935770627\n",
      "Training:: Epoch 61, Iteration 130, Current loss 0.4626784646909116 Accuracy 66.99493640604442\n",
      "Training:: Epoch 61, Iteration 140, Current loss 0.6186186452565225 Accuracy 57.812679783684274\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 61, Probability Accuracy 51.771580206406576\n",
      "Starting Training\n",
      "Training:: Epoch 62, Iteration 0, Current loss 0.41501495665315274 Accuracy 52.34909090909091\n",
      "Training:: Epoch 62, Iteration 10, Current loss 0.4266905178785847 Accuracy 68.98753420492551\n",
      "Training:: Epoch 62, Iteration 20, Current loss 0.40887307618967134 Accuracy 59.79945305378305\n",
      "Training:: Epoch 62, Iteration 30, Current loss 0.6319706870187525 Accuracy 64.43384383630429\n",
      "Training:: Epoch 62, Iteration 40, Current loss 0.38245631046873185 Accuracy 60.96100006510841\n",
      "Training:: Epoch 62, Iteration 50, Current loss 0.4421573786549168 Accuracy 54.52037790497207\n",
      "Training:: Epoch 62, Iteration 60, Current loss 0.6243004101203342 Accuracy 64.7747670741089\n",
      "Training:: Epoch 62, Iteration 70, Current loss 0.650358763562352 Accuracy 66.07142857142857\n",
      "Training:: Epoch 62, Iteration 80, Current loss 0.5148732574993555 Accuracy 61.394407187144125\n",
      "Training:: Epoch 62, Iteration 90, Current loss 0.3853995517013016 Accuracy 67.08465116279069\n",
      "Training:: Epoch 62, Iteration 100, Current loss 0.5079841608150338 Accuracy 60.021351913243805\n",
      "Training:: Epoch 62, Iteration 110, Current loss 0.5024225106468043 Accuracy 61.89371573175875\n",
      "Training:: Epoch 62, Iteration 120, Current loss 0.5348836307192176 Accuracy 48.4121464997682\n",
      "Training:: Epoch 62, Iteration 130, Current loss 0.5069944209719133 Accuracy 60.4397240557844\n",
      "Training:: Epoch 62, Iteration 140, Current loss 0.5554036154304925 Accuracy 60.73942093541203\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 62, Probability Accuracy 52.61897136582592\n",
      "Starting Training\n",
      "Training:: Epoch 63, Iteration 0, Current loss 0.5296527173909855 Accuracy 54.102373887240354\n",
      "Training:: Epoch 63, Iteration 10, Current loss 0.5124465245984074 Accuracy 59.50873362445415\n",
      "Training:: Epoch 63, Iteration 20, Current loss 0.37700928248729215 Accuracy 68.25552825552826\n",
      "Training:: Epoch 63, Iteration 30, Current loss 0.5271954282590231 Accuracy 66.43165794860131\n",
      "Training:: Epoch 63, Iteration 40, Current loss 0.45636025272525793 Accuracy 59.18601145613506\n",
      "Training:: Epoch 63, Iteration 50, Current loss 0.4328637516871228 Accuracy 62.53491981376099\n",
      "Training:: Epoch 63, Iteration 60, Current loss 0.518439469444492 Accuracy 54.4405448813277\n",
      "Training:: Epoch 63, Iteration 70, Current loss 0.6190791766808724 Accuracy 55.02052257483231\n",
      "Training:: Epoch 63, Iteration 80, Current loss 0.5683362692597332 Accuracy 63.66187881789665\n",
      "Training:: Epoch 63, Iteration 90, Current loss 0.37256686598518274 Accuracy 73.39200347674924\n",
      "Training:: Epoch 63, Iteration 100, Current loss 0.4711650258484904 Accuracy 69.90059642147118\n",
      "Training:: Epoch 63, Iteration 110, Current loss 0.448593895778975 Accuracy 67.57786008659815\n",
      "Training:: Epoch 63, Iteration 120, Current loss 0.4353666799413291 Accuracy 70.05561735261402\n",
      "Training:: Epoch 63, Iteration 130, Current loss 0.6215405827217138 Accuracy 60.076710474364035\n",
      "Training:: Epoch 63, Iteration 140, Current loss 0.5457123814240827 Accuracy 60.502202643171806\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 63, Probability Accuracy 51.95017614494213\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 64, Iteration 0, Current loss 0.47990795192220814 Accuracy 65.97018988634044\n",
      "Training:: Epoch 64, Iteration 10, Current loss 0.37875076357645565 Accuracy 68.33095577746077\n",
      "Training:: Epoch 64, Iteration 20, Current loss 0.48574786140032433 Accuracy 65.62041874976507\n",
      "Training:: Epoch 64, Iteration 30, Current loss 0.3862107182419526 Accuracy 61.490345390263805\n",
      "Training:: Epoch 64, Iteration 40, Current loss 0.4796094711432949 Accuracy 51.96671289875173\n",
      "Training:: Epoch 64, Iteration 50, Current loss 0.5709959234757618 Accuracy 64.41668345758613\n",
      "Training:: Epoch 64, Iteration 60, Current loss 0.4679239098175544 Accuracy 70.07676767676767\n",
      "Training:: Epoch 64, Iteration 70, Current loss 0.4574076300118878 Accuracy 58.72125630959058\n",
      "Training:: Epoch 64, Iteration 80, Current loss 0.6967878960542433 Accuracy 65.03011498448622\n",
      "Training:: Epoch 64, Iteration 90, Current loss 0.5214501373410814 Accuracy 59.71563981042654\n",
      "Training:: Epoch 64, Iteration 100, Current loss 0.3709731851975413 Accuracy 60.80297793140122\n",
      "Training:: Epoch 64, Iteration 110, Current loss 0.6159240302021203 Accuracy 69.27250660384094\n",
      "Training:: Epoch 64, Iteration 120, Current loss 0.35287421034930927 Accuracy 67.01949010228488\n",
      "Training:: Epoch 64, Iteration 130, Current loss 0.5624918837478365 Accuracy 65.76138261564157\n",
      "Training:: Epoch 64, Iteration 140, Current loss 0.44967332289630163 Accuracy 63.01000061353457\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 64, Probability Accuracy 52.27117497499984\n",
      "Starting Training\n",
      "Training:: Epoch 65, Iteration 0, Current loss 0.36836019854788915 Accuracy 52.559129020147665\n",
      "Training:: Epoch 65, Iteration 10, Current loss 0.4686292511826086 Accuracy 53.58440068820493\n",
      "Training:: Epoch 65, Iteration 20, Current loss 0.38664549985888813 Accuracy 60.15980024968789\n",
      "Training:: Epoch 65, Iteration 30, Current loss 0.5102716724185045 Accuracy 64.89586889723455\n",
      "Training:: Epoch 65, Iteration 40, Current loss 0.6462390386229488 Accuracy 57.14658774373259\n",
      "Training:: Epoch 65, Iteration 50, Current loss 0.4113652296138719 Accuracy 64.16733411373298\n",
      "Training:: Epoch 65, Iteration 60, Current loss 0.4313164180973873 Accuracy 63.37629101544648\n",
      "Training:: Epoch 65, Iteration 70, Current loss 0.5503742808377046 Accuracy 64.01456632090046\n",
      "Training:: Epoch 65, Iteration 80, Current loss 0.5752178068241733 Accuracy 68.47606438575708\n",
      "Training:: Epoch 65, Iteration 90, Current loss 0.4937933966152419 Accuracy 66.57148178037122\n",
      "Training:: Epoch 65, Iteration 100, Current loss 0.4106570348611282 Accuracy 61.652763295099064\n",
      "Training:: Epoch 65, Iteration 110, Current loss 0.5435020127553571 Accuracy 65.24646747923633\n",
      "Training:: Epoch 65, Iteration 120, Current loss 0.2985865130070381 Accuracy 70.39609407234218\n",
      "Training:: Epoch 65, Iteration 130, Current loss 0.4139887869548707 Accuracy 70.08640552995392\n",
      "Training:: Epoch 65, Iteration 140, Current loss 0.7680542985400851 Accuracy 57.930182961050626\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 65, Probability Accuracy 51.77975019444572\n",
      "Calculating Expectation\n",
      "Epoch 65 iter 0\n",
      "Epoch 65 iter 10\n",
      "Epoch 65 iter 20\n",
      "Epoch 65 iter 30\n",
      "Epoch 65 iter 40\n",
      "Epoch 65 iter 50\n",
      "Epoch 65 iter 60\n",
      "Epoch 65 iter 70\n",
      "Epoch 65 iter 80\n",
      "Epoch 65 iter 90\n",
      "Epoch 65 iter 100\n",
      "Epoch 65 iter 110\n",
      "Epoch 65 iter 120\n",
      "Epoch 65 iter 130\n",
      "Epoch 65 iter 140\n",
      "Train Boundary avergage error = 302.372\n",
      "Train From boundary avergage accuracy = 59.896\n",
      "Starting Training\n",
      "Training:: Epoch 66, Iteration 0, Current loss 0.31598680663049983 Accuracy 56.708462051002485\n",
      "Training:: Epoch 66, Iteration 10, Current loss 0.4655452395537669 Accuracy 70.6117831346271\n",
      "Training:: Epoch 66, Iteration 20, Current loss 0.4753251026480529 Accuracy 53.33811916726489\n",
      "Training:: Epoch 66, Iteration 30, Current loss 0.3288923846987317 Accuracy 73.15143687439458\n",
      "Training:: Epoch 66, Iteration 40, Current loss 0.5821017330878255 Accuracy 55.40532698891661\n",
      "Training:: Epoch 66, Iteration 50, Current loss 0.41409595382520514 Accuracy 63.321214170964744\n",
      "Training:: Epoch 66, Iteration 60, Current loss 0.46967199214050914 Accuracy 67.92925079259136\n",
      "Training:: Epoch 66, Iteration 70, Current loss 0.40446947557728247 Accuracy 60.66696933426885\n",
      "Training:: Epoch 66, Iteration 80, Current loss 0.5522210187692437 Accuracy 54.66414124332003\n",
      "Training:: Epoch 66, Iteration 90, Current loss 0.37748733327467054 Accuracy 66.45773559920548\n",
      "Training:: Epoch 66, Iteration 100, Current loss 0.49931646081258907 Accuracy 57.586933614330874\n",
      "Training:: Epoch 66, Iteration 110, Current loss 0.4172518625832988 Accuracy 63.95122172355954\n",
      "Training:: Epoch 66, Iteration 120, Current loss 0.6731330301228651 Accuracy 62.93497713263074\n",
      "Training:: Epoch 66, Iteration 130, Current loss 0.6362020541973584 Accuracy 71.04283859800952\n",
      "Training:: Epoch 66, Iteration 140, Current loss 0.49242284090681954 Accuracy 65.89014587674903\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 66, Probability Accuracy 52.06684357414101\n",
      "Starting Training\n",
      "Training:: Epoch 67, Iteration 0, Current loss 0.7306637996252339 Accuracy 55.884203901825046\n",
      "Training:: Epoch 67, Iteration 10, Current loss 0.3833589314257363 Accuracy 67.00522344747533\n",
      "Training:: Epoch 67, Iteration 20, Current loss 0.450848434975508 Accuracy 64.00252171476605\n",
      "Training:: Epoch 67, Iteration 30, Current loss 0.6664129261246872 Accuracy 53.484162895927604\n",
      "Training:: Epoch 67, Iteration 40, Current loss 0.4826997130372547 Accuracy 58.54127798507463\n",
      "Training:: Epoch 67, Iteration 50, Current loss 0.5315409306527756 Accuracy 67.93384020274776\n",
      "Training:: Epoch 67, Iteration 60, Current loss 0.47730775060769465 Accuracy 64.976290097629\n",
      "Training:: Epoch 67, Iteration 70, Current loss 0.6038893690233571 Accuracy 55.97358266547937\n",
      "Training:: Epoch 67, Iteration 80, Current loss 0.5142741530474965 Accuracy 56.81930353715382\n",
      "Training:: Epoch 67, Iteration 90, Current loss 0.39100551852702975 Accuracy 69.57769839244705\n",
      "Training:: Epoch 67, Iteration 100, Current loss 0.4470832700197296 Accuracy 67.35491071428571\n",
      "Training:: Epoch 67, Iteration 110, Current loss 0.6456456119148188 Accuracy 57.511619143323706\n",
      "Training:: Epoch 67, Iteration 120, Current loss 0.48181425990861976 Accuracy 62.74991912002588\n",
      "Training:: Epoch 67, Iteration 130, Current loss 0.6005796899366552 Accuracy 60.12435793457691\n",
      "Training:: Epoch 67, Iteration 140, Current loss 0.4505721203358847 Accuracy 57.717250324254216\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 67, Probability Accuracy 51.73416166118733\n",
      "Starting Training\n",
      "Training:: Epoch 68, Iteration 0, Current loss 0.5731430991750998 Accuracy 56.803604153940135\n",
      "Training:: Epoch 68, Iteration 10, Current loss 0.37569224816272684 Accuracy 72.79814070595071\n",
      "Training:: Epoch 68, Iteration 20, Current loss 0.4216877792765437 Accuracy 62.06935888660735\n",
      "Training:: Epoch 68, Iteration 30, Current loss 0.32322977499106986 Accuracy 67.58053017045823\n",
      "Training:: Epoch 68, Iteration 40, Current loss 0.5085767293237284 Accuracy 63.897611918498505\n",
      "Training:: Epoch 68, Iteration 50, Current loss 0.4102979576198048 Accuracy 61.95652173913044\n",
      "Training:: Epoch 68, Iteration 60, Current loss 0.4448703699067333 Accuracy 49.14890640302197\n",
      "Training:: Epoch 68, Iteration 70, Current loss 0.5454614632921071 Accuracy 59.79172052143728\n",
      "Training:: Epoch 68, Iteration 80, Current loss 0.4685915450695264 Accuracy 65.86289793836964\n",
      "Training:: Epoch 68, Iteration 90, Current loss 0.36490850690538956 Accuracy 67.86019612773447\n",
      "Training:: Epoch 68, Iteration 100, Current loss 0.4844648034555631 Accuracy 68.28384798099762\n",
      "Training:: Epoch 68, Iteration 110, Current loss 0.3803380936483945 Accuracy 68.26016402789351\n",
      "Training:: Epoch 68, Iteration 120, Current loss 0.5118977668041932 Accuracy 63.460589106467005\n",
      "Training:: Epoch 68, Iteration 130, Current loss 0.5412191297077363 Accuracy 54.54675640842045\n",
      "Training:: Epoch 68, Iteration 140, Current loss 0.5021468785114742 Accuracy 66.00173460537728\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 68, Probability Accuracy 52.10042222498186\n",
      "Starting Training\n",
      "Training:: Epoch 69, Iteration 0, Current loss 0.29992238453226017 Accuracy 64.73870798319328\n",
      "Training:: Epoch 69, Iteration 10, Current loss 0.5002289059241397 Accuracy 64.39164407590496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 69, Iteration 20, Current loss 0.5235570496993173 Accuracy 41.65119117100865\n",
      "Training:: Epoch 69, Iteration 30, Current loss 0.6341062070689275 Accuracy 55.283674257043614\n",
      "Training:: Epoch 69, Iteration 40, Current loss 0.4509560634246122 Accuracy 75.0035196395889\n",
      "Training:: Epoch 69, Iteration 50, Current loss 0.5031266000832625 Accuracy 61.953213322897646\n",
      "Training:: Epoch 69, Iteration 60, Current loss 0.4690747468285372 Accuracy 66.05575451162137\n",
      "Training:: Epoch 69, Iteration 70, Current loss 0.5300285208797755 Accuracy 71.09029599100786\n",
      "Training:: Epoch 69, Iteration 80, Current loss 0.5103530111240686 Accuracy 70.56536803853629\n",
      "Training:: Epoch 69, Iteration 90, Current loss 0.38128457533775145 Accuracy 65.29086071762421\n",
      "Training:: Epoch 69, Iteration 100, Current loss 0.4113945977711392 Accuracy 61.34651316979085\n",
      "Training:: Epoch 69, Iteration 110, Current loss 0.5491627621070096 Accuracy 58.1847934077494\n",
      "Training:: Epoch 69, Iteration 120, Current loss 0.4637973986413431 Accuracy 63.42180774748924\n",
      "Training:: Epoch 69, Iteration 130, Current loss 0.39587880981199747 Accuracy 60.87000763164589\n",
      "Training:: Epoch 69, Iteration 140, Current loss 0.5188407427172982 Accuracy 59.48556223514339\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 69, Probability Accuracy 51.7259099732678\n",
      "Starting Training\n",
      "Training:: Epoch 70, Iteration 0, Current loss 0.426925661680112 Accuracy 58.330231321457056\n",
      "Training:: Epoch 70, Iteration 10, Current loss 0.5288294064388461 Accuracy 60.41381299113258\n",
      "Training:: Epoch 70, Iteration 20, Current loss 0.4650604464670173 Accuracy 68.7613408461465\n",
      "Training:: Epoch 70, Iteration 30, Current loss 0.4508594164214282 Accuracy 75.94244604316546\n",
      "Training:: Epoch 70, Iteration 40, Current loss 0.468388075835554 Accuracy 58.06532663316583\n",
      "Training:: Epoch 70, Iteration 50, Current loss 0.48130345551248155 Accuracy 53.47437123727001\n",
      "Training:: Epoch 70, Iteration 60, Current loss 0.4133649018095096 Accuracy 61.67109657193485\n",
      "Training:: Epoch 70, Iteration 70, Current loss 0.6180707532907845 Accuracy 70.8175366968018\n",
      "Training:: Epoch 70, Iteration 80, Current loss 4.582651211703023 Accuracy 52.63181019332162\n",
      "Training:: Epoch 70, Iteration 90, Current loss 2.7086790234290086 Accuracy 60.612043435340574\n",
      "Training:: Epoch 70, Iteration 100, Current loss 4.278324928686985 Accuracy 41.34933383728622\n",
      "Training:: Epoch 70, Iteration 110, Current loss 2.950463827284828 Accuracy 60.324903701222574\n",
      "Training:: Epoch 70, Iteration 120, Current loss 2.291062180452128 Accuracy 64.34509099078859\n",
      "Training:: Epoch 70, Iteration 130, Current loss 3.3584067020220196 Accuracy 54.85865724381625\n",
      "Training:: Epoch 70, Iteration 140, Current loss 1.5123554664140932 Accuracy 67.8897373812628\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 70, Probability Accuracy 49.85048921888378\n",
      "Calculating Expectation\n",
      "Epoch 70 iter 0\n",
      "Epoch 70 iter 10\n",
      "Epoch 70 iter 20\n",
      "Epoch 70 iter 30\n",
      "Epoch 70 iter 40\n",
      "Epoch 70 iter 50\n",
      "Epoch 70 iter 60\n",
      "Epoch 70 iter 70\n",
      "Epoch 70 iter 80\n",
      "Epoch 70 iter 90\n",
      "Epoch 70 iter 100\n",
      "Epoch 70 iter 110\n",
      "Epoch 70 iter 120\n",
      "Epoch 70 iter 130\n",
      "Epoch 70 iter 140\n",
      "Train Boundary avergage error = 300.824\n",
      "Train From boundary avergage accuracy = 59.278\n",
      "Starting Training\n",
      "Training:: Epoch 71, Iteration 0, Current loss 2.1719244326481633 Accuracy 56.49500384319754\n",
      "Training:: Epoch 71, Iteration 10, Current loss 1.3782707914220762 Accuracy 59.92088020768946\n",
      "Training:: Epoch 71, Iteration 20, Current loss 7.569386335251077 Accuracy 41.603907999185836\n",
      "Training:: Epoch 71, Iteration 30, Current loss 5.145855961973463 Accuracy 64.01998022789948\n",
      "Training:: Epoch 71, Iteration 40, Current loss 5.0563704280893145 Accuracy 46.68662674650699\n",
      "Training:: Epoch 71, Iteration 50, Current loss 2.5009560881735085 Accuracy 57.29912083418524\n",
      "Training:: Epoch 71, Iteration 60, Current loss 1.9975709753702722 Accuracy 67.33926262586687\n",
      "Training:: Epoch 71, Iteration 70, Current loss 1.2089941714507046 Accuracy 73.11231298728664\n",
      "Training:: Epoch 71, Iteration 80, Current loss 2.10639767047935 Accuracy 58.85569224760789\n",
      "Training:: Epoch 71, Iteration 90, Current loss 1.9769259849883574 Accuracy 58.11571293076194\n",
      "Training:: Epoch 71, Iteration 100, Current loss 2.5064080759953513 Accuracy 52.10563882940757\n",
      "Training:: Epoch 71, Iteration 110, Current loss 1.299530327224153 Accuracy 68.94818433785879\n",
      "Training:: Epoch 71, Iteration 120, Current loss 4.066288545862649 Accuracy 50.592193808882904\n",
      "Training:: Epoch 71, Iteration 130, Current loss 1.2400938582465473 Accuracy 66.51309972544092\n",
      "Training:: Epoch 71, Iteration 140, Current loss 3.3837906177928483 Accuracy 53.07267709291629\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 71, Probability Accuracy 50.90474447545409\n",
      "Starting Training\n",
      "Training:: Epoch 72, Iteration 0, Current loss 1.132425364429263 Accuracy 72.94747218701592\n",
      "Training:: Epoch 72, Iteration 10, Current loss 1.355037274598536 Accuracy 66.4213682202235\n",
      "Training:: Epoch 72, Iteration 20, Current loss 0.6394419872756829 Accuracy 70.45321091122618\n",
      "Training:: Epoch 72, Iteration 30, Current loss 1.8134469768654935 Accuracy 66.06726849155504\n",
      "Training:: Epoch 72, Iteration 40, Current loss 1.1101108671426085 Accuracy 63.05820105820106\n",
      "Training:: Epoch 72, Iteration 50, Current loss 0.87340168880888 Accuracy 62.11708645336964\n",
      "Training:: Epoch 72, Iteration 60, Current loss 1.25855636232651 Accuracy 62.89164862709354\n",
      "Training:: Epoch 72, Iteration 70, Current loss 1.0676269739779582 Accuracy 66.57812941508901\n",
      "Training:: Epoch 72, Iteration 80, Current loss 1.0021260921256936 Accuracy 57.479835641454876\n",
      "Training:: Epoch 72, Iteration 90, Current loss 1.6197707410613864 Accuracy 46.913977111996914\n",
      "Training:: Epoch 72, Iteration 100, Current loss 1.220376686019678 Accuracy 57.25328709724028\n",
      "Training:: Epoch 72, Iteration 110, Current loss 1.0632751621560892 Accuracy 59.81789802289282\n",
      "Training:: Epoch 72, Iteration 120, Current loss 0.8551396298377905 Accuracy 67.92622077703649\n",
      "Training:: Epoch 72, Iteration 130, Current loss 1.6870923841980967 Accuracy 58.56344643290955\n",
      "Training:: Epoch 72, Iteration 140, Current loss 1.1012043182614337 Accuracy 63.43425058884357\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 72, Probability Accuracy 51.182687468545545\n",
      "Starting Training\n",
      "Training:: Epoch 73, Iteration 0, Current loss 0.9314306687689223 Accuracy 61.761369495720324\n",
      "Training:: Epoch 73, Iteration 10, Current loss 1.8980228333385711 Accuracy 60.761694058154234\n",
      "Training:: Epoch 73, Iteration 20, Current loss 0.7672859539325607 Accuracy 76.48004286096973\n",
      "Training:: Epoch 73, Iteration 30, Current loss 0.8680016632068135 Accuracy 68.16331722208089\n",
      "Training:: Epoch 73, Iteration 40, Current loss 0.829835052576616 Accuracy 68.8648926597249\n",
      "Training:: Epoch 73, Iteration 50, Current loss 0.7822573629785748 Accuracy 66.26687847498015\n",
      "Training:: Epoch 73, Iteration 60, Current loss 0.7706374360724924 Accuracy 61.64917541229385\n",
      "Training:: Epoch 73, Iteration 70, Current loss 1.107018590530803 Accuracy 63.07185896005356\n",
      "Training:: Epoch 73, Iteration 80, Current loss 0.8295469497910446 Accuracy 60.270399744504175\n",
      "Training:: Epoch 73, Iteration 90, Current loss 0.8693612154551322 Accuracy 62.07309344412365\n",
      "Training:: Epoch 73, Iteration 100, Current loss 0.9806094282226809 Accuracy 47.3638301996511\n",
      "Training:: Epoch 73, Iteration 110, Current loss 0.6440636054637228 Accuracy 69.91037131882203\n",
      "Training:: Epoch 73, Iteration 120, Current loss 1.0189086673779724 Accuracy 62.6278865828705\n",
      "Training:: Epoch 73, Iteration 130, Current loss 0.9095456214773879 Accuracy 57.763503649635034\n",
      "Training:: Epoch 73, Iteration 140, Current loss 0.8713956585648963 Accuracy 69.98647552069245\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 73, Probability Accuracy 52.17550441506154\n",
      "Starting Training\n",
      "Training:: Epoch 74, Iteration 0, Current loss 0.9305446659973049 Accuracy 71.57456861133936\n",
      "Training:: Epoch 74, Iteration 10, Current loss 0.6219737249710691 Accuracy 69.06005221932115\n",
      "Training:: Epoch 74, Iteration 20, Current loss 0.6681327139507368 Accuracy 71.36404697380307\n",
      "Training:: Epoch 74, Iteration 30, Current loss 0.8806122783724961 Accuracy 62.59660895093164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 74, Iteration 40, Current loss 0.7046459849430678 Accuracy 54.08199964035246\n",
      "Training:: Epoch 74, Iteration 50, Current loss 0.6342403072763964 Accuracy 67.28376777251185\n",
      "Training:: Epoch 74, Iteration 60, Current loss 0.820435346876057 Accuracy 52.783342873497425\n",
      "Training:: Epoch 74, Iteration 70, Current loss 0.715709663210116 Accuracy 66.9227764031775\n",
      "Training:: Epoch 74, Iteration 80, Current loss 0.5423830257212954 Accuracy 66.20218769595206\n",
      "Training:: Epoch 74, Iteration 90, Current loss 0.7275088205168986 Accuracy 62.75005930260141\n",
      "Training:: Epoch 74, Iteration 100, Current loss 0.7330680172896564 Accuracy 65.38821328344247\n",
      "Training:: Epoch 74, Iteration 110, Current loss 0.8086671054512764 Accuracy 51.81327160493827\n",
      "Training:: Epoch 74, Iteration 120, Current loss 0.7426945069573812 Accuracy 64.22111889351893\n",
      "Training:: Epoch 74, Iteration 130, Current loss 0.6429250378356602 Accuracy 63.50047641734159\n",
      "Training:: Epoch 74, Iteration 140, Current loss 1.280652624007618 Accuracy 70.48249763481552\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 74, Probability Accuracy 52.56276184811666\n",
      "Starting Training\n",
      "Training:: Epoch 75, Iteration 0, Current loss 0.7472853673535707 Accuracy 67.94645808086372\n",
      "Training:: Epoch 75, Iteration 10, Current loss 0.6885607503618496 Accuracy 56.934066450491095\n",
      "Training:: Epoch 75, Iteration 20, Current loss 0.428767906076024 Accuracy 66.8606202957348\n",
      "Training:: Epoch 75, Iteration 30, Current loss 0.7001442065965849 Accuracy 66.42540779950308\n",
      "Training:: Epoch 75, Iteration 40, Current loss 0.7063704108426166 Accuracy 67.1531256806796\n",
      "Training:: Epoch 75, Iteration 50, Current loss 0.6673199168905873 Accuracy 54.26629160806376\n",
      "Training:: Epoch 75, Iteration 60, Current loss 0.6021584407338382 Accuracy 67.74076229269711\n",
      "Training:: Epoch 75, Iteration 70, Current loss 0.5423596378445974 Accuracy 58.41784989858012\n",
      "Training:: Epoch 75, Iteration 80, Current loss 0.6334547824676737 Accuracy 56.46938406887832\n",
      "Training:: Epoch 75, Iteration 90, Current loss 0.6995122140429195 Accuracy 64.94826647304411\n",
      "Training:: Epoch 75, Iteration 100, Current loss 0.8153357173723469 Accuracy 58.6242595042273\n",
      "Training:: Epoch 75, Iteration 110, Current loss 0.7885314361906596 Accuracy 55.6631636788241\n",
      "Training:: Epoch 75, Iteration 120, Current loss 0.7465706516643733 Accuracy 59.08105765062852\n",
      "Training:: Epoch 75, Iteration 130, Current loss 0.5060366646339838 Accuracy 69.0934771443246\n",
      "Training:: Epoch 75, Iteration 140, Current loss 0.7555391088347141 Accuracy 53.75021211606991\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 75, Probability Accuracy 52.57109523591657\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Total correct pivots labels selected =  62.032710280373834\n",
      "Calculating Expectation\n",
      "Epoch 75 iter 0\n",
      "Epoch 75 iter 10\n",
      "Epoch 75 iter 20\n",
      "Epoch 75 iter 30\n",
      "Epoch 75 iter 40\n",
      "Epoch 75 iter 50\n",
      "Epoch 75 iter 60\n",
      "Epoch 75 iter 70\n",
      "Epoch 75 iter 80\n",
      "Epoch 75 iter 90\n",
      "Epoch 75 iter 100\n",
      "Epoch 75 iter 110\n",
      "Epoch 75 iter 120\n",
      "Epoch 75 iter 130\n",
      "Epoch 75 iter 140\n",
      "Train Boundary avergage error = 300.265\n",
      "Train From boundary avergage accuracy = 59.366\n",
      "Starting Training\n",
      "Training:: Epoch 76, Iteration 0, Current loss 0.4649367115141073 Accuracy 56.49625935162095\n",
      "Training:: Epoch 76, Iteration 10, Current loss 0.6111649405143622 Accuracy 64.80054551653598\n",
      "Training:: Epoch 76, Iteration 20, Current loss 0.4272268550919729 Accuracy 59.041900703725226\n",
      "Training:: Epoch 76, Iteration 30, Current loss 0.47000361421956754 Accuracy 61.18734093172513\n",
      "Training:: Epoch 76, Iteration 40, Current loss 0.5153212234757205 Accuracy 55.67395516191531\n",
      "Training:: Epoch 76, Iteration 50, Current loss 0.40133166077743854 Accuracy 69.1054131054131\n",
      "Training:: Epoch 76, Iteration 60, Current loss 0.5782450106681511 Accuracy 51.70742552245442\n",
      "Training:: Epoch 76, Iteration 70, Current loss 0.5103152474421065 Accuracy 54.96582892416226\n",
      "Training:: Epoch 76, Iteration 80, Current loss 0.6652047197525558 Accuracy 52.10519235942965\n",
      "Training:: Epoch 76, Iteration 90, Current loss 0.3690065375188119 Accuracy 62.073037790697676\n",
      "Training:: Epoch 76, Iteration 100, Current loss 0.33653946646425864 Accuracy 64.84607745779543\n",
      "Training:: Epoch 76, Iteration 110, Current loss 0.44887843617341244 Accuracy 66.4733676975945\n",
      "Training:: Epoch 76, Iteration 120, Current loss 0.4478874229602583 Accuracy 63.040158802870664\n",
      "Training:: Epoch 76, Iteration 130, Current loss 0.5055053951431752 Accuracy 71.68275792346965\n",
      "Training:: Epoch 76, Iteration 140, Current loss 0.5252801609811021 Accuracy 66.58646705875364\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 76, Probability Accuracy 51.62149752612762\n",
      "Starting Training\n",
      "Training:: Epoch 77, Iteration 0, Current loss 0.4944593745204098 Accuracy 63.4929944607364\n",
      "Training:: Epoch 77, Iteration 10, Current loss 0.42492420068589887 Accuracy 70.65471072349834\n",
      "Training:: Epoch 77, Iteration 20, Current loss 0.43959647189202966 Accuracy 62.972786589570845\n",
      "Training:: Epoch 77, Iteration 30, Current loss 0.38269574574580817 Accuracy 71.83161665920287\n",
      "Training:: Epoch 77, Iteration 40, Current loss 0.592762530197882 Accuracy 69.30128840436075\n",
      "Training:: Epoch 77, Iteration 50, Current loss 0.6493887553920833 Accuracy 55.01899535669059\n",
      "Training:: Epoch 77, Iteration 60, Current loss 0.8596919102742335 Accuracy 61.89288919916226\n",
      "Training:: Epoch 77, Iteration 70, Current loss 0.6060351869489575 Accuracy 60.039164490861616\n",
      "Training:: Epoch 77, Iteration 80, Current loss 0.43780502889281003 Accuracy 65.12853325303925\n",
      "Training:: Epoch 77, Iteration 90, Current loss 0.6913215983809472 Accuracy 59.31636882214002\n",
      "Training:: Epoch 77, Iteration 100, Current loss 0.4255383108042578 Accuracy 61.47019423978567\n",
      "Training:: Epoch 77, Iteration 110, Current loss 0.4933588818449223 Accuracy 60.712967746697174\n",
      "Training:: Epoch 77, Iteration 120, Current loss 0.4759013849201749 Accuracy 62.906724511930584\n",
      "Training:: Epoch 77, Iteration 130, Current loss 0.37112941078755846 Accuracy 76.10019267822736\n",
      "Training:: Epoch 77, Iteration 140, Current loss 0.3863265488800555 Accuracy 60.24474023185917\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 77, Probability Accuracy 51.73293616298146\n",
      "Starting Training\n",
      "Training:: Epoch 78, Iteration 0, Current loss 0.37585499716172666 Accuracy 64.57734011949546\n",
      "Training:: Epoch 78, Iteration 10, Current loss 0.4684785741557445 Accuracy 69.91114371892068\n",
      "Training:: Epoch 78, Iteration 20, Current loss 0.4634325487031304 Accuracy 61.00119308013522\n",
      "Training:: Epoch 78, Iteration 30, Current loss 1.1951402705506262 Accuracy 54.23157894736842\n",
      "Training:: Epoch 78, Iteration 40, Current loss 0.7003681842736575 Accuracy 64.98493394112647\n",
      "Training:: Epoch 78, Iteration 50, Current loss 0.5746091633953674 Accuracy 71.37919684002634\n",
      "Training:: Epoch 78, Iteration 60, Current loss 0.5873738986547439 Accuracy 50.32171581769437\n",
      "Training:: Epoch 78, Iteration 70, Current loss 0.6336870226388788 Accuracy 65.4862011483608\n",
      "Training:: Epoch 78, Iteration 80, Current loss 0.6087410036256792 Accuracy 62.343256437254716\n",
      "Training:: Epoch 78, Iteration 90, Current loss 0.3816761651621744 Accuracy 72.77012517676636\n",
      "Training:: Epoch 78, Iteration 100, Current loss 0.5364036487609335 Accuracy 68.87867070749294\n",
      "Training:: Epoch 78, Iteration 110, Current loss 0.46281528790733106 Accuracy 63.1892106307021\n",
      "Training:: Epoch 78, Iteration 120, Current loss 0.44831038646123456 Accuracy 62.80018652366519\n",
      "Training:: Epoch 78, Iteration 130, Current loss 0.5255916596070723 Accuracy 61.53442760501337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 78, Iteration 140, Current loss 0.4770534285087831 Accuracy 57.94853842114476\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 78, Probability Accuracy 52.44119242609429\n",
      "Starting Training\n",
      "Training:: Epoch 79, Iteration 0, Current loss 0.4946840730772616 Accuracy 62.615795258282304\n",
      "Training:: Epoch 79, Iteration 10, Current loss 0.6370109886262196 Accuracy 50.80507593093405\n",
      "Training:: Epoch 79, Iteration 20, Current loss 0.41756021659916476 Accuracy 67.24565756823822\n",
      "Training:: Epoch 79, Iteration 30, Current loss 0.4211838419214195 Accuracy 59.10192997769372\n",
      "Training:: Epoch 79, Iteration 40, Current loss 0.3812083771187479 Accuracy 65.71279916753382\n",
      "Training:: Epoch 79, Iteration 50, Current loss 0.37491670632558394 Accuracy 65.38534638411099\n",
      "Training:: Epoch 79, Iteration 60, Current loss 0.5482284276694446 Accuracy 69.63871643354028\n",
      "Training:: Epoch 79, Iteration 70, Current loss 0.528742750618454 Accuracy 57.23477973931694\n",
      "Training:: Epoch 79, Iteration 80, Current loss 0.4282806530838556 Accuracy 56.60501981505944\n",
      "Training:: Epoch 79, Iteration 90, Current loss 0.3005926464891956 Accuracy 63.75566979135168\n",
      "Training:: Epoch 79, Iteration 100, Current loss 0.40185390544782207 Accuracy 70.14108839619925\n",
      "Training:: Epoch 79, Iteration 110, Current loss 0.3957567505592094 Accuracy 63.50676170808074\n",
      "Training:: Epoch 79, Iteration 120, Current loss 0.562441639067205 Accuracy 66.23227689741451\n",
      "Training:: Epoch 79, Iteration 130, Current loss 0.44204458197350627 Accuracy 57.47294013695604\n",
      "Training:: Epoch 79, Iteration 140, Current loss 0.3621204103384766 Accuracy 62.9866776825364\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 79, Probability Accuracy 52.08988294041138\n",
      "Starting Training\n",
      "Training:: Epoch 80, Iteration 0, Current loss 0.42350390099716045 Accuracy 65.21112642525999\n",
      "Training:: Epoch 80, Iteration 10, Current loss 0.35655046064080254 Accuracy 65.5264496439471\n",
      "Training:: Epoch 80, Iteration 20, Current loss 0.4099205092422538 Accuracy 61.862573400638716\n",
      "Training:: Epoch 80, Iteration 30, Current loss 0.4038764007405735 Accuracy 70.1586209861153\n",
      "Training:: Epoch 80, Iteration 40, Current loss 0.40295217419146323 Accuracy 68.58832224685884\n",
      "Training:: Epoch 80, Iteration 50, Current loss 0.30495139122141435 Accuracy 65.6319086219602\n",
      "Training:: Epoch 80, Iteration 60, Current loss 0.5135255686824469 Accuracy 59.822710840390236\n",
      "Training:: Epoch 80, Iteration 70, Current loss 0.3885150844303864 Accuracy 68.17799624862558\n",
      "Training:: Epoch 80, Iteration 80, Current loss 0.3780617311835107 Accuracy 67.50422927654493\n",
      "Training:: Epoch 80, Iteration 90, Current loss 0.4486513379416792 Accuracy 68.8568257491676\n",
      "Training:: Epoch 80, Iteration 100, Current loss 0.39397872560142216 Accuracy 74.82784642958211\n",
      "Training:: Epoch 80, Iteration 110, Current loss 0.5102631214916448 Accuracy 50.69152542372881\n",
      "Training:: Epoch 80, Iteration 120, Current loss 0.37372628799604485 Accuracy 63.00789524359715\n",
      "Training:: Epoch 80, Iteration 130, Current loss 0.42526245748691577 Accuracy 58.89799730206496\n",
      "Training:: Epoch 80, Iteration 140, Current loss 0.3922690486361678 Accuracy 76.62096417514374\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 80, Probability Accuracy 52.27852796423506\n",
      "Calculating Expectation\n",
      "Epoch 80 iter 0\n",
      "Epoch 80 iter 10\n",
      "Epoch 80 iter 20\n",
      "Epoch 80 iter 30\n",
      "Epoch 80 iter 40\n",
      "Epoch 80 iter 50\n",
      "Epoch 80 iter 60\n",
      "Epoch 80 iter 70\n",
      "Epoch 80 iter 80\n",
      "Epoch 80 iter 90\n",
      "Epoch 80 iter 100\n",
      "Epoch 80 iter 110\n",
      "Epoch 80 iter 120\n",
      "Epoch 80 iter 130\n",
      "Epoch 80 iter 140\n",
      "Train Boundary avergage error = 300.587\n",
      "Train From boundary avergage accuracy = 59.196\n",
      "Starting Training\n",
      "Training:: Epoch 81, Iteration 0, Current loss 0.33770683270144786 Accuracy 54.67752157168625\n",
      "Training:: Epoch 81, Iteration 10, Current loss 0.3507714010810995 Accuracy 63.73149233641613\n",
      "Training:: Epoch 81, Iteration 20, Current loss 0.3360656443489036 Accuracy 75.74754757120908\n",
      "Training:: Epoch 81, Iteration 30, Current loss 0.5164802702035629 Accuracy 52.97748729121278\n",
      "Training:: Epoch 81, Iteration 40, Current loss 0.2923989436111209 Accuracy 67.84478605527087\n",
      "Training:: Epoch 81, Iteration 50, Current loss 0.44197075463605356 Accuracy 57.67666321957945\n",
      "Training:: Epoch 81, Iteration 60, Current loss 0.41016598077722544 Accuracy 55.146182751351844\n",
      "Training:: Epoch 81, Iteration 70, Current loss 0.39353844360312523 Accuracy 65.89584143023708\n",
      "Training:: Epoch 81, Iteration 80, Current loss 0.5007145989215668 Accuracy 57.87264202377058\n",
      "Training:: Epoch 81, Iteration 90, Current loss 0.4422127407826245 Accuracy 56.877174203906876\n",
      "Training:: Epoch 81, Iteration 100, Current loss 0.39911074656187245 Accuracy 67.06890718394045\n",
      "Training:: Epoch 81, Iteration 110, Current loss 0.3813774747163601 Accuracy 69.01251944588488\n",
      "Training:: Epoch 81, Iteration 120, Current loss 0.36219369931458356 Accuracy 64.6055211148201\n",
      "Training:: Epoch 81, Iteration 130, Current loss 0.3615736552156829 Accuracy 65.8952317978106\n",
      "Training:: Epoch 81, Iteration 140, Current loss 0.41364475346668156 Accuracy 62.57330459626084\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 81, Probability Accuracy 52.32003150347388\n",
      "Starting Training\n",
      "Training:: Epoch 82, Iteration 0, Current loss 0.4203955186782848 Accuracy 54.90412166629932\n",
      "Training:: Epoch 82, Iteration 10, Current loss 0.3099778413727434 Accuracy 63.05322128851541\n",
      "Training:: Epoch 82, Iteration 20, Current loss 0.35563159603850175 Accuracy 63.866384145581456\n",
      "Training:: Epoch 82, Iteration 30, Current loss 0.38533998130239766 Accuracy 56.07816405362418\n",
      "Training:: Epoch 82, Iteration 40, Current loss 0.3747405159281992 Accuracy 56.97374411898619\n",
      "Training:: Epoch 82, Iteration 50, Current loss 0.3704375404449625 Accuracy 67.81221631435612\n",
      "Training:: Epoch 82, Iteration 60, Current loss 0.36607145574952105 Accuracy 60.474771650466465\n",
      "Training:: Epoch 82, Iteration 70, Current loss 0.3907352499160607 Accuracy 68.0882138162699\n",
      "Training:: Epoch 82, Iteration 80, Current loss 0.35603256116572984 Accuracy 73.21718721790937\n",
      "Training:: Epoch 82, Iteration 90, Current loss 0.39703672022370334 Accuracy 62.769891446976025\n",
      "Training:: Epoch 82, Iteration 100, Current loss 0.38928756356047933 Accuracy 60.54455720068763\n",
      "Training:: Epoch 82, Iteration 110, Current loss 0.4248019057347313 Accuracy 61.8452109818212\n",
      "Training:: Epoch 82, Iteration 120, Current loss 0.33861746642657453 Accuracy 61.11419660785235\n",
      "Training:: Epoch 82, Iteration 130, Current loss 0.38108976172710607 Accuracy 63.94342291371994\n",
      "Training:: Epoch 82, Iteration 140, Current loss 0.4594620845123809 Accuracy 58.63758647194466\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 82, Probability Accuracy 51.59224896894751\n",
      "Starting Training\n",
      "Training:: Epoch 83, Iteration 0, Current loss 0.4650463166618844 Accuracy 54.69787516600265\n",
      "Training:: Epoch 83, Iteration 10, Current loss 0.6442322621490558 Accuracy 60.516693640232575\n",
      "Training:: Epoch 83, Iteration 20, Current loss 0.2651120294868815 Accuracy 69.39993876926216\n",
      "Training:: Epoch 83, Iteration 30, Current loss 0.3109676185644023 Accuracy 74.49712643678161\n",
      "Training:: Epoch 83, Iteration 40, Current loss 0.35645563809000963 Accuracy 58.348868175765645\n",
      "Training:: Epoch 83, Iteration 50, Current loss 0.3242453137636647 Accuracy 68.35265191429575\n",
      "Training:: Epoch 83, Iteration 60, Current loss 0.44029742683271367 Accuracy 71.80690814825195\n",
      "Training:: Epoch 83, Iteration 70, Current loss 0.297425856906492 Accuracy 58.81491426130469\n",
      "Training:: Epoch 83, Iteration 80, Current loss 0.4144089304768689 Accuracy 58.809966530308664\n",
      "Training:: Epoch 83, Iteration 90, Current loss 0.40257927523406484 Accuracy 67.16800912395752\n",
      "Training:: Epoch 83, Iteration 100, Current loss 0.48048266853128696 Accuracy 58.091153793512476\n",
      "Training:: Epoch 83, Iteration 110, Current loss 0.29534661907363724 Accuracy 60.46931407942238\n",
      "Training:: Epoch 83, Iteration 120, Current loss 0.40880779229097763 Accuracy 62.30033845971142\n",
      "Training:: Epoch 83, Iteration 130, Current loss 0.3399703969957549 Accuracy 58.879685525761616\n",
      "Training:: Epoch 83, Iteration 140, Current loss 0.40441672264950507 Accuracy 62.40601503759399\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 83, Probability Accuracy 52.38604500683011\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 84, Iteration 0, Current loss 0.3624364820331095 Accuracy 70.5748822427785\n",
      "Training:: Epoch 84, Iteration 10, Current loss 0.32312194507533526 Accuracy 61.15307150050352\n",
      "Training:: Epoch 84, Iteration 20, Current loss 0.4746155782808582 Accuracy 61.22139574548728\n",
      "Training:: Epoch 84, Iteration 30, Current loss 0.33075196748178126 Accuracy 68.61156131820637\n",
      "Training:: Epoch 84, Iteration 40, Current loss 0.35529578841294984 Accuracy 63.50587776839644\n",
      "Training:: Epoch 84, Iteration 50, Current loss 0.40902661789899086 Accuracy 59.14082464258581\n",
      "Training:: Epoch 84, Iteration 60, Current loss 0.3441218391810903 Accuracy 60.107998650016874\n",
      "Training:: Epoch 84, Iteration 70, Current loss 0.31640103260776614 Accuracy 61.895595934708965\n",
      "Training:: Epoch 84, Iteration 80, Current loss 0.5090225910356896 Accuracy 64.05353728489484\n",
      "Training:: Epoch 84, Iteration 90, Current loss 0.3986112549415498 Accuracy 66.5982263771788\n",
      "Training:: Epoch 84, Iteration 100, Current loss 0.3337322083596673 Accuracy 62.622249388753055\n",
      "Training:: Epoch 84, Iteration 110, Current loss 0.333569985854094 Accuracy 67.55042787286064\n",
      "Training:: Epoch 84, Iteration 120, Current loss 0.3762620105317528 Accuracy 66.67159544580808\n",
      "Training:: Epoch 84, Iteration 130, Current loss 0.35466062480362853 Accuracy 58.98526077097506\n",
      "Training:: Epoch 84, Iteration 140, Current loss 0.31850511276646465 Accuracy 61.61751563896336\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 84, Probability Accuracy 51.97272531193014\n",
      "Starting Training\n",
      "Training:: Epoch 85, Iteration 0, Current loss 0.525811602042342 Accuracy 69.97971602434077\n",
      "Training:: Epoch 85, Iteration 10, Current loss 0.43541607522936665 Accuracy 62.03487658111261\n",
      "Training:: Epoch 85, Iteration 20, Current loss 0.3302970226803974 Accuracy 64.24780301052814\n",
      "Training:: Epoch 85, Iteration 30, Current loss 0.43417270887975273 Accuracy 71.54736240045756\n",
      "Training:: Epoch 85, Iteration 40, Current loss 0.35508818258970376 Accuracy 64.75251885701701\n",
      "Training:: Epoch 85, Iteration 50, Current loss 0.3366388211355784 Accuracy 67.33629415410039\n",
      "Training:: Epoch 85, Iteration 60, Current loss 0.3304414543708334 Accuracy 58.975488846047924\n",
      "Training:: Epoch 85, Iteration 70, Current loss 0.4176419780684773 Accuracy 55.04372672958698\n",
      "Training:: Epoch 85, Iteration 80, Current loss 0.36283408168088926 Accuracy 61.407310258311\n",
      "Training:: Epoch 85, Iteration 90, Current loss 0.3211484228844915 Accuracy 64.37207660400671\n",
      "Training:: Epoch 85, Iteration 100, Current loss 0.35791205130239495 Accuracy 60.91464940823113\n",
      "Training:: Epoch 85, Iteration 110, Current loss 0.3936263034597107 Accuracy 52.71747577845707\n",
      "Training:: Epoch 85, Iteration 120, Current loss 0.3335734196259288 Accuracy 59.214296879070496\n",
      "Training:: Epoch 85, Iteration 130, Current loss 0.32474757201153176 Accuracy 68.64036893683604\n",
      "Training:: Epoch 85, Iteration 140, Current loss 0.2736591141773917 Accuracy 58.7592449497737\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 85, Probability Accuracy 51.74502774527938\n",
      "Calculating Expectation\n",
      "Epoch 85 iter 0\n",
      "Epoch 85 iter 10\n",
      "Epoch 85 iter 20\n",
      "Epoch 85 iter 30\n",
      "Epoch 85 iter 40\n",
      "Epoch 85 iter 50\n",
      "Epoch 85 iter 60\n",
      "Epoch 85 iter 70\n",
      "Epoch 85 iter 80\n",
      "Epoch 85 iter 90\n",
      "Epoch 85 iter 100\n",
      "Epoch 85 iter 110\n",
      "Epoch 85 iter 120\n",
      "Epoch 85 iter 130\n",
      "Epoch 85 iter 140\n",
      "Train Boundary avergage error = 300.935\n",
      "Train From boundary avergage accuracy = 59.092\n",
      "Starting Training\n",
      "Training:: Epoch 86, Iteration 0, Current loss 0.33335246817464526 Accuracy 67.22641078364177\n",
      "Training:: Epoch 86, Iteration 10, Current loss 0.27478935227318435 Accuracy 66.51231921339965\n",
      "Training:: Epoch 86, Iteration 20, Current loss 0.28414730106760144 Accuracy 59.66531122927745\n",
      "Training:: Epoch 86, Iteration 30, Current loss 0.44483490228121203 Accuracy 49.77131656321463\n",
      "Training:: Epoch 86, Iteration 40, Current loss 0.36301476001640015 Accuracy 68.42808088515834\n",
      "Training:: Epoch 86, Iteration 50, Current loss 0.3548658991789967 Accuracy 66.8810475693841\n",
      "Training:: Epoch 86, Iteration 60, Current loss 0.3527342519514821 Accuracy 66.27422480620154\n",
      "Training:: Epoch 86, Iteration 70, Current loss 0.37217331273145693 Accuracy 64.60616438356165\n",
      "Training:: Epoch 86, Iteration 80, Current loss 0.34982424060608686 Accuracy 55.12860241710567\n",
      "Training:: Epoch 86, Iteration 90, Current loss 0.32656240261645825 Accuracy 65.94187856772184\n",
      "Training:: Epoch 86, Iteration 100, Current loss 0.29035903396529383 Accuracy 65.91842946279105\n",
      "Training:: Epoch 86, Iteration 110, Current loss 0.49738234831890377 Accuracy 63.688814442583286\n",
      "Training:: Epoch 86, Iteration 120, Current loss 0.4217038199315601 Accuracy 49.191941554128846\n",
      "Training:: Epoch 86, Iteration 130, Current loss 0.2934833965299659 Accuracy 75.83626897777224\n",
      "Training:: Epoch 86, Iteration 140, Current loss 0.37666143144370867 Accuracy 59.040650406504064\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 86, Probability Accuracy 52.243315315786376\n",
      "Starting Training\n",
      "Training:: Epoch 87, Iteration 0, Current loss 0.5687971522642619 Accuracy 66.94306569343065\n",
      "Training:: Epoch 87, Iteration 10, Current loss 0.45647544712426413 Accuracy 54.2894013353532\n",
      "Training:: Epoch 87, Iteration 20, Current loss 0.6689991745672079 Accuracy 57.96116504854369\n",
      "Training:: Epoch 87, Iteration 30, Current loss 0.4373076354570573 Accuracy 49.44334487877288\n",
      "Training:: Epoch 87, Iteration 40, Current loss 0.4285973691947246 Accuracy 51.129629629629626\n",
      "Training:: Epoch 87, Iteration 50, Current loss 0.5051306535856611 Accuracy 46.023275252362886\n",
      "Training:: Epoch 87, Iteration 60, Current loss 0.4486724156149494 Accuracy 63.08387744851833\n",
      "Training:: Epoch 87, Iteration 70, Current loss 0.36946303470146324 Accuracy 65.77840112201963\n",
      "Training:: Epoch 87, Iteration 80, Current loss 0.33669842018041013 Accuracy 68.60907017988346\n",
      "Training:: Epoch 87, Iteration 90, Current loss 0.353405766411731 Accuracy 68.84088076443706\n",
      "Training:: Epoch 87, Iteration 100, Current loss 0.40586964503644746 Accuracy 59.12367650371705\n",
      "Training:: Epoch 87, Iteration 110, Current loss 0.2752378129586883 Accuracy 70.29279018632103\n",
      "Training:: Epoch 87, Iteration 120, Current loss 0.3360932538117219 Accuracy 59.50777803575575\n",
      "Training:: Epoch 87, Iteration 130, Current loss 0.23065556105623516 Accuracy 79.171974522293\n",
      "Training:: Epoch 87, Iteration 140, Current loss 0.41549115455497415 Accuracy 70.48793090721193\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 87, Probability Accuracy 53.045853240870855\n",
      "Starting Training\n",
      "Training:: Epoch 88, Iteration 0, Current loss 0.35786594136099925 Accuracy 57.890487004794345\n",
      "Training:: Epoch 88, Iteration 10, Current loss 0.3514808838423078 Accuracy 63.2357315881178\n",
      "Training:: Epoch 88, Iteration 20, Current loss 0.2767971912077126 Accuracy 69.73946986201888\n",
      "Training:: Epoch 88, Iteration 30, Current loss 0.5019870931116508 Accuracy 56.050636084477034\n",
      "Training:: Epoch 88, Iteration 40, Current loss 0.4820509177571312 Accuracy 59.894459102902374\n",
      "Training:: Epoch 88, Iteration 50, Current loss 0.6549170210639046 Accuracy 65.13566312133709\n",
      "Training:: Epoch 88, Iteration 60, Current loss 0.2810051487639024 Accuracy 69.90597810833567\n",
      "Training:: Epoch 88, Iteration 70, Current loss 0.4026104069943174 Accuracy 59.97679173343648\n",
      "Training:: Epoch 88, Iteration 80, Current loss 1.296566375285442 Accuracy 73.54893485643717\n",
      "Training:: Epoch 88, Iteration 90, Current loss 2.1297822846077485 Accuracy 57.08282793276729\n",
      "Training:: Epoch 88, Iteration 100, Current loss 2.7051677758112427 Accuracy 56.18919825561892\n",
      "Training:: Epoch 88, Iteration 110, Current loss 2.6981596069017115 Accuracy 60.864381520119224\n",
      "Training:: Epoch 88, Iteration 120, Current loss 8.529672092028061 Accuracy 26.78731870106533\n",
      "Training:: Epoch 88, Iteration 130, Current loss 3.557886971375168 Accuracy 50.51022482416555\n",
      "Training:: Epoch 88, Iteration 140, Current loss 2.182739683463984 Accuracy 62.787690716317556\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 88, Probability Accuracy 46.6040627716521\n",
      "Starting Training\n",
      "Training:: Epoch 89, Iteration 0, Current loss 4.9475814873569774 Accuracy 41.21210011487451\n",
      "Training:: Epoch 89, Iteration 10, Current loss 1.5215296806894039 Accuracy 55.452854646903006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 89, Iteration 20, Current loss 1.618281477283559 Accuracy 68.98098949108514\n",
      "Training:: Epoch 89, Iteration 30, Current loss 0.7336534233925269 Accuracy 64.03219025884331\n",
      "Training:: Epoch 89, Iteration 40, Current loss 1.5955529601346259 Accuracy 62.17920516204722\n",
      "Training:: Epoch 89, Iteration 50, Current loss 1.060890973572632 Accuracy 71.07170846394985\n",
      "Training:: Epoch 89, Iteration 60, Current loss 1.8829005040027837 Accuracy 47.76372900547273\n",
      "Training:: Epoch 89, Iteration 70, Current loss 1.0998646363360047 Accuracy 62.330373596917404\n",
      "Training:: Epoch 89, Iteration 80, Current loss 0.8962214572801216 Accuracy 64.21364646867697\n",
      "Training:: Epoch 89, Iteration 90, Current loss 1.1713452647556764 Accuracy 62.01133144475921\n",
      "Training:: Epoch 89, Iteration 100, Current loss 2.484139280432726 Accuracy 58.736\n",
      "Training:: Epoch 89, Iteration 110, Current loss 1.0191745883565875 Accuracy 60.2487952482349\n",
      "Training:: Epoch 89, Iteration 120, Current loss 1.0496070960784334 Accuracy 54.83027798382254\n",
      "Training:: Epoch 89, Iteration 130, Current loss 0.862214082542429 Accuracy 63.528574816220065\n",
      "Training:: Epoch 89, Iteration 140, Current loss 0.7203391126784567 Accuracy 58.26736370425691\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 89, Probability Accuracy 52.07370636409388\n",
      "Starting Training\n",
      "Training:: Epoch 90, Iteration 0, Current loss 0.6484353859161064 Accuracy 62.850552385577274\n",
      "Training:: Epoch 90, Iteration 10, Current loss 0.5591390228077526 Accuracy 65.95581171950047\n",
      "Training:: Epoch 90, Iteration 20, Current loss 0.5665515561531689 Accuracy 55.0914353374556\n",
      "Training:: Epoch 90, Iteration 30, Current loss 0.5313741054670841 Accuracy 55.330330330330334\n",
      "Training:: Epoch 90, Iteration 40, Current loss 0.4550886642060661 Accuracy 73.64926549921155\n",
      "Training:: Epoch 90, Iteration 50, Current loss 0.3961596915992707 Accuracy 70.93975903614458\n",
      "Training:: Epoch 90, Iteration 60, Current loss 0.37683297606100696 Accuracy 72.09777860395947\n",
      "Training:: Epoch 90, Iteration 70, Current loss 0.47324555890998365 Accuracy 60.05674653215637\n",
      "Training:: Epoch 90, Iteration 80, Current loss 0.5546618053631048 Accuracy 66.86906601898873\n",
      "Training:: Epoch 90, Iteration 90, Current loss 0.5775675308326604 Accuracy 58.93783877292123\n",
      "Training:: Epoch 90, Iteration 100, Current loss 0.4775211466042502 Accuracy 64.2807130931222\n",
      "Training:: Epoch 90, Iteration 110, Current loss 0.4915635451141751 Accuracy 60.39325842696629\n",
      "Training:: Epoch 90, Iteration 120, Current loss 0.47097952977448526 Accuracy 56.10436085219707\n",
      "Training:: Epoch 90, Iteration 130, Current loss 0.5537690032965089 Accuracy 66.87555953446733\n",
      "Training:: Epoch 90, Iteration 140, Current loss 0.49563751171503256 Accuracy 63.46881191090833\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 90, Probability Accuracy 52.006875861933736\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Total correct pivots labels selected =  62.123572170301145\n",
      "Calculating Expectation\n",
      "Epoch 90 iter 0\n",
      "Epoch 90 iter 10\n",
      "Epoch 90 iter 20\n",
      "Epoch 90 iter 30\n",
      "Epoch 90 iter 40\n",
      "Epoch 90 iter 50\n",
      "Epoch 90 iter 60\n",
      "Epoch 90 iter 70\n",
      "Epoch 90 iter 80\n",
      "Epoch 90 iter 90\n",
      "Epoch 90 iter 100\n",
      "Epoch 90 iter 110\n",
      "Epoch 90 iter 120\n",
      "Epoch 90 iter 130\n",
      "Epoch 90 iter 140\n",
      "Train Boundary avergage error = 301.799\n",
      "Train From boundary avergage accuracy = 59.111\n",
      "Starting Training\n",
      "Training:: Epoch 91, Iteration 0, Current loss 0.4956325187637912 Accuracy 75.43459860668013\n",
      "Training:: Epoch 91, Iteration 10, Current loss 0.5264452334654323 Accuracy 54.00441229285311\n",
      "Training:: Epoch 91, Iteration 20, Current loss 0.40492894366822485 Accuracy 63.265662062229666\n",
      "Training:: Epoch 91, Iteration 30, Current loss 0.4620906626691656 Accuracy 65.59175531914893\n",
      "Training:: Epoch 91, Iteration 40, Current loss 0.33829644554070243 Accuracy 76.41913093087382\n",
      "Training:: Epoch 91, Iteration 50, Current loss 0.2978356685678692 Accuracy 72.5885725988122\n",
      "Training:: Epoch 91, Iteration 60, Current loss 0.46626724402967923 Accuracy 53.93468647238916\n",
      "Training:: Epoch 91, Iteration 70, Current loss 0.3472131464856085 Accuracy 66.52332657200812\n",
      "Training:: Epoch 91, Iteration 80, Current loss 0.41516920281545866 Accuracy 64.7207126449661\n",
      "Training:: Epoch 91, Iteration 90, Current loss 0.3925524692148884 Accuracy 61.80740898900395\n",
      "Training:: Epoch 91, Iteration 100, Current loss 0.31404163958015063 Accuracy 66.54628397643033\n",
      "Training:: Epoch 91, Iteration 110, Current loss 0.3748124077027325 Accuracy 66.77896466721447\n",
      "Training:: Epoch 91, Iteration 120, Current loss 0.3792074411328762 Accuracy 73.52148726929813\n",
      "Training:: Epoch 91, Iteration 130, Current loss 0.33779996699627396 Accuracy 64.2919708029197\n",
      "Training:: Epoch 91, Iteration 140, Current loss 0.39879053721988816 Accuracy 67.27667148737346\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 91, Probability Accuracy 51.560059216073306\n",
      "Starting Training\n",
      "Training:: Epoch 92, Iteration 0, Current loss 0.40595893972892316 Accuracy 63.67256908277679\n",
      "Training:: Epoch 92, Iteration 10, Current loss 0.3970878283652848 Accuracy 64.1304347826087\n",
      "Training:: Epoch 92, Iteration 20, Current loss 0.41081242806829577 Accuracy 65.52974130828802\n",
      "Training:: Epoch 92, Iteration 30, Current loss 0.34107571492011424 Accuracy 63.19969159599075\n",
      "Training:: Epoch 92, Iteration 40, Current loss 0.3014149365630894 Accuracy 63.80035413899956\n",
      "Training:: Epoch 92, Iteration 50, Current loss 0.28989057793654815 Accuracy 66.01333069359202\n",
      "Training:: Epoch 92, Iteration 60, Current loss 0.41467752079588155 Accuracy 56.706165206938\n",
      "Training:: Epoch 92, Iteration 70, Current loss 0.42811939499149854 Accuracy 61.101144447881225\n",
      "Training:: Epoch 92, Iteration 80, Current loss 0.4039308002254985 Accuracy 54.754882017900734\n",
      "Training:: Epoch 92, Iteration 90, Current loss 0.36188174290653025 Accuracy 77.18093424899708\n",
      "Training:: Epoch 92, Iteration 100, Current loss 0.3402466961541912 Accuracy 66.55935840957868\n",
      "Training:: Epoch 92, Iteration 110, Current loss 0.46068630571791447 Accuracy 57.428908599489894\n",
      "Training:: Epoch 92, Iteration 120, Current loss 0.40345232679746784 Accuracy 61.17121990803354\n",
      "Training:: Epoch 92, Iteration 130, Current loss 0.28867030516205827 Accuracy 66.90250272754322\n",
      "Training:: Epoch 92, Iteration 140, Current loss 0.2998251720096638 Accuracy 45.83093732029902\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 92, Probability Accuracy 51.78734828332211\n",
      "Starting Training\n",
      "Training:: Epoch 93, Iteration 0, Current loss 0.4768069614542273 Accuracy 56.19268020913688\n",
      "Training:: Epoch 93, Iteration 10, Current loss 0.38608428945884243 Accuracy 59.059661799387825\n",
      "Training:: Epoch 93, Iteration 20, Current loss 0.3414364697817242 Accuracy 60.154608856398625\n",
      "Training:: Epoch 93, Iteration 30, Current loss 0.3226156892790546 Accuracy 71.40047932157562\n",
      "Training:: Epoch 93, Iteration 40, Current loss 0.3117746112193412 Accuracy 61.45973261690015\n",
      "Training:: Epoch 93, Iteration 50, Current loss 0.30258693507282175 Accuracy 61.57129421977863\n",
      "Training:: Epoch 93, Iteration 60, Current loss 0.31204990194999704 Accuracy 64.30136373798345\n",
      "Training:: Epoch 93, Iteration 70, Current loss 0.590641345195075 Accuracy 56.53493849777545\n",
      "Training:: Epoch 93, Iteration 80, Current loss 0.2676245803594029 Accuracy 75.4858934169279\n",
      "Training:: Epoch 93, Iteration 90, Current loss 0.41483268068678536 Accuracy 62.07326362440274\n",
      "Training:: Epoch 93, Iteration 100, Current loss 0.4276745497148403 Accuracy 56.718942189421895\n",
      "Training:: Epoch 93, Iteration 110, Current loss 0.28723679020695153 Accuracy 70.7094646813334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 93, Iteration 120, Current loss 0.2872496389682971 Accuracy 71.2031476496169\n",
      "Training:: Epoch 93, Iteration 130, Current loss 0.33941905117290005 Accuracy 59.63138816562005\n",
      "Training:: Epoch 93, Iteration 140, Current loss 0.468205031682407 Accuracy 65.17956725407093\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 93, Probability Accuracy 51.923378584173754\n",
      "Starting Training\n",
      "Training:: Epoch 94, Iteration 0, Current loss 0.2932045991321948 Accuracy 64.01439050600383\n",
      "Training:: Epoch 94, Iteration 10, Current loss 0.36991084255686213 Accuracy 62.41052874624798\n",
      "Training:: Epoch 94, Iteration 20, Current loss 0.3940205475857432 Accuracy 62.901805372082784\n",
      "Training:: Epoch 94, Iteration 30, Current loss 0.5056056633854902 Accuracy 53.9034716342083\n",
      "Training:: Epoch 94, Iteration 40, Current loss 0.35791846691894014 Accuracy 65.37706038090357\n",
      "Training:: Epoch 94, Iteration 50, Current loss 0.3153251472787921 Accuracy 71.79923656246775\n",
      "Training:: Epoch 94, Iteration 60, Current loss 0.5260650732855013 Accuracy 65.64462257849031\n",
      "Training:: Epoch 94, Iteration 70, Current loss 0.35177630995159764 Accuracy 57.15367719457699\n",
      "Training:: Epoch 94, Iteration 80, Current loss 0.3504156556076342 Accuracy 72.15244229736983\n",
      "Training:: Epoch 94, Iteration 90, Current loss 0.4130712964737763 Accuracy 59.203261262191035\n",
      "Training:: Epoch 94, Iteration 100, Current loss 0.32603480637564697 Accuracy 68.55830929534349\n",
      "Training:: Epoch 94, Iteration 110, Current loss 0.31830226959385627 Accuracy 50.554422952612995\n",
      "Training:: Epoch 94, Iteration 120, Current loss 0.3813155691621941 Accuracy 60.99829766536965\n",
      "Training:: Epoch 94, Iteration 130, Current loss 0.2743001540154961 Accuracy 65.86527239624668\n",
      "Training:: Epoch 94, Iteration 140, Current loss 0.3180759568626955 Accuracy 62.72106881968474\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 94, Probability Accuracy 51.13129824377937\n",
      "Starting Training\n",
      "Training:: Epoch 95, Iteration 0, Current loss 0.2748642460885452 Accuracy 61.428669930359234\n",
      "Training:: Epoch 95, Iteration 10, Current loss 0.3008814727817011 Accuracy 57.11336336336336\n",
      "Training:: Epoch 95, Iteration 20, Current loss 0.31931394242749156 Accuracy 55.03207560184866\n",
      "Training:: Epoch 95, Iteration 30, Current loss 0.3407217747823829 Accuracy 61.30423531441387\n",
      "Training:: Epoch 95, Iteration 40, Current loss 0.3370989599043526 Accuracy 54.969613801215445\n",
      "Training:: Epoch 95, Iteration 50, Current loss 0.28736254462355826 Accuracy 63.000548546352164\n",
      "Training:: Epoch 95, Iteration 60, Current loss 0.3234984954473316 Accuracy 64.65333900467886\n",
      "Training:: Epoch 95, Iteration 70, Current loss 0.4575889684859057 Accuracy 62.31675768899109\n",
      "Training:: Epoch 95, Iteration 80, Current loss 0.3052234752276535 Accuracy 70.11678832116789\n",
      "Training:: Epoch 95, Iteration 90, Current loss 0.3750909327632465 Accuracy 54.25412029863361\n",
      "Training:: Epoch 95, Iteration 100, Current loss 0.35761281982961596 Accuracy 56.326385318198\n",
      "Training:: Epoch 95, Iteration 110, Current loss 0.3754296432408455 Accuracy 67.14940951280292\n",
      "Training:: Epoch 95, Iteration 120, Current loss 0.287644394953055 Accuracy 70.23875283864236\n",
      "Training:: Epoch 95, Iteration 130, Current loss 0.3709996789633293 Accuracy 60.30112733600666\n",
      "Training:: Epoch 95, Iteration 140, Current loss 0.29321786867986666 Accuracy 70.8528843499862\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 95, Probability Accuracy 51.84600879744312\n",
      "Calculating Expectation\n",
      "Epoch 95 iter 0\n",
      "Epoch 95 iter 10\n",
      "Epoch 95 iter 20\n",
      "Epoch 95 iter 30\n",
      "Epoch 95 iter 40\n",
      "Epoch 95 iter 50\n",
      "Epoch 95 iter 60\n",
      "Epoch 95 iter 70\n",
      "Epoch 95 iter 80\n",
      "Epoch 95 iter 90\n",
      "Epoch 95 iter 100\n",
      "Epoch 95 iter 110\n",
      "Epoch 95 iter 120\n",
      "Epoch 95 iter 130\n",
      "Epoch 95 iter 140\n",
      "Train Boundary avergage error = 302.492\n",
      "Train From boundary avergage accuracy = 59.011\n",
      "Starting Training\n",
      "Training:: Epoch 96, Iteration 0, Current loss 0.2680830355470692 Accuracy 71.36921798541225\n",
      "Training:: Epoch 96, Iteration 10, Current loss 0.3038520986579359 Accuracy 61.99109085258469\n",
      "Training:: Epoch 96, Iteration 20, Current loss 0.2971445471963102 Accuracy 56.92883895131086\n",
      "Training:: Epoch 96, Iteration 30, Current loss 0.33942711082057037 Accuracy 72.95324397457681\n",
      "Training:: Epoch 96, Iteration 40, Current loss 0.30904414339090414 Accuracy 68.28354800401937\n",
      "Training:: Epoch 96, Iteration 50, Current loss 0.31485626848707665 Accuracy 66.48836336336336\n",
      "Training:: Epoch 96, Iteration 60, Current loss 0.23429275620079446 Accuracy 66.8840579710145\n",
      "Training:: Epoch 96, Iteration 70, Current loss 0.3694848037314809 Accuracy 46.85187589250941\n",
      "Training:: Epoch 96, Iteration 80, Current loss 0.290180727448328 Accuracy 58.002001158565484\n",
      "Training:: Epoch 96, Iteration 90, Current loss 0.31912575915623953 Accuracy 68.00039615727444\n",
      "Training:: Epoch 96, Iteration 100, Current loss 0.32391845690750676 Accuracy 64.41522729225746\n",
      "Training:: Epoch 96, Iteration 110, Current loss 0.24971702808889062 Accuracy 66.07770666185883\n",
      "Training:: Epoch 96, Iteration 120, Current loss 0.4412110342280694 Accuracy 57.31260368041357\n",
      "Training:: Epoch 96, Iteration 130, Current loss 0.4108384956153608 Accuracy 53.325448093895005\n",
      "Training:: Epoch 96, Iteration 140, Current loss 0.35820935315453273 Accuracy 66.55958485204177\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 96, Probability Accuracy 51.42002562108249\n",
      "Starting Training\n",
      "Training:: Epoch 97, Iteration 0, Current loss 0.2893181266773758 Accuracy 58.93435384162496\n",
      "Training:: Epoch 97, Iteration 10, Current loss 0.3903117276054199 Accuracy 60.067553594816296\n",
      "Training:: Epoch 97, Iteration 20, Current loss 0.41311789715047204 Accuracy 66.1517797179315\n",
      "Training:: Epoch 97, Iteration 30, Current loss 0.40330794744956644 Accuracy 71.32682926829268\n",
      "Training:: Epoch 97, Iteration 40, Current loss 0.3184544042260543 Accuracy 64.76106911447084\n",
      "Training:: Epoch 97, Iteration 50, Current loss 0.3763250773912965 Accuracy 60.57813484562067\n",
      "Training:: Epoch 97, Iteration 60, Current loss 0.41329420261997274 Accuracy 52.28946525776497\n",
      "Training:: Epoch 97, Iteration 70, Current loss 0.3036102069145498 Accuracy 66.35270963660645\n",
      "Training:: Epoch 97, Iteration 80, Current loss 0.36690193794023856 Accuracy 66.30072603556522\n",
      "Training:: Epoch 97, Iteration 90, Current loss 0.39472503513816204 Accuracy 69.67048077395276\n",
      "Training:: Epoch 97, Iteration 100, Current loss 0.2832451495517929 Accuracy 68.07286673058485\n",
      "Training:: Epoch 97, Iteration 110, Current loss 0.33243047068843634 Accuracy 46.819370411344664\n",
      "Training:: Epoch 97, Iteration 120, Current loss 0.2925639068164143 Accuracy 76.43824701195219\n",
      "Training:: Epoch 97, Iteration 130, Current loss 0.4179320107261481 Accuracy 65.67570510726343\n",
      "Training:: Epoch 97, Iteration 140, Current loss 0.3144525431316035 Accuracy 59.03581012306838\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 97, Probability Accuracy 51.338979339734244\n",
      "Starting Training\n",
      "Training:: Epoch 98, Iteration 0, Current loss 0.27642518769800156 Accuracy 63.9247211316757\n",
      "Training:: Epoch 98, Iteration 10, Current loss 0.3454971855803096 Accuracy 62.76399307559146\n",
      "Training:: Epoch 98, Iteration 20, Current loss 0.38730901518858896 Accuracy 64.30469441984057\n",
      "Training:: Epoch 98, Iteration 30, Current loss 0.35541012606565525 Accuracy 51.15984281911523\n",
      "Training:: Epoch 98, Iteration 40, Current loss 0.3981849354440106 Accuracy 69.56594184787137\n",
      "Training:: Epoch 98, Iteration 50, Current loss 0.3254730348901229 Accuracy 59.103037184217996\n",
      "Training:: Epoch 98, Iteration 60, Current loss 0.3877024783453708 Accuracy 65.5574887632304\n",
      "Training:: Epoch 98, Iteration 70, Current loss 0.24406257914392515 Accuracy 54.7426626967248\n",
      "Training:: Epoch 98, Iteration 80, Current loss 0.30177898891408644 Accuracy 57.2608990565456\n",
      "Training:: Epoch 98, Iteration 90, Current loss 0.37919067901591025 Accuracy 64.49825697211155\n",
      "Training:: Epoch 98, Iteration 100, Current loss 0.30511286519739933 Accuracy 63.767574035297635\n",
      "Training:: Epoch 98, Iteration 110, Current loss 0.4876453928565948 Accuracy 68.21301579426114\n",
      "Training:: Epoch 98, Iteration 120, Current loss 0.33820803180701997 Accuracy 53.50110926234054\n",
      "Training:: Epoch 98, Iteration 130, Current loss 0.3414824064961987 Accuracy 62.4066852367688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 98, Iteration 140, Current loss 0.4006468215772878 Accuracy 64.08030860950377\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 98, Probability Accuracy 51.80581245629057\n",
      "Starting Training\n",
      "Training:: Epoch 99, Iteration 0, Current loss 0.3091787535384496 Accuracy 48.607851072440305\n",
      "Training:: Epoch 99, Iteration 10, Current loss 0.2659227757267371 Accuracy 69.10815173527038\n",
      "Training:: Epoch 99, Iteration 20, Current loss 0.3219961733127045 Accuracy 58.94885030502112\n",
      "Training:: Epoch 99, Iteration 30, Current loss 0.3379089658900077 Accuracy 66.9114334624741\n",
      "Training:: Epoch 99, Iteration 40, Current loss 0.29942175208993627 Accuracy 69.88261502870363\n",
      "Training:: Epoch 99, Iteration 50, Current loss 0.24931944659402944 Accuracy 73.63617927398094\n",
      "Training:: Epoch 99, Iteration 60, Current loss 0.21380909848162502 Accuracy 67.2777431698852\n",
      "Training:: Epoch 99, Iteration 70, Current loss 0.3311006345906243 Accuracy 52.09861695730607\n",
      "Training:: Epoch 99, Iteration 80, Current loss 0.32225137964096595 Accuracy 64.73998151726455\n",
      "Training:: Epoch 99, Iteration 90, Current loss 0.3843908812199874 Accuracy 63.222233831365585\n",
      "Training:: Epoch 99, Iteration 100, Current loss 0.3076814385921386 Accuracy 65.16006592418718\n",
      "Training:: Epoch 99, Iteration 110, Current loss 0.281117626645528 Accuracy 43.2602842438908\n",
      "Training:: Epoch 99, Iteration 120, Current loss 0.2938651896336892 Accuracy 57.09748613877375\n",
      "Training:: Epoch 99, Iteration 130, Current loss 0.36580358445111766 Accuracy 63.34835355285962\n",
      "Training:: Epoch 99, Iteration 140, Current loss 0.40560524771061884 Accuracy 60.16867469879518\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 99, Probability Accuracy 52.25908339270191\n",
      "Starting Training\n",
      "Training:: Epoch 100, Iteration 0, Current loss 0.26056454889201647 Accuracy 68.05537669027689\n",
      "Training:: Epoch 100, Iteration 10, Current loss 0.3017610588453895 Accuracy 51.85331489894002\n",
      "Training:: Epoch 100, Iteration 20, Current loss 0.41259485785026156 Accuracy 53.39921976592978\n",
      "Training:: Epoch 100, Iteration 30, Current loss 0.2592998978156111 Accuracy 71.19418290295516\n",
      "Training:: Epoch 100, Iteration 40, Current loss 0.3424197238299648 Accuracy 52.79903342730568\n",
      "Training:: Epoch 100, Iteration 50, Current loss 0.2550885386675332 Accuracy 57.20950323974082\n",
      "Training:: Epoch 100, Iteration 60, Current loss 0.3130435249226036 Accuracy 64.12756449319521\n",
      "Training:: Epoch 100, Iteration 70, Current loss 0.34196160705821543 Accuracy 69.63455149501661\n",
      "Training:: Epoch 100, Iteration 80, Current loss 0.25692799015684215 Accuracy 61.72288246204575\n",
      "Training:: Epoch 100, Iteration 90, Current loss 0.36063151646655545 Accuracy 51.030047231434025\n",
      "Training:: Epoch 100, Iteration 100, Current loss 0.24261542282125154 Accuracy 72.23971452560873\n",
      "Training:: Epoch 100, Iteration 110, Current loss 0.2600593605331538 Accuracy 73.35863911148601\n",
      "Training:: Epoch 100, Iteration 120, Current loss 0.38445364702947205 Accuracy 62.390246983766026\n",
      "Training:: Epoch 100, Iteration 130, Current loss 0.2691375063967856 Accuracy 66.3069011491334\n",
      "Training:: Epoch 100, Iteration 140, Current loss 0.28768625548115745 Accuracy 62.385006178772485\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 100, Probability Accuracy 52.04282380930594\n",
      "Calculating Expectation\n",
      "Epoch 100 iter 0\n",
      "Epoch 100 iter 10\n",
      "Epoch 100 iter 20\n",
      "Epoch 100 iter 30\n",
      "Epoch 100 iter 40\n",
      "Epoch 100 iter 50\n",
      "Epoch 100 iter 60\n",
      "Epoch 100 iter 70\n",
      "Epoch 100 iter 80\n",
      "Epoch 100 iter 90\n",
      "Epoch 100 iter 100\n",
      "Epoch 100 iter 110\n",
      "Epoch 100 iter 120\n",
      "Epoch 100 iter 130\n",
      "Epoch 100 iter 140\n",
      "Train Boundary avergage error = 301.722\n",
      "Train From boundary avergage accuracy = 59.126\n",
      "Starting Training\n",
      "Training:: Epoch 101, Iteration 0, Current loss 0.2407120731383226 Accuracy 63.69377127157912\n",
      "Training:: Epoch 101, Iteration 10, Current loss 0.26153769581099584 Accuracy 66.79036600451138\n",
      "Training:: Epoch 101, Iteration 20, Current loss 0.27163652434728625 Accuracy 68.56368563685636\n",
      "Training:: Epoch 101, Iteration 30, Current loss 0.27175880602786034 Accuracy 62.095247583939425\n",
      "Training:: Epoch 101, Iteration 40, Current loss 0.26880175953540913 Accuracy 68.58400586940573\n",
      "Training:: Epoch 101, Iteration 50, Current loss 0.3149102099589119 Accuracy 58.19397993311037\n",
      "Training:: Epoch 101, Iteration 60, Current loss 0.24912298607742955 Accuracy 65.19177517233253\n",
      "Training:: Epoch 101, Iteration 70, Current loss 0.21417871505150424 Accuracy 72.67384916748286\n",
      "Training:: Epoch 101, Iteration 80, Current loss 0.2664770657489906 Accuracy 65.99598620902589\n",
      "Training:: Epoch 101, Iteration 90, Current loss 0.29433479145925995 Accuracy 66.32220297473269\n",
      "Training:: Epoch 101, Iteration 100, Current loss 0.30002622372277227 Accuracy 60.69989287353977\n",
      "Training:: Epoch 101, Iteration 110, Current loss 0.34410270610258603 Accuracy 69.06598661141217\n",
      "Training:: Epoch 101, Iteration 120, Current loss 0.3264505366248227 Accuracy 62.166019186553555\n",
      "Training:: Epoch 101, Iteration 130, Current loss 0.255833697310929 Accuracy 58.40826397892184\n",
      "Training:: Epoch 101, Iteration 140, Current loss 0.24527367157421048 Accuracy 66.52421652421653\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 101, Probability Accuracy 51.748704239896995\n",
      "Starting Training\n",
      "Training:: Epoch 102, Iteration 0, Current loss 0.2509710413127626 Accuracy 63.80801559264222\n",
      "Training:: Epoch 102, Iteration 10, Current loss 0.5294055234695045 Accuracy 53.36524721348957\n",
      "Training:: Epoch 102, Iteration 20, Current loss 0.2868374253601124 Accuracy 67.56636676663335\n",
      "Training:: Epoch 102, Iteration 30, Current loss 0.46890204644503564 Accuracy 59.10614525139665\n",
      "Training:: Epoch 102, Iteration 40, Current loss 0.393062010058204 Accuracy 61.87482614742698\n",
      "Training:: Epoch 102, Iteration 50, Current loss 0.23937397585167555 Accuracy 49.76200574956407\n",
      "Training:: Epoch 102, Iteration 60, Current loss 0.39352235898109184 Accuracy 67.33954451345755\n",
      "Training:: Epoch 102, Iteration 70, Current loss 0.26210621007168305 Accuracy 69.14035807024737\n",
      "Training:: Epoch 102, Iteration 80, Current loss 0.32790928567083577 Accuracy 61.36137381781981\n",
      "Training:: Epoch 102, Iteration 90, Current loss 0.33007945221176355 Accuracy 60.82523607499658\n",
      "Training:: Epoch 102, Iteration 100, Current loss 0.30842424036504085 Accuracy 62.09949409780776\n",
      "Training:: Epoch 102, Iteration 110, Current loss 0.42572162457611273 Accuracy 58.94153957879448\n",
      "Training:: Epoch 102, Iteration 120, Current loss 0.35710761347398134 Accuracy 59.92694311032943\n",
      "Training:: Epoch 102, Iteration 130, Current loss 0.3129234042204915 Accuracy 62.52397391637898\n",
      "Training:: Epoch 102, Iteration 140, Current loss 0.35335952846394164 Accuracy 65.00355366027007\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 102, Probability Accuracy 52.95753567016778\n",
      "Starting Training\n",
      "Training:: Epoch 103, Iteration 0, Current loss 0.3752475282578808 Accuracy 55.038419319429195\n",
      "Training:: Epoch 103, Iteration 10, Current loss 0.2635071150857503 Accuracy 57.24864130434783\n",
      "Training:: Epoch 103, Iteration 20, Current loss 0.4688516088412821 Accuracy 63.61798888327438\n",
      "Training:: Epoch 103, Iteration 30, Current loss 0.30151413832774326 Accuracy 63.56495149725854\n",
      "Training:: Epoch 103, Iteration 40, Current loss 0.34726110437135793 Accuracy 64.46631461033765\n",
      "Training:: Epoch 103, Iteration 50, Current loss 0.2774073721099307 Accuracy 47.37059471365639\n",
      "Training:: Epoch 103, Iteration 60, Current loss 0.290890900066364 Accuracy 62.24105461393597\n",
      "Training:: Epoch 103, Iteration 70, Current loss 0.3496417271742077 Accuracy 50.28622187129886\n",
      "Training:: Epoch 103, Iteration 80, Current loss 0.4431320319063967 Accuracy 66.07833415964303\n",
      "Training:: Epoch 103, Iteration 90, Current loss 0.6951120008117337 Accuracy 53.2930252645217\n",
      "Training:: Epoch 103, Iteration 100, Current loss 0.26934982535896895 Accuracy 67.46672045179508\n",
      "Training:: Epoch 103, Iteration 110, Current loss 0.3226942774488695 Accuracy 55.78573179700907\n",
      "Training:: Epoch 103, Iteration 120, Current loss 0.3147356679220329 Accuracy 68.28993094733042\n",
      "Training:: Epoch 103, Iteration 130, Current loss 0.3666415492885296 Accuracy 60.93905695723225\n",
      "Training:: Epoch 103, Iteration 140, Current loss 0.34020179378320103 Accuracy 68.96298112282422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 103, Probability Accuracy 51.38056457885346\n",
      "Starting Training\n",
      "Training:: Epoch 104, Iteration 0, Current loss 0.34018720819684367 Accuracy 59.168241965973536\n",
      "Training:: Epoch 104, Iteration 10, Current loss 0.3305948031319344 Accuracy 54.8512709572742\n",
      "Training:: Epoch 104, Iteration 20, Current loss 0.32062776966644013 Accuracy 59.147914791479145\n",
      "Training:: Epoch 104, Iteration 30, Current loss 0.27982600228828436 Accuracy 62.230570556468656\n",
      "Training:: Epoch 104, Iteration 40, Current loss 0.2793317868428582 Accuracy 49.96012304887775\n",
      "Training:: Epoch 104, Iteration 50, Current loss 0.4324975562561765 Accuracy 55.34639128115235\n",
      "Training:: Epoch 104, Iteration 60, Current loss 0.3755620770823356 Accuracy 60.8116848119004\n",
      "Training:: Epoch 104, Iteration 70, Current loss 0.3742321174980743 Accuracy 68.27236128128828\n",
      "Training:: Epoch 104, Iteration 80, Current loss 0.3400820186285599 Accuracy 59.19954833448341\n",
      "Training:: Epoch 104, Iteration 90, Current loss 0.4070874644356271 Accuracy 64.41994190527002\n",
      "Training:: Epoch 104, Iteration 100, Current loss 0.2864914184846956 Accuracy 71.5362673186634\n",
      "Training:: Epoch 104, Iteration 110, Current loss 0.3472352010393398 Accuracy 64.09172957006892\n",
      "Training:: Epoch 104, Iteration 120, Current loss 0.32120689546556475 Accuracy 62.55243029854429\n",
      "Training:: Epoch 104, Iteration 130, Current loss 0.2265681121454846 Accuracy 67.57833244822092\n",
      "Training:: Epoch 104, Iteration 140, Current loss 0.3764839496941472 Accuracy 65.53076402974983\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 104, Probability Accuracy 51.868149465029184\n",
      "Starting Training\n",
      "Training:: Epoch 105, Iteration 0, Current loss 0.5144938828563028 Accuracy 65.48950676467454\n",
      "Training:: Epoch 105, Iteration 10, Current loss 0.3740867868196654 Accuracy 61.85334180252664\n",
      "Training:: Epoch 105, Iteration 20, Current loss 0.36932464336651194 Accuracy 69.68529826209488\n",
      "Training:: Epoch 105, Iteration 30, Current loss 0.43353914734276217 Accuracy 57.42644139573867\n",
      "Training:: Epoch 105, Iteration 40, Current loss 0.7486140996268259 Accuracy 57.25486096592097\n",
      "Training:: Epoch 105, Iteration 50, Current loss 0.8377893982608939 Accuracy 67.68718801996673\n",
      "Training:: Epoch 105, Iteration 60, Current loss 1.3442185056716909 Accuracy 61.92247454972592\n",
      "Training:: Epoch 105, Iteration 70, Current loss 1.1725790526568707 Accuracy 67.12855146716349\n",
      "Training:: Epoch 105, Iteration 80, Current loss 1.914529628561711 Accuracy 67.73556331072628\n",
      "Training:: Epoch 105, Iteration 90, Current loss 2.2642302705836608 Accuracy 62.168827508455465\n",
      "Training:: Epoch 105, Iteration 100, Current loss 1.454983713192144 Accuracy 60.11404133998575\n",
      "Training:: Epoch 105, Iteration 110, Current loss 2.6303456545268817 Accuracy 53.506258482883425\n",
      "Training:: Epoch 105, Iteration 120, Current loss 1.4528497616718208 Accuracy 62.69056638639933\n",
      "Training:: Epoch 105, Iteration 130, Current loss 0.8435638468434155 Accuracy 66.36298561853322\n",
      "Training:: Epoch 105, Iteration 140, Current loss 0.751587333916967 Accuracy 52.895845875978324\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 105, Probability Accuracy 52.53318649141497\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Total correct pivots labels selected =  62.759605399792314\n",
      "Calculating Expectation\n",
      "Epoch 105 iter 0\n",
      "Epoch 105 iter 10\n",
      "Epoch 105 iter 20\n",
      "Epoch 105 iter 30\n",
      "Epoch 105 iter 40\n",
      "Epoch 105 iter 50\n",
      "Epoch 105 iter 60\n",
      "Epoch 105 iter 70\n",
      "Epoch 105 iter 80\n",
      "Epoch 105 iter 90\n",
      "Epoch 105 iter 100\n",
      "Epoch 105 iter 110\n",
      "Epoch 105 iter 120\n",
      "Epoch 105 iter 130\n",
      "Epoch 105 iter 140\n",
      "Train Boundary avergage error = 295.714\n",
      "Train From boundary avergage accuracy = 59.767\n",
      "Starting Training\n",
      "Training:: Epoch 106, Iteration 0, Current loss 0.46807314505680536 Accuracy 74.81088121837583\n",
      "Training:: Epoch 106, Iteration 10, Current loss 1.0455399416888465 Accuracy 50.74776925977127\n",
      "Training:: Epoch 106, Iteration 20, Current loss 0.6319287102517561 Accuracy 66.30120110871574\n",
      "Training:: Epoch 106, Iteration 30, Current loss 0.6582687392859616 Accuracy 60.83832905128937\n",
      "Training:: Epoch 106, Iteration 40, Current loss 0.7082286994068255 Accuracy 61.72394366197183\n",
      "Training:: Epoch 106, Iteration 50, Current loss 0.5968350803557538 Accuracy 58.47215377033021\n",
      "Training:: Epoch 106, Iteration 60, Current loss 0.5496048390449766 Accuracy 60.45050898852068\n",
      "Training:: Epoch 106, Iteration 70, Current loss 0.43781279231632253 Accuracy 56.20670545857578\n",
      "Training:: Epoch 106, Iteration 80, Current loss 0.48559680127406474 Accuracy 63.17271589486859\n",
      "Training:: Epoch 106, Iteration 90, Current loss 1.3228427163563252 Accuracy 53.184300917844475\n",
      "Training:: Epoch 106, Iteration 100, Current loss 3.2832586253720364 Accuracy 46.316630905801674\n",
      "Training:: Epoch 106, Iteration 110, Current loss 1.4930962262372751 Accuracy 56.96933492632417\n",
      "Training:: Epoch 106, Iteration 120, Current loss 0.9175697198953329 Accuracy 63.64337762537505\n",
      "Training:: Epoch 106, Iteration 130, Current loss 0.5667829223540083 Accuracy 62.586041003626676\n",
      "Training:: Epoch 106, Iteration 140, Current loss 1.2063612674946875 Accuracy 68.02346376707919\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 106, Probability Accuracy 50.14379178948882\n",
      "Starting Training\n",
      "Training:: Epoch 107, Iteration 0, Current loss 1.0240733843431138 Accuracy 57.50229231615624\n",
      "Training:: Epoch 107, Iteration 10, Current loss 1.1209907693623895 Accuracy 65.04040342669664\n",
      "Training:: Epoch 107, Iteration 20, Current loss 0.8313489850931056 Accuracy 61.54223968565815\n",
      "Training:: Epoch 107, Iteration 30, Current loss 0.6253447072020146 Accuracy 62.97539149888143\n",
      "Training:: Epoch 107, Iteration 40, Current loss 0.5994953415269133 Accuracy 58.70836908197489\n",
      "Training:: Epoch 107, Iteration 50, Current loss 0.5014427186171432 Accuracy 64.64730290456431\n",
      "Training:: Epoch 107, Iteration 60, Current loss 0.5986485828609723 Accuracy 66.03016994462479\n",
      "Training:: Epoch 107, Iteration 70, Current loss 0.5665767676065081 Accuracy 63.606640547929764\n",
      "Training:: Epoch 107, Iteration 80, Current loss 0.5772483755705874 Accuracy 60.84402151427389\n",
      "Training:: Epoch 107, Iteration 90, Current loss 1.52355796422089 Accuracy 64.56658700847274\n",
      "Training:: Epoch 107, Iteration 100, Current loss 0.6513335920067417 Accuracy 63.611667143265656\n",
      "Training:: Epoch 107, Iteration 110, Current loss 0.5389715081909872 Accuracy 67.27222832052689\n",
      "Training:: Epoch 107, Iteration 120, Current loss 0.6667111301550787 Accuracy 54.34160745593799\n",
      "Training:: Epoch 107, Iteration 130, Current loss 0.4424667540291809 Accuracy 69.74055371756921\n",
      "Training:: Epoch 107, Iteration 140, Current loss 0.8832470459746871 Accuracy 44.9352105656616\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 107, Probability Accuracy 53.36521807332074\n",
      "Starting Training\n",
      "Training:: Epoch 108, Iteration 0, Current loss 0.7487119689261645 Accuracy 74.25531914893617\n",
      "Training:: Epoch 108, Iteration 10, Current loss 0.5780261818407897 Accuracy 61.38663967611336\n",
      "Training:: Epoch 108, Iteration 20, Current loss 0.46091220430566415 Accuracy 60.71816535908268\n",
      "Training:: Epoch 108, Iteration 30, Current loss 0.4554998265419098 Accuracy 64.67989363878094\n",
      "Training:: Epoch 108, Iteration 40, Current loss 0.5190058884550339 Accuracy 55.50593984328924\n",
      "Training:: Epoch 108, Iteration 50, Current loss 0.46981781526501015 Accuracy 71.0798577432913\n",
      "Training:: Epoch 108, Iteration 60, Current loss 0.3188578563197517 Accuracy 69.84600099354198\n",
      "Training:: Epoch 108, Iteration 70, Current loss 0.7106225364385528 Accuracy 67.95262605566938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 108, Iteration 80, Current loss 0.6918528231285184 Accuracy 55.52756555853809\n",
      "Training:: Epoch 108, Iteration 90, Current loss 0.38356161051533966 Accuracy 75.40121748754842\n",
      "Training:: Epoch 108, Iteration 100, Current loss 0.4781920645338512 Accuracy 59.93318275926971\n",
      "Training:: Epoch 108, Iteration 110, Current loss 0.6324900105102367 Accuracy 53.230275630742305\n",
      "Training:: Epoch 108, Iteration 120, Current loss 0.4732539226468045 Accuracy 59.37427978796958\n",
      "Training:: Epoch 108, Iteration 130, Current loss 0.265072419751438 Accuracy 71.7035000528709\n",
      "Training:: Epoch 108, Iteration 140, Current loss 0.43796580221248294 Accuracy 78.65546218487395\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 108, Probability Accuracy 53.17453055248727\n",
      "Starting Training\n",
      "Training:: Epoch 109, Iteration 0, Current loss 0.42365094878837234 Accuracy 56.27332564293954\n",
      "Training:: Epoch 109, Iteration 10, Current loss 0.4549025929552956 Accuracy 69.95176768932426\n",
      "Training:: Epoch 109, Iteration 20, Current loss 0.47524666500475565 Accuracy 49.97705632671791\n",
      "Training:: Epoch 109, Iteration 30, Current loss 0.39166414124210586 Accuracy 63.967800571280186\n",
      "Training:: Epoch 109, Iteration 40, Current loss 0.34549025698718944 Accuracy 76.96275995486054\n",
      "Training:: Epoch 109, Iteration 50, Current loss 0.33951587211218226 Accuracy 63.367814866161886\n",
      "Training:: Epoch 109, Iteration 60, Current loss 0.3963025301480177 Accuracy 65.20353277110034\n",
      "Training:: Epoch 109, Iteration 70, Current loss 0.3622518427886621 Accuracy 68.58596221253313\n",
      "Training:: Epoch 109, Iteration 80, Current loss 0.4194981006576676 Accuracy 67.81032078103208\n",
      "Training:: Epoch 109, Iteration 90, Current loss 0.4967796604362284 Accuracy 66.18194348725017\n",
      "Training:: Epoch 109, Iteration 100, Current loss 0.3465445397836418 Accuracy 61.19324872432291\n",
      "Training:: Epoch 109, Iteration 110, Current loss 0.3606116587474518 Accuracy 55.146209496017995\n",
      "Training:: Epoch 109, Iteration 120, Current loss 0.3434986129344312 Accuracy 69.16912197996464\n",
      "Training:: Epoch 109, Iteration 130, Current loss 0.38537554417303066 Accuracy 64.61453440176844\n",
      "Training:: Epoch 109, Iteration 140, Current loss 0.31614051760423323 Accuracy 64.41589672193393\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 109, Probability Accuracy 52.71031183210348\n",
      "Starting Training\n",
      "Training:: Epoch 110, Iteration 0, Current loss 0.3413613569938291 Accuracy 63.68052856587641\n",
      "Training:: Epoch 110, Iteration 10, Current loss 0.3242061353055029 Accuracy 65.95544890187281\n",
      "Training:: Epoch 110, Iteration 20, Current loss 0.3636418461665237 Accuracy 69.74267211997274\n",
      "Training:: Epoch 110, Iteration 30, Current loss 0.36764044545277735 Accuracy 64.92443617763311\n",
      "Training:: Epoch 110, Iteration 40, Current loss 0.2939763572326883 Accuracy 74.2141211323239\n",
      "Training:: Epoch 110, Iteration 50, Current loss 0.4317638368109643 Accuracy 49.268168512154766\n",
      "Training:: Epoch 110, Iteration 60, Current loss 0.3379923266736214 Accuracy 66.04903309329234\n",
      "Training:: Epoch 110, Iteration 70, Current loss 0.47713207349248915 Accuracy 62.82086416369782\n",
      "Training:: Epoch 110, Iteration 80, Current loss 0.37112520640394087 Accuracy 66.14648219788866\n",
      "Training:: Epoch 110, Iteration 90, Current loss 0.3092023384566731 Accuracy 66.903073286052\n",
      "Training:: Epoch 110, Iteration 100, Current loss 0.4385666125705816 Accuracy 65.6581159102536\n",
      "Training:: Epoch 110, Iteration 110, Current loss 0.5496873459071456 Accuracy 64.64443829551743\n",
      "Training:: Epoch 110, Iteration 120, Current loss 0.35060417072059374 Accuracy 69.23957481602616\n",
      "Training:: Epoch 110, Iteration 130, Current loss 0.4903633736243281 Accuracy 53.218210361067506\n",
      "Training:: Epoch 110, Iteration 140, Current loss 0.314385217988302 Accuracy 74.2064499746064\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 110, Probability Accuracy 54.56334681926025\n",
      "Calculating Expectation\n",
      "Epoch 110 iter 0\n",
      "Epoch 110 iter 10\n",
      "Epoch 110 iter 20\n",
      "Epoch 110 iter 30\n",
      "Epoch 110 iter 40\n",
      "Epoch 110 iter 50\n",
      "Epoch 110 iter 60\n",
      "Epoch 110 iter 70\n",
      "Epoch 110 iter 80\n",
      "Epoch 110 iter 90\n",
      "Epoch 110 iter 100\n",
      "Epoch 110 iter 110\n",
      "Epoch 110 iter 120\n",
      "Epoch 110 iter 130\n",
      "Epoch 110 iter 140\n",
      "Train Boundary avergage error = 291.678\n",
      "Train From boundary avergage accuracy = 60.217\n",
      "Starting Training\n",
      "Training:: Epoch 111, Iteration 0, Current loss 0.4496264873063918 Accuracy 52.568010582619195\n",
      "Training:: Epoch 111, Iteration 10, Current loss 0.3502841029185462 Accuracy 60.610310971229175\n",
      "Training:: Epoch 111, Iteration 20, Current loss 0.3476674439888289 Accuracy 68.18724623835682\n",
      "Training:: Epoch 111, Iteration 30, Current loss 0.2939464893039592 Accuracy 65.8418243571082\n",
      "Training:: Epoch 111, Iteration 40, Current loss 0.3194390943968154 Accuracy 58.910587617129345\n",
      "Training:: Epoch 111, Iteration 50, Current loss 0.3184063701027081 Accuracy 62.37486095661846\n",
      "Training:: Epoch 111, Iteration 60, Current loss 0.37392130995471434 Accuracy 62.51051786124073\n",
      "Training:: Epoch 111, Iteration 70, Current loss 0.35685930201988514 Accuracy 59.112834578643714\n",
      "Training:: Epoch 111, Iteration 80, Current loss 0.2918149352411425 Accuracy 64.28571428571429\n",
      "Training:: Epoch 111, Iteration 90, Current loss 0.2558581114979276 Accuracy 70.98922738329665\n",
      "Training:: Epoch 111, Iteration 100, Current loss 0.3391353700424089 Accuracy 64.58110516934046\n",
      "Training:: Epoch 111, Iteration 110, Current loss 1.0643987892494082 Accuracy 63.0227229329769\n",
      "Training:: Epoch 111, Iteration 120, Current loss 0.7264262846132408 Accuracy 61.85430993123301\n",
      "Training:: Epoch 111, Iteration 130, Current loss 0.4302926210921484 Accuracy 63.589712629799564\n",
      "Training:: Epoch 111, Iteration 140, Current loss 0.28146058068382174 Accuracy 61.165133214145555\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 111, Probability Accuracy 54.418901430728305\n",
      "Starting Training\n",
      "Training:: Epoch 112, Iteration 0, Current loss 0.3226885569234734 Accuracy 64.22317954419121\n",
      "Training:: Epoch 112, Iteration 10, Current loss 0.39037497454553366 Accuracy 62.17000816474644\n",
      "Training:: Epoch 112, Iteration 20, Current loss 0.42168184618919247 Accuracy 68.33032576692943\n",
      "Training:: Epoch 112, Iteration 30, Current loss 0.28574806132681846 Accuracy 71.89884240989214\n",
      "Training:: Epoch 112, Iteration 40, Current loss 0.3662242260023484 Accuracy 63.60190494703081\n",
      "Training:: Epoch 112, Iteration 50, Current loss 0.2986818461509877 Accuracy 48.36516471969838\n",
      "Training:: Epoch 112, Iteration 60, Current loss 0.25448959121510056 Accuracy 57.307362489280905\n",
      "Training:: Epoch 112, Iteration 70, Current loss 0.4057911350958905 Accuracy 52.08343300004784\n",
      "Training:: Epoch 112, Iteration 80, Current loss 0.4419217850377409 Accuracy 59.42521631644005\n",
      "Training:: Epoch 112, Iteration 90, Current loss 0.30311618451714395 Accuracy 70.0108543960304\n",
      "Training:: Epoch 112, Iteration 100, Current loss 0.3575131764154822 Accuracy 65.40264523689937\n",
      "Training:: Epoch 112, Iteration 110, Current loss 1.1040978475941834 Accuracy 53.4231103388358\n",
      "Training:: Epoch 112, Iteration 120, Current loss 0.45284202078676916 Accuracy 60.8662026295437\n",
      "Training:: Epoch 112, Iteration 130, Current loss 0.2852162813704886 Accuracy 69.49000407996736\n",
      "Training:: Epoch 112, Iteration 140, Current loss 0.31684857072618877 Accuracy 61.1423825782043\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 112, Probability Accuracy 53.376656056575534\n",
      "Starting Training\n",
      "Training:: Epoch 113, Iteration 0, Current loss 0.27631936046131217 Accuracy 71.51937046004842\n",
      "Training:: Epoch 113, Iteration 10, Current loss 0.364572559782536 Accuracy 59.66522678185745\n",
      "Training:: Epoch 113, Iteration 20, Current loss 0.2538828866620669 Accuracy 65.81954993966067\n",
      "Training:: Epoch 113, Iteration 30, Current loss 0.27429837884452124 Accuracy 65.68388515722523\n",
      "Training:: Epoch 113, Iteration 40, Current loss 0.2378933865542494 Accuracy 63.89198218262806\n",
      "Training:: Epoch 113, Iteration 50, Current loss 0.2382657934193143 Accuracy 68.14269160734978\n",
      "Training:: Epoch 113, Iteration 60, Current loss 0.29624585868122855 Accuracy 60.96269851040256\n",
      "Training:: Epoch 113, Iteration 70, Current loss 0.2519482340498724 Accuracy 66.15165815501972\n",
      "Training:: Epoch 113, Iteration 80, Current loss 0.3624782650884474 Accuracy 67.42904957813262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 113, Iteration 90, Current loss 0.331359183011423 Accuracy 66.41436131020163\n",
      "Training:: Epoch 113, Iteration 100, Current loss 0.5049643435481961 Accuracy 61.93951248871502\n",
      "Training:: Epoch 113, Iteration 110, Current loss 0.48838261018745344 Accuracy 65.38442810537079\n",
      "Training:: Epoch 113, Iteration 120, Current loss 0.29844151080160464 Accuracy 60.5633215105362\n",
      "Training:: Epoch 113, Iteration 130, Current loss 0.2327651417791731 Accuracy 69.11664226451927\n",
      "Training:: Epoch 113, Iteration 140, Current loss 0.3577736182806265 Accuracy 68.11155212032588\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 113, Probability Accuracy 53.1514911862169\n",
      "Starting Training\n",
      "Training:: Epoch 114, Iteration 0, Current loss 0.40369622248747805 Accuracy 59.75103734439834\n",
      "Training:: Epoch 114, Iteration 10, Current loss 0.252186035917484 Accuracy 60.63001080343435\n",
      "Training:: Epoch 114, Iteration 20, Current loss 0.45344587376641116 Accuracy 49.062605426767554\n",
      "Training:: Epoch 114, Iteration 30, Current loss 0.4387408680170953 Accuracy 58.15914924825816\n",
      "Training:: Epoch 114, Iteration 40, Current loss 0.30966603383546965 Accuracy 72.98409598214286\n",
      "Training:: Epoch 114, Iteration 50, Current loss 0.31304696844588276 Accuracy 59.001285897985426\n",
      "Training:: Epoch 114, Iteration 60, Current loss 0.2897894617201904 Accuracy 68.73820131390168\n",
      "Training:: Epoch 114, Iteration 70, Current loss 0.20126637267020955 Accuracy 57.052780344621404\n",
      "Training:: Epoch 114, Iteration 80, Current loss 0.313622881289453 Accuracy 54.18738924141085\n",
      "Training:: Epoch 114, Iteration 90, Current loss 0.28019757941343243 Accuracy 71.06153604028958\n",
      "Training:: Epoch 114, Iteration 100, Current loss 0.3379729602488596 Accuracy 65.92236790860704\n",
      "Training:: Epoch 114, Iteration 110, Current loss 0.35760261318087716 Accuracy 64.57199854914762\n",
      "Training:: Epoch 114, Iteration 120, Current loss 0.39244618427125744 Accuracy 66.47604241852201\n",
      "Training:: Epoch 114, Iteration 130, Current loss 0.30192275913240463 Accuracy 62.44149035761093\n",
      "Training:: Epoch 114, Iteration 140, Current loss 0.33076211993650534 Accuracy 70.86819613135403\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 114, Probability Accuracy 54.51024189700586\n",
      "Starting Training\n",
      "Training:: Epoch 115, Iteration 0, Current loss 0.25405083321899724 Accuracy 61.417748917748916\n",
      "Training:: Epoch 115, Iteration 10, Current loss 0.27568750817243515 Accuracy 62.80523255813954\n",
      "Training:: Epoch 115, Iteration 20, Current loss 0.2621043638979307 Accuracy 66.33997748493478\n",
      "Training:: Epoch 115, Iteration 30, Current loss 0.37059131660077294 Accuracy 61.03903592227412\n",
      "Training:: Epoch 115, Iteration 40, Current loss 0.2699134918644327 Accuracy 61.493875112040634\n",
      "Training:: Epoch 115, Iteration 50, Current loss 0.2646540795542725 Accuracy 69.9454166901131\n",
      "Training:: Epoch 115, Iteration 60, Current loss 0.3009762540206104 Accuracy 71.2582648767782\n",
      "Training:: Epoch 115, Iteration 70, Current loss 0.24305526928455756 Accuracy 63.07051106859798\n",
      "Training:: Epoch 115, Iteration 80, Current loss 0.20777169191544637 Accuracy 67.37836891844593\n",
      "Training:: Epoch 115, Iteration 90, Current loss 0.23899800572566157 Accuracy 68.95708582834331\n",
      "Training:: Epoch 115, Iteration 100, Current loss 0.2521473200094307 Accuracy 72.54521127368467\n",
      "Training:: Epoch 115, Iteration 110, Current loss 0.3445227465619725 Accuracy 61.3036271826697\n",
      "Training:: Epoch 115, Iteration 120, Current loss 0.25872913229239836 Accuracy 72.29885057471265\n",
      "Training:: Epoch 115, Iteration 130, Current loss 0.3698778252614453 Accuracy 59.246954595791806\n",
      "Training:: Epoch 115, Iteration 140, Current loss 0.2406415038256216 Accuracy 61.56607120755807\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 115, Probability Accuracy 53.41734259701044\n",
      "Calculating Expectation\n",
      "Epoch 115 iter 0\n",
      "Epoch 115 iter 10\n",
      "Epoch 115 iter 20\n",
      "Epoch 115 iter 30\n",
      "Epoch 115 iter 40\n",
      "Epoch 115 iter 50\n",
      "Epoch 115 iter 60\n",
      "Epoch 115 iter 70\n",
      "Epoch 115 iter 80\n",
      "Epoch 115 iter 90\n",
      "Epoch 115 iter 100\n",
      "Epoch 115 iter 110\n",
      "Epoch 115 iter 120\n",
      "Epoch 115 iter 130\n",
      "Epoch 115 iter 140\n",
      "Train Boundary avergage error = 292.731\n",
      "Train From boundary avergage accuracy = 60.038\n",
      "Starting Training\n",
      "Training:: Epoch 116, Iteration 0, Current loss 0.1802597742098705 Accuracy 70.19521746869994\n",
      "Training:: Epoch 116, Iteration 10, Current loss 0.2697026054009937 Accuracy 67.47880015187951\n",
      "Training:: Epoch 116, Iteration 20, Current loss 0.26479558372827083 Accuracy 52.963343610825625\n",
      "Training:: Epoch 116, Iteration 30, Current loss 0.22577895132969256 Accuracy 60.44321568966262\n",
      "Training:: Epoch 116, Iteration 40, Current loss 0.24783553896863386 Accuracy 72.42723728352526\n",
      "Training:: Epoch 116, Iteration 50, Current loss 0.2640740657995644 Accuracy 66.48573314750972\n",
      "Training:: Epoch 116, Iteration 60, Current loss 0.2036196138047462 Accuracy 67.27263468785009\n",
      "Training:: Epoch 116, Iteration 70, Current loss 0.2208939414384242 Accuracy 62.134870203438254\n",
      "Training:: Epoch 116, Iteration 80, Current loss 0.24382288996670243 Accuracy 60.849676639150324\n",
      "Training:: Epoch 116, Iteration 90, Current loss 0.19416857131367235 Accuracy 53.48794807278562\n",
      "Training:: Epoch 116, Iteration 100, Current loss 0.341953088908154 Accuracy 61.47402302645153\n",
      "Training:: Epoch 116, Iteration 110, Current loss 0.24155637377304434 Accuracy 62.678874194642255\n",
      "Training:: Epoch 116, Iteration 120, Current loss 0.33392370998808 Accuracy 61.21870244847143\n",
      "Training:: Epoch 116, Iteration 130, Current loss 0.3056235439959649 Accuracy 63.20840950639854\n",
      "Training:: Epoch 116, Iteration 140, Current loss 0.30703265991134865 Accuracy 70.0501411536679\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 116, Probability Accuracy 53.68752410146472\n",
      "Starting Training\n",
      "Training:: Epoch 117, Iteration 0, Current loss 0.35470520499253816 Accuracy 57.81609195402299\n",
      "Training:: Epoch 117, Iteration 10, Current loss 0.320151824211949 Accuracy 67.21597518417991\n",
      "Training:: Epoch 117, Iteration 20, Current loss 0.20114204184033302 Accuracy 63.03545286741773\n",
      "Training:: Epoch 117, Iteration 30, Current loss 0.23431683147905813 Accuracy 63.99983529605534\n",
      "Training:: Epoch 117, Iteration 40, Current loss 0.2372018868667826 Accuracy 68.8180698929823\n",
      "Training:: Epoch 117, Iteration 50, Current loss 0.33782296693509306 Accuracy 58.72399605957003\n",
      "Training:: Epoch 117, Iteration 60, Current loss 0.2509636221348463 Accuracy 70.92367354133616\n",
      "Training:: Epoch 117, Iteration 70, Current loss 0.27054549545813034 Accuracy 58.941330381402835\n",
      "Training:: Epoch 117, Iteration 80, Current loss 0.2562372002830275 Accuracy 64.6801246845777\n",
      "Training:: Epoch 117, Iteration 90, Current loss 0.25047089811935747 Accuracy 69.59884500360937\n",
      "Training:: Epoch 117, Iteration 100, Current loss 0.2961364269638244 Accuracy 70.7113729043951\n",
      "Training:: Epoch 117, Iteration 110, Current loss 0.28858294983921645 Accuracy 57.94725931639589\n",
      "Training:: Epoch 117, Iteration 120, Current loss 0.25845021732014634 Accuracy 67.83074450990894\n",
      "Training:: Epoch 117, Iteration 130, Current loss 0.3239144352328955 Accuracy 61.741470613768556\n",
      "Training:: Epoch 117, Iteration 140, Current loss 0.28443674072210806 Accuracy 65.27055765595463\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 117, Probability Accuracy 52.84168523977281\n",
      "Starting Training\n",
      "Training:: Epoch 118, Iteration 0, Current loss 0.424904260393068 Accuracy 68.99045020463848\n",
      "Training:: Epoch 118, Iteration 10, Current loss 0.3090413918141729 Accuracy 54.82917214191853\n",
      "Training:: Epoch 118, Iteration 20, Current loss 0.3114414748950493 Accuracy 50.27213546298602\n",
      "Training:: Epoch 118, Iteration 30, Current loss 0.33090403532023877 Accuracy 54.91825613079019\n",
      "Training:: Epoch 118, Iteration 40, Current loss 0.26390882540763755 Accuracy 67.43505934973335\n",
      "Training:: Epoch 118, Iteration 50, Current loss 0.3165390725993667 Accuracy 61.0485011634804\n",
      "Training:: Epoch 118, Iteration 60, Current loss 0.29464100593371256 Accuracy 61.311696333314615\n",
      "Training:: Epoch 118, Iteration 70, Current loss 0.21118738979813248 Accuracy 65.82717919585937\n",
      "Training:: Epoch 118, Iteration 80, Current loss 0.36054215052180605 Accuracy 68.85050078103464\n",
      "Training:: Epoch 118, Iteration 90, Current loss 0.23988108821712287 Accuracy 60.658016682113065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 118, Iteration 100, Current loss 0.3216775244169544 Accuracy 64.42506568282185\n",
      "Training:: Epoch 118, Iteration 110, Current loss 0.31141016347344025 Accuracy 56.458871971655654\n",
      "Training:: Epoch 118, Iteration 120, Current loss 0.33879583238814903 Accuracy 53.162708477442166\n",
      "Training:: Epoch 118, Iteration 130, Current loss 0.31178811805082535 Accuracy 66.44954455244007\n",
      "Training:: Epoch 118, Iteration 140, Current loss 0.3564444916640341 Accuracy 57.261822904729165\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 118, Probability Accuracy 53.09511826874685\n",
      "Starting Training\n",
      "Training:: Epoch 119, Iteration 0, Current loss 0.2997063197275309 Accuracy 65.81984566004235\n",
      "Training:: Epoch 119, Iteration 10, Current loss 0.23342120901473962 Accuracy 64.7940074906367\n",
      "Training:: Epoch 119, Iteration 20, Current loss 0.2610383874113223 Accuracy 67.81794980859209\n",
      "Training:: Epoch 119, Iteration 30, Current loss 0.2589096053876222 Accuracy 67.71839356727702\n",
      "Training:: Epoch 119, Iteration 40, Current loss 0.29679597678881964 Accuracy 68.55494361395228\n",
      "Training:: Epoch 119, Iteration 50, Current loss 0.2284494949284509 Accuracy 59.50352629006354\n",
      "Training:: Epoch 119, Iteration 60, Current loss 0.23841058575419166 Accuracy 68.47448688085088\n",
      "Training:: Epoch 119, Iteration 70, Current loss 0.2795699064325712 Accuracy 58.61642989499691\n",
      "Training:: Epoch 119, Iteration 80, Current loss 0.2836318887317984 Accuracy 57.93954874414644\n",
      "Training:: Epoch 119, Iteration 90, Current loss 0.30272317395914006 Accuracy 57.70389989953421\n",
      "Training:: Epoch 119, Iteration 100, Current loss 0.7018402900933927 Accuracy 67.78806130943636\n",
      "Training:: Epoch 119, Iteration 110, Current loss 0.2452674300338975 Accuracy 70.18190910795774\n",
      "Training:: Epoch 119, Iteration 120, Current loss 0.3472623880536621 Accuracy 64.22748815165876\n",
      "Training:: Epoch 119, Iteration 130, Current loss 0.4218154876284599 Accuracy 68.81955278211129\n",
      "Training:: Epoch 119, Iteration 140, Current loss 0.48925196172305535 Accuracy 60.9117840684661\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 119, Probability Accuracy 53.74267152072889\n",
      "Starting Training\n",
      "Training:: Epoch 120, Iteration 0, Current loss 0.37450901213734955 Accuracy 65.16590878393589\n",
      "Training:: Epoch 120, Iteration 10, Current loss 0.23157610289454472 Accuracy 61.43966547192353\n",
      "Training:: Epoch 120, Iteration 20, Current loss 0.3175883939297668 Accuracy 68.51136042236259\n",
      "Training:: Epoch 120, Iteration 30, Current loss 0.24840976178440344 Accuracy 63.953894516241704\n",
      "Training:: Epoch 120, Iteration 40, Current loss 0.35338418323329135 Accuracy 55.519963390916374\n",
      "Training:: Epoch 120, Iteration 50, Current loss 0.3204312334166438 Accuracy 66.63435218978103\n",
      "Training:: Epoch 120, Iteration 60, Current loss 0.26303140822811455 Accuracy 70.7785946727733\n",
      "Training:: Epoch 120, Iteration 70, Current loss 0.26920809569358056 Accuracy 59.2095385294767\n",
      "Training:: Epoch 120, Iteration 80, Current loss 0.26711690490941925 Accuracy 63.55436991869919\n",
      "Training:: Epoch 120, Iteration 90, Current loss 0.2945629241336991 Accuracy 62.08661614894364\n",
      "Training:: Epoch 120, Iteration 100, Current loss 0.3039935906340963 Accuracy 64.01592215833702\n",
      "Training:: Epoch 120, Iteration 110, Current loss 0.3480078643673009 Accuracy 56.00826499644864\n",
      "Training:: Epoch 120, Iteration 120, Current loss 0.45967384763806496 Accuracy 63.9504054897068\n",
      "Training:: Epoch 120, Iteration 130, Current loss 0.30466499747413955 Accuracy 65.85154520073168\n",
      "Training:: Epoch 120, Iteration 140, Current loss 0.1998826283145354 Accuracy 67.99744781697201\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 120, Probability Accuracy 53.35092059425225\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.69522326064382\n",
      "Calculating Expectation\n",
      "Epoch 120 iter 0\n",
      "Epoch 120 iter 10\n",
      "Epoch 120 iter 20\n",
      "Epoch 120 iter 30\n",
      "Epoch 120 iter 40\n",
      "Epoch 120 iter 50\n",
      "Epoch 120 iter 60\n",
      "Epoch 120 iter 70\n",
      "Epoch 120 iter 80\n",
      "Epoch 120 iter 90\n",
      "Epoch 120 iter 100\n",
      "Epoch 120 iter 110\n",
      "Epoch 120 iter 120\n",
      "Epoch 120 iter 130\n",
      "Epoch 120 iter 140\n",
      "Train Boundary avergage error = 292.579\n",
      "Train From boundary avergage accuracy = 60.028\n",
      "Starting Training\n",
      "Training:: Epoch 121, Iteration 0, Current loss 0.23171963628635245 Accuracy 63.755750731911334\n",
      "Training:: Epoch 121, Iteration 10, Current loss 0.2701017537143832 Accuracy 69.59449001702522\n",
      "Training:: Epoch 121, Iteration 20, Current loss 0.3606547459475457 Accuracy 66.92612942612942\n",
      "Training:: Epoch 121, Iteration 30, Current loss 0.3905281556280824 Accuracy 66.95701679476231\n",
      "Training:: Epoch 121, Iteration 40, Current loss 2.454827584293802 Accuracy 58.601671545543255\n",
      "Training:: Epoch 121, Iteration 50, Current loss 6.555639237143755 Accuracy 39.70204841713222\n",
      "Training:: Epoch 121, Iteration 60, Current loss 3.6580197855453833 Accuracy 55.449006622516556\n",
      "Training:: Epoch 121, Iteration 70, Current loss 2.838874971218811 Accuracy 55.89603485195304\n",
      "Training:: Epoch 121, Iteration 80, Current loss 2.028030822254042 Accuracy 56.93696724988784\n",
      "Training:: Epoch 121, Iteration 90, Current loss 2.4751945475050445 Accuracy 55.883161890092964\n",
      "Training:: Epoch 121, Iteration 100, Current loss 2.049006004108514 Accuracy 71.13724746277151\n",
      "Training:: Epoch 121, Iteration 110, Current loss 1.9453652612201797 Accuracy 59.82480350392992\n",
      "Training:: Epoch 121, Iteration 120, Current loss 2.0893605686659322 Accuracy 64.11162133521724\n",
      "Training:: Epoch 121, Iteration 130, Current loss 1.1543892804438247 Accuracy 68.38647770888691\n",
      "Training:: Epoch 121, Iteration 140, Current loss 0.9073252190730752 Accuracy 60.456057778138444\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 121, Probability Accuracy 46.594095386244355\n",
      "Starting Training\n",
      "Training:: Epoch 122, Iteration 0, Current loss 0.8784425857989389 Accuracy 65.51126516464471\n",
      "Training:: Epoch 122, Iteration 10, Current loss 1.7584446670501475 Accuracy 68.84911100432484\n",
      "Training:: Epoch 122, Iteration 20, Current loss 2.138508177828945 Accuracy 48.33984981071185\n",
      "Training:: Epoch 122, Iteration 30, Current loss 0.9653880916979282 Accuracy 50.06355547485019\n",
      "Training:: Epoch 122, Iteration 40, Current loss 1.4135217044759065 Accuracy 48.48042199229052\n",
      "Training:: Epoch 122, Iteration 50, Current loss 0.8090467306835452 Accuracy 71.99102407180743\n",
      "Training:: Epoch 122, Iteration 60, Current loss 0.9069774103159697 Accuracy 64.14120682577845\n",
      "Training:: Epoch 122, Iteration 70, Current loss 0.7949866251923603 Accuracy 64.96033328901298\n",
      "Training:: Epoch 122, Iteration 80, Current loss 0.7771889792780633 Accuracy 67.26437892701789\n",
      "Training:: Epoch 122, Iteration 90, Current loss 0.7684728063762922 Accuracy 56.04150504266874\n",
      "Training:: Epoch 122, Iteration 100, Current loss 0.45359028239201044 Accuracy 58.75422455876831\n",
      "Training:: Epoch 122, Iteration 110, Current loss 1.0053903037121368 Accuracy 63.691902252036414\n",
      "Training:: Epoch 122, Iteration 120, Current loss 0.6034590595466821 Accuracy 52.869042110134195\n",
      "Training:: Epoch 122, Iteration 130, Current loss 0.4259446182658758 Accuracy 62.99126637554585\n",
      "Training:: Epoch 122, Iteration 140, Current loss 0.6185324379990302 Accuracy 68.30135704258306\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 122, Probability Accuracy 52.39331629618494\n",
      "Starting Training\n",
      "Training:: Epoch 123, Iteration 0, Current loss 0.41252171696171164 Accuracy 62.87813681677552\n",
      "Training:: Epoch 123, Iteration 10, Current loss 0.5442688710617013 Accuracy 60.86748429554292\n",
      "Training:: Epoch 123, Iteration 20, Current loss 0.3414198937246153 Accuracy 66.93616661022689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 123, Iteration 30, Current loss 0.4578019353677565 Accuracy 64.60176991150442\n",
      "Training:: Epoch 123, Iteration 40, Current loss 0.49441214662424177 Accuracy 72.07018318252041\n",
      "Training:: Epoch 123, Iteration 50, Current loss 0.660570120032757 Accuracy 58.86407912483141\n",
      "Training:: Epoch 123, Iteration 60, Current loss 0.30377675723113 Accuracy 72.13437590501013\n",
      "Training:: Epoch 123, Iteration 70, Current loss 0.3875562016892188 Accuracy 61.869253601679574\n",
      "Training:: Epoch 123, Iteration 80, Current loss 0.5501961735688352 Accuracy 60.82503355230628\n",
      "Training:: Epoch 123, Iteration 90, Current loss 0.4033298319895361 Accuracy 59.679015837104075\n",
      "Training:: Epoch 123, Iteration 100, Current loss 0.5361009691253212 Accuracy 64.75710748740715\n",
      "Training:: Epoch 123, Iteration 110, Current loss 0.3892304327088991 Accuracy 66.2253183244141\n",
      "Training:: Epoch 123, Iteration 120, Current loss 0.3480294530051366 Accuracy 50.08771433421991\n",
      "Training:: Epoch 123, Iteration 130, Current loss 0.3769215887165717 Accuracy 73.21570859419465\n",
      "Training:: Epoch 123, Iteration 140, Current loss 0.3084382871851572 Accuracy 72.43792599805258\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 123, Probability Accuracy 53.03466035725724\n",
      "Starting Training\n",
      "Training:: Epoch 124, Iteration 0, Current loss 0.354511400535564 Accuracy 57.41727107887579\n",
      "Training:: Epoch 124, Iteration 10, Current loss 0.33678845633649773 Accuracy 64.27047212590024\n",
      "Training:: Epoch 124, Iteration 20, Current loss 0.3067841140663327 Accuracy 65.72350327903533\n",
      "Training:: Epoch 124, Iteration 30, Current loss 0.3012672665251222 Accuracy 65.84833284154618\n",
      "Training:: Epoch 124, Iteration 40, Current loss 0.31686036553261543 Accuracy 72.61835524020007\n",
      "Training:: Epoch 124, Iteration 50, Current loss 0.3774461910964643 Accuracy 58.56829938947663\n",
      "Training:: Epoch 124, Iteration 60, Current loss 0.4327569686438821 Accuracy 66.84146455660643\n",
      "Training:: Epoch 124, Iteration 70, Current loss 0.31231668223205866 Accuracy 68.48305119650728\n",
      "Training:: Epoch 124, Iteration 80, Current loss 0.33321928599077716 Accuracy 62.51456608402331\n",
      "Training:: Epoch 124, Iteration 90, Current loss 0.30018559254406857 Accuracy 49.39888164026095\n",
      "Training:: Epoch 124, Iteration 100, Current loss 0.35925543327059406 Accuracy 60.18564444129526\n",
      "Training:: Epoch 124, Iteration 110, Current loss 0.3046217219417412 Accuracy 55.855998313303814\n",
      "Training:: Epoch 124, Iteration 120, Current loss 0.37408925505155655 Accuracy 66.10866653912377\n",
      "Training:: Epoch 124, Iteration 130, Current loss 0.33134811574678824 Accuracy 64.21899994839775\n",
      "Training:: Epoch 124, Iteration 140, Current loss 0.333267511490759 Accuracy 70.85295424255887\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 124, Probability Accuracy 53.542670213530805\n",
      "Starting Training\n",
      "Training:: Epoch 125, Iteration 0, Current loss 0.3787434189955635 Accuracy 65.39709408943433\n",
      "Training:: Epoch 125, Iteration 10, Current loss 0.37250971114473863 Accuracy 59.153430812280774\n",
      "Training:: Epoch 125, Iteration 20, Current loss 0.3677690094763211 Accuracy 72.24288556353257\n",
      "Training:: Epoch 125, Iteration 30, Current loss 0.39082543583735063 Accuracy 54.18173243200754\n",
      "Training:: Epoch 125, Iteration 40, Current loss 0.3445335252069296 Accuracy 56.03896639973582\n",
      "Training:: Epoch 125, Iteration 50, Current loss 0.2870336587143716 Accuracy 64.16061820676705\n",
      "Training:: Epoch 125, Iteration 60, Current loss 0.2920222701552805 Accuracy 63.77929970097424\n",
      "Training:: Epoch 125, Iteration 70, Current loss 0.2952562130890063 Accuracy 64.91521642124052\n",
      "Training:: Epoch 125, Iteration 80, Current loss 0.3211924346297653 Accuracy 65.67432657282907\n",
      "Training:: Epoch 125, Iteration 90, Current loss 0.3007254290322503 Accuracy 58.0972329401389\n",
      "Training:: Epoch 125, Iteration 100, Current loss 0.3711502111642073 Accuracy 56.80923098182823\n",
      "Training:: Epoch 125, Iteration 110, Current loss 0.279521461111133 Accuracy 68.98876404494382\n",
      "Training:: Epoch 125, Iteration 120, Current loss 0.3768600053592801 Accuracy 66.97656018198002\n",
      "Training:: Epoch 125, Iteration 130, Current loss 0.3055809262255558 Accuracy 63.95324566896264\n",
      "Training:: Epoch 125, Iteration 140, Current loss 0.2576263743481917 Accuracy 64.34767370542365\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 125, Probability Accuracy 53.534908724893626\n",
      "Calculating Expectation\n",
      "Epoch 125 iter 0\n",
      "Epoch 125 iter 10\n",
      "Epoch 125 iter 20\n",
      "Epoch 125 iter 30\n",
      "Epoch 125 iter 40\n",
      "Epoch 125 iter 50\n",
      "Epoch 125 iter 60\n",
      "Epoch 125 iter 70\n",
      "Epoch 125 iter 80\n",
      "Epoch 125 iter 90\n",
      "Epoch 125 iter 100\n",
      "Epoch 125 iter 110\n",
      "Epoch 125 iter 120\n",
      "Epoch 125 iter 130\n",
      "Epoch 125 iter 140\n",
      "Train Boundary avergage error = 292.454\n",
      "Train From boundary avergage accuracy = 60.033\n",
      "Starting Training\n",
      "Training:: Epoch 126, Iteration 0, Current loss 0.2290848767174772 Accuracy 63.13437357976064\n",
      "Training:: Epoch 126, Iteration 10, Current loss 0.24748256826314208 Accuracy 56.85988798324302\n",
      "Training:: Epoch 126, Iteration 20, Current loss 0.3788287147280666 Accuracy 63.45579329834477\n",
      "Training:: Epoch 126, Iteration 30, Current loss 0.2546803745854426 Accuracy 64.42081408524362\n",
      "Training:: Epoch 126, Iteration 40, Current loss 0.25002157195144975 Accuracy 69.45815668738022\n",
      "Training:: Epoch 126, Iteration 50, Current loss 0.28381481597505676 Accuracy 61.09931444518595\n",
      "Training:: Epoch 126, Iteration 60, Current loss 0.24732674123979106 Accuracy 49.462035044574236\n",
      "Training:: Epoch 126, Iteration 70, Current loss 0.22522955219317775 Accuracy 57.43080363625803\n",
      "Training:: Epoch 126, Iteration 80, Current loss 0.2435084139545615 Accuracy 64.78698157983953\n",
      "Training:: Epoch 126, Iteration 90, Current loss 0.28305371334994284 Accuracy 61.287272268801615\n",
      "Training:: Epoch 126, Iteration 100, Current loss 0.21421479153033088 Accuracy 63.88694823753573\n",
      "Training:: Epoch 126, Iteration 110, Current loss 0.22562892123801115 Accuracy 60.80574640849469\n",
      "Training:: Epoch 126, Iteration 120, Current loss 0.23807705672302554 Accuracy 76.15265401007362\n",
      "Training:: Epoch 126, Iteration 130, Current loss 0.18409337106615156 Accuracy 74.31641408066714\n",
      "Training:: Epoch 126, Iteration 140, Current loss 0.27495185255859433 Accuracy 47.466374726305915\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 126, Probability Accuracy 53.56726187752861\n",
      "Starting Training\n",
      "Training:: Epoch 127, Iteration 0, Current loss 0.17027123371853023 Accuracy 69.40053145971265\n",
      "Training:: Epoch 127, Iteration 10, Current loss 0.27075196273371116 Accuracy 66.10230118039823\n",
      "Training:: Epoch 127, Iteration 20, Current loss 0.2299353880962477 Accuracy 59.34535104364326\n",
      "Training:: Epoch 127, Iteration 30, Current loss 0.25202571077169744 Accuracy 62.39301609038001\n",
      "Training:: Epoch 127, Iteration 40, Current loss 0.32820167099020814 Accuracy 66.89189189189189\n",
      "Training:: Epoch 127, Iteration 50, Current loss 0.2878064565656864 Accuracy 61.56703218960028\n",
      "Training:: Epoch 127, Iteration 60, Current loss 0.35975063100589727 Accuracy 59.882521035084935\n",
      "Training:: Epoch 127, Iteration 70, Current loss 0.32103152390002543 Accuracy 69.76533272871556\n",
      "Training:: Epoch 127, Iteration 80, Current loss 0.2565175737454374 Accuracy 70.00969663388281\n",
      "Training:: Epoch 127, Iteration 90, Current loss 0.3016159155936732 Accuracy 61.223946194313115\n",
      "Training:: Epoch 127, Iteration 100, Current loss 0.2923812133704452 Accuracy 68.25627957772114\n",
      "Training:: Epoch 127, Iteration 110, Current loss 0.2307154441014967 Accuracy 70.01757469244288\n",
      "Training:: Epoch 127, Iteration 120, Current loss 0.22564438833012243 Accuracy 62.132891635344336\n",
      "Training:: Epoch 127, Iteration 130, Current loss 0.2833841442956563 Accuracy 58.89443059019119\n",
      "Training:: Epoch 127, Iteration 140, Current loss 0.3427566653110626 Accuracy 58.20858127153147\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 127, Probability Accuracy 53.43270217452402\n",
      "Starting Training\n",
      "Training:: Epoch 128, Iteration 0, Current loss 0.22333348018513724 Accuracy 59.24448615673393\n",
      "Training:: Epoch 128, Iteration 10, Current loss 0.2601762563112525 Accuracy 70.73250848571115\n",
      "Training:: Epoch 128, Iteration 20, Current loss 0.2280338987420758 Accuracy 74.49560269011899\n",
      "Training:: Epoch 128, Iteration 30, Current loss 0.3139524202502803 Accuracy 59.95547381666828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 128, Iteration 40, Current loss 0.28393731155213686 Accuracy 60.86927845930616\n",
      "Training:: Epoch 128, Iteration 50, Current loss 0.22650679210806812 Accuracy 66.54442209866319\n",
      "Training:: Epoch 128, Iteration 60, Current loss 0.2607433163691399 Accuracy 61.524155137219324\n",
      "Training:: Epoch 128, Iteration 70, Current loss 0.23637249119473686 Accuracy 72.18487977271153\n",
      "Training:: Epoch 128, Iteration 80, Current loss 0.3485084466623647 Accuracy 52.82165368928439\n",
      "Training:: Epoch 128, Iteration 90, Current loss 0.20595799140584395 Accuracy 67.39788199697428\n",
      "Training:: Epoch 128, Iteration 100, Current loss 0.22182023093502476 Accuracy 72.39450940518556\n",
      "Training:: Epoch 128, Iteration 110, Current loss 0.4783390625068689 Accuracy 71.37530819652414\n",
      "Training:: Epoch 128, Iteration 120, Current loss 0.17531933542419936 Accuracy 63.34653159870417\n",
      "Training:: Epoch 128, Iteration 130, Current loss 0.2564299754972214 Accuracy 69.4698485281509\n",
      "Training:: Epoch 128, Iteration 140, Current loss 0.2495116419650628 Accuracy 64.16821004466718\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 128, Probability Accuracy 53.43564337021811\n",
      "Starting Training\n",
      "Training:: Epoch 129, Iteration 0, Current loss 0.1968058478174608 Accuracy 73.0259900990099\n",
      "Training:: Epoch 129, Iteration 10, Current loss 0.2829389484487243 Accuracy 64.49779633495709\n",
      "Training:: Epoch 129, Iteration 20, Current loss 0.27172653451115913 Accuracy 63.89394538979027\n",
      "Training:: Epoch 129, Iteration 30, Current loss 0.19362953961318838 Accuracy 62.19326818675353\n",
      "Training:: Epoch 129, Iteration 40, Current loss 0.24404088222602008 Accuracy 54.36286006374406\n",
      "Training:: Epoch 129, Iteration 50, Current loss 0.16742225419494666 Accuracy 73.63016210665297\n",
      "Training:: Epoch 129, Iteration 60, Current loss 0.19817143361883416 Accuracy 70.00298240381748\n",
      "Training:: Epoch 129, Iteration 70, Current loss 0.2782556743309276 Accuracy 66.44732285100783\n",
      "Training:: Epoch 129, Iteration 80, Current loss 0.37725816784646904 Accuracy 53.973684210526315\n",
      "Training:: Epoch 129, Iteration 90, Current loss 0.23030096422429003 Accuracy 58.18758609174771\n",
      "Training:: Epoch 129, Iteration 100, Current loss 0.21376541861557502 Accuracy 63.53661932609301\n",
      "Training:: Epoch 129, Iteration 110, Current loss 0.3081371603544807 Accuracy 54.0398740818468\n",
      "Training:: Epoch 129, Iteration 120, Current loss 0.26235994108652116 Accuracy 57.28487614080834\n",
      "Training:: Epoch 129, Iteration 130, Current loss 0.2554715633564744 Accuracy 60.68469028382018\n",
      "Training:: Epoch 129, Iteration 140, Current loss 0.18882536919924003 Accuracy 64.46818046011353\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 129, Probability Accuracy 53.34618200118955\n",
      "Starting Training\n",
      "Training:: Epoch 130, Iteration 0, Current loss 0.27165071741792424 Accuracy 52.73972602739726\n",
      "Training:: Epoch 130, Iteration 10, Current loss 0.18907265356536918 Accuracy 64.78265804108501\n",
      "Training:: Epoch 130, Iteration 20, Current loss 0.25342604017224224 Accuracy 56.05774569683509\n",
      "Training:: Epoch 130, Iteration 30, Current loss 0.2767368690493888 Accuracy 61.51879947229551\n",
      "Training:: Epoch 130, Iteration 40, Current loss 0.2494882099247044 Accuracy 65.64601769911505\n",
      "Training:: Epoch 130, Iteration 50, Current loss 0.21883028372215632 Accuracy 66.40762327689887\n",
      "Training:: Epoch 130, Iteration 60, Current loss 0.2872683667610966 Accuracy 57.53683415187004\n",
      "Training:: Epoch 130, Iteration 70, Current loss 0.22513605612584314 Accuracy 73.1598926025368\n",
      "Training:: Epoch 130, Iteration 80, Current loss 0.2423087920256206 Accuracy 66.9425537707596\n",
      "Training:: Epoch 130, Iteration 90, Current loss 0.24576129986724393 Accuracy 62.74240818108125\n",
      "Training:: Epoch 130, Iteration 100, Current loss 0.2643819888442244 Accuracy 66.44063376149181\n",
      "Training:: Epoch 130, Iteration 110, Current loss 0.22630437111120094 Accuracy 70.96793036976459\n",
      "Training:: Epoch 130, Iteration 120, Current loss 0.28197179134226463 Accuracy 65.44579321892004\n",
      "Training:: Epoch 130, Iteration 130, Current loss 0.1810387927897584 Accuracy 73.7864077669903\n",
      "Training:: Epoch 130, Iteration 140, Current loss 0.2468593091364755 Accuracy 58.88501742160279\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 130, Probability Accuracy 53.62020340002222\n",
      "Calculating Expectation\n",
      "Epoch 130 iter 0\n",
      "Epoch 130 iter 10\n",
      "Epoch 130 iter 20\n",
      "Epoch 130 iter 30\n",
      "Epoch 130 iter 40\n",
      "Epoch 130 iter 50\n",
      "Epoch 130 iter 60\n",
      "Epoch 130 iter 70\n",
      "Epoch 130 iter 80\n",
      "Epoch 130 iter 90\n",
      "Epoch 130 iter 100\n",
      "Epoch 130 iter 110\n",
      "Epoch 130 iter 120\n",
      "Epoch 130 iter 130\n",
      "Epoch 130 iter 140\n",
      "Train Boundary avergage error = 292.429\n",
      "Train From boundary avergage accuracy = 60.034\n",
      "Starting Training\n",
      "Training:: Epoch 131, Iteration 0, Current loss 0.1940723479106933 Accuracy 65.31015157304802\n",
      "Training:: Epoch 131, Iteration 10, Current loss 0.18393904459249144 Accuracy 62.61671243624951\n",
      "Training:: Epoch 131, Iteration 20, Current loss 0.20998615025241163 Accuracy 63.8119879258301\n",
      "Training:: Epoch 131, Iteration 30, Current loss 0.3279313604936557 Accuracy 73.4078940224768\n",
      "Training:: Epoch 131, Iteration 40, Current loss 0.21832941213628992 Accuracy 65.04959422903516\n",
      "Training:: Epoch 131, Iteration 50, Current loss 0.2107729366681841 Accuracy 59.7530754934065\n",
      "Training:: Epoch 131, Iteration 60, Current loss 0.25202613266985097 Accuracy 62.65243902439025\n",
      "Training:: Epoch 131, Iteration 70, Current loss 0.2147945608228179 Accuracy 56.06105956300509\n",
      "Training:: Epoch 131, Iteration 80, Current loss 0.2398530077451814 Accuracy 67.52800597460792\n",
      "Training:: Epoch 131, Iteration 90, Current loss 0.23207751361126994 Accuracy 69.01384667342114\n",
      "Training:: Epoch 131, Iteration 100, Current loss 0.2671185255806711 Accuracy 58.408459296414286\n",
      "Training:: Epoch 131, Iteration 110, Current loss 0.22945034535566441 Accuracy 66.93719806763285\n",
      "Training:: Epoch 131, Iteration 120, Current loss 0.20215541855351235 Accuracy 62.011368605159596\n",
      "Training:: Epoch 131, Iteration 130, Current loss 0.2110200987663063 Accuracy 57.18326062988351\n",
      "Training:: Epoch 131, Iteration 140, Current loss 0.2089172993913537 Accuracy 62.59860576041093\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 131, Probability Accuracy 53.314972646880044\n",
      "Starting Training\n",
      "Training:: Epoch 132, Iteration 0, Current loss 0.20046528059996374 Accuracy 58.8235294117647\n",
      "Training:: Epoch 132, Iteration 10, Current loss 0.203732025174345 Accuracy 67.43176178660049\n",
      "Training:: Epoch 132, Iteration 20, Current loss 0.1817217869220592 Accuracy 61.82036079222909\n",
      "Training:: Epoch 132, Iteration 30, Current loss 0.22084635785811946 Accuracy 63.4100201379142\n",
      "Training:: Epoch 132, Iteration 40, Current loss 0.17685881239886692 Accuracy 61.53990024937656\n",
      "Training:: Epoch 132, Iteration 50, Current loss 0.21885444347509242 Accuracy 61.768666766422264\n",
      "Training:: Epoch 132, Iteration 60, Current loss 0.21070499176717183 Accuracy 69.80728051391863\n",
      "Training:: Epoch 132, Iteration 70, Current loss 0.1691903016142313 Accuracy 66.23191227045616\n",
      "Training:: Epoch 132, Iteration 80, Current loss 0.1880207621748917 Accuracy 53.83073839987668\n",
      "Training:: Epoch 132, Iteration 90, Current loss 0.1959132475692787 Accuracy 57.84443854526148\n",
      "Training:: Epoch 132, Iteration 100, Current loss 0.24147694706759415 Accuracy 66.22929522572264\n",
      "Training:: Epoch 132, Iteration 110, Current loss 0.17941669904764035 Accuracy 69.39902687064394\n",
      "Training:: Epoch 132, Iteration 120, Current loss 0.17735683171132688 Accuracy 60.69008009858287\n",
      "Training:: Epoch 132, Iteration 130, Current loss 0.38521506845486764 Accuracy 54.13364872856298\n",
      "Training:: Epoch 132, Iteration 140, Current loss 0.19698638283507114 Accuracy 63.64341085271318\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 132, Probability Accuracy 53.23637736194354\n",
      "Starting Training\n",
      "Training:: Epoch 133, Iteration 0, Current loss 0.2799027550934131 Accuracy 70.05347593582887\n",
      "Training:: Epoch 133, Iteration 10, Current loss 0.2208251831249057 Accuracy 63.593350383631716\n",
      "Training:: Epoch 133, Iteration 20, Current loss 0.3236274845923033 Accuracy 52.14132762312634\n",
      "Training:: Epoch 133, Iteration 30, Current loss 0.31580532248029247 Accuracy 75.64981949458483\n",
      "Training:: Epoch 133, Iteration 40, Current loss 0.23273093985568125 Accuracy 61.06571936056838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 133, Iteration 50, Current loss 0.21141394882008693 Accuracy 57.985339848956016\n",
      "Training:: Epoch 133, Iteration 60, Current loss 0.1883705769155963 Accuracy 72.02450058048761\n",
      "Training:: Epoch 133, Iteration 70, Current loss 0.2082813394136704 Accuracy 56.88700918964077\n",
      "Training:: Epoch 133, Iteration 80, Current loss 0.24121537249823935 Accuracy 64.9319022278344\n",
      "Training:: Epoch 133, Iteration 90, Current loss 0.19338715251874808 Accuracy 55.03366817529529\n",
      "Training:: Epoch 133, Iteration 100, Current loss 0.24668024275023848 Accuracy 51.635883905013195\n",
      "Training:: Epoch 133, Iteration 110, Current loss 0.24408442996201182 Accuracy 52.299790928097444\n",
      "Training:: Epoch 133, Iteration 120, Current loss 0.36969954213908524 Accuracy 58.07782418254049\n",
      "Training:: Epoch 133, Iteration 130, Current loss 0.3213811248958726 Accuracy 70.16301100964411\n",
      "Training:: Epoch 133, Iteration 140, Current loss 0.33373768878601906 Accuracy 60.87178613996254\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 133, Probability Accuracy 53.542588513650415\n",
      "Starting Training\n",
      "Training:: Epoch 134, Iteration 0, Current loss 0.2327390521346891 Accuracy 67.11163268299839\n",
      "Training:: Epoch 134, Iteration 10, Current loss 0.30342649521265064 Accuracy 58.59501765772645\n",
      "Training:: Epoch 134, Iteration 20, Current loss 0.23911011824815476 Accuracy 72.13432638491032\n",
      "Training:: Epoch 134, Iteration 30, Current loss 0.2533100764481283 Accuracy 59.208658063294735\n",
      "Training:: Epoch 134, Iteration 40, Current loss 0.3502482802439748 Accuracy 60.67193675889328\n",
      "Training:: Epoch 134, Iteration 50, Current loss 0.20327290627187214 Accuracy 58.27069777877496\n",
      "Training:: Epoch 134, Iteration 60, Current loss 0.23684766869750984 Accuracy 57.014737250339344\n",
      "Training:: Epoch 134, Iteration 70, Current loss 0.17793004782736382 Accuracy 52.69392663860493\n",
      "Training:: Epoch 134, Iteration 80, Current loss 0.1928505856044829 Accuracy 72.27462940634088\n",
      "Training:: Epoch 134, Iteration 90, Current loss 0.2141345063589397 Accuracy 64.0011561250542\n",
      "Training:: Epoch 134, Iteration 100, Current loss 0.31677978149617547 Accuracy 55.34009998485078\n",
      "Training:: Epoch 134, Iteration 110, Current loss 0.2232317700890239 Accuracy 53.36903781012543\n",
      "Training:: Epoch 134, Iteration 120, Current loss 0.2486837220586852 Accuracy 62.075848303393215\n",
      "Training:: Epoch 134, Iteration 130, Current loss 0.2387962799603952 Accuracy 67.97595692282005\n",
      "Training:: Epoch 134, Iteration 140, Current loss 0.24714343393859972 Accuracy 68.09767625049231\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 134, Probability Accuracy 52.651079418819734\n",
      "Starting Training\n",
      "Training:: Epoch 135, Iteration 0, Current loss 0.249409676217802 Accuracy 72.50797822414117\n",
      "Training:: Epoch 135, Iteration 10, Current loss 0.266905309939348 Accuracy 55.40711796388214\n",
      "Training:: Epoch 135, Iteration 20, Current loss 0.22367531218318057 Accuracy 58.19617394037004\n",
      "Training:: Epoch 135, Iteration 30, Current loss 0.3458086816398115 Accuracy 62.32345849121598\n",
      "Training:: Epoch 135, Iteration 40, Current loss 0.27742297598313137 Accuracy 59.598957288951276\n",
      "Training:: Epoch 135, Iteration 50, Current loss 0.2063793208223932 Accuracy 72.31807474374483\n",
      "Training:: Epoch 135, Iteration 60, Current loss 0.24956969111598365 Accuracy 68.94804807787821\n",
      "Training:: Epoch 135, Iteration 70, Current loss 0.18948923944131796 Accuracy 66.82722652227353\n",
      "Training:: Epoch 135, Iteration 80, Current loss 0.45758525341064465 Accuracy 70.05799502899751\n",
      "Training:: Epoch 135, Iteration 90, Current loss 0.2354835792080166 Accuracy 68.91891891891892\n",
      "Training:: Epoch 135, Iteration 100, Current loss 0.20446838081523522 Accuracy 56.736819266652205\n",
      "Training:: Epoch 135, Iteration 110, Current loss 0.27090076200003793 Accuracy 65.00708793333047\n",
      "Training:: Epoch 135, Iteration 120, Current loss 0.20554757428721337 Accuracy 67.7778457398006\n",
      "Training:: Epoch 135, Iteration 130, Current loss 0.276045480039524 Accuracy 62.449415896770255\n",
      "Training:: Epoch 135, Iteration 140, Current loss 0.24115712415969667 Accuracy 61.88131868131868\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 135, Probability Accuracy 53.27077301158831\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.72118380062305\n",
      "Calculating Expectation\n",
      "Epoch 135 iter 0\n",
      "Epoch 135 iter 10\n",
      "Epoch 135 iter 20\n",
      "Epoch 135 iter 30\n",
      "Epoch 135 iter 40\n",
      "Epoch 135 iter 50\n",
      "Epoch 135 iter 60\n",
      "Epoch 135 iter 70\n",
      "Epoch 135 iter 80\n",
      "Epoch 135 iter 90\n",
      "Epoch 135 iter 100\n",
      "Epoch 135 iter 110\n",
      "Epoch 135 iter 120\n",
      "Epoch 135 iter 130\n",
      "Epoch 135 iter 140\n",
      "Train Boundary avergage error = 292.456\n",
      "Train From boundary avergage accuracy = 59.972\n",
      "Starting Training\n",
      "Training:: Epoch 136, Iteration 0, Current loss 0.1912254696272816 Accuracy 58.91326389528989\n",
      "Training:: Epoch 136, Iteration 10, Current loss 0.14761721883391365 Accuracy 59.95516081745279\n",
      "Training:: Epoch 136, Iteration 20, Current loss 0.18467346486763359 Accuracy 71.9876160990712\n",
      "Training:: Epoch 136, Iteration 30, Current loss 0.1577010695521356 Accuracy 64.14067278287462\n",
      "Training:: Epoch 136, Iteration 40, Current loss 0.14928972236249796 Accuracy 69.01193025390027\n",
      "Training:: Epoch 136, Iteration 50, Current loss 0.18611479457773064 Accuracy 64.51218802722671\n",
      "Training:: Epoch 136, Iteration 60, Current loss 0.20657170448138434 Accuracy 63.12209500056683\n",
      "Training:: Epoch 136, Iteration 70, Current loss 0.284093236465063 Accuracy 53.82775119617225\n",
      "Training:: Epoch 136, Iteration 80, Current loss 0.18633236943194176 Accuracy 74.4636251541307\n",
      "Training:: Epoch 136, Iteration 90, Current loss 0.23126945738726642 Accuracy 58.36903809030557\n",
      "Training:: Epoch 136, Iteration 100, Current loss 0.2619900942398772 Accuracy 62.71691766684504\n",
      "Training:: Epoch 136, Iteration 110, Current loss 0.21958949119737758 Accuracy 58.34637825530098\n",
      "Training:: Epoch 136, Iteration 120, Current loss 0.2049243500133676 Accuracy 63.78162450066578\n",
      "Training:: Epoch 136, Iteration 130, Current loss 0.13799018065580057 Accuracy 62.98442026148908\n",
      "Training:: Epoch 136, Iteration 140, Current loss 0.151788625423311 Accuracy 64.73679987160969\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 136, Probability Accuracy 53.259498428094304\n",
      "Starting Training\n",
      "Training:: Epoch 137, Iteration 0, Current loss 0.19356968433600488 Accuracy 71.48494983277592\n",
      "Training:: Epoch 137, Iteration 10, Current loss 0.27035744093396835 Accuracy 62.105082417582416\n",
      "Training:: Epoch 137, Iteration 20, Current loss 0.1697505649241819 Accuracy 68.62144838802257\n",
      "Training:: Epoch 137, Iteration 30, Current loss 0.30560905087371354 Accuracy 63.801442511667375\n",
      "Training:: Epoch 137, Iteration 40, Current loss 0.1825825052514174 Accuracy 63.295722465476594\n",
      "Training:: Epoch 137, Iteration 50, Current loss 0.24554877922172316 Accuracy 55.0148334094021\n",
      "Training:: Epoch 137, Iteration 60, Current loss 0.21256230083804803 Accuracy 58.88106240746556\n",
      "Training:: Epoch 137, Iteration 70, Current loss 0.3459492105067809 Accuracy 72.26302112755621\n",
      "Training:: Epoch 137, Iteration 80, Current loss 0.19814905025198673 Accuracy 68.91169181268751\n",
      "Training:: Epoch 137, Iteration 90, Current loss 0.22577255017606346 Accuracy 67.28540514546766\n",
      "Training:: Epoch 137, Iteration 100, Current loss 0.16689326709326902 Accuracy 62.892543533263876\n",
      "Training:: Epoch 137, Iteration 110, Current loss 0.24821927490483517 Accuracy 62.936240294878836\n",
      "Training:: Epoch 137, Iteration 120, Current loss 0.20636587355999708 Accuracy 59.15902808089626\n",
      "Training:: Epoch 137, Iteration 130, Current loss 0.24682249834064973 Accuracy 54.979038492949314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 137, Iteration 140, Current loss 0.20839558098819885 Accuracy 70.39541547277938\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 137, Probability Accuracy 52.71987071810927\n",
      "Starting Training\n",
      "Training:: Epoch 138, Iteration 0, Current loss 0.26389216192077924 Accuracy 61.29011511994341\n",
      "Training:: Epoch 138, Iteration 10, Current loss 0.23960271053204732 Accuracy 73.20341047503045\n",
      "Training:: Epoch 138, Iteration 20, Current loss 0.2065446496921826 Accuracy 61.66967509025271\n",
      "Training:: Epoch 138, Iteration 30, Current loss 0.2391201826032384 Accuracy 67.64060213255279\n",
      "Training:: Epoch 138, Iteration 40, Current loss 0.23661470921180355 Accuracy 62.413923571698824\n",
      "Training:: Epoch 138, Iteration 50, Current loss 0.18096399949976588 Accuracy 71.23222100656456\n",
      "Training:: Epoch 138, Iteration 60, Current loss 0.2540848190052297 Accuracy 64.96887124424795\n",
      "Training:: Epoch 138, Iteration 70, Current loss 0.1822595294647808 Accuracy 72.79137529137529\n",
      "Training:: Epoch 138, Iteration 80, Current loss 0.21445066684817984 Accuracy 67.54779801240983\n",
      "Training:: Epoch 138, Iteration 90, Current loss 0.23912509690759481 Accuracy 68.39193508728793\n",
      "Training:: Epoch 138, Iteration 100, Current loss 0.25275127513955276 Accuracy 64.27679067184897\n",
      "Training:: Epoch 138, Iteration 110, Current loss 0.22256373241297828 Accuracy 64.00578642819569\n",
      "Training:: Epoch 138, Iteration 120, Current loss 0.2483086639477018 Accuracy 54.16444077509592\n",
      "Training:: Epoch 138, Iteration 130, Current loss 0.2801828448115866 Accuracy 50.70189925681255\n",
      "Training:: Epoch 138, Iteration 140, Current loss 0.25285400119586493 Accuracy 61.454768798806704\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 138, Probability Accuracy 52.59429800194773\n",
      "Starting Training\n",
      "Training:: Epoch 139, Iteration 0, Current loss 0.2233150508210058 Accuracy 66.54616240266964\n",
      "Training:: Epoch 139, Iteration 10, Current loss 0.2328037686878368 Accuracy 71.30913248535086\n",
      "Training:: Epoch 139, Iteration 20, Current loss 0.2105658355313911 Accuracy 71.5725806451613\n",
      "Training:: Epoch 139, Iteration 30, Current loss 0.2876440341398367 Accuracy 60.89423076923077\n",
      "Training:: Epoch 139, Iteration 40, Current loss 0.3093415163824774 Accuracy 64.29110421732204\n",
      "Training:: Epoch 139, Iteration 50, Current loss 0.18936023109906802 Accuracy 60.698279201018096\n",
      "Training:: Epoch 139, Iteration 60, Current loss 0.22263759085634816 Accuracy 57.91793828416412\n",
      "Training:: Epoch 139, Iteration 70, Current loss 0.3184506634097021 Accuracy 66.60093309605118\n",
      "Training:: Epoch 139, Iteration 80, Current loss 0.28014403708459396 Accuracy 70.74521951510097\n",
      "Training:: Epoch 139, Iteration 90, Current loss 0.22964581825051683 Accuracy 59.28646841456977\n",
      "Training:: Epoch 139, Iteration 100, Current loss 0.25037744226397335 Accuracy 69.30824618549632\n",
      "Training:: Epoch 139, Iteration 110, Current loss 0.34040966053433486 Accuracy 63.9116842516608\n",
      "Training:: Epoch 139, Iteration 120, Current loss 0.25306237415912275 Accuracy 66.48789457554398\n",
      "Training:: Epoch 139, Iteration 130, Current loss 0.18513416323633697 Accuracy 72.40729483282675\n",
      "Training:: Epoch 139, Iteration 140, Current loss 0.16973594938437486 Accuracy 72.5289032392459\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 139, Probability Accuracy 52.897159458558555\n",
      "Starting Training\n",
      "Training:: Epoch 140, Iteration 0, Current loss 0.17999033050863433 Accuracy 62.518604801656636\n",
      "Training:: Epoch 140, Iteration 10, Current loss 0.23031160617785373 Accuracy 66.85813373794299\n",
      "Training:: Epoch 140, Iteration 20, Current loss 0.2187686047825294 Accuracy 59.83711747285291\n",
      "Training:: Epoch 140, Iteration 30, Current loss 0.21668211891453837 Accuracy 67.22445600756859\n",
      "Training:: Epoch 140, Iteration 40, Current loss 0.26978271912714413 Accuracy 64.73273572377158\n",
      "Training:: Epoch 140, Iteration 50, Current loss 0.3033794976171895 Accuracy 66.65185514330149\n",
      "Training:: Epoch 140, Iteration 60, Current loss 0.2761593427105059 Accuracy 70.19935253024366\n",
      "Training:: Epoch 140, Iteration 70, Current loss 0.2574393151670479 Accuracy 63.920605416887945\n",
      "Training:: Epoch 140, Iteration 80, Current loss 0.2471977995938652 Accuracy 62.09295352323838\n",
      "Training:: Epoch 140, Iteration 90, Current loss 0.23862442926501887 Accuracy 64.13330723304297\n",
      "Training:: Epoch 140, Iteration 100, Current loss 0.19197252832525916 Accuracy 68.19582334816843\n",
      "Training:: Epoch 140, Iteration 110, Current loss 0.17395424612657368 Accuracy 75.04835589941973\n",
      "Training:: Epoch 140, Iteration 120, Current loss 0.32433974068249144 Accuracy 62.404658833230265\n",
      "Training:: Epoch 140, Iteration 130, Current loss 0.32604863610251994 Accuracy 71.1340206185567\n",
      "Training:: Epoch 140, Iteration 140, Current loss 0.2736883138496891 Accuracy 65.16548097742036\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 140, Probability Accuracy 50.5171602428774\n",
      "Calculating Expectation\n",
      "Epoch 140 iter 0\n",
      "Epoch 140 iter 10\n",
      "Epoch 140 iter 20\n",
      "Epoch 140 iter 30\n",
      "Epoch 140 iter 40\n",
      "Epoch 140 iter 50\n",
      "Epoch 140 iter 60\n",
      "Epoch 140 iter 70\n",
      "Epoch 140 iter 80\n",
      "Epoch 140 iter 90\n",
      "Epoch 140 iter 100\n",
      "Epoch 140 iter 110\n",
      "Epoch 140 iter 120\n",
      "Epoch 140 iter 130\n",
      "Epoch 140 iter 140\n",
      "Train Boundary avergage error = 292.819\n",
      "Train From boundary avergage accuracy = 59.910\n",
      "Starting Training\n",
      "Training:: Epoch 141, Iteration 0, Current loss 0.24465783128451662 Accuracy 60.991417060781224\n",
      "Training:: Epoch 141, Iteration 10, Current loss 0.4550421083745531 Accuracy 64.06327543424318\n",
      "Training:: Epoch 141, Iteration 20, Current loss 0.5023826583118047 Accuracy 67.66231724571608\n",
      "Training:: Epoch 141, Iteration 30, Current loss 0.25935438439492714 Accuracy 61.36332179930796\n",
      "Training:: Epoch 141, Iteration 40, Current loss 0.2391428202665084 Accuracy 63.28000509911403\n",
      "Training:: Epoch 141, Iteration 50, Current loss 0.2425406557892923 Accuracy 60.13100921505496\n",
      "Training:: Epoch 141, Iteration 60, Current loss 0.2814037145192016 Accuracy 60.91492329149233\n",
      "Training:: Epoch 141, Iteration 70, Current loss 0.2699606720936235 Accuracy 65.88759794650095\n",
      "Training:: Epoch 141, Iteration 80, Current loss 0.3434652492310607 Accuracy 62.462014792729775\n",
      "Training:: Epoch 141, Iteration 90, Current loss 0.24946098470911127 Accuracy 46.19588604871331\n",
      "Training:: Epoch 141, Iteration 100, Current loss 0.34291678039354007 Accuracy 61.75119202427395\n",
      "Training:: Epoch 141, Iteration 110, Current loss 0.32794992229671394 Accuracy 60.77459222533592\n",
      "Training:: Epoch 141, Iteration 120, Current loss 0.26541419357060114 Accuracy 63.61438313701178\n",
      "Training:: Epoch 141, Iteration 130, Current loss 0.37391507049165845 Accuracy 71.94390626441553\n",
      "Training:: Epoch 141, Iteration 140, Current loss 0.31828800167361077 Accuracy 58.53743148546451\n",
      "Calculating Validation Data Accuracy\n",
      "Training:: Epoch 142, Iteration 100, Current loss 0.281875173451424 Accuracy 65.44717800289436\n",
      "Training:: Epoch 142, Iteration 110, Current loss 0.29395595304875355 Accuracy 66.0873039656378\n",
      "Training:: Epoch 142, Iteration 120, Current loss 0.28009753343425364 Accuracy 53.138397273826534\n",
      "Training:: Epoch 142, Iteration 130, Current loss 0.3677015329362558 Accuracy 52.3397462824498\n",
      "Training:: Epoch 142, Iteration 140, Current loss 0.45988401667020673 Accuracy 57.813251274160976\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 142, Probability Accuracy 53.40753861136347\n",
      "Starting Training\n",
      "Training:: Epoch 143, Iteration 0, Current loss 0.33173145524071146 Accuracy 63.35241819112787\n",
      "Training:: Epoch 143, Iteration 10, Current loss 0.45549429413584464 Accuracy 64.17351857102354\n",
      "Training:: Epoch 143, Iteration 20, Current loss 0.36289976732324625 Accuracy 61.75870348139256\n",
      "Training:: Epoch 143, Iteration 30, Current loss 0.34136608981823197 Accuracy 58.72761828548565\n",
      "Training:: Epoch 143, Iteration 40, Current loss 0.42241207183769564 Accuracy 65.84741992882562\n",
      "Training:: Epoch 143, Iteration 50, Current loss 1.9508732772239732 Accuracy 48.194945848375454\n",
      "Training:: Epoch 143, Iteration 60, Current loss 1.138568349554779 Accuracy 70.8857781437478\n",
      "Training:: Epoch 143, Iteration 70, Current loss 3.4732549637547603 Accuracy 59.2883459375606\n",
      "Training:: Epoch 143, Iteration 80, Current loss 1.243451545320051 Accuracy 57.19074986316365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 143, Iteration 90, Current loss 4.626537559327595 Accuracy 55.665248226950354\n",
      "Training:: Epoch 143, Iteration 100, Current loss 5.569461023718995 Accuracy 35.29340150961772\n",
      "Training:: Epoch 143, Iteration 110, Current loss 2.129641062238322 Accuracy 53.45506419400856\n",
      "Training:: Epoch 143, Iteration 120, Current loss 2.950692219464929 Accuracy 49.358727362800686\n",
      "Training:: Epoch 143, Iteration 130, Current loss 1.292532427271698 Accuracy 64.47934757985351\n",
      "Training:: Epoch 143, Iteration 140, Current loss 0.8989352965106805 Accuracy 66.90417690417691\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 143, Probability Accuracy 52.79495290818894\n",
      "Starting Training\n",
      "Training:: Epoch 144, Iteration 0, Current loss 1.0617888351501636 Accuracy 56.68280992560787\n",
      "Training:: Epoch 144, Iteration 10, Current loss 0.7959425897177992 Accuracy 58.366654549860655\n",
      "Training:: Epoch 144, Iteration 20, Current loss 0.7312188409567602 Accuracy 58.966171901967556\n",
      "Training:: Epoch 144, Iteration 30, Current loss 0.6858225703171896 Accuracy 62.439775160599574\n",
      "Training:: Epoch 144, Iteration 40, Current loss 0.6307522456238113 Accuracy 72.63728053791557\n",
      "Training:: Epoch 144, Iteration 50, Current loss 4.060307017553365 Accuracy 46.26522738110721\n",
      "Training:: Epoch 144, Iteration 60, Current loss 3.5214283284710017 Accuracy 46.02133487098169\n",
      "Training:: Epoch 144, Iteration 70, Current loss 1.9258312049048647 Accuracy 58.42016707500664\n",
      "Training:: Epoch 144, Iteration 80, Current loss 1.6658359517058796 Accuracy 62.170966901224915\n",
      "Training:: Epoch 144, Iteration 90, Current loss 0.99214947248055 Accuracy 73.63119648895604\n",
      "Training:: Epoch 144, Iteration 100, Current loss 0.7630140042753027 Accuracy 67.03841387856258\n",
      "Training:: Epoch 144, Iteration 110, Current loss 0.4319666220259729 Accuracy 73.71575822082796\n",
      "Training:: Epoch 144, Iteration 120, Current loss 0.6210021119487943 Accuracy 70.68574309844952\n",
      "Training:: Epoch 144, Iteration 130, Current loss 1.7618953211585993 Accuracy 65.13564772820978\n",
      "Training:: Epoch 144, Iteration 140, Current loss 0.6800243366382878 Accuracy 64.05337123006474\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 144, Probability Accuracy 48.883326034810686\n",
      "Starting Training\n",
      "Training:: Epoch 145, Iteration 0, Current loss 1.3064257799576875 Accuracy 64.02684563758389\n",
      "Training:: Epoch 145, Iteration 10, Current loss 0.929026051528429 Accuracy 59.101206713209116\n",
      "Training:: Epoch 145, Iteration 20, Current loss 0.7033658131704673 Accuracy 66.15796918037668\n",
      "Training:: Epoch 145, Iteration 30, Current loss 0.5842185206877695 Accuracy 62.96582849774339\n",
      "Training:: Epoch 145, Iteration 40, Current loss 0.5170506354656431 Accuracy 59.44075304540421\n",
      "Training:: Epoch 145, Iteration 50, Current loss 0.5542406181201351 Accuracy 53.86263221314768\n",
      "Training:: Epoch 145, Iteration 60, Current loss 0.6248452231770923 Accuracy 73.0861594330229\n",
      "Training:: Epoch 145, Iteration 70, Current loss 0.46517785780579 Accuracy 64.41349918231825\n",
      "Training:: Epoch 145, Iteration 80, Current loss 0.5211449083997978 Accuracy 69.68690702087287\n",
      "Training:: Epoch 145, Iteration 90, Current loss 0.6252601165313633 Accuracy 46.55787246902388\n",
      "Training:: Epoch 145, Iteration 100, Current loss 0.44680514459734055 Accuracy 68.21096173733196\n",
      "Training:: Epoch 145, Iteration 110, Current loss 0.34915063125144274 Accuracy 73.55866561042161\n",
      "Training:: Epoch 145, Iteration 120, Current loss 0.4050062853195855 Accuracy 60.83815891588562\n",
      "Training:: Epoch 145, Iteration 130, Current loss 0.30013179520862937 Accuracy 63.56684538982157\n",
      "Training:: Epoch 145, Iteration 140, Current loss 0.39789534466738186 Accuracy 55.92303066746843\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 145, Probability Accuracy 52.20173007666717\n",
      "Calculating Expectation\n",
      "Epoch 145 iter 0\n",
      "Epoch 145 iter 10\n",
      "Epoch 145 iter 20\n",
      "Epoch 145 iter 30\n",
      "Epoch 145 iter 40\n",
      "Epoch 145 iter 50\n",
      "Epoch 145 iter 60\n",
      "Epoch 145 iter 70\n",
      "Epoch 145 iter 80\n",
      "Epoch 145 iter 90\n",
      "Epoch 145 iter 100\n",
      "Epoch 145 iter 110\n",
      "Epoch 145 iter 120\n",
      "Epoch 145 iter 130\n",
      "Epoch 145 iter 140\n",
      "Train Boundary avergage error = 292.669\n",
      "Train From boundary avergage accuracy = 59.959\n",
      "Starting Training\n",
      "Training:: Epoch 146, Iteration 0, Current loss 0.27848471992776613 Accuracy 56.851125170176985\n",
      "Training:: Epoch 146, Iteration 10, Current loss 0.2545376864958377 Accuracy 70.07716940521811\n",
      "Training:: Epoch 146, Iteration 20, Current loss 0.2555544662697338 Accuracy 46.77335188728475\n",
      "Training:: Epoch 146, Iteration 30, Current loss 0.20355545571727085 Accuracy 72.0589573287235\n",
      "Training:: Epoch 146, Iteration 40, Current loss 0.34910603853963823 Accuracy 55.95195502172246\n",
      "Training:: Epoch 146, Iteration 50, Current loss 0.29573976482974085 Accuracy 69.76498800959233\n",
      "Training:: Epoch 146, Iteration 60, Current loss 0.20223015959032312 Accuracy 68.74627931896654\n",
      "Training:: Epoch 146, Iteration 70, Current loss 0.3903820470283823 Accuracy 69.8209127671866\n",
      "Training:: Epoch 146, Iteration 80, Current loss 0.35980552546719863 Accuracy 65.55714626580769\n",
      "Training:: Epoch 146, Iteration 90, Current loss 0.2901264151941009 Accuracy 71.38899248761255\n",
      "Training:: Epoch 146, Iteration 100, Current loss 0.29784298351576244 Accuracy 64.08370395712168\n",
      "Training:: Epoch 146, Iteration 110, Current loss 0.30865458773460347 Accuracy 58.07706790510857\n",
      "Training:: Epoch 146, Iteration 120, Current loss 0.19797594828886522 Accuracy 58.46913580246913\n",
      "Training:: Epoch 146, Iteration 130, Current loss 0.335579449231081 Accuracy 60.61827956989247\n",
      "Training:: Epoch 146, Iteration 140, Current loss 0.19956693056598485 Accuracy 64.89849133916931\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 146, Probability Accuracy 53.08637638154498\n",
      "Starting Training\n",
      "Training:: Epoch 147, Iteration 0, Current loss 0.3145197060077117 Accuracy 58.91206759968313\n",
      "Training:: Epoch 147, Iteration 10, Current loss 0.164586892692997 Accuracy 61.401824291886705\n",
      "Training:: Epoch 147, Iteration 20, Current loss 0.23572251507117448 Accuracy 67.78102799832845\n",
      "Training:: Epoch 147, Iteration 30, Current loss 0.2882964300507686 Accuracy 68.15433734121324\n",
      "Training:: Epoch 147, Iteration 40, Current loss 0.15240562627838405 Accuracy 71.3894477978985\n",
      "Training:: Epoch 147, Iteration 50, Current loss 0.3073990419424627 Accuracy 63.18891687657431\n",
      "Training:: Epoch 147, Iteration 60, Current loss 0.27824060610532053 Accuracy 57.17082498634129\n",
      "Training:: Epoch 147, Iteration 70, Current loss 0.2190353986683047 Accuracy 64.7135033272481\n",
      "Training:: Epoch 147, Iteration 80, Current loss 0.18995518683760748 Accuracy 49.61167043353195\n",
      "Training:: Epoch 147, Iteration 90, Current loss 0.1911148207497655 Accuracy 70.4569236135333\n",
      "Training:: Epoch 147, Iteration 100, Current loss 0.21252690781145686 Accuracy 74.96765847347994\n",
      "Training:: Epoch 147, Iteration 110, Current loss 0.2749882948015437 Accuracy 65.18224078690292\n",
      "Training:: Epoch 147, Iteration 120, Current loss 0.21686223758770545 Accuracy 72.00887753043244\n",
      "Training:: Epoch 147, Iteration 130, Current loss 0.30258568218963183 Accuracy 62.147517416786464\n",
      "Training:: Epoch 147, Iteration 140, Current loss 0.2839817634185377 Accuracy 58.57083506439551\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 147, Probability Accuracy 52.48432996294093\n",
      "Starting Training\n",
      "Training:: Epoch 148, Iteration 0, Current loss 0.4436426160005833 Accuracy 65.76857117068327\n",
      "Training:: Epoch 148, Iteration 10, Current loss 0.22354578060889901 Accuracy 61.900088330552556\n",
      "Training:: Epoch 148, Iteration 20, Current loss 0.19323542152362141 Accuracy 69.9818671355569\n",
      "Training:: Epoch 148, Iteration 30, Current loss 0.2150602877645241 Accuracy 59.01924270639354\n",
      "Training:: Epoch 148, Iteration 40, Current loss 0.19534437293208678 Accuracy 71.86170624178204\n",
      "Training:: Epoch 148, Iteration 50, Current loss 0.3180328734603199 Accuracy 63.46040189125296\n",
      "Training:: Epoch 148, Iteration 60, Current loss 0.23380176095173089 Accuracy 61.27450980392157\n",
      "Training:: Epoch 148, Iteration 70, Current loss 0.2211204542297462 Accuracy 60.408860021650426\n",
      "Training:: Epoch 148, Iteration 80, Current loss 0.2171148999529624 Accuracy 51.03127079174983\n",
      "Training:: Epoch 148, Iteration 90, Current loss 0.20661892176970986 Accuracy 58.086312118570184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 148, Iteration 100, Current loss 0.2747047504115696 Accuracy 67.22272317403066\n",
      "Training:: Epoch 148, Iteration 110, Current loss 0.2771530538507485 Accuracy 57.511080009330534\n",
      "Training:: Epoch 148, Iteration 120, Current loss 0.18389523128845364 Accuracy 68.70823033965029\n",
      "Training:: Epoch 148, Iteration 130, Current loss 0.3223961373414184 Accuracy 64.05144694533762\n",
      "Training:: Epoch 148, Iteration 140, Current loss 0.24641498754189123 Accuracy 62.44258872651357\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 148, Probability Accuracy 52.87199589539801\n",
      "Starting Training\n",
      "Training:: Epoch 149, Iteration 0, Current loss 0.21537164517578924 Accuracy 62.26166773529511\n",
      "Training:: Epoch 149, Iteration 10, Current loss 0.2341540609870178 Accuracy 60.49213161659514\n",
      "Training:: Epoch 149, Iteration 20, Current loss 0.15712084789323885 Accuracy 63.35321918338886\n",
      "Training:: Epoch 149, Iteration 30, Current loss 0.1838801748945153 Accuracy 75.54215399610136\n",
      "Training:: Epoch 149, Iteration 40, Current loss 0.19061637197291798 Accuracy 64.25690350605026\n",
      "Training:: Epoch 149, Iteration 50, Current loss 0.24649567147565482 Accuracy 74.02548012930215\n",
      "Training:: Epoch 149, Iteration 60, Current loss 0.2868071409568197 Accuracy 60.60391601792875\n",
      "Training:: Epoch 149, Iteration 70, Current loss 0.27905495315379925 Accuracy 66.90183781900531\n",
      "Training:: Epoch 149, Iteration 80, Current loss 0.21856210733629894 Accuracy 63.64836325237592\n",
      "Training:: Epoch 149, Iteration 90, Current loss 0.214071406019506 Accuracy 64.939106175224\n",
      "Training:: Epoch 149, Iteration 100, Current loss 0.2743701788556795 Accuracy 65.21532465063218\n",
      "Training:: Epoch 149, Iteration 110, Current loss 0.2375716262602846 Accuracy 63.79395296752519\n",
      "Training:: Epoch 149, Iteration 120, Current loss 0.1604276159798546 Accuracy 74.30956631313661\n",
      "Training:: Epoch 149, Iteration 130, Current loss 0.2055757726763313 Accuracy 63.38584932684045\n",
      "Training:: Epoch 149, Iteration 140, Current loss 0.17663069430289188 Accuracy 66.95289206917114\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 149, Probability Accuracy 53.19928561624586\n"
     ]
    }
   ],
   "source": [
    "initialize_epoch = 25\n",
    "expectation_cal_gap = 5\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(25, 150):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        psuedo_l = get_single_random(predictions[-1], item[4])\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, psuedo_l)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                            max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                es_loss, _ = get_estimated_loss(prob, item_1, item[4])\n",
    "                loss += es_loss\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(predictions[-1], dim=1)\n",
    "                correct = float(torch.sum((pred == item_2) * src_mask).item())\n",
    "                total = float(torch.sum(src_mask).item())\n",
    "                print(f\"Training:: Epoch {epoch}, Iteration {i}, Current loss {loss.item()}\" +\n",
    "                      f\" Accuracy {correct * 100.0 / total}\")\n",
    "\n",
    "    # Calculating Expectation Step\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-last-model.wt\")\n",
    "    print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")\n",
    "\n",
    "    if (epoch == initialize_epoch) or ((epoch > initialize_epoch) and ((epoch % (3 * expectation_cal_gap)) == 0)):\n",
    "        torch.save(model.state_dict(), config.output_dir + f\"ms-tcn-initial-{initialize_epoch}-epochs.wt\")\n",
    "        selected_frames_dict = change_selected_frames(model)\n",
    "        get_new_selected_frame_acc(selected_frames_dict)\n",
    "\n",
    "    if (epoch == initialize_epoch) or ((epoch > initialize_epoch) and (epoch % expectation_cal_gap == 0)):\n",
    "        print(\"Calculating Expectation\")\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, item in enumerate(trainloader):\n",
    "            with torch.no_grad():\n",
    "                item_0 = item[0].to(device)\n",
    "                item_1 = item[1].to(device)\n",
    "                item_2 = item[2].to(device)\n",
    "                src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "                src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "                middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "                prob = torch.softmax(predictions[-1], dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                calculate_element_probb(prob, item_1, item[4])\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Epoch {epoch} iter {i}\")\n",
    "                    \n",
    "        get_boundary_err()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 130, Probability Accuracy 51.43919338691232\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.61000906173455"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-emmax-best-model.wt\"))\n",
    "# model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-initial-15-epochs.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.625639564561894\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Validation Data Accuracy\")\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "        pred = torch.argmax(predictions[-1], dim=1)\n",
    "        correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "        total += float(torch.sum(src_mask).item())\n",
    "\n",
    "print(f\"Validation:: Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration done\n",
      "11 iteration done\n",
      "21 iteration done\n",
      "31 iteration done\n",
      "41 iteration done\n",
      "51 iteration done\n",
      "61 iteration done\n",
      "71 iteration done\n",
      "81 iteration done\n",
      "91 iteration done\n",
      "101 iteration done\n",
      "111 iteration done\n",
      "121 iteration done\n",
      "131 iteration done\n",
      "141 iteration done\n",
      "151 iteration done\n",
      "161 iteration done\n",
      "171 iteration done\n",
      "181 iteration done\n",
      "Train Boundary avergage error = 307.224\n",
      "Train From boundary avergage accuracy = 57.704\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        prob = torch.softmax(predictions[-1], dim=1)\n",
    "        prob = prob.permute(0, 2, 1)\n",
    "        calculate_element_probb(prob, item_1, item[4])\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f'{i+1} iteration done')\n",
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    idx = 1\n",
    "\n",
    "    cur_vid_feat = torch.softmax(predictions[-1], dim=1).permute(0, 2, 1)[idx]\n",
    "    cur_vidid = item[4][idx]\n",
    "\n",
    "    selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "    selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "    selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "    \n",
    "    cumsum_feat = torch.cumsum(cur_vid_feat, dim=0)\n",
    "    prob_each_segment = prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 228, 481, 735, 1578, 2388, 2567, 2745]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_frames_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[88, 229, 578, 1128, 2241, 2479, 2720, 2810]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_frames_dict[cur_vidid + \".txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min prob 0 = 0.0\n",
      "Min prob 1 = 0.0\n",
      "Min prob 2 = 0.0\n",
      "Min prob 3 = 0.0\n",
      "Min prob 4 = 0.0\n",
      "Min prob 5 = 7.224189870987231e-126\n",
      "Min prob 6 = 4.631831900603335e-244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 2811)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ymax = 1\n",
    "\n",
    "plt.plot([0, item[1][idx].item()], [0, 0])\n",
    "\n",
    "for pivot in selected_frames_indices:\n",
    "    plt.plot([pivot, pivot], [0, ymax], '--')\n",
    "    \n",
    "for pivot in boundary_frames_dict[cur_vidid + \".txt\"]:\n",
    "    plt.plot([pivot, pivot], [0, ymax])\n",
    "    \n",
    "all_prob = []\n",
    "for i, segment in enumerate(prob_each_segment):\n",
    "    segment = segment.cpu().numpy()\n",
    "    print(f\"Min prob {i} = {np.min(segment).item()}\")\n",
    "    xs = np.arange(selected_frames_indices[i], \n",
    "                   selected_frames_indices[i+1])\n",
    "    plt.plot(xs, segment, '*')\n",
    "\n",
    "    \n",
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "\n",
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]])\n",
    "loss_arr = -loss_arr[0].detach().cpu().numpy()\n",
    "plt.plot(np.arange(selected_frames_indices[0] - 1, selected_frames_indices[-1] + 1), loss_arr/np.max(loss_arr), 'k+')\n",
    "\n",
    "plt.ylim([0, ymax])\n",
    "plt.xlim([0, item[1][idx].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1895, 48])\n"
     ]
    }
   ],
   "source": [
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "print(loss_prob.shape)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]], item_2[idx].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1387])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faf5b8ecb00>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "plt.plot(np.arange(selected_frames[0] - 1, selected_frames[-1] + 1), loss_arr[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3987, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([75, 345, 1305, 1415, 1440, 1519],\n",
       " [73, 282, 455, 1312, 1434, 1458],\n",
       " tensor(1520, device='cuda:0', dtype=torch.int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid], loaded_vidid_selected_frames[cur_vidid + \".txt\"], item_1[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_features_shortened = cur_vid_feat[:item[1][idx]]\n",
    "cur_features_shortened[:, item[2][idx][:item[1][idx]]].shape\n",
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47, 47, 47, 47, 47, 47, 47,  4,  4,  4,  4,  4,  4,  4,  4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[2][idx][video_id_boundary_frames[cur_vidid][1]-6:video_id_boundary_frames[cur_vidid][1]+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid][0]-6,video_id_boundary_frames[cur_vidid][0]+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0794, 13.3350],\n",
       "        [ 1.0831, 13.5102],\n",
       "        [ 1.1767, 13.7662],\n",
       "        [ 1.3750, 14.0177],\n",
       "        [ 1.7298, 14.1727],\n",
       "        [ 2.1706, 14.0367],\n",
       "        [ 2.7338, 13.4563],\n",
       "        [ 4.5600, 12.1745],\n",
       "        [ 7.8450, 10.3246],\n",
       "        [11.0151,  8.3563],\n",
       "        [13.4775,  6.6546],\n",
       "        [14.1836,  5.2898],\n",
       "        [11.2142,  4.2791],\n",
       "        [ 5.9829,  3.5694],\n",
       "        [ 2.3440,  2.9389],\n",
       "        [ 0.7406,  2.3515]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_vid_feat[video_id_boundary_frames[cur_vidid][1]-7:video_id_boundary_frames[cur_vidid][1]+9][:,[47,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frames_and_get_classification_value(model_output, count_list, video_ids_list, labels_all, p_criterion):\n",
    "    new_selected_frames = {}\n",
    "#     new_selected_frames_probs_values = {}\n",
    "#     new_selected_frames_labels = {}\n",
    "    \n",
    "    labels_arr = []\n",
    "    probs_arr = []\n",
    "    \n",
    "    for i, video_id in enumerate(video_ids_list):\n",
    "        current_boundary_frames = boundaries_dict[video_id]\n",
    "        current_video_logits = model_output[i].T\n",
    "        current_video_count = count_list[i]\n",
    "        current_selected_frames = loaded_vidid_selected_frames[video_id]\n",
    "        labels = labels_all[i]\n",
    "        cur_seg_start = 0\n",
    "        for seg_num, ele in enumerate(current_boundary_frames):\n",
    "            cur_seg_end = ele + 1\n",
    "            total_seg_len = cur_seg_end - cur_seg_start\n",
    "            per_frames_far_from_boundary = int(0.3 * total_seg_len)\n",
    "            new_frames_start = cur_seg_start + per_frames_far_from_boundary\n",
    "            new_frames_end = cur_seg_end - per_frames_far_from_boundary\n",
    "            \n",
    "            frames_added = list(range(new_frames_start, new_frames_end))\n",
    "            frames_added.append(current_selected_frames[seg_num])\n",
    "            frames_added = list(set(frames_added))\n",
    "            frames_added.sort()\n",
    "            new_selected_frames[video_id] = frames_added\n",
    "\n",
    "            \n",
    "            labels_seg = torch.stack([labels[current_selected_frames[seg_num]]] * len(frames_added))\n",
    "            frames_added = torch.tensor(np.array(frames_added), dtype=torch.long, device=current_video_logits.device)\n",
    "            prob_seg = current_video_logits[frames_added, :]\n",
    "            \n",
    "            labels_arr.append(labels_seg)\n",
    "            probs_arr.append(prob_seg)\n",
    "            \n",
    "            cur_seg_start = cur_seg_end\n",
    "            \n",
    "    labels_arr = torch.cat(labels_arr)\n",
    "    probs_arr = torch.cat(probs_arr)\n",
    "    loss = p_criterion(probs_arr, labels_arr)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mask_for_this_class(video_len, weakly_labels_video, old_index_label_pair_list, \n",
    "                             cur_ele_searched, cur_index_searched):\n",
    "    searched_label_index = np.where(cur_ele_searched == np.array(weakly_labels_video))[0]\n",
    "    if len(searched_label_index) <= 1:\n",
    "        mask = torch.ones(video_len)\n",
    "        return mask\n",
    "    else:\n",
    "        start = 0\n",
    "        for i, index in enumerate(searched_label_index[:-1]):\n",
    "            cur_index_frame_selected = old_index_label_pair_list[index][0]\n",
    "            next_index = searched_label_index[i + 1]\n",
    "            next_index_frame_selected = old_index_label_pair_list[next_index][0]\n",
    "            \n",
    "            mid_select = (cur_index_frame_selected + next_index_frame_selected) // 2\n",
    "            \n",
    "            if index == cur_index_searched:\n",
    "                mask = torch.zeros(video_len)\n",
    "                mask[start: mid_select + 1] = 1\n",
    "                return mask\n",
    "            \n",
    "            start = mid_select\n",
    "        if searched_label_index[-1] == cur_index_searched:\n",
    "            mask = torch.zeros(video_len)\n",
    "            mask[start: video_len] = 1\n",
    "            return mask\n",
    "        else:\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "            return \"Error 1\"\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2, 2, 2, 2, 3, 3, 4, 4, 3, 3, 2, 2, 2, 2]\n",
    "find_mask_for_this_class(12, [2, 3, 4, 3,  2], [3, 5, 7, 8, 10], 4, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
