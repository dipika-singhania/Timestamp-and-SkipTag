{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import C2F_TCN\n",
    "from dataset import AugmentDataset, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 50, 'learning_rate': 0.0001, 'weight_decay': 0.003, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 10, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 2, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize/', 'project_name': 'breakfast-split-2', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split2.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split2.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split2_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=50,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=3e-3,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=10,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=2,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize/\",\n",
    "    project_name=\"breakfast-split-2\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 257\n",
      "Number of videos not found in train fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = AugmentDataset(config, fold='train', fold_file_name=config.semi_supervised_split, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=7, collate_fn=collate_fn_override,\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = iter(trainloader).next()\n",
    "# print(item[0]) # -- data feature\n",
    "# print(item[1]) # -- valid count\n",
    "# item[2] # -- Actual labels\n",
    "# print(item[5]) # video names\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vidid_selected_frames = pickle.load(open(\"dump_dir/loaded_vidid_selected_frames_dict.pkl\", \"rb\"))\n",
    "# loaded_vidid_selected_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id_boundary_frames = pickle.load(open(\"dump_dir/video_id_boundary_frames_dict.pkl\", \"rb\"))\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_video_each_segment_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels):\n",
    "    prob_each_segment = []\n",
    "    \n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "        \n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "        \n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[cur_ele]\n",
    "        label_next_ele = labels[next_ele]\n",
    "        prob_list = []\n",
    "        for ele in range(cur_ele, next_ele, 1):\n",
    "            start_sum = cumsum_feat[cur_ele - 1, :] if cur_ele > 0 else 0\n",
    "            sum_window_class_1 = (cumsum_feat[ele, :] - start_sum)[label_cur_ele]\n",
    "            sum_window_class_2 = (cumsum_feat[next_ele - 1, :] - cumsum_feat[ele, :])[label_next_ele]\n",
    "            prob_list.append((sum_window_class_1 + sum_window_class_2))\n",
    "            \n",
    "        prob_list = torch.softmax(torch.stack(prob_list), dim=0)\n",
    "        prob_each_segment.append(prob_list)\n",
    "    \n",
    "    return prob_each_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_frames = torch.tensor([2, 10, 17, 21])\n",
    "# cur_vid_feat = torch.randn((27, 48))\n",
    "# labels = torch.tensor([47, 47, 47, 47, 47, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 10, 10])\n",
    "# # print(len(labels))\n",
    "# probs_all_segs = prob_vals_per_segment(selected_frames, cur_vid_feat, labels)\n",
    "# print(probs_all_segs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_element_probb(data_feat, data_count, video_ids, labels_all): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        labels = labels_all[iter_num]\n",
    "        \n",
    "        selected_frames = loaded_vidid_selected_frames[cur_vidid]\n",
    "        prob_video = prob_vals_per_segment(selected_frames, cur_vid_feat, labels)\n",
    "        prob_video_each_segment_dict[cur_vidid] = prob_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_loss(data_feat, data_count, video_ids, labels_all): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    loss_arr = []\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        labels = labels_all[iter_num]\n",
    "        \n",
    "        selected_frames = loaded_vidid_selected_frames[cur_vidid]\n",
    "        prob_each_video = prob_video_each_segment_dict[cur_vidid]\n",
    "        \n",
    "        log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "        cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "        \n",
    "        \n",
    "        current_vid_prob_arr = []\n",
    "        # Start segment log probability\n",
    "        start_ele_idx = selected_frames[0]\n",
    "        if start_ele_idx > 0:\n",
    "            start_ele_label_idx = labels[selected_frames[0]]\n",
    "            first_segment_prob = (cumsum_feat[start_ele_idx - 1, :])[start_ele_label_idx]\n",
    "            current_vid_prob_arr.append(first_segment_prob)\n",
    "        \n",
    "        for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "            next_ele = selected_frames[i + 1]\n",
    "            label_cur_ele = labels[cur_ele]\n",
    "            label_next_ele = labels[next_ele]\n",
    "\n",
    "            count = 0\n",
    "            for ele in range(cur_ele, next_ele, 1):\n",
    "                start_sum = cumsum_feat[cur_ele - 1, :] if cur_ele > 0 else 0\n",
    "                sum_window_class_1 = (cumsum_feat[ele, :] - start_sum)[label_cur_ele]\n",
    "                sum_window_class_2 = (cumsum_feat[next_ele - 1, :] - cumsum_feat[ele, :])[label_next_ele]\n",
    "                current_vid_prob_arr.append((sum_window_class_1 + sum_window_class_2)  * (prob_each_video[i][count].item()))\n",
    "                count = count + 1\n",
    "        \n",
    "        # End segment log probability\n",
    "        end_index = cur_vid_count.item() - 1\n",
    "        last_ele_label_idx = labels[selected_frames[-1]]\n",
    "        last_segment_sum_prob = (cumsum_feat[end_index, :] - cumsum_feat[selected_frames[-1] - 1, :])[last_ele_label_idx]\n",
    "        current_vid_prob_arr.append(last_segment_sum_prob)\n",
    "            \n",
    "        loss_arr.append(torch.stack(current_vid_prob_arr))\n",
    "    return -torch.mean(torch.cat(loss_arr)), loss_arr\n",
    "#     return loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_boundaries():\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames, video_id_boundary_frames\n",
    "    estimated_boundary_dict = {}\n",
    "    for ele in video_id_boundary_frames.keys():\n",
    "        \n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        selected_ele_list = loaded_vidid_selected_frames[ele]\n",
    "        boundary_list = []\n",
    "        for i, segment in enumerate(estimated_boundary_probs):\n",
    "            estimated_boundary = np.sum(np.arange(selected_ele_list[i], selected_ele_list[i + 1], 1) \\\n",
    "                                        * segment.detach().cpu().numpy())\n",
    "            estimated_boundary = int(estimated_boundary.item() + 1e-5)\n",
    "            \n",
    "            if (estimated_boundary < selected_ele_list[i]) or (estimated_boundary > selected_ele_list[i + 1]):\n",
    "                print(\"Estimated value wrong\")\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "            boundary_list.append(estimated_boundary)\n",
    "\n",
    "        estimated_boundary_dict[ele] = boundary_list\n",
    "    return estimated_boundary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_err():\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    err_list = []\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    estimated_boundar_dict = get_estimated_boundaries()\n",
    "    for ele in video_id_boundary_frames.keys():\n",
    "        \n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        estimated_boundary_list = estimated_boundar_dict[ele]\n",
    "        \n",
    "        estimated = np.array(estimated_boundary_list) #.detach().cpu().numpy()\n",
    "        actual = np.array(video_id_boundary_frames[ele][:-1])\n",
    "        if len(actual) != len(estimated):\n",
    "            print(ele)\n",
    "            continue\n",
    "        \n",
    "        mse_err = (actual - estimated)**2\n",
    "        err_list.append(mse_err)\n",
    "        \n",
    "        estimated_labels = []\n",
    "        actual_labels = []\n",
    "        start_v1 = 0\n",
    "        start_v2 = 0\n",
    "        for i, v1 in enumerate(estimated):\n",
    "            estimated_labels.extend([i] * (v1 - start_v1))\n",
    "            start_v1 = v1\n",
    "            v2 = actual[i]\n",
    "            actual_labels.extend([i] * (v2 - start_v2))\n",
    "            start_v2 = v2\n",
    "            \n",
    "        last_ele = video_id_boundary_frames[ele][-1]\n",
    "        estimated_labels.extend([i+1] * (last_ele - start_v1))\n",
    "        actual_labels.extend([i+1] * (last_ele - start_v2))\n",
    "        \n",
    "        correct += np.sum(np.array(actual_labels) == np.array(estimated_labels))\n",
    "        total += len(actual_labels)\n",
    "        \n",
    "    print(f\"Boundary avergage error = {np.sqrt(np.mean(np.concatenate(err_list))):.3f}\")\n",
    "    print(f\"From boundary avergage accuracy = {correct * 100.0 / total:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = C2F_TCN(n_channels=config.feature_size, n_classes=config.num_class).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=3e-3)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Expectation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy calculated with probabilities  4.331\n",
      "Boundary avergage error = 25.967\n",
      "From boundary avergage accuracy = 72.272\n",
      "Starting Maximization\n",
      "Current loss 4.494490146636963\n",
      "Current loss 3.990020751953125\n",
      "Starting Maximization\n",
      "Current loss 3.4496347904205322\n",
      "Current loss 3.318120002746582\n",
      "Starting Maximization\n",
      "Current loss 3.339700222015381\n",
      "Current loss 3.1745240688323975\n",
      "Starting Maximization\n",
      "Current loss 2.8060801029205322\n",
      "Current loss 2.8036012649536133\n",
      "Starting Maximization\n",
      "Current loss 2.793907403945923\n",
      "Current loss 2.896103620529175\n",
      "Starting Maximization\n",
      "Current loss 2.406277656555176\n",
      "Current loss 3.132328987121582\n",
      "Starting Maximization\n",
      "Current loss 2.1675148010253906\n",
      "Current loss 2.7150490283966064\n",
      "Starting Maximization\n",
      "Current loss 2.012951374053955\n",
      "Current loss 2.3352463245391846\n",
      "Starting Maximization\n",
      "Current loss 2.118556499481201\n",
      "Current loss 2.6177589893341064\n",
      "Starting Maximization\n",
      "Current loss 1.961077332496643\n",
      "Current loss 2.0752017498016357\n",
      "Starting Maximization\n",
      "Current loss 1.8737683296203613\n",
      "Current loss 3.0526037216186523\n",
      "Starting Maximization\n",
      "Current loss 1.7506734132766724\n",
      "Current loss 2.483687400817871\n",
      "Starting Maximization\n",
      "Current loss 1.6046735048294067\n",
      "Current loss 2.1757652759552\n",
      "Starting Maximization\n",
      "Current loss 1.5487439632415771\n",
      "Current loss 1.8010611534118652\n",
      "Starting Maximization\n",
      "Current loss 1.6591784954071045\n",
      "Current loss 2.042534828186035\n",
      "Starting Maximization\n",
      "Current loss 1.6323610544204712\n",
      "Current loss 2.201662540435791\n",
      "Starting Maximization\n",
      "Current loss 1.387863039970398\n",
      "Current loss 2.9830992221832275\n",
      "Starting Maximization\n",
      "Current loss 1.3151211738586426\n",
      "Current loss 1.7434487342834473\n",
      "Starting Maximization\n",
      "Current loss 1.3444600105285645\n",
      "Current loss 1.6946252584457397\n",
      "Starting Maximization\n",
      "Current loss 1.2923634052276611\n",
      "Current loss 1.590136170387268\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  56.355\n",
      "Boundary avergage error = 28.463\n",
      "From boundary avergage accuracy = 67.970\n",
      "Starting Maximization\n",
      "Current loss 0.887972891330719\n",
      "Current loss 1.0265381336212158\n",
      "Starting Maximization\n",
      "Current loss 0.7680999636650085\n",
      "Current loss 1.19805908203125\n",
      "Starting Maximization\n",
      "Current loss 0.8489121794700623\n",
      "Current loss 1.193380355834961\n",
      "Starting Maximization\n",
      "Current loss 0.7555122375488281\n",
      "Current loss 1.233811855316162\n",
      "Starting Maximization\n",
      "Current loss 0.7551783919334412\n",
      "Current loss 1.0119104385375977\n",
      "Starting Maximization\n",
      "Current loss 0.7031915187835693\n",
      "Current loss 1.4990959167480469\n",
      "Starting Maximization\n",
      "Current loss 0.6825202703475952\n",
      "Current loss 1.1443732976913452\n",
      "Starting Maximization\n",
      "Current loss 0.5743537545204163\n",
      "Current loss 1.0061126947402954\n",
      "Starting Maximization\n",
      "Current loss 0.5701563954353333\n",
      "Current loss 0.9011480212211609\n",
      "Starting Maximization\n",
      "Current loss 0.6811345815658569\n",
      "Current loss 0.8193057179450989\n",
      "Starting Maximization\n",
      "Current loss 0.6795128583908081\n",
      "Current loss 4.293736934661865\n",
      "Starting Maximization\n",
      "Current loss 0.6982985734939575\n",
      "Current loss 1.0720351934432983\n",
      "Starting Maximization\n",
      "Current loss 0.7773944735527039\n",
      "Current loss 1.2834075689315796\n",
      "Starting Maximization\n",
      "Current loss 0.5726839900016785\n",
      "Current loss 1.6509100198745728\n",
      "Starting Maximization\n",
      "Current loss 0.6009710431098938\n",
      "Current loss 0.7934194803237915\n",
      "Starting Maximization\n",
      "Current loss 0.5819258093833923\n",
      "Current loss 2.1508212089538574\n",
      "Starting Maximization\n",
      "Current loss 0.5635787844657898\n",
      "Current loss 3.9869399070739746\n",
      "Starting Maximization\n",
      "Current loss 0.7555763721466064\n",
      "Current loss 1.2558754682540894\n",
      "Starting Maximization\n",
      "Current loss 0.7306191921234131\n",
      "Current loss 1.729618787765503\n",
      "Starting Maximization\n",
      "Current loss 0.6369261741638184\n",
      "Current loss 1.0361117124557495\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  54.645\n",
      "Boundary avergage error = 25.859\n",
      "From boundary avergage accuracy = 68.930\n",
      "Starting Maximization\n",
      "Current loss 0.7791624665260315\n",
      "Current loss 0.9466418027877808\n",
      "Starting Maximization\n",
      "Current loss 0.6654947400093079\n",
      "Current loss 0.922524094581604\n",
      "Starting Maximization\n",
      "Current loss 0.5886021256446838\n",
      "Current loss 0.7540481686592102\n",
      "Starting Maximization\n",
      "Current loss 0.5769389867782593\n",
      "Current loss 0.7305193543434143\n",
      "Starting Maximization\n",
      "Current loss 0.5316123962402344\n",
      "Current loss 1.7661532163619995\n",
      "Starting Maximization\n",
      "Current loss 0.4405815005302429\n",
      "Current loss 0.9747500419616699\n",
      "Starting Maximization\n",
      "Current loss 0.5836848020553589\n",
      "Current loss 1.0833021402359009\n",
      "Starting Maximization\n",
      "Current loss 0.6235908269882202\n",
      "Current loss 0.7220337390899658\n",
      "Starting Maximization\n",
      "Current loss 0.5052133202552795\n",
      "Current loss 0.7680556178092957\n",
      "Starting Maximization\n",
      "Current loss 0.45984894037246704\n",
      "Current loss 0.6154614090919495\n",
      "Starting Maximization\n",
      "Current loss 0.4233415126800537\n",
      "Current loss 0.5400751829147339\n",
      "Starting Maximization\n",
      "Current loss 0.49000924825668335\n",
      "Current loss 0.9204245209693909\n",
      "Starting Maximization\n",
      "Current loss 0.3630480468273163\n",
      "Current loss 0.9193667769432068\n",
      "Starting Maximization\n",
      "Current loss 0.3757767975330353\n",
      "Current loss 0.551867663860321\n",
      "Starting Maximization\n",
      "Current loss 0.37395188212394714\n",
      "Current loss 1.867762565612793\n",
      "Starting Maximization\n",
      "Current loss 0.40099868178367615\n",
      "Current loss 0.6709752082824707\n",
      "Starting Maximization\n",
      "Current loss 0.41355377435684204\n",
      "Current loss 0.5764979720115662\n",
      "Starting Maximization\n",
      "Current loss 0.36280950903892517\n",
      "Current loss 2.8596224784851074\n",
      "Starting Maximization\n",
      "Current loss 0.4091774523258209\n",
      "Current loss 0.8089914917945862\n",
      "Starting Maximization\n",
      "Current loss 0.5235844254493713\n",
      "Current loss 1.0025460720062256\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  60.942\n",
      "Boundary avergage error = 25.877\n",
      "From boundary avergage accuracy = 69.639\n",
      "Starting Maximization\n",
      "Current loss 0.5085902810096741\n",
      "Current loss 1.2359472513198853\n",
      "Starting Maximization\n",
      "Current loss 0.5145326852798462\n",
      "Current loss 1.2111905813217163\n",
      "Starting Maximization\n",
      "Current loss 0.47456252574920654\n",
      "Current loss 0.7128930687904358\n",
      "Starting Maximization\n",
      "Current loss 0.5695303082466125\n",
      "Current loss 0.7003397941589355\n",
      "Starting Maximization\n",
      "Current loss 0.42235493659973145\n",
      "Current loss 0.7493777275085449\n",
      "Starting Maximization\n",
      "Current loss 0.3385935425758362\n",
      "Current loss 1.1842899322509766\n",
      "Starting Maximization\n",
      "Current loss 0.3736070394515991\n",
      "Current loss 0.6596710085868835\n",
      "Starting Maximization\n",
      "Current loss 0.3534761965274811\n",
      "Current loss 0.38570636510849\n",
      "Starting Maximization\n",
      "Current loss 0.3823482096195221\n",
      "Current loss 0.5345591306686401\n",
      "Starting Maximization\n",
      "Current loss 0.3259892165660858\n",
      "Current loss 1.7155296802520752\n",
      "Starting Maximization\n",
      "Current loss 0.32530489563941956\n",
      "Current loss 0.6261470913887024\n",
      "Starting Maximization\n",
      "Current loss 0.36130738258361816\n",
      "Current loss 1.1016061305999756\n",
      "Starting Maximization\n",
      "Current loss 0.31559300422668457\n",
      "Current loss 0.9785844087600708\n",
      "Starting Maximization\n",
      "Current loss 0.36612704396247864\n",
      "Current loss 0.5203512907028198\n",
      "Starting Maximization\n",
      "Current loss 0.3383693993091583\n",
      "Current loss 0.6305837035179138\n",
      "Starting Maximization\n",
      "Current loss 0.31351765990257263\n",
      "Current loss 0.5204149484634399\n",
      "Starting Maximization\n",
      "Current loss 0.27736029028892517\n",
      "Current loss 0.41584616899490356\n",
      "Starting Maximization\n",
      "Current loss 0.2875940501689911\n",
      "Current loss 0.8597472310066223\n",
      "Starting Maximization\n",
      "Current loss 0.24483931064605713\n",
      "Current loss 0.44838380813598633\n",
      "Starting Maximization\n",
      "Current loss 0.28071996569633484\n",
      "Current loss 0.3857285976409912\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  65.455\n",
      "Boundary avergage error = 25.786\n",
      "From boundary avergage accuracy = 69.471\n",
      "Starting Maximization\n",
      "Current loss 0.26834896206855774\n",
      "Current loss 0.7518966197967529\n",
      "Starting Maximization\n",
      "Current loss 0.2398778349161148\n",
      "Current loss 0.4762655198574066\n",
      "Starting Maximization\n",
      "Current loss 0.39688700437545776\n",
      "Current loss 0.5760806202888489\n",
      "Starting Maximization\n",
      "Current loss 0.25954878330230713\n",
      "Current loss 0.6332746744155884\n",
      "Starting Maximization\n",
      "Current loss 0.25910818576812744\n",
      "Current loss 0.5878400206565857\n",
      "Starting Maximization\n",
      "Current loss 0.24695943295955658\n",
      "Current loss 0.5372506380081177\n",
      "Starting Maximization\n",
      "Current loss 0.271319180727005\n",
      "Current loss 0.775968074798584\n",
      "Starting Maximization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 0.25533849000930786\n",
      "Current loss 0.801825225353241\n",
      "Starting Maximization\n",
      "Current loss 0.24907559156417847\n",
      "Current loss 0.5301936268806458\n",
      "Starting Maximization\n",
      "Current loss 0.2596633732318878\n",
      "Current loss 0.6994645595550537\n",
      "Starting Maximization\n",
      "Current loss 0.21838192641735077\n",
      "Current loss 0.4531419575214386\n",
      "Starting Maximization\n",
      "Current loss 0.2119472473859787\n",
      "Current loss 0.3317258059978485\n",
      "Starting Maximization\n",
      "Current loss 0.2114890068769455\n",
      "Current loss 0.32695472240448\n",
      "Starting Maximization\n",
      "Current loss 0.21251513063907623\n",
      "Current loss 0.41449883580207825\n",
      "Starting Maximization\n",
      "Current loss 0.23351576924324036\n",
      "Current loss 0.4815447926521301\n",
      "Starting Maximization\n",
      "Current loss 0.20313702523708344\n",
      "Current loss 0.4030141830444336\n",
      "Starting Maximization\n",
      "Current loss 0.20874278247356415\n",
      "Current loss 0.7844823598861694\n",
      "Starting Maximization\n",
      "Current loss 0.21900752186775208\n",
      "Current loss 0.44344139099121094\n",
      "Starting Maximization\n",
      "Current loss 0.20541520416736603\n",
      "Current loss 0.3884802460670471\n",
      "Starting Maximization\n",
      "Current loss 0.2234361618757248\n",
      "Current loss 0.39370977878570557\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  66.426\n",
      "Boundary avergage error = 25.516\n",
      "From boundary avergage accuracy = 69.810\n",
      "Starting Maximization\n",
      "Current loss 0.25422579050064087\n",
      "Current loss 0.41325077414512634\n",
      "Starting Maximization\n",
      "Current loss 0.22213798761367798\n",
      "Current loss 0.34961092472076416\n",
      "Starting Maximization\n",
      "Current loss 0.20314359664916992\n",
      "Current loss 0.3412924110889435\n",
      "Starting Maximization\n",
      "Current loss 0.1765962839126587\n",
      "Current loss 0.33474552631378174\n",
      "Starting Maximization\n",
      "Current loss 0.1885794699192047\n",
      "Current loss 0.6443185806274414\n",
      "Starting Maximization\n",
      "Current loss 0.17205241322517395\n",
      "Current loss 1.0493950843811035\n",
      "Starting Maximization\n",
      "Current loss 0.27633967995643616\n",
      "Current loss 0.39225903153419495\n",
      "Starting Maximization\n",
      "Current loss 0.2625935673713684\n",
      "Current loss 1.1312475204467773\n",
      "Starting Maximization\n",
      "Current loss 0.23057378828525543\n",
      "Current loss 0.42930924892425537\n",
      "Starting Maximization\n",
      "Current loss 0.32744306325912476\n",
      "Current loss 1.3356879949569702\n",
      "Starting Maximization\n",
      "Current loss 0.24744407832622528\n",
      "Current loss 1.0316381454467773\n",
      "Starting Maximization\n",
      "Current loss 0.3736938536167145\n",
      "Current loss 0.5176291465759277\n",
      "Starting Maximization\n",
      "Current loss 0.4121972322463989\n",
      "Current loss 0.8784288167953491\n",
      "Starting Maximization\n",
      "Current loss 0.26519811153411865\n",
      "Current loss 0.35009774565696716\n",
      "Starting Maximization\n",
      "Current loss 0.2608060836791992\n",
      "Current loss 0.4210485517978668\n",
      "Starting Maximization\n",
      "Current loss 0.221922367811203\n",
      "Current loss 0.36728236079216003\n",
      "Starting Maximization\n",
      "Current loss 0.22454436123371124\n",
      "Current loss 0.42744991183280945\n",
      "Starting Maximization\n",
      "Current loss 0.2335309386253357\n",
      "Current loss 0.46735137701034546\n",
      "Starting Maximization\n",
      "Current loss 0.21224656701087952\n",
      "Current loss 0.5989477038383484\n",
      "Starting Maximization\n",
      "Current loss 0.19175812602043152\n",
      "Current loss 0.7333031296730042\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  66.422\n",
      "Boundary avergage error = 23.810\n",
      "From boundary avergage accuracy = 71.655\n",
      "Starting Maximization\n",
      "Current loss 0.2180064171552658\n",
      "Current loss 0.5392793416976929\n",
      "Starting Maximization\n",
      "Current loss 0.22165706753730774\n",
      "Current loss 0.4450961649417877\n",
      "Starting Maximization\n",
      "Current loss 0.2279394268989563\n",
      "Current loss 0.24835476279258728\n",
      "Starting Maximization\n",
      "Current loss 0.19805718958377838\n",
      "Current loss 0.6701826453208923\n",
      "Starting Maximization\n",
      "Current loss 0.1732269823551178\n",
      "Current loss 0.2818927466869354\n",
      "Starting Maximization\n",
      "Current loss 0.21307696402072906\n",
      "Current loss 0.42639797925949097\n",
      "Starting Maximization\n",
      "Current loss 0.22567661106586456\n",
      "Current loss 0.3251035809516907\n",
      "Starting Maximization\n",
      "Current loss 0.21181830763816833\n",
      "Current loss 0.336675226688385\n",
      "Starting Maximization\n",
      "Current loss 0.17169158160686493\n",
      "Current loss 0.1851053535938263\n",
      "Starting Maximization\n",
      "Current loss 0.17247842252254486\n",
      "Current loss 0.6736557483673096\n",
      "Starting Maximization\n",
      "Current loss 0.15337970852851868\n",
      "Current loss 0.3240431547164917\n",
      "Starting Maximization\n",
      "Current loss 0.26289117336273193\n",
      "Current loss 0.3050798177719116\n",
      "Starting Maximization\n",
      "Current loss 0.17454254627227783\n",
      "Current loss 0.4872887134552002\n",
      "Starting Maximization\n",
      "Current loss 0.168707013130188\n",
      "Current loss 0.3077370524406433\n",
      "Starting Maximization\n",
      "Current loss 0.1467791646718979\n",
      "Current loss 0.3451094329357147\n",
      "Starting Maximization\n",
      "Current loss 0.1412310004234314\n",
      "Current loss 0.18832558393478394\n",
      "Starting Maximization\n",
      "Current loss 0.1465258151292801\n",
      "Current loss 0.1921219378709793\n",
      "Starting Maximization\n",
      "Current loss 0.1361892968416214\n",
      "Current loss 0.18789108097553253\n",
      "Starting Maximization\n",
      "Current loss 0.14024652540683746\n",
      "Current loss 0.3584090769290924\n",
      "Starting Maximization\n",
      "Current loss 0.14162205159664154\n",
      "Current loss 0.3400178551673889\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  69.389\n",
      "Boundary avergage error = 23.793\n",
      "From boundary avergage accuracy = 71.942\n",
      "Starting Maximization\n",
      "Current loss 0.1684402972459793\n",
      "Current loss 0.6555526256561279\n",
      "Starting Maximization\n",
      "Current loss 0.129120334982872\n",
      "Current loss 0.38859260082244873\n",
      "Starting Maximization\n",
      "Current loss 0.21094471216201782\n",
      "Current loss 0.43790194392204285\n",
      "Starting Maximization\n",
      "Current loss 0.1417814940214157\n",
      "Current loss 0.6074737906455994\n",
      "Starting Maximization\n",
      "Current loss 0.17527049779891968\n",
      "Current loss 0.5105847716331482\n",
      "Starting Maximization\n",
      "Current loss 0.19625118374824524\n",
      "Current loss 0.2783859372138977\n",
      "Starting Maximization\n",
      "Current loss 0.16591034829616547\n",
      "Current loss 0.5116493105888367\n",
      "Starting Maximization\n",
      "Current loss 0.15671449899673462\n",
      "Current loss 1.2047851085662842\n",
      "Starting Maximization\n",
      "Current loss 0.1794884353876114\n",
      "Current loss 0.7850621938705444\n",
      "Starting Maximization\n",
      "Current loss 0.28126394748687744\n",
      "Current loss 0.5393935441970825\n",
      "Starting Maximization\n",
      "Current loss 0.21271754801273346\n",
      "Current loss 0.5704888701438904\n",
      "Starting Maximization\n",
      "Current loss 0.19632399082183838\n",
      "Current loss 1.4617905616760254\n",
      "Starting Maximization\n",
      "Current loss 0.1892092376947403\n",
      "Current loss 0.696020781993866\n",
      "Starting Maximization\n",
      "Current loss 0.3179834187030792\n",
      "Current loss 0.28967711329460144\n",
      "Starting Maximization\n",
      "Current loss 0.23530572652816772\n",
      "Current loss 0.29668128490448\n",
      "Starting Maximization\n",
      "Current loss 0.1817985475063324\n",
      "Current loss 0.4991125166416168\n",
      "Starting Maximization\n",
      "Current loss 0.1564209908246994\n",
      "Current loss 0.5300676822662354\n",
      "Starting Maximization\n",
      "Current loss 0.22507575154304504\n",
      "Current loss 0.259624719619751\n",
      "Starting Maximization\n",
      "Current loss 0.20474392175674438\n",
      "Current loss 0.46730464696884155\n",
      "Starting Maximization\n",
      "Current loss 0.16351111233234406\n",
      "Current loss 0.9040875434875488\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  68.934\n",
      "Boundary avergage error = 23.893\n",
      "From boundary avergage accuracy = 71.620\n",
      "Starting Maximization\n",
      "Current loss 0.17997244000434875\n",
      "Current loss 0.2244870811700821\n",
      "Starting Maximization\n",
      "Current loss 0.19931569695472717\n",
      "Current loss 0.43099674582481384\n",
      "Starting Maximization\n",
      "Current loss 0.1717861145734787\n",
      "Current loss 0.6189868450164795\n",
      "Starting Maximization\n",
      "Current loss 0.15940739214420319\n",
      "Current loss 0.5174453854560852\n",
      "Starting Maximization\n",
      "Current loss 0.25009164214134216\n",
      "Current loss 0.2692800462245941\n",
      "Starting Maximization\n",
      "Current loss 0.18734177947044373\n",
      "Current loss 0.24017314612865448\n",
      "Starting Maximization\n",
      "Current loss 0.1543257087469101\n",
      "Current loss 0.2322487086057663\n",
      "Starting Maximization\n",
      "Current loss 0.13386596739292145\n",
      "Current loss 0.23914046585559845\n",
      "Starting Maximization\n",
      "Current loss 0.1375003457069397\n",
      "Current loss 0.6606167554855347\n",
      "Starting Maximization\n",
      "Current loss 0.11911477148532867\n",
      "Current loss 0.5158906579017639\n",
      "Starting Maximization\n",
      "Current loss 0.14788830280303955\n",
      "Current loss 0.7565322518348694\n",
      "Starting Maximization\n",
      "Current loss 0.18903344869613647\n",
      "Current loss 0.4137583076953888\n",
      "Starting Maximization\n",
      "Current loss 0.22456352412700653\n",
      "Current loss 0.791303813457489\n",
      "Starting Maximization\n",
      "Current loss 0.1627662032842636\n",
      "Current loss 0.2696298360824585\n",
      "Starting Maximization\n",
      "Current loss 0.18250374495983124\n",
      "Current loss 0.44484084844589233\n",
      "Starting Maximization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 0.15942732989788055\n",
      "Current loss 0.29187363386154175\n",
      "Starting Maximization\n",
      "Current loss 0.2671394646167755\n",
      "Current loss 0.3501001000404358\n",
      "Starting Maximization\n",
      "Current loss 0.16392214596271515\n",
      "Current loss 0.2960975170135498\n",
      "Starting Maximization\n",
      "Current loss 0.14465798437595367\n",
      "Current loss 0.33365127444267273\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  69.843\n",
      "Boundary avergage error = 23.535\n",
      "From boundary avergage accuracy = 72.224\n",
      "Starting Maximization\n",
      "Current loss 0.12820930778980255\n",
      "Current loss 0.5010755658149719\n",
      "Starting Maximization\n",
      "Current loss 0.13095463812351227\n",
      "Current loss 1.9360158443450928\n",
      "Starting Maximization\n",
      "Current loss 0.15495926141738892\n",
      "Current loss 0.41971829533576965\n",
      "Starting Maximization\n",
      "Current loss 0.1844165176153183\n",
      "Current loss 0.29353585839271545\n",
      "Starting Maximization\n",
      "Current loss 0.20127779245376587\n",
      "Current loss 0.5316897034645081\n",
      "Starting Maximization\n",
      "Current loss 0.13907720148563385\n",
      "Current loss 0.21682296693325043\n",
      "Starting Maximization\n",
      "Current loss 0.17523926496505737\n",
      "Current loss 0.7007399201393127\n",
      "Starting Maximization\n",
      "Current loss 0.13887836039066315\n",
      "Current loss 0.5030433535575867\n",
      "Starting Maximization\n",
      "Current loss 0.25142616033554077\n",
      "Current loss 0.34263667464256287\n",
      "Starting Maximization\n",
      "Current loss 0.15731920301914215\n",
      "Current loss 0.34456562995910645\n",
      "Starting Maximization\n",
      "Current loss 0.15915580093860626\n",
      "Current loss 0.6472858190536499\n",
      "Starting Maximization\n",
      "Current loss 0.16814979910850525\n",
      "Current loss 0.6244418621063232\n",
      "Starting Maximization\n",
      "Current loss 0.15874963998794556\n",
      "Current loss 0.2474401295185089\n",
      "Starting Maximization\n",
      "Current loss 0.18561342358589172\n",
      "Current loss 0.23001454770565033\n",
      "Starting Maximization\n",
      "Current loss 0.15617746114730835\n",
      "Current loss 0.5518478155136108\n",
      "Starting Maximization\n",
      "Current loss 0.1635180115699768\n",
      "Current loss 0.45311224460601807\n",
      "Starting Maximization\n",
      "Current loss 0.15491780638694763\n",
      "Current loss 0.3253864645957947\n",
      "Starting Maximization\n",
      "Current loss 0.1238330528140068\n",
      "Current loss 0.28949397802352905\n",
      "Starting Maximization\n",
      "Current loss 0.1545984447002411\n",
      "Current loss 0.36087340116500854\n",
      "Starting Maximization\n",
      "Current loss 0.1423765867948532\n",
      "Current loss 0.6613652110099792\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  70.076\n",
      "Boundary avergage error = 23.445\n",
      "From boundary avergage accuracy = 72.557\n",
      "Starting Maximization\n",
      "Current loss 0.12510399520397186\n",
      "Current loss 0.4242660105228424\n",
      "Starting Maximization\n",
      "Current loss 0.14471140503883362\n",
      "Current loss 0.19875848293304443\n",
      "Starting Maximization\n",
      "Current loss 0.14707839488983154\n",
      "Current loss 0.2843722105026245\n",
      "Starting Maximization\n",
      "Current loss 0.12614059448242188\n",
      "Current loss 0.149778351187706\n",
      "Starting Maximization\n",
      "Current loss 0.12102361768484116\n",
      "Current loss 0.27955594658851624\n",
      "Starting Maximization\n",
      "Current loss 0.1153516098856926\n",
      "Current loss 0.28148743510246277\n",
      "Starting Maximization\n",
      "Current loss 0.1190524697303772\n",
      "Current loss 0.2601156532764435\n",
      "Starting Maximization\n",
      "Current loss 0.10135965049266815\n",
      "Current loss 0.3671937584877014\n",
      "Starting Maximization\n",
      "Current loss 0.11299721896648407\n",
      "Current loss 0.14693450927734375\n",
      "Starting Maximization\n",
      "Current loss 0.10667309165000916\n",
      "Current loss 0.2157508134841919\n",
      "Starting Maximization\n",
      "Current loss 0.1413709670305252\n",
      "Current loss 0.2424890697002411\n",
      "Starting Maximization\n",
      "Current loss 0.09252949804067612\n",
      "Current loss 0.3568839132785797\n",
      "Starting Maximization\n",
      "Current loss 0.11641917377710342\n",
      "Current loss 0.2259165495634079\n",
      "Starting Maximization\n",
      "Current loss 0.11421608179807663\n",
      "Current loss 0.20754575729370117\n",
      "Starting Maximization\n",
      "Current loss 0.12171048671007156\n",
      "Current loss 0.199827641248703\n",
      "Starting Maximization\n",
      "Current loss 0.10209258645772934\n",
      "Current loss 0.25983935594558716\n",
      "Starting Maximization\n",
      "Current loss 0.09875219315290451\n",
      "Current loss 0.16359646618366241\n",
      "Starting Maximization\n",
      "Current loss 0.10951484739780426\n",
      "Current loss 0.4753625690937042\n",
      "Starting Maximization\n",
      "Current loss 0.09790020436048508\n",
      "Current loss 0.2190883457660675\n",
      "Starting Maximization\n",
      "Current loss 0.12406542152166367\n",
      "Current loss 0.18457245826721191\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  70.203\n",
      "Boundary avergage error = 23.464\n",
      "From boundary avergage accuracy = 72.462\n",
      "Starting Maximization\n",
      "Current loss 0.13661929965019226\n",
      "Current loss 0.36849814653396606\n",
      "Starting Maximization\n",
      "Current loss 0.10851503163576126\n",
      "Current loss 0.2701883316040039\n",
      "Starting Maximization\n",
      "Current loss 0.11982720345258713\n",
      "Current loss 0.38732200860977173\n",
      "Starting Maximization\n",
      "Current loss 0.09777969121932983\n",
      "Current loss 0.1661282479763031\n",
      "Starting Maximization\n",
      "Current loss 0.09912466257810593\n",
      "Current loss 0.4915153682231903\n",
      "Starting Maximization\n",
      "Current loss 0.119839608669281\n",
      "Current loss 0.20297686755657196\n",
      "Starting Maximization\n",
      "Current loss 0.14212018251419067\n",
      "Current loss 0.1564905047416687\n",
      "Starting Maximization\n",
      "Current loss 0.11358314007520676\n",
      "Current loss 0.21292035281658173\n",
      "Starting Maximization\n",
      "Current loss 0.11671092361211777\n",
      "Current loss 0.20795980095863342\n",
      "Starting Maximization\n",
      "Current loss 0.1084364652633667\n",
      "Current loss 0.18279217183589935\n",
      "Starting Maximization\n",
      "Current loss 0.10403884202241898\n",
      "Current loss 0.15349797904491425\n",
      "Starting Maximization\n",
      "Current loss 0.09003377705812454\n",
      "Current loss 0.19195556640625\n",
      "Starting Maximization\n",
      "Current loss 0.099918432533741\n",
      "Current loss 0.1673704832792282\n",
      "Starting Maximization\n",
      "Current loss 0.09869355708360672\n",
      "Current loss 0.10880293697118759\n",
      "Starting Maximization\n",
      "Current loss 0.09247031807899475\n",
      "Current loss 0.3158942461013794\n",
      "Starting Maximization\n",
      "Current loss 0.09119762480258942\n",
      "Current loss 0.4272339642047882\n",
      "Starting Maximization\n",
      "Current loss 0.09426648169755936\n",
      "Current loss 0.17980603873729706\n",
      "Starting Maximization\n",
      "Current loss 0.12126131355762482\n",
      "Current loss 0.1978902369737625\n",
      "Starting Maximization\n",
      "Current loss 0.12519627809524536\n",
      "Current loss 0.21313486993312836\n",
      "Starting Maximization\n",
      "Current loss 0.11154479533433914\n",
      "Current loss 0.2298254817724228\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  70.394\n",
      "Boundary avergage error = 23.511\n",
      "From boundary avergage accuracy = 72.390\n",
      "Starting Maximization\n",
      "Current loss 0.09452131390571594\n",
      "Current loss 0.18284118175506592\n",
      "Starting Maximization\n",
      "Current loss 0.09531794488430023\n",
      "Current loss 0.296663761138916\n",
      "Starting Maximization\n",
      "Current loss 0.10226491093635559\n",
      "Current loss 0.22803330421447754\n",
      "Starting Maximization\n",
      "Current loss 0.10868580639362335\n",
      "Current loss 0.18954986333847046\n",
      "Starting Maximization\n",
      "Current loss 0.09764251112937927\n",
      "Current loss 0.16656142473220825\n",
      "Starting Maximization\n",
      "Current loss 0.08607448637485504\n",
      "Current loss 0.1862429678440094\n",
      "Starting Maximization\n",
      "Current loss 0.08217743784189224\n",
      "Current loss 0.16530311107635498\n",
      "Starting Maximization\n",
      "Current loss 0.09278436750173569\n",
      "Current loss 0.1892472803592682\n",
      "Starting Maximization\n",
      "Current loss 0.07945489138364792\n",
      "Current loss 0.16906553506851196\n",
      "Starting Maximization\n",
      "Current loss 0.09230590611696243\n",
      "Current loss 0.282790869474411\n",
      "Starting Maximization\n",
      "Current loss 0.08765066415071487\n",
      "Current loss 0.1574278622865677\n",
      "Starting Maximization\n",
      "Current loss 0.08637742698192596\n",
      "Current loss 0.18079248070716858\n",
      "Starting Maximization\n",
      "Current loss 0.10007882863283157\n",
      "Current loss 0.14424750208854675\n",
      "Starting Maximization\n",
      "Current loss 0.0796060860157013\n",
      "Current loss 0.1656770557165146\n",
      "Starting Maximization\n",
      "Current loss 0.07745058089494705\n",
      "Current loss 0.14908616244792938\n",
      "Starting Maximization\n",
      "Current loss 0.07467810064554214\n",
      "Current loss 0.09659833461046219\n",
      "Starting Maximization\n",
      "Current loss 0.0706411600112915\n",
      "Current loss 0.6220013499259949\n",
      "Starting Maximization\n",
      "Current loss 0.07590676844120026\n",
      "Current loss 0.184997096657753\n",
      "Starting Maximization\n",
      "Current loss 0.10973178595304489\n",
      "Current loss 0.22435323894023895\n",
      "Starting Maximization\n",
      "Current loss 0.0876573920249939\n",
      "Current loss 0.2066061645746231\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  70.849\n",
      "Boundary avergage error = 23.498\n",
      "From boundary avergage accuracy = 72.568\n",
      "Starting Maximization\n",
      "Current loss 0.08600899577140808\n",
      "Current loss 0.21818281710147858\n",
      "Starting Maximization\n",
      "Current loss 0.07811151444911957\n",
      "Current loss 0.1829536408185959\n",
      "Starting Maximization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 0.0893232673406601\n",
      "Current loss 0.13249072432518005\n",
      "Starting Maximization\n",
      "Current loss 0.1200186163187027\n",
      "Current loss 0.31393471360206604\n",
      "Starting Maximization\n",
      "Current loss 0.07908844947814941\n",
      "Current loss 0.1776372194290161\n",
      "Starting Maximization\n",
      "Current loss 0.09160803258419037\n",
      "Current loss 0.11447453498840332\n",
      "Starting Maximization\n",
      "Current loss 0.07439353317022324\n",
      "Current loss 0.12699493765830994\n",
      "Starting Maximization\n",
      "Current loss 0.0852833092212677\n",
      "Current loss 0.1501261442899704\n",
      "Starting Maximization\n",
      "Current loss 0.07572557777166367\n",
      "Current loss 0.21132434904575348\n",
      "Starting Maximization\n",
      "Current loss 0.08000674098730087\n",
      "Current loss 0.3169117271900177\n",
      "Starting Maximization\n",
      "Current loss 0.0779327005147934\n",
      "Current loss 0.1910882592201233\n",
      "Starting Maximization\n",
      "Current loss 0.10560677200555801\n",
      "Current loss 0.1806829571723938\n",
      "Starting Maximization\n",
      "Current loss 0.10452376306056976\n",
      "Current loss 0.1769002079963684\n",
      "Starting Maximization\n",
      "Current loss 0.08599433302879333\n",
      "Current loss 0.14041626453399658\n",
      "Starting Maximization\n",
      "Current loss 0.08470186591148376\n",
      "Current loss 0.17154711484909058\n",
      "Starting Maximization\n",
      "Current loss 0.08301778882741928\n",
      "Current loss 0.1700187474489212\n",
      "Starting Maximization\n",
      "Current loss 0.08542589098215103\n",
      "Current loss 0.14233054220676422\n",
      "Starting Maximization\n",
      "Current loss 0.08130497485399246\n",
      "Current loss 0.2593775689601898\n",
      "Starting Maximization\n",
      "Current loss 0.07337014377117157\n",
      "Current loss 0.17633818089962006\n",
      "Starting Maximization\n",
      "Current loss 0.08290958404541016\n",
      "Current loss 0.21133820712566376\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  71.069\n",
      "Boundary avergage error = 23.541\n",
      "From boundary avergage accuracy = 72.627\n",
      "Starting Maximization\n",
      "Current loss 0.08423848450183868\n",
      "Current loss 0.15168482065200806\n",
      "Starting Maximization\n",
      "Current loss 0.09191763401031494\n",
      "Current loss 0.1660071611404419\n",
      "Starting Maximization\n",
      "Current loss 0.09059226512908936\n",
      "Current loss 0.16967858374118805\n",
      "Starting Maximization\n",
      "Current loss 0.08831220120191574\n",
      "Current loss 0.1482962667942047\n",
      "Starting Maximization\n",
      "Current loss 0.07203346490859985\n",
      "Current loss 0.19838139414787292\n",
      "Starting Maximization\n",
      "Current loss 0.07151640951633453\n",
      "Current loss 0.8242779970169067\n",
      "Starting Maximization\n",
      "Current loss 0.08455844968557358\n",
      "Current loss 0.18716838955879211\n",
      "Starting Maximization\n",
      "Current loss 0.1187724694609642\n",
      "Current loss 0.4244449734687805\n",
      "Starting Maximization\n",
      "Current loss 0.13389883935451508\n",
      "Current loss 0.2940419912338257\n",
      "Starting Maximization\n",
      "Current loss 0.15764473378658295\n",
      "Current loss 0.7720044851303101\n",
      "Starting Maximization\n",
      "Current loss 0.2874215543270111\n",
      "Current loss 0.48295924067497253\n",
      "Starting Maximization\n",
      "Current loss 0.2712439000606537\n",
      "Current loss 0.5305377244949341\n",
      "Starting Maximization\n",
      "Current loss 0.2251817137002945\n",
      "Current loss 0.5630227327346802\n",
      "Starting Maximization\n",
      "Current loss 0.19270558655261993\n",
      "Current loss 0.2204439640045166\n",
      "Starting Maximization\n",
      "Current loss 0.1877564638853073\n",
      "Current loss 0.5006808042526245\n",
      "Starting Maximization\n",
      "Current loss 0.15956619381904602\n",
      "Current loss 0.21925902366638184\n",
      "Starting Maximization\n",
      "Current loss 0.16091220080852509\n",
      "Current loss 0.293745219707489\n",
      "Starting Maximization\n",
      "Current loss 0.12698805332183838\n",
      "Current loss 0.26336175203323364\n",
      "Starting Maximization\n",
      "Current loss 0.13391271233558655\n",
      "Current loss 0.18660491704940796\n",
      "Starting Maximization\n",
      "Current loss 0.12299899756908417\n",
      "Current loss 1.3372244834899902\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  70.652\n",
      "Boundary avergage error = 23.470\n",
      "From boundary avergage accuracy = 72.675\n",
      "Starting Maximization\n",
      "Current loss 0.11420367658138275\n",
      "Current loss 0.2202695608139038\n",
      "Starting Maximization\n",
      "Current loss 0.1641702800989151\n",
      "Current loss 0.535923957824707\n",
      "Starting Maximization\n",
      "Current loss 0.17373895645141602\n",
      "Current loss 0.47951313853263855\n",
      "Starting Maximization\n",
      "Current loss 0.20324315130710602\n",
      "Current loss 1.19853937625885\n",
      "Starting Maximization\n",
      "Current loss 0.15300694108009338\n",
      "Current loss 0.8447578549385071\n",
      "Starting Maximization\n",
      "Current loss 0.1961866170167923\n",
      "Current loss 0.38015487790107727\n",
      "Starting Maximization\n",
      "Current loss 0.21068234741687775\n",
      "Current loss 0.33202263712882996\n",
      "Starting Maximization\n",
      "Current loss 0.1605043113231659\n",
      "Current loss 0.4307161569595337\n",
      "Starting Maximization\n",
      "Current loss 0.17500661313533783\n",
      "Current loss 0.18311789631843567\n",
      "Starting Maximization\n",
      "Current loss 0.192748561501503\n",
      "Current loss 0.3476994037628174\n",
      "Starting Maximization\n",
      "Current loss 0.14674653112888336\n",
      "Current loss 0.38248422741889954\n",
      "Starting Maximization\n",
      "Current loss 0.1377241462469101\n",
      "Current loss 0.6217011213302612\n",
      "Starting Maximization\n",
      "Current loss 0.1314312219619751\n",
      "Current loss 0.1473097801208496\n",
      "Starting Maximization\n",
      "Current loss 0.13910798728466034\n",
      "Current loss 0.12658333778381348\n",
      "Starting Maximization\n",
      "Current loss 0.11535146087408066\n",
      "Current loss 0.17290087044239044\n",
      "Starting Maximization\n",
      "Current loss 0.10760233551263809\n",
      "Current loss 0.19133135676383972\n",
      "Starting Maximization\n",
      "Current loss 0.09643591940402985\n",
      "Current loss 0.3056204319000244\n",
      "Starting Maximization\n",
      "Current loss 0.09728547185659409\n",
      "Current loss 0.1412459909915924\n",
      "Starting Maximization\n",
      "Current loss 0.10688886046409607\n",
      "Current loss 0.1922260820865631\n",
      "Starting Maximization\n",
      "Current loss 0.09713461250066757\n",
      "Current loss 0.1655987650156021\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  70.841\n",
      "Boundary avergage error = 23.404\n",
      "From boundary avergage accuracy = 72.659\n",
      "Starting Maximization\n",
      "Current loss 0.0963590145111084\n",
      "Current loss 0.31472375988960266\n",
      "Starting Maximization\n",
      "Current loss 0.09352266043424606\n",
      "Current loss 0.23048508167266846\n",
      "Starting Maximization\n",
      "Current loss 0.09370849281549454\n",
      "Current loss 0.4383147656917572\n",
      "Starting Maximization\n",
      "Current loss 0.0997515544295311\n",
      "Current loss 0.20313666760921478\n",
      "Starting Maximization\n",
      "Current loss 0.10474596917629242\n",
      "Current loss 0.4536428451538086\n",
      "Starting Maximization\n",
      "Current loss 0.1026620864868164\n",
      "Current loss 0.35885322093963623\n",
      "Starting Maximization\n",
      "Current loss 0.11282766610383987\n",
      "Current loss 0.16662882268428802\n",
      "Starting Maximization\n",
      "Current loss 0.13524027168750763\n",
      "Current loss 0.9469508528709412\n",
      "Starting Maximization\n",
      "Current loss 0.13769130408763885\n",
      "Current loss 0.21231384575366974\n",
      "Starting Maximization\n",
      "Current loss 0.18368269503116608\n",
      "Current loss 0.28598466515541077\n",
      "Starting Maximization\n",
      "Current loss 0.15715935826301575\n",
      "Current loss 0.3778586983680725\n",
      "Starting Maximization\n",
      "Current loss 0.11581265181303024\n",
      "Current loss 0.4841812252998352\n",
      "Starting Maximization\n",
      "Current loss 0.13792671263217926\n",
      "Current loss 0.47587358951568604\n",
      "Starting Maximization\n",
      "Current loss 0.12743858993053436\n",
      "Current loss 0.20130978524684906\n",
      "Starting Maximization\n",
      "Current loss 0.14365284144878387\n",
      "Current loss 0.1896272450685501\n",
      "Starting Maximization\n",
      "Current loss 0.09012963622808456\n",
      "Current loss 0.24190044403076172\n",
      "Starting Maximization\n",
      "Current loss 0.10810554772615433\n",
      "Current loss 0.424592524766922\n",
      "Starting Maximization\n",
      "Current loss 0.10472102463245392\n",
      "Current loss 0.1764436662197113\n",
      "Calculating Expectation\n",
      "Accuracy calculated with probabilities  68.188\n",
      "Boundary avergage error = 23.424\n",
      "From boundary avergage accuracy = 72.740\n",
      "Starting Maximization\n",
      "Current loss 0.141127347946167\n",
      "Current loss 0.3095707893371582\n",
      "Starting Maximization\n",
      "Current loss 0.131344735622406\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3f1f39daad71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_estimated_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-2ff6527b3383>\u001b[0m in \u001b[0;36mget_estimated_loss\u001b[0;34m(data_feat, data_count, video_ids, labels_all)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0msum_window_class_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcumsum_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_cur_ele\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0msum_window_class_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcumsum_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_ele\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcumsum_feat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel_next_ele\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mcurrent_vid_prob_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_window_class_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msum_window_class_2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprob_each_video\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(2000):\n",
    "    if epoch % 20 == 0:\n",
    "        model.eval()\n",
    "        print(\"Calculating Expectation\")\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        for i, item in enumerate(trainloader):\n",
    "            with torch.no_grad():\n",
    "                item[0] = item[0].to(device)\n",
    "                item[1] = item[1].to(device)\n",
    "                item[2] = item[2].to(device)\n",
    "                y, _, features = model(item[0].permute(0,2,1))\n",
    "                prob = torch.softmax(y, dim=1)\n",
    "                prob = prob.permute(0,2,1)\n",
    "                calculate_element_probb(prob, item[1], item[5], item[2])\n",
    "                \n",
    "                src_mask = torch.arange(item[2].shape[1], device=item[2].device)[None, :] < item[1][:, None]\n",
    "                pred = torch.argmax(prob, dim=2)\n",
    "                correct += float(torch.sum((pred == item[2]) * src_mask).item())\n",
    "                total += float(torch.sum(src_mask).item())\n",
    "        print(f\"Accuracy calculated with probabilities {correct * 100.0 / total: .3f}\")\n",
    "        get_boundary_err()\n",
    "    model.train()\n",
    "    print(\"Starting Maximization\")\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item[0] = item[0].to(device)\n",
    "        item[1] = item[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y, _, features = model(item[0].permute(0,2,1))\n",
    "        prob = torch.softmax(y, dim=1)\n",
    "        prob = prob.permute(0,2,1)\n",
    "        loss, _ = get_estimated_loss(prob, item[1], item[5], item[2].to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%5==0:\n",
    "            print(f\"Current loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_labels(labels_arr):\n",
    "    unique_ids = []\n",
    "    \n",
    "    prev_ele = None\n",
    "    start = 0\n",
    "    for i, ele in enumerate(labels_arr):\n",
    "        if prev_ele is not None and prev_ele != ele:\n",
    "            select_item = np.random.randint(start, i, 1)[0]\n",
    "            unique_ids.append(select_item)\n",
    "            start = i\n",
    "        prev_ele = ele\n",
    "    \n",
    "    select_item = np.random.randint(start, len(labels_arr), 1)[0]\n",
    "    unique_ids.append(select_item)\n",
    "    return unique_ids\n",
    "# get_selected_labels(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary(labels_arr):\n",
    "    unique_ids = []\n",
    "    \n",
    "    prev_ele = None\n",
    "    start = 0\n",
    "    for i, ele in enumerate(labels_arr):\n",
    "        if prev_ele is not None and prev_ele != ele:\n",
    "            unique_ids.append(i - 1)\n",
    "            start = i\n",
    "        prev_ele = ele\n",
    "    \n",
    "    unique_ids.append(len(labels_arr) - 1)\n",
    "    return unique_ids\n",
    "# get_boundary(np.array([2, 2, 2, 2, 3, 3, 4, 4, 4, 1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    }
   ],
   "source": [
    "loaded_vidid_selected_frames = {}\n",
    "for batch in trainloader:\n",
    "    count_all = batch[1]\n",
    "    labels_all = batch[2]\n",
    "    video_ids = batch[5]\n",
    "    for i, count in enumerate(count_all):\n",
    "        video_id = video_ids[i]\n",
    "        labels = labels_all[i][:count]\n",
    "        selected_ids = get_selected_labels(labels)\n",
    "\n",
    "        loaded_vidid_selected_frames[video_id] = selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id_boundary_frames = {}\n",
    "for batch in trainloader:\n",
    "    count_all = batch[1]\n",
    "    labels_all = batch[2]\n",
    "    video_ids = batch[5]\n",
    "    for i, count in enumerate(count_all):\n",
    "        \n",
    "        labels = labels_all[i][:count]\n",
    "        selected_ids = get_boundary(labels)\n",
    "        video_id = video_ids[i]\n",
    "        video_id_boundary_frames[video_id] = selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in video_id_boundary_frames.keys():\n",
    "    if len(video_id_boundary_frames[ele]) != len(loaded_vidid_selected_frames[ele]):\n",
    "        print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(video_id_boundary_frames, open(\"dump_dir/video_id_boundary_frames_dict.pkl\", \"wb\"))\n",
    "pickle.dump(loaded_vidid_selected_frames, open(\"dump_dir/loaded_vidid_selected_frames_dict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_out(outp):\n",
    "    \n",
    "    weights = [1, 1, 1, 1, 0, 0]\n",
    "    ensemble_prob = F.softmax(outp[0], dim=1) * weights[0] / sum(weights)\n",
    "\n",
    "    for i, outp_ele in enumerate(outp[1]):\n",
    "        upped_logit = F.upsample(outp_ele, size=outp[0].shape[-1], mode='linear', align_corners=True)\n",
    "        ensemble_prob = ensemble_prob + F.softmax(upped_logit, dim=1) * weights[i + 1] / sum(weights)\n",
    "    \n",
    "    return ensemble_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/results/c2f-tcn-model/split2_c2ftcn_model.wt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary avergage error = 25.242\n",
      "From boundary avergage accuracy = 69.543\n",
      "tensor(0.4019)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "loss_arr = []\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        item[0] = item[0].to(device)\n",
    "        item[1] = item[1].to(device)\n",
    "        y, y_list, _ = model(item[0].permute(0,2,1))\n",
    "        prob = torch.softmax(y, dim=1).permute(0,2,1)\n",
    "#         prob = get_ensemble_out([y, y_list]).permute(0,2,1)\n",
    "        calculate_element_probb(prob, item[1], item[5], item[2].to(device))\n",
    "        loss, _ = get_estimated_loss(prob, item[1], item[5], item[2].to(device))\n",
    "        loss_arr.append(loss)\n",
    "        \n",
    "        estimated_labels = torch.argmax(prob, dim=2)\n",
    "        correct += torch.sum(estimated_labels == )\n",
    "#         probs = get_ensemble_out([y, y_list])\n",
    "#         features = torch.log(probs + 1e-4).permute(0,2,1)\n",
    "#         get_estimated_boundary(features, item[1], item[5])\n",
    "get_boundary_err()\n",
    "print(\"Average loss\", torch.mean(torch.tensor(loss_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4542, device='cuda:0')\n",
      "tensor(0.1349, device='cuda:0')\n",
      "tensor(1.5728, device='cuda:0')\n",
      "tensor(0.6470, device='cuda:0')\n",
      "tensor(0.2702, device='cuda:0')\n",
      "tensor(0.5915, device='cuda:0')\n",
      "tensor(2.8901, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(prob.shape[0]):\n",
    "    loss_i, _ = get_estimated_loss(prob[i].unsqueeze(0), item[1][i].unsqueeze(0), [item[5][i]], item[2][i].unsqueeze(0))\n",
    "    print(loss_i)\n",
    "#     print(torch.mean(torch.cat(loss_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7432, device='cuda:0')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    idx = 6\n",
    "\n",
    "    cur_vid_feat = prob[idx]\n",
    "    cur_vidid = item[5][idx]\n",
    "    labels = item[2][idx]\n",
    "    selected_frames = torch.tensor(loaded_vidid_selected_frames[cur_vidid], dtype=torch.long, \n",
    "                                   device=cur_vid_feat.device)\n",
    "    prob_each_segment = prob_vals_per_segment(selected_frames, cur_vid_feat, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_i, _ = get_estimated_loss(prob[idx].unsqueeze(0), item[1][idx].unsqueeze(0), [item[5][idx]], item[2][idx].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8901, device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1.2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ymax = 1.2\n",
    "\n",
    "plt.plot([0, item[1][idx].item()], [0, 0])\n",
    "\n",
    "for pivot in loaded_vidid_selected_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, ymax], '--')\n",
    "    \n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, ymax])\n",
    "    \n",
    "all_prob = []\n",
    "for i, segment in enumerate(prob_each_segment):\n",
    "#     all_prob.append(segment/torch.sum(segment))\n",
    "    prob_i = segment / torch.sum(segment)\n",
    "    prob_i = prob_i.cpu().numpy()\n",
    "    xs = np.arange(loaded_vidid_selected_frames[cur_vidid][i], loaded_vidid_selected_frames[cur_vidid][i+1])\n",
    "    plt.plot(xs, prob_i, '*')\n",
    "\n",
    "plt.ylim([0, ymax])\n",
    "# all_prob = torch.cat(all_prob).cpu().numpy()\n",
    "# xs = np.arange(loaded_vidid_selected_frames[cur_vidid][0] + 1, loaded_vidid_selected_frames[cur_vidid][-1])\n",
    "# plt.plot(xs, all_prob, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_vid_feat = torch.softmax(y, dim=1).permute(0,2,1)[idx]\n",
    "cur_vid_count = item[1][idx]\n",
    "labels = item[2][idx]\n",
    "\n",
    "selected_frames = loaded_vidid_selected_frames[cur_vidid]\n",
    "prob_each_video = prob_video_each_segment_dict[cur_vidid]\n",
    "\n",
    "log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "\n",
    "full_arr = []\n",
    "for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "    next_ele = selected_frames[i + 1]\n",
    "    label_cur_ele = labels[cur_ele]\n",
    "    label_next_ele = labels[next_ele]\n",
    "    prob_list = [] \n",
    "\n",
    "    count = 0\n",
    "    for ele in range(cur_ele, next_ele, 1):\n",
    "        start_sum = cumsum_feat[cur_ele - 1, :] if cur_ele > 0 else 0\n",
    "        sum_window_class_1 = (cumsum_feat[ele, :] - start_sum)[label_cur_ele]\n",
    "        sum_window_class_2 = (cumsum_feat[next_ele - 1, :] - cumsum_feat[ele, :])[label_next_ele]\n",
    "        prob_list.append((sum_window_class_1 + sum_window_class_2)  * (prob_each_video[i][count].item()))\n",
    "        count = count + 1\n",
    "    full_arr.append(torch.stack(prob_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3756, device='cuda:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.mean(torch.cat(full_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cur_ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(47)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_next_ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 18, 60, 102, 183, 198, 242]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_arr = []\n",
    "\n",
    "\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "all_prob = []\n",
    "for i, segment in enumerate(prob_each_segment):\n",
    "#     all_prob.append(segment/torch.sum(segment))\n",
    "    prob_i = segment / torch.sum(segment)\n",
    "    prob_i = prob_i.cpu().numpy()\n",
    "    xs = np.arange(loaded_vidid_selected_frames[cur_vidid][i], loaded_vidid_selected_frames[cur_vidid][i+1])\n",
    "    plt.plot(xs, prob_i, '*')\n",
    "\n",
    "for pivot in loaded_vidid_selected_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, ymax], '--')\n",
    "    \n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
