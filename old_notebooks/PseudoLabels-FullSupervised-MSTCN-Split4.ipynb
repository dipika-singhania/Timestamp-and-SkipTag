{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 4, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split4/', 'project_name': 'breakfast-split-4', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split4.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split4.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split4_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=4,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split4/\",\n",
    "    project_name=\"breakfast-split-4\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1136\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 576\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = Breakfast(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels_dir = \"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/length_segmentation_output/\"\n",
    "def get_single_random(output_p, video_ids):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((output_p.shape[0], output_p.shape[2]), dtype=torch.long, \n",
    "                                        device=output_p.device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        pseudo_l = open(pseudo_labels_dir + cur_vidid + \".txt\").read().split(\"\\n\")[0:-1]\n",
    "        pseudo_l = [label_name_to_label_id_dict[ele] for ele in pseudo_l]\n",
    "        abc = torch.tensor(pseudo_l).to(torch.long).to(boundary_target_tensor.device)\n",
    "        frame_idx_tensor = torch.arange(0, len(pseudo_l), 1).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = abc\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Training:: Epoch 0, Iteration 0, Current loss 15.743518829345703 Accuracy 3.737044714243411\n",
      "Training:: Epoch 0, Iteration 10, Current loss 13.267817497253418 Accuracy 16.09777263523286\n",
      "Training:: Epoch 0, Iteration 20, Current loss 13.018302917480469 Accuracy 3.632347527303964\n",
      "Training:: Epoch 0, Iteration 30, Current loss 12.549955368041992 Accuracy 18.77851684899126\n",
      "Training:: Epoch 0, Iteration 40, Current loss 14.110186576843262 Accuracy 8.210645526613817\n",
      "Training:: Epoch 0, Iteration 50, Current loss 11.841203689575195 Accuracy 27.4247491638796\n",
      "Training:: Epoch 0, Iteration 60, Current loss 11.493738174438477 Accuracy 18.26611033843301\n",
      "Training:: Epoch 0, Iteration 70, Current loss 12.444272994995117 Accuracy 8.700303084328757\n",
      "Training:: Epoch 0, Iteration 80, Current loss 11.369422912597656 Accuracy 12.475806451612904\n",
      "Training:: Epoch 0, Iteration 90, Current loss 11.29186725616455 Accuracy 16.064356435643564\n",
      "Training:: Epoch 0, Iteration 100, Current loss 10.371188163757324 Accuracy 30.22625500824888\n",
      "Training:: Epoch 0, Iteration 110, Current loss 11.697405815124512 Accuracy 14.440403372458258\n",
      "Training:: Epoch 0, Iteration 120, Current loss 9.912446975708008 Accuracy 24.318026045236465\n",
      "Training:: Epoch 0, Iteration 130, Current loss 11.427206039428711 Accuracy 8.181644906127895\n",
      "Training:: Epoch 0, Iteration 140, Current loss 11.368038177490234 Accuracy 14.250871080139373\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 0, Probability Accuracy 15.346832332237465\n",
      "Starting Training\n",
      "Training:: Epoch 1, Iteration 0, Current loss 9.956944465637207 Accuracy 19.096714626452258\n",
      "Training:: Epoch 1, Iteration 10, Current loss 9.28412914276123 Accuracy 21.138845553822154\n",
      "Training:: Epoch 1, Iteration 20, Current loss 9.505902290344238 Accuracy 24.016034985422742\n",
      "Training:: Epoch 1, Iteration 30, Current loss 10.731428146362305 Accuracy 13.583733408641626\n",
      "Training:: Epoch 1, Iteration 40, Current loss 9.540072441101074 Accuracy 16.059479553903344\n",
      "Training:: Epoch 1, Iteration 50, Current loss 8.559831619262695 Accuracy 24.026792227601298\n",
      "Training:: Epoch 1, Iteration 60, Current loss 9.275534629821777 Accuracy 21.87886279357231\n",
      "Training:: Epoch 1, Iteration 70, Current loss 9.272943496704102 Accuracy 22.248689852310623\n",
      "Training:: Epoch 1, Iteration 80, Current loss 8.99483871459961 Accuracy 30.867107697766965\n",
      "Training:: Epoch 1, Iteration 90, Current loss 9.149032592773438 Accuracy 34.61524045129128\n",
      "Training:: Epoch 1, Iteration 100, Current loss 9.088083267211914 Accuracy 22.674726105024558\n",
      "Training:: Epoch 1, Iteration 110, Current loss 9.578926086425781 Accuracy 18.590767094758764\n",
      "Training:: Epoch 1, Iteration 120, Current loss 11.219330787658691 Accuracy 18.184484528523242\n",
      "Training:: Epoch 1, Iteration 130, Current loss 9.461384773254395 Accuracy 14.545454545454545\n",
      "Training:: Epoch 1, Iteration 140, Current loss 9.778787612915039 Accuracy 16.517161507685827\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 1, Probability Accuracy 22.71501774521402\n",
      "Starting Training\n",
      "Training:: Epoch 2, Iteration 0, Current loss 9.538920402526855 Accuracy 19.627281826414375\n",
      "Training:: Epoch 2, Iteration 10, Current loss 7.762294292449951 Accuracy 23.371046329176647\n",
      "Training:: Epoch 2, Iteration 20, Current loss 9.094808578491211 Accuracy 16.92299698638678\n",
      "Training:: Epoch 2, Iteration 30, Current loss 9.04069995880127 Accuracy 25.081279186617014\n",
      "Training:: Epoch 2, Iteration 40, Current loss 7.6993560791015625 Accuracy 29.41625333842045\n",
      "Training:: Epoch 2, Iteration 50, Current loss 9.381558418273926 Accuracy 28.128086499974007\n",
      "Training:: Epoch 2, Iteration 60, Current loss 9.4222993850708 Accuracy 23.472906403940886\n",
      "Training:: Epoch 2, Iteration 70, Current loss 8.20183277130127 Accuracy 30.251880356830505\n",
      "Training:: Epoch 2, Iteration 80, Current loss 9.177494049072266 Accuracy 21.361097703923328\n",
      "Training:: Epoch 2, Iteration 90, Current loss 7.578465938568115 Accuracy 51.63948400295505\n",
      "Training:: Epoch 2, Iteration 100, Current loss 6.903007984161377 Accuracy 39.690804659402005\n",
      "Training:: Epoch 2, Iteration 110, Current loss 8.362993240356445 Accuracy 25.909473845446886\n",
      "Training:: Epoch 2, Iteration 120, Current loss 7.460357666015625 Accuracy 43.190190506262496\n",
      "Training:: Epoch 2, Iteration 130, Current loss 7.265622615814209 Accuracy 26.0562052055828\n",
      "Training:: Epoch 2, Iteration 140, Current loss 9.501059532165527 Accuracy 24.761351909184725\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 2, Probability Accuracy 22.57996784292708\n",
      "Starting Training\n",
      "Training:: Epoch 3, Iteration 0, Current loss 17.179471969604492 Accuracy 8.95175618422851\n",
      "Training:: Epoch 3, Iteration 10, Current loss 10.535399436950684 Accuracy 20.302049622437973\n",
      "Training:: Epoch 3, Iteration 20, Current loss 7.769298076629639 Accuracy 40.40086797624486\n",
      "Training:: Epoch 3, Iteration 30, Current loss 7.201054573059082 Accuracy 27.572331864341827\n",
      "Training:: Epoch 3, Iteration 40, Current loss 8.918535232543945 Accuracy 19.70403405635516\n",
      "Training:: Epoch 3, Iteration 50, Current loss 7.815446853637695 Accuracy 38.05123897522049\n",
      "Training:: Epoch 3, Iteration 60, Current loss 7.387252330780029 Accuracy 27.731232314265107\n",
      "Training:: Epoch 3, Iteration 70, Current loss 7.348655700683594 Accuracy 34.803754266211605\n",
      "Training:: Epoch 3, Iteration 80, Current loss 7.623445510864258 Accuracy 41.449799512540295\n",
      "Training:: Epoch 3, Iteration 90, Current loss 5.929027557373047 Accuracy 39.12190963341858\n",
      "Training:: Epoch 3, Iteration 100, Current loss 7.810126304626465 Accuracy 29.754355273707997\n",
      "Training:: Epoch 3, Iteration 110, Current loss 6.775308132171631 Accuracy 28.891920569956042\n",
      "Training:: Epoch 3, Iteration 120, Current loss 6.547199249267578 Accuracy 34.283096655978014\n",
      "Training:: Epoch 3, Iteration 130, Current loss 6.855334281921387 Accuracy 37.65896921017403\n",
      "Training:: Epoch 3, Iteration 140, Current loss 9.079529762268066 Accuracy 28.326357908292323\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 3, Probability Accuracy 29.14349113392898\n",
      "Starting Training\n",
      "Training:: Epoch 4, Iteration 0, Current loss 9.63637924194336 Accuracy 27.692307692307693\n",
      "Training:: Epoch 4, Iteration 10, Current loss 7.587550163269043 Accuracy 35.032476701496755\n",
      "Training:: Epoch 4, Iteration 20, Current loss 8.519071578979492 Accuracy 34.90393903617044\n",
      "Training:: Epoch 4, Iteration 30, Current loss 6.272207260131836 Accuracy 52.84351381489282\n",
      "Training:: Epoch 4, Iteration 40, Current loss 6.4051833152771 Accuracy 39.03497952538359\n",
      "Training:: Epoch 4, Iteration 50, Current loss 6.469259738922119 Accuracy 38.399497730126534\n",
      "Training:: Epoch 4, Iteration 60, Current loss 8.237857818603516 Accuracy 31.729402080371173\n",
      "Training:: Epoch 4, Iteration 70, Current loss 5.4066572189331055 Accuracy 56.50132275132275\n",
      "Training:: Epoch 4, Iteration 80, Current loss 5.273443698883057 Accuracy 50.09527108955482\n",
      "Training:: Epoch 4, Iteration 90, Current loss 6.040935039520264 Accuracy 40.93836679046589\n",
      "Training:: Epoch 4, Iteration 100, Current loss 5.786163806915283 Accuracy 52.301178203240056\n",
      "Training:: Epoch 4, Iteration 110, Current loss 5.671540260314941 Accuracy 42.858055857352845\n",
      "Training:: Epoch 4, Iteration 120, Current loss 7.4497246742248535 Accuracy 41.667186622574405\n",
      "Training:: Epoch 4, Iteration 130, Current loss 6.89249324798584 Accuracy 41.79188989067468\n",
      "Training:: Epoch 4, Iteration 140, Current loss 7.519433498382568 Accuracy 34.71769225193883\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 4, Probability Accuracy 38.89886535206112\n",
      "Starting Training\n",
      "Training:: Epoch 5, Iteration 0, Current loss 8.38113021850586 Accuracy 34.11403733060598\n",
      "Training:: Epoch 5, Iteration 10, Current loss 6.448785305023193 Accuracy 35.91639871382637\n",
      "Training:: Epoch 5, Iteration 20, Current loss 6.449431419372559 Accuracy 39.662094345935095\n",
      "Training:: Epoch 5, Iteration 30, Current loss 6.41994571685791 Accuracy 43.70188552939864\n",
      "Training:: Epoch 5, Iteration 40, Current loss 6.739335536956787 Accuracy 35.06722637950964\n",
      "Training:: Epoch 5, Iteration 50, Current loss 5.31435489654541 Accuracy 58.95328719723183\n",
      "Training:: Epoch 5, Iteration 60, Current loss 6.433504581451416 Accuracy 44.227295122351784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 5, Iteration 70, Current loss 5.100342273712158 Accuracy 44.30602891056528\n",
      "Training:: Epoch 5, Iteration 80, Current loss 6.855910301208496 Accuracy 35.39423117530301\n",
      "Training:: Epoch 5, Iteration 90, Current loss 5.335494518280029 Accuracy 55.97463059172795\n",
      "Training:: Epoch 5, Iteration 100, Current loss 6.217436790466309 Accuracy 37.892152783556625\n",
      "Training:: Epoch 5, Iteration 110, Current loss 5.597986698150635 Accuracy 53.34494355032429\n",
      "Training:: Epoch 5, Iteration 120, Current loss 8.061092376708984 Accuracy 43.213135526107386\n",
      "Training:: Epoch 5, Iteration 130, Current loss 5.146203517913818 Accuracy 59.9833232261977\n",
      "Training:: Epoch 5, Iteration 140, Current loss 5.598455429077148 Accuracy 52.331765636675314\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 5, Probability Accuracy 45.65454676174354\n",
      "Starting Training\n",
      "Training:: Epoch 6, Iteration 0, Current loss 4.9656662940979 Accuracy 55.60447003047748\n",
      "Training:: Epoch 6, Iteration 10, Current loss 5.175919055938721 Accuracy 49.28080721339631\n",
      "Training:: Epoch 6, Iteration 20, Current loss 4.459949016571045 Accuracy 56.22843765401676\n",
      "Training:: Epoch 6, Iteration 30, Current loss 5.922669410705566 Accuracy 47.24686120752453\n",
      "Training:: Epoch 6, Iteration 40, Current loss 5.36837100982666 Accuracy 50.82236842105263\n",
      "Training:: Epoch 6, Iteration 50, Current loss 5.171493053436279 Accuracy 52.76130837385917\n",
      "Training:: Epoch 6, Iteration 60, Current loss 7.019561290740967 Accuracy 37.4721723518851\n",
      "Training:: Epoch 6, Iteration 70, Current loss 8.21052360534668 Accuracy 32.94189107106702\n",
      "Training:: Epoch 6, Iteration 80, Current loss 5.180146217346191 Accuracy 49.678030303030305\n",
      "Training:: Epoch 6, Iteration 90, Current loss 7.081171035766602 Accuracy 42.1984983575786\n",
      "Training:: Epoch 6, Iteration 100, Current loss 6.262087345123291 Accuracy 53.23375578354456\n",
      "Training:: Epoch 6, Iteration 110, Current loss 6.1626691818237305 Accuracy 47.27252277584074\n",
      "Training:: Epoch 6, Iteration 120, Current loss 5.966052055358887 Accuracy 41.60101805841716\n",
      "Training:: Epoch 6, Iteration 130, Current loss 7.590896129608154 Accuracy 34.95221160257835\n",
      "Training:: Epoch 6, Iteration 140, Current loss 4.982239246368408 Accuracy 55.764060049294194\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 6, Probability Accuracy 46.32285178334499\n",
      "Starting Training\n",
      "Training:: Epoch 7, Iteration 0, Current loss 7.708240985870361 Accuracy 36.336900580017975\n",
      "Training:: Epoch 7, Iteration 10, Current loss 4.744542598724365 Accuracy 57.90426704455991\n",
      "Training:: Epoch 7, Iteration 20, Current loss 5.8559041023254395 Accuracy 43.559846966660594\n",
      "Training:: Epoch 7, Iteration 30, Current loss 5.289144992828369 Accuracy 51.83778980531545\n",
      "Training:: Epoch 7, Iteration 40, Current loss 5.788193225860596 Accuracy 45.4928568418391\n",
      "Training:: Epoch 7, Iteration 50, Current loss 6.756792068481445 Accuracy 42.70259733931095\n",
      "Training:: Epoch 7, Iteration 60, Current loss 6.729721546173096 Accuracy 36.71586012279297\n",
      "Training:: Epoch 7, Iteration 70, Current loss 6.745980739593506 Accuracy 38.27138695153174\n",
      "Training:: Epoch 7, Iteration 80, Current loss 6.386098384857178 Accuracy 53.98347107438016\n",
      "Training:: Epoch 7, Iteration 90, Current loss 6.518807888031006 Accuracy 51.69530042723389\n",
      "Training:: Epoch 7, Iteration 100, Current loss 6.698978900909424 Accuracy 40.18879207244148\n",
      "Training:: Epoch 7, Iteration 110, Current loss 6.873932361602783 Accuracy 38.903259182617695\n",
      "Training:: Epoch 7, Iteration 120, Current loss 5.653384208679199 Accuracy 46.85552407932011\n",
      "Training:: Epoch 7, Iteration 130, Current loss 4.516263484954834 Accuracy 59.868988980856145\n",
      "Training:: Epoch 7, Iteration 140, Current loss 5.4105634689331055 Accuracy 49.81415643180349\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 7, Probability Accuracy 44.82169818103386\n",
      "Starting Training\n",
      "Training:: Epoch 8, Iteration 0, Current loss 6.521260738372803 Accuracy 36.145743766122095\n",
      "Training:: Epoch 8, Iteration 10, Current loss 5.971322059631348 Accuracy 47.53974261922786\n",
      "Training:: Epoch 8, Iteration 20, Current loss 5.752521991729736 Accuracy 54.64920919993048\n",
      "Training:: Epoch 8, Iteration 30, Current loss 5.314441204071045 Accuracy 43.62471830150635\n",
      "Training:: Epoch 8, Iteration 40, Current loss 6.005746841430664 Accuracy 44.488680254322894\n",
      "Training:: Epoch 8, Iteration 50, Current loss 4.359042167663574 Accuracy 60.2589361103293\n",
      "Training:: Epoch 8, Iteration 60, Current loss 6.54273796081543 Accuracy 43.890079906450985\n",
      "Training:: Epoch 8, Iteration 70, Current loss 6.0837225914001465 Accuracy 42.75100019051248\n",
      "Training:: Epoch 8, Iteration 80, Current loss 5.749353408813477 Accuracy 49.893471313346524\n",
      "Training:: Epoch 8, Iteration 90, Current loss 5.524838924407959 Accuracy 51.81684520058811\n",
      "Training:: Epoch 8, Iteration 100, Current loss 5.169139862060547 Accuracy 51.701393169769446\n",
      "Training:: Epoch 8, Iteration 110, Current loss 5.351966857910156 Accuracy 42.6038757721926\n",
      "Training:: Epoch 8, Iteration 120, Current loss 4.119466304779053 Accuracy 60.03269309358398\n",
      "Training:: Epoch 8, Iteration 130, Current loss 5.6420722007751465 Accuracy 52.59014046703051\n",
      "Training:: Epoch 8, Iteration 140, Current loss 10.08149528503418 Accuracy 40.14549145660633\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 8, Probability Accuracy 46.990830005424876\n",
      "Starting Training\n",
      "Training:: Epoch 9, Iteration 0, Current loss 5.397943496704102 Accuracy 47.55064762537363\n",
      "Training:: Epoch 9, Iteration 10, Current loss 5.8638410568237305 Accuracy 51.63980509745127\n",
      "Training:: Epoch 9, Iteration 20, Current loss 4.184443950653076 Accuracy 58.229302289959406\n",
      "Training:: Epoch 9, Iteration 30, Current loss 4.8490681648254395 Accuracy 59.534821368724444\n",
      "Training:: Epoch 9, Iteration 40, Current loss 5.249014854431152 Accuracy 53.322796177886346\n",
      "Training:: Epoch 9, Iteration 50, Current loss 5.821920394897461 Accuracy 49.67198992777152\n",
      "Training:: Epoch 9, Iteration 60, Current loss 6.865965366363525 Accuracy 41.427520235467256\n",
      "Training:: Epoch 9, Iteration 70, Current loss 4.383700370788574 Accuracy 56.60852364682611\n",
      "Training:: Epoch 9, Iteration 80, Current loss 5.160571098327637 Accuracy 65.63491477901572\n",
      "Training:: Epoch 9, Iteration 90, Current loss 5.8210062980651855 Accuracy 48.85254691689008\n",
      "Training:: Epoch 9, Iteration 100, Current loss 6.404684066772461 Accuracy 49.44629014396456\n",
      "Training:: Epoch 9, Iteration 110, Current loss 5.520312309265137 Accuracy 45.39988362319777\n",
      "Training:: Epoch 9, Iteration 120, Current loss 5.509257793426514 Accuracy 49.5917441596734\n",
      "Training:: Epoch 9, Iteration 130, Current loss 4.652880668640137 Accuracy 55.19641626464507\n",
      "Training:: Epoch 9, Iteration 140, Current loss 5.47988748550415 Accuracy 55.08017081621143\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 9, Probability Accuracy 48.27441682625377\n",
      "Starting Training\n",
      "Training:: Epoch 10, Iteration 0, Current loss 7.159200668334961 Accuracy 56.58531508560129\n",
      "Training:: Epoch 10, Iteration 10, Current loss 4.683297157287598 Accuracy 53.3235077376566\n",
      "Training:: Epoch 10, Iteration 20, Current loss 4.704902648925781 Accuracy 60.69553511330491\n",
      "Training:: Epoch 10, Iteration 30, Current loss 3.842725992202759 Accuracy 62.60186507603125\n",
      "Training:: Epoch 10, Iteration 40, Current loss 4.267852783203125 Accuracy 57.69785655399835\n",
      "Training:: Epoch 10, Iteration 50, Current loss 4.0300188064575195 Accuracy 53.865087300976846\n",
      "Training:: Epoch 10, Iteration 60, Current loss 4.7502217292785645 Accuracy 57.15383039737812\n",
      "Training:: Epoch 10, Iteration 70, Current loss 3.907172918319702 Accuracy 59.26761232120601\n",
      "Training:: Epoch 10, Iteration 80, Current loss 5.600942134857178 Accuracy 42.24164985429276\n",
      "Training:: Epoch 10, Iteration 90, Current loss 4.110939025878906 Accuracy 54.07417526125265\n",
      "Training:: Epoch 10, Iteration 100, Current loss 4.511251449584961 Accuracy 62.2652676889965\n",
      "Training:: Epoch 10, Iteration 110, Current loss 6.994142055511475 Accuracy 50.118806965279994\n",
      "Training:: Epoch 10, Iteration 120, Current loss 5.099335670471191 Accuracy 57.92071571803177\n",
      "Training:: Epoch 10, Iteration 130, Current loss 7.70813512802124 Accuracy 36.86311340690303\n",
      "Training:: Epoch 10, Iteration 140, Current loss 5.696743488311768 Accuracy 50.93052899936265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 10, Probability Accuracy 48.58683716887038\n",
      "Starting Training\n",
      "Training:: Epoch 11, Iteration 0, Current loss 5.692268371582031 Accuracy 51.03734439834025\n",
      "Training:: Epoch 11, Iteration 10, Current loss 4.9820475578308105 Accuracy 56.28290941543953\n",
      "Training:: Epoch 11, Iteration 20, Current loss 4.41371488571167 Accuracy 64.45260921981745\n",
      "Training:: Epoch 11, Iteration 30, Current loss 6.036645412445068 Accuracy 50.77559462254395\n",
      "Training:: Epoch 11, Iteration 40, Current loss 6.863383769989014 Accuracy 49.708682677277245\n",
      "Training:: Epoch 11, Iteration 50, Current loss 4.880638122558594 Accuracy 51.4818209593645\n",
      "Training:: Epoch 11, Iteration 60, Current loss 3.9843735694885254 Accuracy 62.959502823022866\n",
      "Training:: Epoch 11, Iteration 70, Current loss 3.9651095867156982 Accuracy 64.33219418566547\n",
      "Training:: Epoch 11, Iteration 80, Current loss 4.728310585021973 Accuracy 58.86927177581063\n",
      "Training:: Epoch 11, Iteration 90, Current loss 4.421289443969727 Accuracy 57.72685609532539\n",
      "Training:: Epoch 11, Iteration 100, Current loss 5.043396949768066 Accuracy 62.83032312029493\n",
      "Training:: Epoch 11, Iteration 110, Current loss 4.859136581420898 Accuracy 53.82953181272509\n",
      "Training:: Epoch 11, Iteration 120, Current loss 6.965358734130859 Accuracy 43.817188847369934\n",
      "Training:: Epoch 11, Iteration 130, Current loss 5.174752712249756 Accuracy 50.14188422247446\n",
      "Training:: Epoch 11, Iteration 140, Current loss 5.1081862449646 Accuracy 57.41611176393785\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 11, Probability Accuracy 50.399675814874605\n",
      "Starting Training\n",
      "Training:: Epoch 12, Iteration 0, Current loss 5.0306010246276855 Accuracy 57.475457325250794\n",
      "Training:: Epoch 12, Iteration 10, Current loss 3.36983060836792 Accuracy 60.96951524237881\n",
      "Training:: Epoch 12, Iteration 20, Current loss 3.9410831928253174 Accuracy 54.00945719633533\n",
      "Training:: Epoch 12, Iteration 30, Current loss 4.359616756439209 Accuracy 64.69889064976228\n",
      "Training:: Epoch 12, Iteration 40, Current loss 5.174204349517822 Accuracy 61.075382182393255\n",
      "Training:: Epoch 12, Iteration 50, Current loss 4.497352600097656 Accuracy 54.37627217214307\n",
      "Training:: Epoch 12, Iteration 60, Current loss 3.5505447387695312 Accuracy 67.51636455186303\n",
      "Training:: Epoch 12, Iteration 70, Current loss 5.738663673400879 Accuracy 43.981534252821156\n",
      "Training:: Epoch 12, Iteration 80, Current loss 4.176992416381836 Accuracy 53.292682926829265\n",
      "Training:: Epoch 12, Iteration 90, Current loss 4.487502574920654 Accuracy 45.8650289622444\n",
      "Training:: Epoch 12, Iteration 100, Current loss 3.959486484527588 Accuracy 61.70585942575029\n",
      "Training:: Epoch 12, Iteration 110, Current loss 4.96331787109375 Accuracy 46.96794129007339\n",
      "Training:: Epoch 12, Iteration 120, Current loss 5.738580226898193 Accuracy 50.03236769703835\n",
      "Training:: Epoch 12, Iteration 130, Current loss 4.950526237487793 Accuracy 50.31268436578171\n",
      "Training:: Epoch 12, Iteration 140, Current loss 4.679725170135498 Accuracy 59.41655499433048\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 12, Probability Accuracy 47.65496833312636\n",
      "Starting Training\n",
      "Training:: Epoch 13, Iteration 0, Current loss 5.181124687194824 Accuracy 49.7093023255814\n",
      "Training:: Epoch 13, Iteration 10, Current loss 5.345545291900635 Accuracy 49.62558075977043\n",
      "Training:: Epoch 13, Iteration 20, Current loss 4.357002258300781 Accuracy 52.15341308937368\n",
      "Training:: Epoch 13, Iteration 30, Current loss 4.24446439743042 Accuracy 60.6400844489228\n",
      "Training:: Epoch 13, Iteration 40, Current loss 5.1449174880981445 Accuracy 56.172563069114794\n",
      "Training:: Epoch 13, Iteration 50, Current loss 6.32667875289917 Accuracy 39.30507534041917\n",
      "Training:: Epoch 13, Iteration 60, Current loss 4.11165714263916 Accuracy 63.916577212084036\n",
      "Training:: Epoch 13, Iteration 70, Current loss 4.492498397827148 Accuracy 54.85462985585146\n",
      "Training:: Epoch 13, Iteration 80, Current loss 6.14796257019043 Accuracy 43.58904109589041\n",
      "Training:: Epoch 13, Iteration 90, Current loss 4.581820011138916 Accuracy 55.639746196020454\n",
      "Training:: Epoch 13, Iteration 100, Current loss 4.427867412567139 Accuracy 58.53583132381129\n",
      "Training:: Epoch 13, Iteration 110, Current loss 4.058035850524902 Accuracy 66.05845987635796\n",
      "Training:: Epoch 13, Iteration 120, Current loss 3.916969060897827 Accuracy 65.89781746031746\n",
      "Training:: Epoch 13, Iteration 130, Current loss 4.343955993652344 Accuracy 40.634513699727606\n",
      "Training:: Epoch 13, Iteration 140, Current loss 5.0397491455078125 Accuracy 65.18795538074666\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 13, Probability Accuracy 50.96626448538879\n",
      "Starting Training\n",
      "Training:: Epoch 14, Iteration 0, Current loss 3.797717571258545 Accuracy 63.17271781056756\n",
      "Training:: Epoch 14, Iteration 10, Current loss 4.775511264801025 Accuracy 53.85362694300518\n",
      "Training:: Epoch 14, Iteration 20, Current loss 4.363343238830566 Accuracy 56.487504279356386\n",
      "Training:: Epoch 14, Iteration 30, Current loss 4.183525085449219 Accuracy 59.04610931146185\n",
      "Training:: Epoch 14, Iteration 40, Current loss 3.9311766624450684 Accuracy 61.87336969409533\n",
      "Training:: Epoch 14, Iteration 50, Current loss 4.984413146972656 Accuracy 45.92203752308739\n",
      "Training:: Epoch 14, Iteration 60, Current loss 4.062319755554199 Accuracy 60.36992635725296\n",
      "Training:: Epoch 14, Iteration 70, Current loss 4.315950870513916 Accuracy 48.992436932135426\n",
      "Training:: Epoch 14, Iteration 80, Current loss 3.7587711811065674 Accuracy 66.75552342655763\n",
      "Training:: Epoch 14, Iteration 90, Current loss 3.793947696685791 Accuracy 69.07539613442452\n",
      "Training:: Epoch 14, Iteration 100, Current loss 4.458977222442627 Accuracy 61.261705273533764\n",
      "Training:: Epoch 14, Iteration 110, Current loss 4.752182960510254 Accuracy 56.19047619047619\n",
      "Training:: Epoch 14, Iteration 120, Current loss 4.145740509033203 Accuracy 56.732944398142635\n",
      "Training:: Epoch 14, Iteration 130, Current loss 4.180488109588623 Accuracy 58.66191979579499\n",
      "Training:: Epoch 14, Iteration 140, Current loss 3.0817501544952393 Accuracy 63.39512442864398\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 14, Probability Accuracy 50.90188497964039\n",
      "Starting Training\n",
      "Training:: Epoch 15, Iteration 0, Current loss 3.9891159534454346 Accuracy 60.00486854917234\n",
      "Training:: Epoch 15, Iteration 10, Current loss 4.364564895629883 Accuracy 45.364010989010985\n",
      "Training:: Epoch 15, Iteration 20, Current loss 4.378768444061279 Accuracy 58.15150986210508\n",
      "Training:: Epoch 15, Iteration 30, Current loss 4.043278217315674 Accuracy 63.71250118292798\n",
      "Training:: Epoch 15, Iteration 40, Current loss 3.6311943531036377 Accuracy 65.20240480961924\n",
      "Training:: Epoch 15, Iteration 50, Current loss 3.5532402992248535 Accuracy 58.96876435461645\n",
      "Training:: Epoch 15, Iteration 60, Current loss 4.254510402679443 Accuracy 60.68297655453619\n",
      "Training:: Epoch 15, Iteration 70, Current loss 4.3997039794921875 Accuracy 64.79520595764487\n",
      "Training:: Epoch 15, Iteration 80, Current loss 5.414240837097168 Accuracy 62.145486597189816\n",
      "Training:: Epoch 15, Iteration 90, Current loss 4.524170398712158 Accuracy 46.786380597014926\n",
      "Training:: Epoch 15, Iteration 100, Current loss 4.3626298904418945 Accuracy 55.84998877161464\n",
      "Training:: Epoch 15, Iteration 110, Current loss 4.447286605834961 Accuracy 52.60267955194377\n",
      "Training:: Epoch 15, Iteration 120, Current loss 4.089983940124512 Accuracy 65.12185009443958\n",
      "Training:: Epoch 15, Iteration 130, Current loss 3.8533387184143066 Accuracy 65.85995482413682\n",
      "Training:: Epoch 15, Iteration 140, Current loss 4.461073398590088 Accuracy 62.09933354490638\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 15, Probability Accuracy 51.928852476159975\n",
      "Starting Training\n",
      "Training:: Epoch 16, Iteration 0, Current loss 3.4101288318634033 Accuracy 59.427946802696304\n",
      "Training:: Epoch 16, Iteration 10, Current loss 4.2882537841796875 Accuracy 59.722481488395246\n",
      "Training:: Epoch 16, Iteration 20, Current loss 4.550772666931152 Accuracy 58.6374695863747\n",
      "Training:: Epoch 16, Iteration 30, Current loss 3.611281633377075 Accuracy 54.459188968789384\n",
      "Training:: Epoch 16, Iteration 40, Current loss 3.905447244644165 Accuracy 61.90429205722743\n",
      "Training:: Epoch 16, Iteration 50, Current loss 4.719476222991943 Accuracy 50.375465749498424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 16, Iteration 60, Current loss 3.8104162216186523 Accuracy 55.778513961192616\n",
      "Training:: Epoch 16, Iteration 70, Current loss 4.625424861907959 Accuracy 52.0742016280526\n",
      "Training:: Epoch 16, Iteration 80, Current loss 4.827786922454834 Accuracy 54.47529170781667\n",
      "Training:: Epoch 16, Iteration 90, Current loss 3.998288631439209 Accuracy 63.82108933509679\n",
      "Training:: Epoch 16, Iteration 100, Current loss 3.2853705883026123 Accuracy 66.35520439711439\n",
      "Training:: Epoch 16, Iteration 110, Current loss 3.682086706161499 Accuracy 69.16115164884891\n",
      "Training:: Epoch 16, Iteration 120, Current loss 3.2372567653656006 Accuracy 69.75381008206331\n",
      "Training:: Epoch 16, Iteration 130, Current loss 3.3535311222076416 Accuracy 64.36553855908694\n",
      "Training:: Epoch 16, Iteration 140, Current loss 3.6133103370666504 Accuracy 62.48002949489984\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 16, Probability Accuracy 49.996241805501995\n",
      "Starting Training\n",
      "Training:: Epoch 17, Iteration 0, Current loss 3.694845676422119 Accuracy 60.661976703955716\n",
      "Training:: Epoch 17, Iteration 10, Current loss 3.3471412658691406 Accuracy 78.29861111111111\n",
      "Training:: Epoch 17, Iteration 20, Current loss 3.3008925914764404 Accuracy 48.19574888779041\n",
      "Training:: Epoch 17, Iteration 30, Current loss 3.175117015838623 Accuracy 69.70873786407768\n",
      "Training:: Epoch 17, Iteration 40, Current loss 3.597712278366089 Accuracy 67.63326226012794\n",
      "Training:: Epoch 17, Iteration 50, Current loss 3.545180559158325 Accuracy 58.882509212443225\n",
      "Training:: Epoch 17, Iteration 60, Current loss 4.002542495727539 Accuracy 62.825866155061505\n",
      "Training:: Epoch 17, Iteration 70, Current loss 3.643207550048828 Accuracy 63.50674373795761\n",
      "Training:: Epoch 17, Iteration 80, Current loss 5.289155960083008 Accuracy 51.020298571581996\n",
      "Training:: Epoch 17, Iteration 90, Current loss 3.008385419845581 Accuracy 60.49370670309298\n",
      "Training:: Epoch 17, Iteration 100, Current loss 3.3626768589019775 Accuracy 66.17749825296995\n",
      "Training:: Epoch 17, Iteration 110, Current loss 3.4836173057556152 Accuracy 68.06172056647644\n",
      "Training:: Epoch 17, Iteration 120, Current loss 3.7077083587646484 Accuracy 63.25556067523981\n",
      "Training:: Epoch 17, Iteration 130, Current loss 3.8894622325897217 Accuracy 63.04502580530343\n",
      "Training:: Epoch 17, Iteration 140, Current loss 4.578783988952637 Accuracy 54.53395953757225\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 17, Probability Accuracy 45.43975777619462\n",
      "Starting Training\n",
      "Training:: Epoch 18, Iteration 0, Current loss 3.701935291290283 Accuracy 52.39559728067336\n",
      "Training:: Epoch 18, Iteration 10, Current loss 4.980194568634033 Accuracy 50.82365783467302\n",
      "Training:: Epoch 18, Iteration 20, Current loss 3.6878750324249268 Accuracy 52.15264600463841\n",
      "Training:: Epoch 18, Iteration 30, Current loss 3.2439792156219482 Accuracy 59.85563041385948\n",
      "Training:: Epoch 18, Iteration 40, Current loss 3.3424782752990723 Accuracy 65.25157232704403\n",
      "Training:: Epoch 18, Iteration 50, Current loss 4.650355815887451 Accuracy 54.830677290836654\n",
      "Training:: Epoch 18, Iteration 60, Current loss 3.3192365169525146 Accuracy 67.13793598392421\n",
      "Training:: Epoch 18, Iteration 70, Current loss 4.096127033233643 Accuracy 63.741173079694484\n",
      "Training:: Epoch 18, Iteration 80, Current loss 3.414846658706665 Accuracy 60.348105025543546\n",
      "Training:: Epoch 18, Iteration 90, Current loss 4.225912570953369 Accuracy 60.294117647058826\n",
      "Training:: Epoch 18, Iteration 100, Current loss 3.758624792098999 Accuracy 55.06783719074222\n",
      "Training:: Epoch 18, Iteration 110, Current loss 3.817540407180786 Accuracy 55.49787234042553\n",
      "Training:: Epoch 18, Iteration 120, Current loss 4.473312854766846 Accuracy 47.68002028397566\n",
      "Training:: Epoch 18, Iteration 130, Current loss 5.918405532836914 Accuracy 56.982846400877264\n",
      "Training:: Epoch 18, Iteration 140, Current loss 4.005621910095215 Accuracy 67.06137336787017\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 18, Probability Accuracy 46.16288341753868\n",
      "Starting Training\n",
      "Training:: Epoch 19, Iteration 0, Current loss 3.9740633964538574 Accuracy 50.01033164583118\n",
      "Training:: Epoch 19, Iteration 10, Current loss 4.226039886474609 Accuracy 55.574693607154686\n",
      "Training:: Epoch 19, Iteration 20, Current loss 3.059555768966675 Accuracy 70.28034979423869\n",
      "Training:: Epoch 19, Iteration 30, Current loss 3.9418118000030518 Accuracy 65.0284562485179\n",
      "Training:: Epoch 19, Iteration 40, Current loss 4.411202430725098 Accuracy 56.38728007867993\n",
      "Training:: Epoch 19, Iteration 50, Current loss 3.7136714458465576 Accuracy 63.57281553398058\n",
      "Training:: Epoch 19, Iteration 60, Current loss 4.017956733703613 Accuracy 54.38907607731868\n",
      "Training:: Epoch 19, Iteration 70, Current loss 6.305218696594238 Accuracy 43.529411764705884\n",
      "Training:: Epoch 19, Iteration 80, Current loss 3.2827510833740234 Accuracy 69.61320159764557\n",
      "Training:: Epoch 19, Iteration 90, Current loss 3.8745317459106445 Accuracy 68.79758466789184\n",
      "Training:: Epoch 19, Iteration 100, Current loss 5.175788402557373 Accuracy 57.865129999313986\n",
      "Training:: Epoch 19, Iteration 110, Current loss 3.4169344902038574 Accuracy 64.35009797517962\n",
      "Training:: Epoch 19, Iteration 120, Current loss 4.535821437835693 Accuracy 59.03768115942029\n",
      "Training:: Epoch 19, Iteration 130, Current loss 4.022698402404785 Accuracy 62.01063315611407\n",
      "Training:: Epoch 19, Iteration 140, Current loss 2.9668478965759277 Accuracy 55.35969509290138\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 19, Probability Accuracy 48.17024947875476\n",
      "Starting Training\n",
      "Training:: Epoch 20, Iteration 0, Current loss 3.1589057445526123 Accuracy 62.76358950328022\n",
      "Training:: Epoch 20, Iteration 10, Current loss 3.6579322814941406 Accuracy 63.97897230860358\n",
      "Training:: Epoch 20, Iteration 20, Current loss 3.4166719913482666 Accuracy 59.28695419949259\n",
      "Training:: Epoch 20, Iteration 30, Current loss 3.4301366806030273 Accuracy 55.852202833842085\n",
      "Training:: Epoch 20, Iteration 40, Current loss 2.844698905944824 Accuracy 71.02113572701808\n",
      "Training:: Epoch 20, Iteration 50, Current loss 3.034663438796997 Accuracy 67.11552909900017\n",
      "Training:: Epoch 20, Iteration 60, Current loss 3.085249185562134 Accuracy 57.84252297410192\n",
      "Training:: Epoch 20, Iteration 70, Current loss 4.840117454528809 Accuracy 51.762845849802375\n",
      "Training:: Epoch 20, Iteration 80, Current loss 2.7503459453582764 Accuracy 68.2534095908491\n",
      "Training:: Epoch 20, Iteration 90, Current loss 3.5410568714141846 Accuracy 73.16206879774242\n",
      "Training:: Epoch 20, Iteration 100, Current loss 2.8808577060699463 Accuracy 72.48689485044711\n",
      "Training:: Epoch 20, Iteration 110, Current loss 3.567286729812622 Accuracy 54.49689305570696\n",
      "Training:: Epoch 20, Iteration 120, Current loss 3.236370086669922 Accuracy 68.14262023217248\n",
      "Training:: Epoch 20, Iteration 130, Current loss 3.5248122215270996 Accuracy 64.59353574926543\n",
      "Training:: Epoch 20, Iteration 140, Current loss 3.698935031890869 Accuracy 61.60729952623267\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 20, Probability Accuracy 52.680491375760624\n",
      "Starting Training\n",
      "Training:: Epoch 21, Iteration 0, Current loss 4.114779472351074 Accuracy 56.60353212183261\n",
      "Training:: Epoch 21, Iteration 10, Current loss 2.63006591796875 Accuracy 67.04061895551257\n",
      "Training:: Epoch 21, Iteration 20, Current loss 3.61767315864563 Accuracy 65.0137631148522\n",
      "Training:: Epoch 21, Iteration 30, Current loss 3.2473788261413574 Accuracy 62.46498599439776\n",
      "Training:: Epoch 21, Iteration 40, Current loss 3.8314015865325928 Accuracy 63.13267976755534\n",
      "Training:: Epoch 21, Iteration 50, Current loss 3.4324591159820557 Accuracy 64.63790030782525\n",
      "Training:: Epoch 21, Iteration 60, Current loss 8.387404441833496 Accuracy 42.72488666189454\n",
      "Training:: Epoch 21, Iteration 70, Current loss 4.115741729736328 Accuracy 62.96525202582063\n",
      "Training:: Epoch 21, Iteration 80, Current loss 4.278815269470215 Accuracy 60.230577482343165\n",
      "Training:: Epoch 21, Iteration 90, Current loss 3.030407428741455 Accuracy 66.21427839803339\n",
      "Training:: Epoch 21, Iteration 100, Current loss 3.0566213130950928 Accuracy 62.625324916450055\n",
      "Training:: Epoch 21, Iteration 110, Current loss 3.275397777557373 Accuracy 66.29476336152601\n",
      "Training:: Epoch 21, Iteration 120, Current loss 2.92958664894104 Accuracy 67.83258113045348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 21, Iteration 130, Current loss 3.8583261966705322 Accuracy 60.57400838439213\n",
      "Training:: Epoch 21, Iteration 140, Current loss 3.4713962078094482 Accuracy 67.2345308500309\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 21, Probability Accuracy 53.779109667383445\n",
      "Starting Training\n",
      "Training:: Epoch 22, Iteration 0, Current loss 2.7069709300994873 Accuracy 66.0601001669449\n",
      "Training:: Epoch 22, Iteration 10, Current loss 3.332634449005127 Accuracy 56.062424969987994\n",
      "Training:: Epoch 22, Iteration 20, Current loss 2.816572904586792 Accuracy 57.216383140101854\n",
      "Training:: Epoch 22, Iteration 30, Current loss 3.3814637660980225 Accuracy 60.04691164972635\n",
      "Training:: Epoch 22, Iteration 40, Current loss 3.6120786666870117 Accuracy 66.19381657573396\n",
      "Training:: Epoch 22, Iteration 50, Current loss 3.470229148864746 Accuracy 64.167577911427\n",
      "Training:: Epoch 22, Iteration 60, Current loss 3.2124738693237305 Accuracy 58.29692415239427\n",
      "Training:: Epoch 22, Iteration 70, Current loss 3.0390477180480957 Accuracy 70.71042347020719\n",
      "Training:: Epoch 22, Iteration 80, Current loss 2.749549627304077 Accuracy 59.15890657855212\n",
      "Training:: Epoch 22, Iteration 90, Current loss 3.5713274478912354 Accuracy 57.224420943359505\n",
      "Training:: Epoch 22, Iteration 100, Current loss 3.803485631942749 Accuracy 64.95232140065656\n",
      "Training:: Epoch 22, Iteration 110, Current loss 3.20527720451355 Accuracy 67.00230498604877\n",
      "Training:: Epoch 22, Iteration 120, Current loss 3.398602247238159 Accuracy 56.728921681653986\n",
      "Training:: Epoch 22, Iteration 130, Current loss 3.044862985610962 Accuracy 76.17957216028924\n",
      "Training:: Epoch 22, Iteration 140, Current loss 3.890390396118164 Accuracy 68.76677167191693\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 22, Probability Accuracy 51.98857508872607\n",
      "Starting Training\n",
      "Training:: Epoch 23, Iteration 0, Current loss 3.3529164791107178 Accuracy 70.41866849691147\n",
      "Training:: Epoch 23, Iteration 10, Current loss 2.662245273590088 Accuracy 76.2293337117718\n",
      "Training:: Epoch 23, Iteration 20, Current loss 4.1620073318481445 Accuracy 60.64484671176937\n",
      "Training:: Epoch 23, Iteration 30, Current loss 3.683000326156616 Accuracy 64.40395447752616\n",
      "Training:: Epoch 23, Iteration 40, Current loss 4.694396495819092 Accuracy 63.036473170503896\n",
      "Training:: Epoch 23, Iteration 50, Current loss 3.309495687484741 Accuracy 74.9650468160827\n",
      "Training:: Epoch 23, Iteration 60, Current loss 3.5965442657470703 Accuracy 64.74997714599141\n",
      "Training:: Epoch 23, Iteration 70, Current loss 3.571929454803467 Accuracy 69.42282067466162\n",
      "Training:: Epoch 23, Iteration 80, Current loss 3.685696601867676 Accuracy 65.29330810252881\n",
      "Training:: Epoch 23, Iteration 90, Current loss 3.4916744232177734 Accuracy 55.398104685147466\n",
      "Training:: Epoch 23, Iteration 100, Current loss 3.412642002105713 Accuracy 59.288830356407935\n",
      "Training:: Epoch 23, Iteration 110, Current loss 3.6480870246887207 Accuracy 65.06469500924214\n",
      "Training:: Epoch 23, Iteration 120, Current loss 3.073895215988159 Accuracy 72.73099495018425\n",
      "Training:: Epoch 23, Iteration 130, Current loss 3.0418002605438232 Accuracy 60.42199797209212\n",
      "Training:: Epoch 23, Iteration 140, Current loss 3.1962337493896484 Accuracy 63.46671012957379\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 23, Probability Accuracy 51.64706958869012\n",
      "Starting Training\n",
      "Training:: Epoch 24, Iteration 0, Current loss 3.2801289558410645 Accuracy 62.94738023112308\n",
      "Training:: Epoch 24, Iteration 10, Current loss 2.771310806274414 Accuracy 68.57008244994111\n",
      "Training:: Epoch 24, Iteration 20, Current loss 2.9538724422454834 Accuracy 65.6657766134314\n",
      "Training:: Epoch 24, Iteration 30, Current loss 3.8219449520111084 Accuracy 67.85141635489043\n",
      "Training:: Epoch 24, Iteration 40, Current loss 2.7415411472320557 Accuracy 64.02406055690727\n",
      "Training:: Epoch 24, Iteration 50, Current loss 3.2235331535339355 Accuracy 65.17822423849644\n",
      "Training:: Epoch 24, Iteration 60, Current loss 2.6207404136657715 Accuracy 59.97439726904203\n",
      "Training:: Epoch 24, Iteration 70, Current loss 2.9639933109283447 Accuracy 63.24962203930791\n",
      "Training:: Epoch 24, Iteration 80, Current loss 3.629641056060791 Accuracy 61.87593364258196\n",
      "Training:: Epoch 24, Iteration 90, Current loss 2.837130069732666 Accuracy 76.82798921186695\n",
      "Training:: Epoch 24, Iteration 100, Current loss 3.0751841068267822 Accuracy 61.80327868852459\n",
      "Training:: Epoch 24, Iteration 110, Current loss 3.416898727416992 Accuracy 70.15554669249616\n",
      "Training:: Epoch 24, Iteration 120, Current loss 3.198077440261841 Accuracy 60.95459690604955\n",
      "Training:: Epoch 24, Iteration 130, Current loss 2.6749184131622314 Accuracy 63.110043338986245\n",
      "Training:: Epoch 24, Iteration 140, Current loss 2.7627906799316406 Accuracy 69.83896706804003\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 24, Probability Accuracy 51.43432310015098\n",
      "Starting Training\n",
      "Training:: Epoch 25, Iteration 0, Current loss 2.3267438411712646 Accuracy 63.35006573443289\n",
      "Training:: Epoch 25, Iteration 10, Current loss 3.039761543273926 Accuracy 66.48766724310549\n",
      "Training:: Epoch 25, Iteration 20, Current loss 2.757816791534424 Accuracy 62.5781701613327\n",
      "Training:: Epoch 25, Iteration 30, Current loss 2.8317763805389404 Accuracy 65.11262657573879\n",
      "Training:: Epoch 25, Iteration 40, Current loss 2.659187078475952 Accuracy 64.15396036776883\n",
      "Training:: Epoch 25, Iteration 50, Current loss 2.949580192565918 Accuracy 64.40495422724825\n",
      "Training:: Epoch 25, Iteration 60, Current loss 2.7397117614746094 Accuracy 68.65995658180383\n",
      "Training:: Epoch 25, Iteration 70, Current loss 3.020270824432373 Accuracy 60.42777047137814\n",
      "Training:: Epoch 25, Iteration 80, Current loss 3.150899648666382 Accuracy 60.59200948940529\n",
      "Training:: Epoch 25, Iteration 90, Current loss 3.3641862869262695 Accuracy 64.17458432304038\n",
      "Training:: Epoch 25, Iteration 100, Current loss 3.7944624423980713 Accuracy 67.70032930845225\n",
      "Training:: Epoch 25, Iteration 110, Current loss 2.795320987701416 Accuracy 57.84886868030746\n",
      "Training:: Epoch 25, Iteration 120, Current loss 2.6202499866485596 Accuracy 59.23506579570198\n",
      "Training:: Epoch 25, Iteration 130, Current loss 3.4632349014282227 Accuracy 68.7652249228604\n",
      "Training:: Epoch 25, Iteration 140, Current loss 2.738609790802002 Accuracy 65.18477043673012\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 25, Probability Accuracy 52.475506375858664\n",
      "Starting Training\n",
      "Training:: Epoch 26, Iteration 0, Current loss 3.4686689376831055 Accuracy 60.69119548607029\n",
      "Training:: Epoch 26, Iteration 10, Current loss 2.64090895652771 Accuracy 66.94871648276256\n",
      "Training:: Epoch 26, Iteration 20, Current loss 2.3642144203186035 Accuracy 66.21935223489052\n",
      "Training:: Epoch 26, Iteration 30, Current loss 3.726550340652466 Accuracy 64.82181818181819\n",
      "Training:: Epoch 26, Iteration 40, Current loss 3.106212854385376 Accuracy 60.81217251108424\n",
      "Training:: Epoch 26, Iteration 50, Current loss 2.9060256481170654 Accuracy 62.94037096974978\n",
      "Training:: Epoch 26, Iteration 60, Current loss 2.950313091278076 Accuracy 56.5866009717375\n",
      "Training:: Epoch 26, Iteration 70, Current loss 2.6586084365844727 Accuracy 62.31264637002342\n",
      "Training:: Epoch 26, Iteration 80, Current loss 2.566041946411133 Accuracy 62.638161721931354\n",
      "Training:: Epoch 26, Iteration 90, Current loss 3.4280405044555664 Accuracy 61.130881771451165\n",
      "Training:: Epoch 26, Iteration 100, Current loss 4.64752721786499 Accuracy 51.993355481727576\n",
      "Training:: Epoch 26, Iteration 110, Current loss 3.806745767593384 Accuracy 66.96424308970258\n",
      "Training:: Epoch 26, Iteration 120, Current loss 4.428390979766846 Accuracy 53.31374469474372\n",
      "Training:: Epoch 26, Iteration 130, Current loss 3.6858787536621094 Accuracy 65.09247253122227\n",
      "Training:: Epoch 26, Iteration 140, Current loss 3.525352716445923 Accuracy 47.67791941579655\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 26, Probability Accuracy 52.96513375904418\n",
      "Starting Training\n",
      "Training:: Epoch 27, Iteration 0, Current loss 2.8031797409057617 Accuracy 70.21649233763074\n",
      "Training:: Epoch 27, Iteration 10, Current loss 2.9640378952026367 Accuracy 66.169225618214\n",
      "Training:: Epoch 27, Iteration 20, Current loss 3.3584728240966797 Accuracy 66.02538870301122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 27, Iteration 30, Current loss 3.367600202560425 Accuracy 66.96640235428758\n",
      "Training:: Epoch 27, Iteration 40, Current loss 2.5105695724487305 Accuracy 60.49983412584319\n",
      "Training:: Epoch 27, Iteration 50, Current loss 2.40655255317688 Accuracy 62.54094030639197\n",
      "Training:: Epoch 27, Iteration 60, Current loss 2.310107469558716 Accuracy 53.37612155347436\n",
      "Training:: Epoch 27, Iteration 70, Current loss 2.263051986694336 Accuracy 73.6498150431566\n",
      "Training:: Epoch 27, Iteration 80, Current loss 3.279843330383301 Accuracy 63.34123124246581\n",
      "Training:: Epoch 27, Iteration 90, Current loss 3.3800206184387207 Accuracy 65.81521932477142\n",
      "Training:: Epoch 27, Iteration 100, Current loss 2.629836320877075 Accuracy 63.8642073656474\n",
      "Training:: Epoch 27, Iteration 110, Current loss 2.577601909637451 Accuracy 56.26210610856522\n",
      "Training:: Epoch 27, Iteration 120, Current loss 2.681715726852417 Accuracy 65.0373679237179\n",
      "Training:: Epoch 27, Iteration 130, Current loss 3.23227596282959 Accuracy 63.548157379384016\n",
      "Training:: Epoch 27, Iteration 140, Current loss 2.7339251041412354 Accuracy 65.6130461042883\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 27, Probability Accuracy 53.74160942228381\n",
      "Starting Training\n",
      "Training:: Epoch 28, Iteration 0, Current loss 3.0790674686431885 Accuracy 63.13962535160692\n",
      "Training:: Epoch 28, Iteration 10, Current loss 2.951256275177002 Accuracy 59.34995993589744\n",
      "Training:: Epoch 28, Iteration 20, Current loss 3.0417559146881104 Accuracy 64.74786800148313\n",
      "Training:: Epoch 28, Iteration 30, Current loss 2.649559497833252 Accuracy 56.46075700475176\n",
      "Training:: Epoch 28, Iteration 40, Current loss 2.9320807456970215 Accuracy 69.52901146131805\n",
      "Training:: Epoch 28, Iteration 50, Current loss 2.8340415954589844 Accuracy 55.46996466431096\n",
      "Training:: Epoch 28, Iteration 60, Current loss 3.23909068107605 Accuracy 51.24543058743518\n",
      "Training:: Epoch 28, Iteration 70, Current loss 3.5762486457824707 Accuracy 57.45378510668631\n",
      "Training:: Epoch 28, Iteration 80, Current loss 2.8864362239837646 Accuracy 71.03783715494914\n",
      "Training:: Epoch 28, Iteration 90, Current loss 2.735399007797241 Accuracy 66.96981424148606\n",
      "Training:: Epoch 28, Iteration 100, Current loss 2.558734893798828 Accuracy 55.7813755884717\n",
      "Training:: Epoch 28, Iteration 110, Current loss 3.2928411960601807 Accuracy 56.94722778891116\n",
      "Training:: Epoch 28, Iteration 120, Current loss 2.0452089309692383 Accuracy 71.27427507315775\n",
      "Training:: Epoch 28, Iteration 130, Current loss 2.7711546421051025 Accuracy 58.75113728870373\n",
      "Training:: Epoch 28, Iteration 140, Current loss 3.1376793384552 Accuracy 56.12210667561221\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 28, Probability Accuracy 53.98760776214224\n",
      "Starting Training\n",
      "Training:: Epoch 29, Iteration 0, Current loss 1.9193192720413208 Accuracy 65.47185801884442\n",
      "Training:: Epoch 29, Iteration 10, Current loss 2.5852696895599365 Accuracy 59.701492537313435\n",
      "Training:: Epoch 29, Iteration 20, Current loss 2.7983453273773193 Accuracy 67.3006993006993\n",
      "Training:: Epoch 29, Iteration 30, Current loss 2.510631799697876 Accuracy 52.27865715776657\n",
      "Training:: Epoch 29, Iteration 40, Current loss 3.2066190242767334 Accuracy 68.15792766862721\n",
      "Training:: Epoch 29, Iteration 50, Current loss 2.617934465408325 Accuracy 68.94570674395736\n",
      "Training:: Epoch 29, Iteration 60, Current loss 2.296746253967285 Accuracy 63.013751396325254\n",
      "Training:: Epoch 29, Iteration 70, Current loss 2.476243257522583 Accuracy 66.33221204036654\n",
      "Training:: Epoch 29, Iteration 80, Current loss 2.3623111248016357 Accuracy 67.94908880532253\n",
      "Training:: Epoch 29, Iteration 90, Current loss 3.457470655441284 Accuracy 57.41534988713318\n",
      "Training:: Epoch 29, Iteration 100, Current loss 2.509997844696045 Accuracy 61.41975308641975\n",
      "Training:: Epoch 29, Iteration 110, Current loss 2.5662646293640137 Accuracy 69.12298910223144\n",
      "Training:: Epoch 29, Iteration 120, Current loss 2.559507131576538 Accuracy 61.455867433209335\n",
      "Training:: Epoch 29, Iteration 130, Current loss 2.591627359390259 Accuracy 72.80718795531811\n",
      "Training:: Epoch 29, Iteration 140, Current loss 3.13584303855896 Accuracy 64.28687415426252\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 29, Probability Accuracy 51.906956908215086\n",
      "Starting Training\n",
      "Training:: Epoch 30, Iteration 0, Current loss 2.1475255489349365 Accuracy 63.179750840419224\n",
      "Training:: Epoch 30, Iteration 10, Current loss 1.9817007780075073 Accuracy 69.31592689295039\n",
      "Training:: Epoch 30, Iteration 20, Current loss 2.2112460136413574 Accuracy 63.09215844785772\n",
      "Training:: Epoch 30, Iteration 30, Current loss 2.210206985473633 Accuracy 50.3624987585659\n",
      "Training:: Epoch 30, Iteration 40, Current loss 2.4225571155548096 Accuracy 61.564487752063876\n",
      "Training:: Epoch 30, Iteration 50, Current loss 3.1588683128356934 Accuracy 50.03804692454027\n",
      "Training:: Epoch 30, Iteration 60, Current loss 2.465980052947998 Accuracy 67.24682325760493\n",
      "Training:: Epoch 30, Iteration 70, Current loss 2.4630751609802246 Accuracy 60.44119839022209\n",
      "Training:: Epoch 30, Iteration 80, Current loss 2.2268245220184326 Accuracy 79.90654205607477\n",
      "Training:: Epoch 30, Iteration 90, Current loss 2.3951005935668945 Accuracy 70.57572460183995\n",
      "Training:: Epoch 30, Iteration 100, Current loss 2.3693645000457764 Accuracy 71.20207332875981\n",
      "Training:: Epoch 30, Iteration 110, Current loss 3.209315776824951 Accuracy 60.05489687774008\n",
      "Training:: Epoch 30, Iteration 120, Current loss 3.328749656677246 Accuracy 62.836810082572796\n",
      "Training:: Epoch 30, Iteration 130, Current loss 2.867604970932007 Accuracy 65.02020963211619\n",
      "Training:: Epoch 30, Iteration 140, Current loss 2.4835054874420166 Accuracy 67.70272777880868\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 30, Probability Accuracy 51.2873450153269\n",
      "Starting Training\n",
      "Training:: Epoch 31, Iteration 0, Current loss 2.298189401626587 Accuracy 57.964161274265805\n",
      "Training:: Epoch 31, Iteration 10, Current loss 2.3209011554718018 Accuracy 52.57847533632287\n",
      "Training:: Epoch 31, Iteration 20, Current loss 3.232208251953125 Accuracy 67.03341940795629\n",
      "Training:: Epoch 31, Iteration 30, Current loss 2.6740689277648926 Accuracy 73.66035182679296\n",
      "Training:: Epoch 31, Iteration 40, Current loss 3.2317941188812256 Accuracy 58.362841074776085\n",
      "Training:: Epoch 31, Iteration 50, Current loss 3.258794069290161 Accuracy 56.65559915484455\n",
      "Training:: Epoch 31, Iteration 60, Current loss 3.9401957988739014 Accuracy 58.307161612521234\n",
      "Training:: Epoch 31, Iteration 70, Current loss 2.9047327041625977 Accuracy 59.08734104348736\n",
      "Training:: Epoch 31, Iteration 80, Current loss 3.03924298286438 Accuracy 60.045517764572004\n",
      "Training:: Epoch 31, Iteration 90, Current loss 2.202214002609253 Accuracy 68.37989621099027\n",
      "Training:: Epoch 31, Iteration 100, Current loss 2.425218343734741 Accuracy 70.04154382203163\n",
      "Training:: Epoch 31, Iteration 110, Current loss 3.4633750915527344 Accuracy 57.082240395000774\n",
      "Training:: Epoch 31, Iteration 120, Current loss 2.2769858837127686 Accuracy 72.44157937147462\n",
      "Training:: Epoch 31, Iteration 130, Current loss 3.0355842113494873 Accuracy 56.10653487095003\n",
      "Training:: Epoch 31, Iteration 140, Current loss 5.743556022644043 Accuracy 69.80860499494281\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 31, Probability Accuracy 45.50952947404885\n",
      "Starting Training\n",
      "Training:: Epoch 32, Iteration 0, Current loss 5.275761604309082 Accuracy 53.44914910858995\n",
      "Training:: Epoch 32, Iteration 10, Current loss 2.932788610458374 Accuracy 63.47737536527052\n",
      "Training:: Epoch 32, Iteration 20, Current loss 2.997558832168579 Accuracy 64.03537504094334\n",
      "Training:: Epoch 32, Iteration 30, Current loss 4.214621067047119 Accuracy 62.30609737367532\n",
      "Training:: Epoch 32, Iteration 40, Current loss 3.5119054317474365 Accuracy 65.9733394621926\n",
      "Training:: Epoch 32, Iteration 50, Current loss 2.7947206497192383 Accuracy 63.71083350399345\n",
      "Training:: Epoch 32, Iteration 60, Current loss 2.3148112297058105 Accuracy 63.03317535545024\n",
      "Training:: Epoch 32, Iteration 70, Current loss 2.4871177673339844 Accuracy 73.40511440107672\n",
      "Training:: Epoch 32, Iteration 80, Current loss 3.0551183223724365 Accuracy 65.82395560351472\n",
      "Training:: Epoch 32, Iteration 90, Current loss 2.677004337310791 Accuracy 50.66842278564373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 32, Iteration 100, Current loss 2.675433397293091 Accuracy 69.71625286876696\n",
      "Training:: Epoch 32, Iteration 110, Current loss 2.290780782699585 Accuracy 68.29881272207297\n",
      "Training:: Epoch 32, Iteration 120, Current loss 3.1344687938690186 Accuracy 64.54319761668322\n",
      "Training:: Epoch 32, Iteration 130, Current loss 2.9279699325561523 Accuracy 64.48895094121612\n",
      "Training:: Epoch 32, Iteration 140, Current loss 2.1218113899230957 Accuracy 62.04665054757503\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 32, Probability Accuracy 53.32853482702501\n",
      "Starting Training\n",
      "Training:: Epoch 33, Iteration 0, Current loss 2.4621336460113525 Accuracy 71.84791548048334\n",
      "Training:: Epoch 33, Iteration 10, Current loss 1.9354077577590942 Accuracy 57.27280313777852\n",
      "Training:: Epoch 33, Iteration 20, Current loss 2.3795955181121826 Accuracy 57.66258246936852\n",
      "Training:: Epoch 33, Iteration 30, Current loss 2.7427830696105957 Accuracy 66.16317792578496\n",
      "Training:: Epoch 33, Iteration 40, Current loss 2.669142723083496 Accuracy 67.51740139211137\n",
      "Training:: Epoch 33, Iteration 50, Current loss 2.270728349685669 Accuracy 68.93797375499226\n",
      "Training:: Epoch 33, Iteration 60, Current loss 2.805121898651123 Accuracy 58.48791737691768\n",
      "Training:: Epoch 33, Iteration 70, Current loss 2.0717973709106445 Accuracy 71.77564903512426\n",
      "Training:: Epoch 33, Iteration 80, Current loss 2.905561923980713 Accuracy 59.918879056047196\n",
      "Training:: Epoch 33, Iteration 90, Current loss 1.670968770980835 Accuracy 62.011752506049085\n",
      "Training:: Epoch 33, Iteration 100, Current loss 1.9305784702301025 Accuracy 74.87279843444227\n",
      "Training:: Epoch 33, Iteration 110, Current loss 2.4242255687713623 Accuracy 72.41153342070773\n",
      "Training:: Epoch 33, Iteration 120, Current loss 1.7481447458267212 Accuracy 69.08177905308465\n",
      "Training:: Epoch 33, Iteration 130, Current loss 2.8629071712493896 Accuracy 59.6124256664033\n",
      "Training:: Epoch 33, Iteration 140, Current loss 1.6648993492126465 Accuracy 63.91656023839932\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 33, Probability Accuracy 52.354999052281386\n",
      "Starting Training\n",
      "Training:: Epoch 34, Iteration 0, Current loss 1.724465250968933 Accuracy 63.00366300366301\n",
      "Training:: Epoch 34, Iteration 10, Current loss 2.507929801940918 Accuracy 64.50277123017138\n",
      "Training:: Epoch 34, Iteration 20, Current loss 3.0417091846466064 Accuracy 68.75461564283316\n",
      "Training:: Epoch 34, Iteration 30, Current loss 1.9674495458602905 Accuracy 66.63493840985443\n",
      "Training:: Epoch 34, Iteration 40, Current loss 2.2755584716796875 Accuracy 63.15005321035828\n",
      "Training:: Epoch 34, Iteration 50, Current loss 2.2431483268737793 Accuracy 70.08933751015199\n",
      "Training:: Epoch 34, Iteration 60, Current loss 1.69094717502594 Accuracy 67.56953722822786\n",
      "Training:: Epoch 34, Iteration 70, Current loss 2.4257619380950928 Accuracy 62.778229859748215\n",
      "Training:: Epoch 34, Iteration 80, Current loss 1.7290948629379272 Accuracy 67.20241084881968\n",
      "Training:: Epoch 34, Iteration 90, Current loss 2.058603525161743 Accuracy 62.503337427244084\n",
      "Training:: Epoch 34, Iteration 100, Current loss 2.1773006916046143 Accuracy 65.95995984172917\n",
      "Training:: Epoch 34, Iteration 110, Current loss 2.5587010383605957 Accuracy 67.47695923795386\n",
      "Training:: Epoch 34, Iteration 120, Current loss 2.3383266925811768 Accuracy 76.60477453580901\n",
      "Training:: Epoch 34, Iteration 130, Current loss 2.1317453384399414 Accuracy 66.75341116894077\n",
      "Training:: Epoch 34, Iteration 140, Current loss 2.255963087081909 Accuracy 74.4923059321549\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 34, Probability Accuracy 52.39127379917516\n",
      "Starting Training\n",
      "Training:: Epoch 35, Iteration 0, Current loss 1.7010363340377808 Accuracy 75.61086797957695\n",
      "Training:: Epoch 35, Iteration 10, Current loss 1.7109549045562744 Accuracy 69.91646054043963\n",
      "Training:: Epoch 35, Iteration 20, Current loss 1.8430120944976807 Accuracy 69.52786601212821\n",
      "Training:: Epoch 35, Iteration 30, Current loss 2.455692768096924 Accuracy 52.088089163421515\n",
      "Training:: Epoch 35, Iteration 40, Current loss 1.733078122138977 Accuracy 63.993046933200894\n",
      "Training:: Epoch 35, Iteration 50, Current loss 2.4985196590423584 Accuracy 63.56844224218024\n",
      "Training:: Epoch 35, Iteration 60, Current loss 2.058131456375122 Accuracy 68.87989043053653\n",
      "Training:: Epoch 35, Iteration 70, Current loss 2.1819465160369873 Accuracy 67.0647024466221\n",
      "Training:: Epoch 35, Iteration 80, Current loss 2.5402722358703613 Accuracy 60.48090291976773\n",
      "Training:: Epoch 35, Iteration 90, Current loss 1.9708377122879028 Accuracy 58.73675951353472\n",
      "Training:: Epoch 35, Iteration 100, Current loss 2.04626727104187 Accuracy 63.4257464133385\n",
      "Training:: Epoch 35, Iteration 110, Current loss 2.417750835418701 Accuracy 63.888454928917355\n",
      "Training:: Epoch 35, Iteration 120, Current loss 2.7337799072265625 Accuracy 72.74415463830506\n",
      "Training:: Epoch 35, Iteration 130, Current loss 2.2237374782562256 Accuracy 58.26892535733192\n",
      "Training:: Epoch 35, Iteration 140, Current loss 1.7592380046844482 Accuracy 61.0181072770755\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 35, Probability Accuracy 52.73539369538363\n",
      "Starting Training\n",
      "Training:: Epoch 36, Iteration 0, Current loss 1.7991639375686646 Accuracy 61.987255133349066\n",
      "Training:: Epoch 36, Iteration 10, Current loss 2.0433616638183594 Accuracy 71.02201911092646\n",
      "Training:: Epoch 36, Iteration 20, Current loss 1.8933905363082886 Accuracy 62.684312303601644\n",
      "Training:: Epoch 36, Iteration 30, Current loss 2.306762456893921 Accuracy 67.99432271799876\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-95645851addf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmiddle_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpsuedo_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_single_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_stages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mmiddle_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmiddle_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mfinal_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dilated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    258\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 259\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_epoch = -1\n",
    "for epoch in range(100):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        psuedo_l = get_single_random(predictions[-1], item[4])\n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            loss += ce_criterion(p, psuedo_l)\n",
    "            loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                        max=16) * src_mask_mse[:, :, 1:])\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(predictions[-1], dim=1)\n",
    "                correct = float(torch.sum((pred == item_2) * src_mask).item())\n",
    "                total = float(torch.sum(src_mask).item())\n",
    "                print(f\"Training:: Epoch {epoch}, Iteration {i}, Current loss {loss.item()}\" +\n",
    "                      f\" Accuracy {correct * 100.0 / total}\")\n",
    "    # Calculating Expectation Step\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-last-model.wt\")\n",
    "    print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split1/ms-tcn-best-model.wt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir + \"ms-tcn-best-model.wt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split3/ms-tcn-initial-15-epochs.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 15, Probability Accuracy 57.770101729343025\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Validation Data Accuracy\")\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "        pred = torch.argmax(predictions[-1], dim=1)\n",
    "        correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "        total += float(torch.sum(src_mask).item())\n",
    "\n",
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(video_id_boundary_frames, open(\"dump_dir/video_id_boundary_frames_dict.pkl\", \"wb\"))\n",
    "# pickle.dump(loaded_vidid_selected_frames, open(\"dump_dir/loaded_vidid_selected_frames_dict.pkl\", \"wb\"))\n",
    "pickle.dump(boundary_dict, open(\"dump_dir/chunk_1_video_id_boundary_frames_dict.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
