{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 1, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split1-slup15/', 'project_name': 'breakfast-split-1', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split1.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split1.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split1_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=1,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split1-slup15/\",\n",
    "    project_name=\"breakfast-split-1\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1460\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 252\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = Breakfast(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = iter(trainloader).next()\n",
    "# print(item[0]) # -- data feature\n",
    "# print(item[1]) # -- valid count\n",
    "# item[2] # -- Actual labels\n",
    "# print(item[5]) # video names\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_frames_dict = pickle.load(open(\"data/breakfast_len_assum_annotations.pkl\", 'rb'))\n",
    "# loaded_vidid_selected_frames\n",
    "boundary_frames_dict = pickle.load(open(\"data/breakfast_boundary_annotations.pkl\", \"rb\"))\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"data/breakfast_meanvar_actions.pkl\", \"rb\"))\n",
    "def get_possion_prob(cur_len, cur_class):\n",
    "    mean_class, std_class = loaded_mean_var_actions[label_id_to_label_name[cur_class]]\n",
    "    mean_class = mean_class\n",
    "    prob = cur_len * torch.log(torch.tensor(mean_class, device=device) + 1e-5)\n",
    "    prob = prob - mean_class\n",
    "    factorials = torch.cumsum(torch.log(torch.arange(1, torch.max(cur_len)+1, 1).type(torch.float).to(device)), \n",
    "                              dim=0)[min(cur_len)-1:]\n",
    "    prob = prob - factorials\n",
    "    return prob\n",
    "\n",
    "# get_possion_prob(torch.arange(10, 21), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_video_each_segment_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels):\n",
    "    prob_each_segment = []\n",
    "    \n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    cur_boundary = 0\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[i]\n",
    "        label_next_ele = labels[i + 1]\n",
    "\n",
    "        indices = torch.arange(cur_ele, next_ele).to(cumsum_feat.device)\n",
    "        strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "        end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "        left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "        right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "\n",
    "        cur_boundary_len = indices - cur_boundary\n",
    "        len_prob = get_possion_prob(cur_boundary_len, label_cur_ele)\n",
    "\n",
    "        prob = torch.softmax((left_sum + right_sum + len_prob), dim=0)\n",
    "#         prob = torch.softmax((left_sum + right_sum), dim=0)\n",
    "\n",
    "        cur_boundary = round(np.sum(np.arange(cur_ele, next_ele, 1) * prob.detach().cpu().numpy()).item())\n",
    "        prob_each_segment.append(prob)\n",
    "    \n",
    "    return prob_each_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_element_probb(data_feat, data_count, video_ids): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "        prob_video = prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels)\n",
    "        prob_video_each_segment_dict[cur_vidid] = prob_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_loss(data_feat, data_count, video_ids): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "#     global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    loss_arr = []\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "\n",
    "        prob_each_video = prob_video_each_segment_dict[cur_vidid]\n",
    "        \n",
    "        log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "        cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "        \n",
    "        \n",
    "        current_vid_prob_arr = []\n",
    "        # Start segment log probability\n",
    "        start_ele_idx = selected_frames_indices[0]\n",
    "        if start_ele_idx > 0:\n",
    "            start_ele_label_idx = selected_frames_labels[0]\n",
    "            first_segment_prob = (cumsum_feat[start_ele_idx - 1, :])[start_ele_label_idx]\n",
    "            current_vid_prob_arr.append(first_segment_prob.unsqueeze(0))\n",
    "        \n",
    "        for i, cur_ele in enumerate(selected_frames_indices[:-1]):\n",
    "            next_ele = selected_frames_indices[i + 1]\n",
    "            label_cur_ele = selected_frames_labels[i]\n",
    "            label_next_ele = selected_frames_labels[i + 1]\n",
    "\n",
    "            indices = torch.arange(cur_ele, next_ele)\n",
    "            strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "            end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "            left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "            right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "            current_vid_prob_arr.append((left_sum + right_sum)  * (prob_each_video[i]))\n",
    "        \n",
    "        # End segment log probability\n",
    "        end_index = cur_vid_count.item() - 1\n",
    "        last_ele_label_idx = selected_frames_labels[-1]\n",
    "        last_segment_sum_prob = (cumsum_feat[end_index, :] - cumsum_feat[selected_frames_indices[-1] - 1, \\\n",
    "                                                                         :])[last_ele_label_idx]\n",
    "        current_vid_prob_arr.append(last_segment_sum_prob.unsqueeze(0))\n",
    "            \n",
    "        loss_arr.append(torch.cat(current_vid_prob_arr))\n",
    "    return -torch.mean(torch.cat(loss_arr)), loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_file_list = set(open(config.train_split_file).read().split(\"\\n\")[0:-1])\n",
    "\n",
    "def get_estimated_boundaries():\n",
    "    estimated_boundary_dict = {}\n",
    "    for video_id in train_split_file_list:\n",
    "        ele = video_id.split(\".txt\")[0]\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[video_id]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        \n",
    "        boundary_list = []\n",
    "        for i, segment in enumerate(estimated_boundary_probs):\n",
    "            estimated_boundary = np.sum(np.arange(selected_frames_indices[i], selected_frames_indices[i + 1], 1) \\\n",
    "                                        * segment.detach().cpu().numpy())\n",
    "            estimated_boundary = round(estimated_boundary.item())\n",
    "            \n",
    "            if (estimated_boundary < selected_frames_indices[i]) or (estimated_boundary > selected_frames_indices[i + 1]):\n",
    "                print(\"Estimated value wrong\")\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "            boundary_list.append(estimated_boundary)\n",
    "\n",
    "        estimated_boundary_dict[ele] = boundary_list\n",
    "    return estimated_boundary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_err():\n",
    "    err_list = []\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    estimated_boundar_dict = get_estimated_boundaries()\n",
    "    for video_id in train_split_file_list:\n",
    "        ele = video_id.split(\".txt\")[0]\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        estimated_boundary_list = estimated_boundar_dict[ele]\n",
    "        \n",
    "        estimated = np.array(estimated_boundary_list) #.detach().cpu().numpy()\n",
    "        actual = np.array(boundary_frames_dict[video_id][:-1])\n",
    "        if len(actual) != len(estimated):\n",
    "            print(ele)\n",
    "            continue\n",
    "        \n",
    "        mse_err = (actual - estimated)**2\n",
    "        err_list.append(mse_err)\n",
    "        \n",
    "        estimated_labels = []\n",
    "        actual_labels = []\n",
    "        start_v1 = 0\n",
    "        start_v2 = 0\n",
    "        for i, v1 in enumerate(estimated):\n",
    "            estimated_labels.extend([i] * (v1 - start_v1))\n",
    "            start_v1 = v1\n",
    "            v2 = actual[i]\n",
    "            actual_labels.extend([i] * (v2 - start_v2))\n",
    "            start_v2 = v2\n",
    "            \n",
    "        last_ele = boundary_frames_dict[video_id][-1]\n",
    "        estimated_labels.extend([i+1] * (last_ele - start_v1))\n",
    "        actual_labels.extend([i+1] * (last_ele - start_v2))\n",
    "        \n",
    "        correct += np.sum(np.array(actual_labels) == np.array(estimated_labels))\n",
    "        total += len(actual_labels)\n",
    "        \n",
    "    print(f\"Train Boundary avergage error = {np.sqrt(np.mean(np.concatenate(err_list))):.3f}\")\n",
    "    print(f\"Train From boundary avergage accuracy = {correct * 100.0 / total:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_file=torch.load(\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split1/ms-tcn-best-model.wt\")\n",
    "# model.load_state_dict(loaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels_dir = \"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/length_segmentation_output/\"\n",
    "def get_single_random(output_p, video_ids):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((output_p.shape[0], output_p.shape[2]), dtype=torch.long, \n",
    "                                        device=output_p.device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        pseudo_l = open(pseudo_labels_dir + cur_vidid + \".txt\").read().split(\"\\n\")[0:-1]\n",
    "        pseudo_l = [label_name_to_label_id_dict[ele] for ele in pseudo_l]\n",
    "        abc = torch.tensor(pseudo_l).to(torch.long).to(boundary_target_tensor.device)\n",
    "        frame_idx_tensor = torch.arange(0, len(pseudo_l), 1).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = abc\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labels = pickle.load(open(\"data/breakfast_weaklysupervised_labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = pickle.load(open('data/breakfast_lengthmodel_multinomial_prior.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def change_selected_frames(model):\n",
    "    global selected_frames_dict\n",
    "    new_selected_frame_dict = {}\n",
    "    with torch.no_grad():\n",
    "        for train_idx, item in enumerate(trainloader):\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            if train_idx % 10 == 0:\n",
    "                print(f\"Completed {train_idx} videos selected frames calculation\")\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            \n",
    "            for idx, video_id in enumerate(item[4]):\n",
    "                start = 0\n",
    "                new_index_label_pair_list = []\n",
    "                weakly_labels_video = [label_name_to_label_id_dict[wl] for wl in weakly_labels[video_id + \".txt\"]]\n",
    "                cur_video_predictions = predictions[-1][idx][:, :item_1[idx]]\n",
    "                cur_preds_for_weakly_labels = torch.softmax(cur_video_predictions[weakly_labels_video], dim=0)\n",
    "                prior_probs_cur_vid = prior_probs[video_id]\n",
    "                weakly_labels_masked = []\n",
    "                for i, prob_class in enumerate(cur_preds_for_weakly_labels):\n",
    "                    prob_class_masked = prob_class * torch.tensor(prior_probs_cur_vid[i], \n",
    "                                                                  dtype=prob_class.dtype, device=prob_class.device)\n",
    "                    weakly_labels_masked.append(prob_class_masked)\n",
    "                    \n",
    "                weakly_labels_masked = torch.stack(weakly_labels_masked)\n",
    "                weakly_labels_masked = weakly_labels_masked / torch.sum(weakly_labels_masked, dim=0)\n",
    "\n",
    "                for i in range(len(weakly_labels_video)):\n",
    "                    cur_l = weakly_labels_video[i]\n",
    "                    prob_class = weakly_labels_masked[i]\n",
    "                    expected_value_of_class = torch.argmax(prob_class)\n",
    "                    new_index_label_pair_list.append((int(expected_value_of_class.item()),\n",
    "                                                      weakly_labels_video[i])) \n",
    "                \n",
    "                back_list = copy.deepcopy(new_index_label_pair_list)\n",
    "                error_list = []\n",
    "                if new_index_label_pair_list[0][0] > new_index_label_pair_list[1][0]:\n",
    "                    error_list.append(1)\n",
    "                else:\n",
    "                    error_list.append(0)\n",
    "                    \n",
    "                for i in range(1, len(new_index_label_pair_list) - 1, 1):\n",
    "                    err = 0\n",
    "                    prev_ele = new_index_label_pair_list[i - 1]\n",
    "                    cur_ele = new_index_label_pair_list[i]\n",
    "                    next_ele = new_index_label_pair_list[i + 1]\n",
    "                    if not (prev_ele[0] < cur_ele[0]):\n",
    "                        err += 1\n",
    "                    if not (cur_ele[0] < next_ele[0]):\n",
    "                        err += 1\n",
    "                    error_list.append(err)\n",
    "\n",
    "                if new_index_label_pair_list[-1][0] < new_index_label_pair_list[-2][0]:\n",
    "                    error_list.append(1)\n",
    "                else:\n",
    "                    error_list.append(0)\n",
    "                    \n",
    "                if error_list[0] == 1 and error_list[1] == 1:\n",
    "                    new_index = new_index_label_pair_list[1][0] // 2\n",
    "                    new_index_label_pair_list[0] = (new_index, new_index_label_pair_list[0][1])\n",
    "                    error_list[0] = 0\n",
    "                    error_list[1] = 0\n",
    "                    \n",
    "                if error_list[-1] == 1 and error_list[-2] == 1:\n",
    "                    new_index = (new_index_label_pair_list[-2][0] + weakly_labels_masked.shape[1]) // 2\n",
    "                    new_index_label_pair_list[-1] = (new_index, new_index_label_pair_list[-1][1])\n",
    "                    error_list[-1] = 0\n",
    "                    error_list[-2] = 0\n",
    "                    \n",
    "                start_flag = False\n",
    "                start_index = -1\n",
    "                end_index = -1\n",
    "                for i in range(1, len(error_list) - 1):\n",
    "                    if error_list[i] == 1 and error_list[i + 1] == 2:\n",
    "                        start_flag = True\n",
    "                        start_index = i\n",
    "                        \n",
    "                    if (start_flag is True) and (error_list[i] == 2 or error_list[i + 1] == 1):\n",
    "                        start_flag = False\n",
    "                        end_index = i + 1\n",
    "                        \n",
    "                        num_div = end_index - start_index - 1\n",
    "                        increm = (new_index_label_pair_list[end_index][0] - \\\n",
    "                                  new_index_label_pair_list[start_index][0]) // num_div\n",
    "                        value = list(range(new_index_label_pair_list[start_index][0], \n",
    "                                           new_index_label_pair_list[end_index][0], increm))\n",
    "                        count = 0\n",
    "                        for ch_i in range(start_index + 1, end_index):\n",
    "                            old_ele = new_index_label_pair_list[ch_i]\n",
    "                            new_ele = (value[count], old_ele[1])\n",
    "                            new_index_label_pair_list[ch_i] = new_ele\n",
    "                            count += 1\n",
    "                    \n",
    "                final_list = new_index_label_pair_list\n",
    "                is_valid_list = True\n",
    "                for i in range(1, len(final_list) - 1, 1):\n",
    "                    cur_ele = final_list[i]\n",
    "                    \n",
    "                    if not (final_list[i - 1][0] < cur_ele[0] and cur_ele[0] < final_list[i + 1][0]):\n",
    "                        is_valid_list  = False\n",
    "\n",
    "                if is_valid_list == False:\n",
    "                    print(f\"Could not find expected solution for video {video_id}\")\n",
    "                    print(final_list)\n",
    "                    print(back_list)\n",
    "                    print(error_list)\n",
    "                    new_selected_frame_dict[video_id + \".txt\"] = selected_frames_dict[video_id + \".txt\"]\n",
    "                else:\n",
    "                \n",
    "                    label_name_final_list = []\n",
    "                    for ele in final_list:\n",
    "                        label_name_final_list.append((ele[0], label_id_to_label_name[ele[1]]))\n",
    "                    new_selected_frame_dict[video_id + \".txt\"] = label_name_final_list\n",
    "                \n",
    "        return new_selected_frame_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_selected_frame_acc(selected_frame_dict):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    for video_id in selected_frame_dict.keys():\n",
    "        ground_labels = open(config.ground_truth_files_dir + video_id).read().split(\"\\n\")[0:-1]\n",
    "        ground_labels = np.array(ground_labels)\n",
    "\n",
    "        selected_frames_index = [ele[0] for ele in selected_frame_dict[video_id]]\n",
    "        selected_frames_labels = np.array([ele[1] for ele in selected_frame_dict[video_id]])\n",
    "\n",
    "        ground_selected_labels = ground_labels[selected_frames_index]\n",
    "\n",
    "        correct += np.sum(ground_selected_labels == selected_frames_labels)\n",
    "        total += len(ground_selected_labels)\n",
    "\n",
    "    print(\"Total correct pivots labels selected = \", correct * 100.0 / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# selected_frames_dict = change_selected_frames(model)\n",
    "# get_new_selected_frame_acc(selected_frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Expection Boundaries\n",
    "# print(\"Calculating Expectation\")\n",
    "# correct = 0.0\n",
    "# total = 0.0\n",
    "# model.eval()\n",
    "# for i, item in enumerate(trainloader):\n",
    "#     with torch.no_grad():\n",
    "#         item_0 = item[0].to(device)\n",
    "#         item_1 = item[1].to(device)\n",
    "#         item_2 = item[2].to(device)\n",
    "#         src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "#         src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "#         middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "#         prob = torch.softmax(predictions[-1], dim=1)\n",
    "#         prob = prob.permute(0, 2, 1)\n",
    "#         calculate_element_probb(prob, item_1, item[4])\n",
    "\n",
    "#         if i % 10 == 0:\n",
    "#             print(f\"Completed iter {i}\")\n",
    "\n",
    "# get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split1-slup15/'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Training:: Epoch 0, Iteration 0, Current loss 15.761063575744629 Accuracy 3.641727949271214\n",
      "Training:: Epoch 0, Iteration 10, Current loss 14.543675422668457 Accuracy 10.09473362534379\n",
      "Training:: Epoch 0, Iteration 20, Current loss 14.211479187011719 Accuracy 7.272293752980448\n",
      "Training:: Epoch 0, Iteration 30, Current loss 14.205370903015137 Accuracy 8.591975775927327\n",
      "Training:: Epoch 0, Iteration 40, Current loss 13.268867492675781 Accuracy 7.281264466635805\n",
      "Training:: Epoch 0, Iteration 50, Current loss 12.063504219055176 Accuracy 12.853293584819125\n",
      "Training:: Epoch 0, Iteration 60, Current loss 11.476430892944336 Accuracy 17.390340342189866\n",
      "Training:: Epoch 0, Iteration 70, Current loss 13.139060020446777 Accuracy 15.825115836996554\n",
      "Training:: Epoch 0, Iteration 80, Current loss 10.582386016845703 Accuracy 20.540387607865327\n",
      "Training:: Epoch 0, Iteration 90, Current loss 11.887202262878418 Accuracy 10.747760883149343\n",
      "Training:: Epoch 0, Iteration 100, Current loss 11.037349700927734 Accuracy 17.0045851841238\n",
      "Training:: Epoch 0, Iteration 110, Current loss 10.88322925567627 Accuracy 12.774646736910888\n",
      "Training:: Epoch 0, Iteration 120, Current loss 10.901997566223145 Accuracy 17.0244458074126\n",
      "Training:: Epoch 0, Iteration 130, Current loss 10.405472755432129 Accuracy 26.401105805478764\n",
      "Training:: Epoch 0, Iteration 140, Current loss 10.53115463256836 Accuracy 13.675002063216969\n",
      "Training:: Epoch 0, Iteration 150, Current loss 9.298531532287598 Accuracy 17.576501056362027\n",
      "Training:: Epoch 0, Iteration 160, Current loss 9.928777694702148 Accuracy 13.685452935969312\n",
      "Training:: Epoch 0, Iteration 170, Current loss 9.194457054138184 Accuracy 18.237478671083007\n",
      "Training:: Epoch 0, Iteration 180, Current loss 8.650455474853516 Accuracy 25.364034143892116\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 0, Probability Accuracy 25.37246103256289\n",
      "Starting Training\n",
      "Training:: Epoch 1, Iteration 0, Current loss 9.485166549682617 Accuracy 35.86751532296087\n",
      "Training:: Epoch 1, Iteration 10, Current loss 9.915010452270508 Accuracy 18.85939036381514\n",
      "Training:: Epoch 1, Iteration 20, Current loss 8.517781257629395 Accuracy 18.32989345679701\n",
      "Training:: Epoch 1, Iteration 30, Current loss 10.071236610412598 Accuracy 11.440318475494355\n",
      "Training:: Epoch 1, Iteration 40, Current loss 8.894887924194336 Accuracy 26.30389847618132\n",
      "Training:: Epoch 1, Iteration 50, Current loss 9.015626907348633 Accuracy 23.848797250859107\n",
      "Training:: Epoch 1, Iteration 60, Current loss 9.588273048400879 Accuracy 26.238383493904\n",
      "Training:: Epoch 1, Iteration 70, Current loss 8.739045143127441 Accuracy 24.34207372609175\n",
      "Training:: Epoch 1, Iteration 80, Current loss 8.815173149108887 Accuracy 24.122950436773017\n",
      "Training:: Epoch 1, Iteration 90, Current loss 8.303487777709961 Accuracy 29.24886542558118\n",
      "Training:: Epoch 1, Iteration 100, Current loss 16.288000106811523 Accuracy 13.164354626933836\n",
      "Training:: Epoch 1, Iteration 110, Current loss 8.692574501037598 Accuracy 25.944424624410352\n",
      "Training:: Epoch 1, Iteration 120, Current loss 9.654293060302734 Accuracy 28.51221726601666\n",
      "Training:: Epoch 1, Iteration 130, Current loss 8.289813995361328 Accuracy 23.341272541680844\n",
      "Training:: Epoch 1, Iteration 140, Current loss 7.971803188323975 Accuracy 16.874302714763854\n",
      "Training:: Epoch 1, Iteration 150, Current loss 7.776771068572998 Accuracy 27.053694355208812\n",
      "Training:: Epoch 1, Iteration 160, Current loss 6.363001346588135 Accuracy 31.663326653306612\n",
      "Training:: Epoch 1, Iteration 170, Current loss 8.800307273864746 Accuracy 29.476542464926837\n",
      "Training:: Epoch 1, Iteration 180, Current loss 8.987942695617676 Accuracy 36.061107327040965\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 1, Probability Accuracy 33.03081385456114\n",
      "Starting Training\n",
      "Training:: Epoch 2, Iteration 0, Current loss 9.099912643432617 Accuracy 20.91026191498497\n",
      "Training:: Epoch 2, Iteration 10, Current loss 7.999375820159912 Accuracy 24.121357765094622\n",
      "Training:: Epoch 2, Iteration 20, Current loss 9.262837409973145 Accuracy 17.960979342004592\n",
      "Training:: Epoch 2, Iteration 30, Current loss 7.626153945922852 Accuracy 26.53448275862069\n",
      "Training:: Epoch 2, Iteration 40, Current loss 6.975917816162109 Accuracy 34.10474464426785\n",
      "Training:: Epoch 2, Iteration 50, Current loss 6.902747631072998 Accuracy 30.584028605482718\n",
      "Training:: Epoch 2, Iteration 60, Current loss 8.286260604858398 Accuracy 41.57075495614257\n",
      "Training:: Epoch 2, Iteration 70, Current loss 8.84718132019043 Accuracy 21.090839008094566\n",
      "Training:: Epoch 2, Iteration 80, Current loss 7.861706256866455 Accuracy 28.49359117502568\n",
      "Training:: Epoch 2, Iteration 90, Current loss 6.678009510040283 Accuracy 40.127077223851416\n",
      "Training:: Epoch 2, Iteration 100, Current loss 6.801527500152588 Accuracy 33.23805859396471\n",
      "Training:: Epoch 2, Iteration 110, Current loss 6.377862930297852 Accuracy 39.234042553191486\n",
      "Training:: Epoch 2, Iteration 120, Current loss 9.270466804504395 Accuracy 34.99705869043848\n",
      "Training:: Epoch 2, Iteration 130, Current loss 9.871869087219238 Accuracy 17.394382818031627\n",
      "Training:: Epoch 2, Iteration 140, Current loss 7.1382293701171875 Accuracy 26.27164293959215\n",
      "Training:: Epoch 2, Iteration 150, Current loss 7.434619426727295 Accuracy 32.21583884808378\n",
      "Training:: Epoch 2, Iteration 160, Current loss 7.149063587188721 Accuracy 36.32554506072012\n",
      "Training:: Epoch 2, Iteration 170, Current loss 7.86452579498291 Accuracy 21.310127449636838\n",
      "Training:: Epoch 2, Iteration 180, Current loss 7.684832572937012 Accuracy 25.80950991831972\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 2, Probability Accuracy 39.64766076664649\n",
      "Starting Training\n",
      "Training:: Epoch 3, Iteration 0, Current loss 7.350787162780762 Accuracy 25.75476893806639\n",
      "Training:: Epoch 3, Iteration 10, Current loss 7.43400764465332 Accuracy 29.497524298551255\n",
      "Training:: Epoch 3, Iteration 20, Current loss 5.918341159820557 Accuracy 49.031547580488436\n",
      "Training:: Epoch 3, Iteration 30, Current loss 6.843905925750732 Accuracy 45.05685773961476\n",
      "Training:: Epoch 3, Iteration 40, Current loss 7.047003269195557 Accuracy 38.6188356617161\n",
      "Training:: Epoch 3, Iteration 50, Current loss 8.53171443939209 Accuracy 23.69166358822805\n",
      "Training:: Epoch 3, Iteration 60, Current loss 7.052195072174072 Accuracy 37.500650330367826\n",
      "Training:: Epoch 3, Iteration 70, Current loss 6.031867027282715 Accuracy 33.90264730999146\n",
      "Training:: Epoch 3, Iteration 80, Current loss 6.509530544281006 Accuracy 40.32251429511704\n",
      "Training:: Epoch 3, Iteration 90, Current loss 6.414446830749512 Accuracy 51.95138595522049\n",
      "Training:: Epoch 3, Iteration 100, Current loss 8.30727481842041 Accuracy 28.15874082249628\n",
      "Training:: Epoch 3, Iteration 110, Current loss 5.774721145629883 Accuracy 36.781716417910445\n",
      "Training:: Epoch 3, Iteration 120, Current loss 7.148531436920166 Accuracy 30.16729868391702\n",
      "Training:: Epoch 3, Iteration 130, Current loss 5.620827674865723 Accuracy 49.18593798610391\n",
      "Training:: Epoch 3, Iteration 140, Current loss 10.511134147644043 Accuracy 23.229987871437235\n",
      "Training:: Epoch 3, Iteration 150, Current loss 9.18430233001709 Accuracy 16.5328265800282\n",
      "Training:: Epoch 3, Iteration 160, Current loss 7.217928886413574 Accuracy 38.11216429699842\n",
      "Training:: Epoch 3, Iteration 170, Current loss 7.227716445922852 Accuracy 40.49239143882222\n",
      "Training:: Epoch 3, Iteration 180, Current loss 7.778365612030029 Accuracy 30.51558181644906\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 3, Probability Accuracy 41.95167602518292\n",
      "Starting Training\n",
      "Training:: Epoch 4, Iteration 0, Current loss 8.963886260986328 Accuracy 28.936416184971097\n",
      "Training:: Epoch 4, Iteration 10, Current loss 5.922534465789795 Accuracy 48.89138366545046\n",
      "Training:: Epoch 4, Iteration 20, Current loss 6.144402027130127 Accuracy 33.535874003499906\n",
      "Training:: Epoch 4, Iteration 30, Current loss 6.097654342651367 Accuracy 51.76997834734881\n",
      "Training:: Epoch 4, Iteration 40, Current loss 5.08465051651001 Accuracy 52.58484369298139\n",
      "Training:: Epoch 4, Iteration 50, Current loss 5.492929935455322 Accuracy 50.74942471546738\n",
      "Training:: Epoch 4, Iteration 60, Current loss 8.6327486038208 Accuracy 27.77060542230074\n",
      "Training:: Epoch 4, Iteration 70, Current loss 10.630049705505371 Accuracy 23.29354968485986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 4, Iteration 80, Current loss 6.008396625518799 Accuracy 40.79711079582097\n",
      "Training:: Epoch 4, Iteration 90, Current loss 5.735780715942383 Accuracy 59.95974408741284\n",
      "Training:: Epoch 4, Iteration 100, Current loss 7.198534965515137 Accuracy 49.98315023252679\n",
      "Training:: Epoch 4, Iteration 110, Current loss 5.953262805938721 Accuracy 48.89082462253194\n",
      "Training:: Epoch 4, Iteration 120, Current loss 5.1580071449279785 Accuracy 47.13030472985605\n",
      "Training:: Epoch 4, Iteration 130, Current loss 6.838930606842041 Accuracy 37.08718064918144\n",
      "Training:: Epoch 4, Iteration 140, Current loss 6.20133638381958 Accuracy 38.865189192938644\n",
      "Training:: Epoch 4, Iteration 150, Current loss 6.425107479095459 Accuracy 43.06343989642466\n",
      "Training:: Epoch 4, Iteration 160, Current loss 8.105634689331055 Accuracy 29.419256240448295\n",
      "Training:: Epoch 4, Iteration 170, Current loss 5.667147159576416 Accuracy 39.253700229309985\n",
      "Training:: Epoch 4, Iteration 180, Current loss 6.21804666519165 Accuracy 35.977421271538915\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 4, Probability Accuracy 39.32911507611461\n",
      "Starting Training\n",
      "Training:: Epoch 5, Iteration 0, Current loss 5.736508369445801 Accuracy 46.78156048406084\n",
      "Training:: Epoch 5, Iteration 10, Current loss 6.434048175811768 Accuracy 46.69034231034823\n",
      "Training:: Epoch 5, Iteration 20, Current loss 8.38858413696289 Accuracy 30.464781983708672\n",
      "Training:: Epoch 5, Iteration 30, Current loss 4.911499977111816 Accuracy 44.61402034910856\n",
      "Training:: Epoch 5, Iteration 40, Current loss 7.06017541885376 Accuracy 37.41240178381822\n",
      "Training:: Epoch 5, Iteration 50, Current loss 6.890168190002441 Accuracy 36.406274027371985\n",
      "Training:: Epoch 5, Iteration 60, Current loss 6.579528331756592 Accuracy 36.218692022263454\n",
      "Training:: Epoch 5, Iteration 70, Current loss 6.826017379760742 Accuracy 39.14360123553994\n",
      "Training:: Epoch 5, Iteration 80, Current loss 5.948441505432129 Accuracy 45.39775500244021\n",
      "Training:: Epoch 5, Iteration 90, Current loss 4.849423885345459 Accuracy 58.692074491121694\n",
      "Training:: Epoch 5, Iteration 100, Current loss 4.380237579345703 Accuracy 51.56106519742883\n",
      "Training:: Epoch 5, Iteration 110, Current loss 7.106153964996338 Accuracy 44.9854121079504\n",
      "Training:: Epoch 5, Iteration 120, Current loss 5.825214385986328 Accuracy 49.743730550979315\n",
      "Training:: Epoch 5, Iteration 130, Current loss 6.883581638336182 Accuracy 48.821811100292116\n",
      "Training:: Epoch 5, Iteration 140, Current loss 5.400161266326904 Accuracy 53.085191082802545\n",
      "Training:: Epoch 5, Iteration 150, Current loss 6.627573013305664 Accuracy 46.529723000311236\n",
      "Training:: Epoch 5, Iteration 160, Current loss 7.693286895751953 Accuracy 49.71129118346354\n",
      "Training:: Epoch 5, Iteration 170, Current loss 8.731287002563477 Accuracy 36.54643449419569\n",
      "Training:: Epoch 5, Iteration 180, Current loss 6.002861499786377 Accuracy 46.98474732671118\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 5, Probability Accuracy 47.970408886039785\n",
      "Starting Training\n",
      "Training:: Epoch 6, Iteration 0, Current loss 5.294703483581543 Accuracy 57.692844190263635\n",
      "Training:: Epoch 6, Iteration 10, Current loss 4.806640148162842 Accuracy 50.94690368304868\n",
      "Training:: Epoch 6, Iteration 20, Current loss 5.740833759307861 Accuracy 55.08956252152945\n",
      "Training:: Epoch 6, Iteration 30, Current loss 5.209044456481934 Accuracy 53.59977974578993\n",
      "Training:: Epoch 6, Iteration 40, Current loss 4.819392681121826 Accuracy 57.80850744025252\n",
      "Training:: Epoch 6, Iteration 50, Current loss 4.44010591506958 Accuracy 56.23068532994001\n",
      "Training:: Epoch 6, Iteration 60, Current loss 4.805217742919922 Accuracy 54.3550858444977\n",
      "Training:: Epoch 6, Iteration 70, Current loss 5.706770420074463 Accuracy 46.615104640582345\n",
      "Training:: Epoch 6, Iteration 80, Current loss 4.7722039222717285 Accuracy 51.189754471051835\n",
      "Training:: Epoch 6, Iteration 90, Current loss 4.632791996002197 Accuracy 58.22831454049672\n",
      "Training:: Epoch 6, Iteration 100, Current loss 4.853725433349609 Accuracy 61.227449140615\n",
      "Training:: Epoch 6, Iteration 110, Current loss 5.689709663391113 Accuracy 47.174891496543964\n",
      "Training:: Epoch 6, Iteration 120, Current loss 7.592609405517578 Accuracy 42.0480636767182\n",
      "Training:: Epoch 6, Iteration 130, Current loss 6.888628959655762 Accuracy 46.2958240357029\n",
      "Training:: Epoch 6, Iteration 140, Current loss 5.60542631149292 Accuracy 51.69276659209545\n",
      "Training:: Epoch 6, Iteration 150, Current loss 5.12055778503418 Accuracy 53.8336820083682\n",
      "Training:: Epoch 6, Iteration 160, Current loss 7.336983680725098 Accuracy 47.772868402197275\n",
      "Training:: Epoch 6, Iteration 170, Current loss 4.282487392425537 Accuracy 56.5603071627168\n",
      "Training:: Epoch 6, Iteration 180, Current loss 7.9466872215271 Accuracy 37.7465000752672\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 6, Probability Accuracy 50.86957037881216\n",
      "Starting Training\n",
      "Training:: Epoch 7, Iteration 0, Current loss 4.785262107849121 Accuracy 58.14524043179588\n",
      "Training:: Epoch 7, Iteration 10, Current loss 6.679765224456787 Accuracy 53.1278439441301\n",
      "Training:: Epoch 7, Iteration 20, Current loss 7.954766750335693 Accuracy 35.99164926931106\n",
      "Training:: Epoch 7, Iteration 30, Current loss 8.001904487609863 Accuracy 38.08807258242974\n",
      "Training:: Epoch 7, Iteration 40, Current loss 4.351290225982666 Accuracy 56.26209565938623\n",
      "Training:: Epoch 7, Iteration 50, Current loss 5.635989665985107 Accuracy 48.00672560611813\n",
      "Training:: Epoch 7, Iteration 60, Current loss 5.707961082458496 Accuracy 47.85041974052404\n",
      "Training:: Epoch 7, Iteration 70, Current loss 4.345188617706299 Accuracy 56.864807995791686\n",
      "Training:: Epoch 7, Iteration 80, Current loss 5.778399467468262 Accuracy 38.9928214052643\n",
      "Training:: Epoch 7, Iteration 90, Current loss 4.600615501403809 Accuracy 53.70185092546273\n",
      "Training:: Epoch 7, Iteration 100, Current loss 5.496479511260986 Accuracy 37.63377926421405\n",
      "Training:: Epoch 7, Iteration 110, Current loss 5.981389999389648 Accuracy 61.4247162766626\n",
      "Training:: Epoch 7, Iteration 120, Current loss 6.241419792175293 Accuracy 47.73364830946405\n",
      "Training:: Epoch 7, Iteration 130, Current loss 5.9148054122924805 Accuracy 39.457364341085274\n",
      "Training:: Epoch 7, Iteration 140, Current loss 4.2879414558410645 Accuracy 48.79897238278741\n",
      "Training:: Epoch 7, Iteration 150, Current loss 6.140986442565918 Accuracy 48.72700347439768\n",
      "Training:: Epoch 7, Iteration 160, Current loss 4.327061653137207 Accuracy 58.42818964663961\n",
      "Training:: Epoch 7, Iteration 170, Current loss 5.332693576812744 Accuracy 49.20064444169042\n",
      "Training:: Epoch 7, Iteration 180, Current loss 4.857205867767334 Accuracy 60.644728005372734\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 7, Probability Accuracy 52.85167642089185\n",
      "Starting Training\n",
      "Training:: Epoch 8, Iteration 0, Current loss 4.066795349121094 Accuracy 66.91256406274266\n",
      "Training:: Epoch 8, Iteration 10, Current loss 5.302887439727783 Accuracy 61.44297484822203\n",
      "Training:: Epoch 8, Iteration 20, Current loss 5.176811695098877 Accuracy 47.863874936508836\n",
      "Training:: Epoch 8, Iteration 30, Current loss 5.593343734741211 Accuracy 58.23945856894786\n",
      "Training:: Epoch 8, Iteration 40, Current loss 6.712518215179443 Accuracy 52.8896307114542\n",
      "Training:: Epoch 8, Iteration 50, Current loss 3.807314395904541 Accuracy 55.19256946112579\n",
      "Training:: Epoch 8, Iteration 60, Current loss 5.177953243255615 Accuracy 57.77920111796902\n",
      "Training:: Epoch 8, Iteration 70, Current loss 5.394857883453369 Accuracy 53.516961438098\n",
      "Training:: Epoch 8, Iteration 80, Current loss 4.204295635223389 Accuracy 60.77821979114868\n",
      "Training:: Epoch 8, Iteration 90, Current loss 4.590915203094482 Accuracy 49.74242177756087\n",
      "Training:: Epoch 8, Iteration 100, Current loss 5.217844009399414 Accuracy 63.04278518140662\n",
      "Training:: Epoch 8, Iteration 110, Current loss 4.434950351715088 Accuracy 49.53703703703704\n",
      "Training:: Epoch 8, Iteration 120, Current loss 4.759374618530273 Accuracy 63.84487072560467\n",
      "Training:: Epoch 8, Iteration 130, Current loss 3.8639566898345947 Accuracy 66.98233215547704\n",
      "Training:: Epoch 8, Iteration 140, Current loss 6.450063705444336 Accuracy 56.80951591511936\n",
      "Training:: Epoch 8, Iteration 150, Current loss 4.373266220092773 Accuracy 55.32710280373832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 8, Iteration 160, Current loss 6.972684860229492 Accuracy 42.918454935622314\n",
      "Training:: Epoch 8, Iteration 170, Current loss 4.073175430297852 Accuracy 57.47234643445517\n",
      "Training:: Epoch 8, Iteration 180, Current loss 4.178826808929443 Accuracy 62.42781242781243\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 8, Probability Accuracy 52.49731907198341\n",
      "Starting Training\n",
      "Training:: Epoch 9, Iteration 0, Current loss 4.093345642089844 Accuracy 63.05899784482759\n",
      "Training:: Epoch 9, Iteration 10, Current loss 4.398512363433838 Accuracy 46.017310587054695\n",
      "Training:: Epoch 9, Iteration 20, Current loss 6.104284763336182 Accuracy 44.84669598216975\n",
      "Training:: Epoch 9, Iteration 30, Current loss 5.327619552612305 Accuracy 50.62379494159011\n",
      "Training:: Epoch 9, Iteration 40, Current loss 4.403750896453857 Accuracy 59.836029444175075\n",
      "Training:: Epoch 9, Iteration 50, Current loss 4.243187427520752 Accuracy 51.52275849002984\n",
      "Training:: Epoch 9, Iteration 60, Current loss 6.321523189544678 Accuracy 42.165845836673924\n",
      "Training:: Epoch 9, Iteration 70, Current loss 4.578480243682861 Accuracy 49.80939248925298\n",
      "Training:: Epoch 9, Iteration 80, Current loss 4.411430358886719 Accuracy 58.79269023367286\n",
      "Training:: Epoch 9, Iteration 90, Current loss 4.843227863311768 Accuracy 56.20771046420142\n",
      "Training:: Epoch 9, Iteration 100, Current loss 4.352052211761475 Accuracy 57.01969402417378\n",
      "Training:: Epoch 9, Iteration 110, Current loss 4.205118179321289 Accuracy 54.43869950048199\n",
      "Training:: Epoch 9, Iteration 120, Current loss 6.333481311798096 Accuracy 45.95990018070734\n",
      "Training:: Epoch 9, Iteration 130, Current loss 4.454916954040527 Accuracy 66.33860086868127\n",
      "Training:: Epoch 9, Iteration 140, Current loss 4.857440948486328 Accuracy 53.91891891891892\n",
      "Training:: Epoch 9, Iteration 150, Current loss 4.2559943199157715 Accuracy 58.82892524078887\n",
      "Training:: Epoch 9, Iteration 160, Current loss 5.3466715812683105 Accuracy 65.62144450006826\n",
      "Training:: Epoch 9, Iteration 170, Current loss 5.150215148925781 Accuracy 57.090202385739175\n",
      "Training:: Epoch 9, Iteration 180, Current loss 3.5042660236358643 Accuracy 56.76589428547869\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 9, Probability Accuracy 51.54425410844799\n",
      "Starting Training\n",
      "Training:: Epoch 10, Iteration 0, Current loss 3.512392997741699 Accuracy 62.27834962373497\n",
      "Training:: Epoch 10, Iteration 10, Current loss 4.475033760070801 Accuracy 56.358734357513484\n",
      "Training:: Epoch 10, Iteration 20, Current loss 4.765177249908447 Accuracy 57.09227705244523\n",
      "Training:: Epoch 10, Iteration 30, Current loss 4.138996601104736 Accuracy 65.20649162158597\n",
      "Training:: Epoch 10, Iteration 40, Current loss 4.440698623657227 Accuracy 56.617126680820945\n",
      "Training:: Epoch 10, Iteration 50, Current loss 5.705042362213135 Accuracy 53.38699466401375\n",
      "Training:: Epoch 10, Iteration 60, Current loss 4.234425067901611 Accuracy 51.53349200952057\n",
      "Training:: Epoch 10, Iteration 70, Current loss 5.071746826171875 Accuracy 58.3968414287026\n",
      "Training:: Epoch 10, Iteration 80, Current loss 3.976550817489624 Accuracy 63.408723747980616\n",
      "Training:: Epoch 10, Iteration 90, Current loss 3.9931399822235107 Accuracy 61.748768472906406\n",
      "Training:: Epoch 10, Iteration 100, Current loss 4.241828441619873 Accuracy 62.10532380732888\n",
      "Training:: Epoch 10, Iteration 110, Current loss 4.420448303222656 Accuracy 52.415278037820634\n",
      "Training:: Epoch 10, Iteration 120, Current loss 5.266472339630127 Accuracy 43.73564418458969\n",
      "Training:: Epoch 10, Iteration 130, Current loss 5.365874767303467 Accuracy 48.14423302795396\n",
      "Training:: Epoch 10, Iteration 140, Current loss 4.458070278167725 Accuracy 60.607557421585575\n",
      "Training:: Epoch 10, Iteration 150, Current loss 9.805367469787598 Accuracy 47.16928833760654\n",
      "Training:: Epoch 10, Iteration 160, Current loss 6.008347034454346 Accuracy 60.418216996576874\n",
      "Training:: Epoch 10, Iteration 170, Current loss 4.576562881469727 Accuracy 59.927717542396444\n",
      "Training:: Epoch 10, Iteration 180, Current loss 4.372973918914795 Accuracy 51.85538339292809\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 10, Probability Accuracy 49.842507844929585\n",
      "Starting Training\n",
      "Training:: Epoch 11, Iteration 0, Current loss 6.084003925323486 Accuracy 33.043570444185306\n",
      "Training:: Epoch 11, Iteration 10, Current loss 4.869857311248779 Accuracy 65.88006986221619\n",
      "Training:: Epoch 11, Iteration 20, Current loss 3.8713855743408203 Accuracy 63.10639009702241\n",
      "Training:: Epoch 11, Iteration 30, Current loss 6.424138069152832 Accuracy 47.330847096430475\n",
      "Training:: Epoch 11, Iteration 40, Current loss 5.090153217315674 Accuracy 45.415318230852215\n",
      "Training:: Epoch 11, Iteration 50, Current loss 3.344667434692383 Accuracy 64.01113367938012\n",
      "Training:: Epoch 11, Iteration 60, Current loss 4.728908538818359 Accuracy 47.529967308390844\n",
      "Training:: Epoch 11, Iteration 70, Current loss 3.74129319190979 Accuracy 53.66507021673837\n",
      "Training:: Epoch 11, Iteration 80, Current loss 4.19304084777832 Accuracy 59.71244570915081\n",
      "Training:: Epoch 11, Iteration 90, Current loss 4.449217796325684 Accuracy 58.779744461376154\n",
      "Training:: Epoch 11, Iteration 100, Current loss 5.116759777069092 Accuracy 50.57813803790678\n",
      "Training:: Epoch 11, Iteration 110, Current loss 5.3553667068481445 Accuracy 54.592043840064946\n",
      "Training:: Epoch 11, Iteration 120, Current loss 5.463425636291504 Accuracy 41.42984807864165\n",
      "Training:: Epoch 11, Iteration 130, Current loss 4.133596420288086 Accuracy 56.49013499480789\n",
      "Training:: Epoch 11, Iteration 140, Current loss 3.91719388961792 Accuracy 59.40838126540674\n",
      "Training:: Epoch 11, Iteration 150, Current loss 5.066384315490723 Accuracy 51.61265038993612\n",
      "Training:: Epoch 11, Iteration 160, Current loss 3.957106828689575 Accuracy 65.54174067495559\n",
      "Training:: Epoch 11, Iteration 170, Current loss 3.7472753524780273 Accuracy 68.09670386045916\n",
      "Training:: Epoch 11, Iteration 180, Current loss 4.840999126434326 Accuracy 57.45250341135719\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 11, Probability Accuracy 50.65865751787615\n",
      "Starting Training\n",
      "Training:: Epoch 12, Iteration 0, Current loss 4.229650020599365 Accuracy 62.938307408383864\n",
      "Training:: Epoch 12, Iteration 10, Current loss 4.483161926269531 Accuracy 60.69236727641066\n",
      "Training:: Epoch 12, Iteration 20, Current loss 3.4931013584136963 Accuracy 62.14775323686215\n",
      "Training:: Epoch 12, Iteration 30, Current loss 3.200742721557617 Accuracy 58.43660629170639\n",
      "Training:: Epoch 12, Iteration 40, Current loss 3.780169725418091 Accuracy 60.6088120042053\n",
      "Training:: Epoch 12, Iteration 50, Current loss 3.4317398071289062 Accuracy 60.51058743169399\n",
      "Training:: Epoch 12, Iteration 60, Current loss 4.281891345977783 Accuracy 55.852903695612596\n",
      "Training:: Epoch 12, Iteration 70, Current loss 4.6878180503845215 Accuracy 54.1272715080802\n",
      "Training:: Epoch 12, Iteration 80, Current loss 3.9621074199676514 Accuracy 57.86100386100386\n",
      "Training:: Epoch 12, Iteration 90, Current loss 4.166508674621582 Accuracy 57.69280040994107\n",
      "Training:: Epoch 12, Iteration 100, Current loss 3.603600025177002 Accuracy 59.58146487294469\n",
      "Training:: Epoch 12, Iteration 110, Current loss 5.101809978485107 Accuracy 64.81015110422317\n",
      "Training:: Epoch 12, Iteration 120, Current loss 4.936676502227783 Accuracy 49.26399881648051\n",
      "Training:: Epoch 12, Iteration 130, Current loss 4.864074230194092 Accuracy 58.3248639923477\n",
      "Training:: Epoch 12, Iteration 140, Current loss 6.016780376434326 Accuracy 43.48884830372461\n",
      "Training:: Epoch 12, Iteration 150, Current loss 5.153026580810547 Accuracy 49.19499105545617\n",
      "Training:: Epoch 12, Iteration 160, Current loss 8.359719276428223 Accuracy 51.45637915226744\n",
      "Training:: Epoch 12, Iteration 170, Current loss 5.43373966217041 Accuracy 58.34383665238215\n",
      "Training:: Epoch 12, Iteration 180, Current loss 5.216806411743164 Accuracy 68.24122714856063\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 12, Probability Accuracy 46.23443379987417\n",
      "Starting Training\n",
      "Training:: Epoch 13, Iteration 0, Current loss 5.106693744659424 Accuracy 56.23821495914519\n",
      "Training:: Epoch 13, Iteration 10, Current loss 5.126430034637451 Accuracy 48.29426923548902\n",
      "Training:: Epoch 13, Iteration 20, Current loss 5.142145156860352 Accuracy 57.354318905752294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 13, Iteration 30, Current loss 4.7474822998046875 Accuracy 50.601334210279056\n",
      "Training:: Epoch 13, Iteration 40, Current loss 4.587673187255859 Accuracy 59.638789202683725\n",
      "Training:: Epoch 13, Iteration 50, Current loss 4.754223346710205 Accuracy 56.66896661536012\n",
      "Training:: Epoch 13, Iteration 60, Current loss 5.033309459686279 Accuracy 59.74377668992813\n",
      "Training:: Epoch 13, Iteration 70, Current loss 6.212155818939209 Accuracy 61.55022947475778\n",
      "Training:: Epoch 13, Iteration 80, Current loss 3.698018789291382 Accuracy 59.987581496429684\n",
      "Training:: Epoch 13, Iteration 90, Current loss 4.479087829589844 Accuracy 49.542048293089096\n",
      "Training:: Epoch 13, Iteration 100, Current loss 3.343437671661377 Accuracy 55.682739972960796\n",
      "Training:: Epoch 13, Iteration 110, Current loss 4.523863792419434 Accuracy 52.52379231417901\n",
      "Training:: Epoch 13, Iteration 120, Current loss 4.510784149169922 Accuracy 53.45132743362832\n",
      "Training:: Epoch 13, Iteration 130, Current loss 4.221951484680176 Accuracy 61.23840445269017\n",
      "Training:: Epoch 13, Iteration 140, Current loss 3.0476183891296387 Accuracy 67.56255044390637\n",
      "Training:: Epoch 13, Iteration 150, Current loss 3.8348989486694336 Accuracy 57.97440877413458\n",
      "Training:: Epoch 13, Iteration 160, Current loss 4.141390323638916 Accuracy 60.20388628314348\n",
      "Training:: Epoch 13, Iteration 170, Current loss 3.340878486633301 Accuracy 68.4064058808086\n",
      "Training:: Epoch 13, Iteration 180, Current loss 3.2548112869262695 Accuracy 65.45027742210841\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 13, Probability Accuracy 52.78124023093573\n",
      "Starting Training\n",
      "Training:: Epoch 14, Iteration 0, Current loss 4.724324703216553 Accuracy 52.3503345208098\n",
      "Training:: Epoch 14, Iteration 10, Current loss 5.18236780166626 Accuracy 58.28138913624221\n",
      "Training:: Epoch 14, Iteration 20, Current loss 3.8722686767578125 Accuracy 54.16420555227407\n",
      "Training:: Epoch 14, Iteration 30, Current loss 3.181663751602173 Accuracy 58.2701169797944\n",
      "Training:: Epoch 14, Iteration 40, Current loss 4.969000339508057 Accuracy 59.13730317484741\n",
      "Training:: Epoch 14, Iteration 50, Current loss 3.120028018951416 Accuracy 57.60576552786488\n",
      "Training:: Epoch 14, Iteration 60, Current loss 3.82965087890625 Accuracy 55.09375714612394\n",
      "Training:: Epoch 14, Iteration 70, Current loss 3.6907973289489746 Accuracy 61.223305898988436\n",
      "Training:: Epoch 14, Iteration 80, Current loss 3.732347249984741 Accuracy 67.79716517752725\n",
      "Training:: Epoch 14, Iteration 90, Current loss 3.8926491737365723 Accuracy 70.70646044788143\n",
      "Training:: Epoch 14, Iteration 100, Current loss 3.53521466255188 Accuracy 68.85935499603731\n",
      "Training:: Epoch 14, Iteration 110, Current loss 3.315471887588501 Accuracy 64.61840868301854\n",
      "Training:: Epoch 14, Iteration 120, Current loss 3.4018170833587646 Accuracy 71.59022871512394\n",
      "Training:: Epoch 14, Iteration 130, Current loss 4.599616050720215 Accuracy 45.79858883899936\n",
      "Training:: Epoch 14, Iteration 140, Current loss 3.550255537033081 Accuracy 65.5049786628734\n",
      "Training:: Epoch 14, Iteration 150, Current loss 5.16988468170166 Accuracy 48.95637898686679\n",
      "Training:: Epoch 14, Iteration 160, Current loss 3.839526891708374 Accuracy 52.96518407462935\n",
      "Training:: Epoch 14, Iteration 170, Current loss 3.7662816047668457 Accuracy 59.587829471077306\n",
      "Training:: Epoch 14, Iteration 180, Current loss 4.113674640655518 Accuracy 61.54294423525193\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 14, Probability Accuracy 50.622450150567246\n",
      "Starting Training\n",
      "Training:: Epoch 15, Iteration 0, Current loss 2.917141914367676 Accuracy 79.32450331125828\n",
      "Training:: Epoch 15, Iteration 10, Current loss 3.3121025562286377 Accuracy 65.13368457334187\n",
      "Training:: Epoch 15, Iteration 20, Current loss 4.368523597717285 Accuracy 61.04159621237741\n",
      "Training:: Epoch 15, Iteration 30, Current loss 5.05447244644165 Accuracy 49.156785243741766\n",
      "Training:: Epoch 15, Iteration 40, Current loss 4.95966911315918 Accuracy 60.393021009418014\n",
      "Training:: Epoch 15, Iteration 50, Current loss 3.481375217437744 Accuracy 62.35277556191638\n",
      "Training:: Epoch 15, Iteration 60, Current loss 6.09650182723999 Accuracy 43.24681038275407\n",
      "Training:: Epoch 15, Iteration 70, Current loss 4.393886089324951 Accuracy 59.437970381160476\n",
      "Training:: Epoch 15, Iteration 80, Current loss 4.200260639190674 Accuracy 52.64202103035514\n",
      "Training:: Epoch 15, Iteration 90, Current loss 3.1650190353393555 Accuracy 67.8063943161634\n",
      "Training:: Epoch 15, Iteration 100, Current loss 4.684140205383301 Accuracy 60.146752032227894\n",
      "Training:: Epoch 15, Iteration 110, Current loss 3.7380332946777344 Accuracy 63.49480968858131\n",
      "Training:: Epoch 15, Iteration 120, Current loss 2.986267566680908 Accuracy 63.37057728119181\n",
      "Training:: Epoch 15, Iteration 130, Current loss 3.032944440841675 Accuracy 67.12336041633476\n",
      "Training:: Epoch 15, Iteration 140, Current loss 4.734501361846924 Accuracy 51.93159832740436\n",
      "Training:: Epoch 15, Iteration 150, Current loss 3.723109722137451 Accuracy 57.77253301014225\n",
      "Training:: Epoch 15, Iteration 160, Current loss 3.3562510013580322 Accuracy 70.21072285942918\n",
      "Training:: Epoch 15, Iteration 170, Current loss 4.575322151184082 Accuracy 47.235567757187525\n",
      "Training:: Epoch 15, Iteration 180, Current loss 4.577511787414551 Accuracy 57.70660849734768\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 15, Probability Accuracy 53.38014570002888\n",
      "Starting Training\n",
      "Training:: Epoch 16, Iteration 0, Current loss 4.433940410614014 Accuracy 61.858361992102914\n",
      "Training:: Epoch 16, Iteration 10, Current loss 4.321213722229004 Accuracy 62.044066896734805\n",
      "Training:: Epoch 16, Iteration 20, Current loss 3.110767364501953 Accuracy 58.17204301075269\n",
      "Training:: Epoch 16, Iteration 30, Current loss 4.032776832580566 Accuracy 49.6121073381661\n",
      "Training:: Epoch 16, Iteration 40, Current loss 3.432386875152588 Accuracy 63.47826086956522\n",
      "Training:: Epoch 16, Iteration 50, Current loss 3.1753969192504883 Accuracy 58.09313924491098\n",
      "Training:: Epoch 16, Iteration 60, Current loss 3.5478434562683105 Accuracy 69.05868500960526\n",
      "Training:: Epoch 16, Iteration 70, Current loss 3.5099024772644043 Accuracy 62.41969297355786\n",
      "Training:: Epoch 16, Iteration 80, Current loss 3.905994415283203 Accuracy 65.08168146256435\n",
      "Training:: Epoch 16, Iteration 90, Current loss 3.8757760524749756 Accuracy 62.62390959555908\n",
      "Training:: Epoch 16, Iteration 100, Current loss 3.5739753246307373 Accuracy 59.94431050290333\n",
      "Training:: Epoch 16, Iteration 110, Current loss 3.4339537620544434 Accuracy 52.72706526700137\n",
      "Training:: Epoch 16, Iteration 120, Current loss 3.8294315338134766 Accuracy 68.21868428957644\n",
      "Training:: Epoch 16, Iteration 130, Current loss 4.305138111114502 Accuracy 49.96498822331148\n",
      "Training:: Epoch 16, Iteration 140, Current loss 3.4011778831481934 Accuracy 60.44409288660376\n",
      "Training:: Epoch 16, Iteration 150, Current loss 3.129225969314575 Accuracy 62.824881405759335\n",
      "Training:: Epoch 16, Iteration 160, Current loss 3.9164860248565674 Accuracy 65.0033645633832\n",
      "Training:: Epoch 16, Iteration 170, Current loss 2.8727290630340576 Accuracy 60.5191150027363\n",
      "Training:: Epoch 16, Iteration 180, Current loss 3.442199230194092 Accuracy 63.12394840157039\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 16, Probability Accuracy 56.150108226392994\n",
      "Starting Training\n",
      "Training:: Epoch 17, Iteration 0, Current loss 4.017168998718262 Accuracy 52.65546981389015\n",
      "Training:: Epoch 17, Iteration 10, Current loss 3.8390326499938965 Accuracy 47.64775066157013\n",
      "Training:: Epoch 17, Iteration 20, Current loss 3.935004472732544 Accuracy 67.72185376571592\n",
      "Training:: Epoch 17, Iteration 30, Current loss 4.06200647354126 Accuracy 65.53362867498993\n",
      "Training:: Epoch 17, Iteration 40, Current loss 3.388744354248047 Accuracy 64.21214881244308\n",
      "Training:: Epoch 17, Iteration 50, Current loss 3.5017752647399902 Accuracy 64.09427759514125\n",
      "Training:: Epoch 17, Iteration 60, Current loss 3.532221794128418 Accuracy 63.970102201657596\n",
      "Training:: Epoch 17, Iteration 70, Current loss 3.227508783340454 Accuracy 60.55505685218432\n",
      "Training:: Epoch 17, Iteration 80, Current loss 4.3454909324646 Accuracy 58.079239302694134\n",
      "Training:: Epoch 17, Iteration 90, Current loss 3.3854358196258545 Accuracy 72.03289551532363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 17, Iteration 100, Current loss 2.8797171115875244 Accuracy 61.37837837837838\n",
      "Training:: Epoch 17, Iteration 110, Current loss 4.895187854766846 Accuracy 43.425685693106004\n",
      "Training:: Epoch 17, Iteration 120, Current loss 4.8804521560668945 Accuracy 57.7720207253886\n",
      "Training:: Epoch 17, Iteration 130, Current loss 3.918246269226074 Accuracy 56.966796290756804\n",
      "Training:: Epoch 17, Iteration 140, Current loss 4.754707336425781 Accuracy 55.18890483022477\n",
      "Training:: Epoch 17, Iteration 150, Current loss 4.968391418457031 Accuracy 40.69064748201439\n",
      "Training:: Epoch 17, Iteration 160, Current loss 3.634014844894409 Accuracy 55.674661664210106\n",
      "Training:: Epoch 17, Iteration 170, Current loss 3.405290365219116 Accuracy 61.87323770994238\n",
      "Training:: Epoch 17, Iteration 180, Current loss 3.090705156326294 Accuracy 75.89579610646102\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 17, Probability Accuracy 56.31511885117783\n",
      "Starting Training\n",
      "Training:: Epoch 18, Iteration 0, Current loss 3.456955671310425 Accuracy 72.83123630991798\n",
      "Training:: Epoch 18, Iteration 10, Current loss 2.430105686187744 Accuracy 63.813738308357635\n",
      "Training:: Epoch 18, Iteration 20, Current loss 3.9245622158050537 Accuracy 51.540022132054595\n",
      "Training:: Epoch 18, Iteration 30, Current loss 3.369523763656616 Accuracy 66.81209568226268\n",
      "Training:: Epoch 18, Iteration 40, Current loss 3.0383522510528564 Accuracy 53.12220089571337\n",
      "Training:: Epoch 18, Iteration 50, Current loss 3.7261059284210205 Accuracy 60.84646305964977\n",
      "Training:: Epoch 18, Iteration 60, Current loss 2.9734573364257812 Accuracy 67.63141620284478\n",
      "Training:: Epoch 18, Iteration 70, Current loss 4.435912132263184 Accuracy 47.74307255458729\n",
      "Training:: Epoch 18, Iteration 80, Current loss 2.9726240634918213 Accuracy 53.96440129449838\n",
      "Training:: Epoch 18, Iteration 90, Current loss 3.520742416381836 Accuracy 66.9914466344366\n",
      "Training:: Epoch 18, Iteration 100, Current loss 4.120977401733398 Accuracy 54.98102066638549\n",
      "Training:: Epoch 18, Iteration 110, Current loss 4.0298380851745605 Accuracy 61.24003225517427\n",
      "Training:: Epoch 18, Iteration 120, Current loss 3.2078652381896973 Accuracy 67.2609819121447\n",
      "Training:: Epoch 18, Iteration 130, Current loss 3.8534936904907227 Accuracy 61.282275165273795\n",
      "Training:: Epoch 18, Iteration 140, Current loss 3.6104085445404053 Accuracy 66.02844471631748\n",
      "Training:: Epoch 18, Iteration 150, Current loss 3.533773183822632 Accuracy 67.40605427974948\n",
      "Training:: Epoch 18, Iteration 160, Current loss 4.599464416503906 Accuracy 52.39996805366984\n",
      "Training:: Epoch 18, Iteration 170, Current loss 3.4959256649017334 Accuracy 60.91816196308509\n",
      "Training:: Epoch 18, Iteration 180, Current loss 2.4901161193847656 Accuracy 70.44908741594621\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 18, Probability Accuracy 53.18980970357444\n",
      "Starting Training\n",
      "Training:: Epoch 19, Iteration 0, Current loss 3.4550278186798096 Accuracy 57.056237683795665\n",
      "Training:: Epoch 19, Iteration 10, Current loss 2.9889156818389893 Accuracy 53.76409170008323\n",
      "Training:: Epoch 19, Iteration 20, Current loss 2.8343727588653564 Accuracy 67.10752986940817\n",
      "Training:: Epoch 19, Iteration 30, Current loss 3.960692882537842 Accuracy 57.02014443177499\n",
      "Training:: Epoch 19, Iteration 40, Current loss 3.291443109512329 Accuracy 65.89198036006546\n",
      "Training:: Epoch 19, Iteration 50, Current loss 3.946521043777466 Accuracy 63.326833658317085\n",
      "Training:: Epoch 19, Iteration 60, Current loss 3.27112078666687 Accuracy 65.21791621393216\n",
      "Training:: Epoch 19, Iteration 70, Current loss 2.9413135051727295 Accuracy 67.02027345591702\n",
      "Training:: Epoch 19, Iteration 80, Current loss 3.231931209564209 Accuracy 64.86187845303867\n",
      "Training:: Epoch 19, Iteration 90, Current loss 2.5849990844726562 Accuracy 60.617543140969836\n",
      "Training:: Epoch 19, Iteration 100, Current loss 3.1799981594085693 Accuracy 58.999545247839926\n",
      "Training:: Epoch 19, Iteration 110, Current loss 3.536642551422119 Accuracy 54.678497349619725\n",
      "Training:: Epoch 19, Iteration 120, Current loss 3.4194252490997314 Accuracy 61.95644361388629\n",
      "Training:: Epoch 19, Iteration 130, Current loss 3.0408568382263184 Accuracy 65.43719162015692\n",
      "Training:: Epoch 19, Iteration 140, Current loss 3.9281539916992188 Accuracy 53.53665891272508\n",
      "Training:: Epoch 19, Iteration 150, Current loss 3.814188241958618 Accuracy 65.29939046253138\n",
      "Training:: Epoch 19, Iteration 160, Current loss 4.018786430358887 Accuracy 64.79253835425384\n",
      "Training:: Epoch 19, Iteration 170, Current loss 4.251917839050293 Accuracy 59.12421647391189\n",
      "Training:: Epoch 19, Iteration 180, Current loss 5.211259365081787 Accuracy 42.861637693699365\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 19, Probability Accuracy 43.72544131438679\n",
      "Starting Training\n",
      "Training:: Epoch 20, Iteration 0, Current loss 4.776368618011475 Accuracy 58.09025058731402\n",
      "Training:: Epoch 20, Iteration 10, Current loss 4.059690952301025 Accuracy 51.590647757761595\n",
      "Training:: Epoch 20, Iteration 20, Current loss 3.7701480388641357 Accuracy 63.178767541183646\n",
      "Training:: Epoch 20, Iteration 30, Current loss 3.3370511531829834 Accuracy 66.99854690275012\n",
      "Training:: Epoch 20, Iteration 40, Current loss 3.53816556930542 Accuracy 56.86329326251048\n",
      "Training:: Epoch 20, Iteration 50, Current loss 3.3767011165618896 Accuracy 52.973677675689096\n",
      "Training:: Epoch 20, Iteration 60, Current loss 3.4698429107666016 Accuracy 59.036913019213905\n",
      "Training:: Epoch 20, Iteration 70, Current loss 6.485641956329346 Accuracy 45.280496283223705\n",
      "Training:: Epoch 20, Iteration 80, Current loss 3.5212957859039307 Accuracy 44.95125705489995\n",
      "Training:: Epoch 20, Iteration 90, Current loss 3.1534597873687744 Accuracy 74.24718729318332\n",
      "Training:: Epoch 20, Iteration 100, Current loss 3.360325574874878 Accuracy 51.760092683361556\n",
      "Training:: Epoch 20, Iteration 110, Current loss 3.360772132873535 Accuracy 57.15901649104007\n",
      "Training:: Epoch 20, Iteration 120, Current loss 4.802685260772705 Accuracy 49.845699135045855\n",
      "Training:: Epoch 20, Iteration 130, Current loss 4.131679534912109 Accuracy 46.807207837648704\n",
      "Training:: Epoch 20, Iteration 140, Current loss 3.9808521270751953 Accuracy 54.24941850062623\n",
      "Training:: Epoch 20, Iteration 150, Current loss 3.2701430320739746 Accuracy 65.0545008301451\n",
      "Training:: Epoch 20, Iteration 160, Current loss 3.7313544750213623 Accuracy 59.60186922765574\n",
      "Training:: Epoch 20, Iteration 170, Current loss 4.5475544929504395 Accuracy 62.499059655457756\n",
      "Training:: Epoch 20, Iteration 180, Current loss 3.196760654449463 Accuracy 65.78059321532177\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 20, Probability Accuracy 55.99103323559323\n",
      "Starting Training\n",
      "Training:: Epoch 21, Iteration 0, Current loss 3.639155149459839 Accuracy 64.51909802116889\n",
      "Training:: Epoch 21, Iteration 10, Current loss 3.8491051197052 Accuracy 61.71644745524128\n",
      "Training:: Epoch 21, Iteration 20, Current loss 3.4329047203063965 Accuracy 57.88440138770701\n",
      "Training:: Epoch 21, Iteration 30, Current loss 4.011196136474609 Accuracy 58.712269151369746\n",
      "Training:: Epoch 21, Iteration 40, Current loss 2.3832294940948486 Accuracy 69.46257197696737\n",
      "Training:: Epoch 21, Iteration 50, Current loss 3.5501599311828613 Accuracy 58.0945558739255\n",
      "Training:: Epoch 21, Iteration 60, Current loss 3.7330234050750732 Accuracy 55.78604840349807\n",
      "Training:: Epoch 21, Iteration 70, Current loss 3.873607873916626 Accuracy 52.37873754152824\n",
      "Training:: Epoch 21, Iteration 80, Current loss 3.536027431488037 Accuracy 57.822337442463365\n",
      "Training:: Epoch 21, Iteration 90, Current loss 3.2231528759002686 Accuracy 62.07717273710782\n",
      "Training:: Epoch 21, Iteration 100, Current loss 3.543551206588745 Accuracy 55.4981688421448\n",
      "Training:: Epoch 21, Iteration 110, Current loss 2.3073573112487793 Accuracy 70.78486334968466\n",
      "Training:: Epoch 21, Iteration 120, Current loss 3.070580244064331 Accuracy 62.04138840794789\n",
      "Training:: Epoch 21, Iteration 130, Current loss 3.0798423290252686 Accuracy 69.79493241506913\n",
      "Training:: Epoch 21, Iteration 140, Current loss 3.4623594284057617 Accuracy 69.0937019969278\n",
      "Training:: Epoch 21, Iteration 150, Current loss 3.6807591915130615 Accuracy 72.30815168707076\n",
      "Training:: Epoch 21, Iteration 160, Current loss 3.9438297748565674 Accuracy 51.90195149269806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 21, Iteration 170, Current loss 4.166781902313232 Accuracy 53.40278305832256\n",
      "Training:: Epoch 21, Iteration 180, Current loss 3.330216407775879 Accuracy 65.11240212174792\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 21, Probability Accuracy 56.56085409815956\n",
      "Starting Training\n",
      "Training:: Epoch 22, Iteration 0, Current loss 2.2356889247894287 Accuracy 60.93329022523979\n",
      "Training:: Epoch 22, Iteration 10, Current loss 2.526156187057495 Accuracy 72.52747252747253\n",
      "Training:: Epoch 22, Iteration 20, Current loss 3.048110008239746 Accuracy 60.25134649910233\n",
      "Training:: Epoch 22, Iteration 30, Current loss 3.304725408554077 Accuracy 60.58989847063359\n",
      "Training:: Epoch 22, Iteration 40, Current loss 2.9977450370788574 Accuracy 65.21101515398404\n",
      "Training:: Epoch 22, Iteration 50, Current loss 2.8187077045440674 Accuracy 48.74983806192512\n",
      "Training:: Epoch 22, Iteration 60, Current loss 2.9589359760284424 Accuracy 60.97927543110267\n",
      "Training:: Epoch 22, Iteration 70, Current loss 3.698120594024658 Accuracy 65.54043877704704\n",
      "Training:: Epoch 22, Iteration 80, Current loss 2.956146240234375 Accuracy 62.347248421225295\n",
      "Training:: Epoch 22, Iteration 90, Current loss 3.493051290512085 Accuracy 68.2262115152079\n",
      "Training:: Epoch 22, Iteration 100, Current loss 3.409060001373291 Accuracy 59.515382521099916\n",
      "Training:: Epoch 22, Iteration 110, Current loss 3.035231351852417 Accuracy 71.29484113426717\n",
      "Training:: Epoch 22, Iteration 120, Current loss 4.253437519073486 Accuracy 54.225563909774436\n",
      "Training:: Epoch 22, Iteration 130, Current loss 3.2738654613494873 Accuracy 61.34792917318266\n",
      "Training:: Epoch 22, Iteration 140, Current loss 3.3148293495178223 Accuracy 46.847400353275475\n",
      "Training:: Epoch 22, Iteration 150, Current loss 2.7479231357574463 Accuracy 60.666179388117364\n",
      "Training:: Epoch 22, Iteration 160, Current loss 3.2010891437530518 Accuracy 59.38724984526511\n",
      "Training:: Epoch 22, Iteration 170, Current loss 2.5965077877044678 Accuracy 70.02063015753939\n",
      "Training:: Epoch 22, Iteration 180, Current loss 2.8464536666870117 Accuracy 67.70491803278688\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 22, Probability Accuracy 54.93429253178532\n",
      "Starting Training\n",
      "Training:: Epoch 23, Iteration 0, Current loss 2.8863441944122314 Accuracy 64.74142097631706\n",
      "Training:: Epoch 23, Iteration 10, Current loss 3.13955020904541 Accuracy 57.76271186440678\n",
      "Training:: Epoch 23, Iteration 20, Current loss 2.845850944519043 Accuracy 60.33130267879496\n",
      "Training:: Epoch 23, Iteration 30, Current loss 2.2658071517944336 Accuracy 70.91988130563799\n",
      "Training:: Epoch 23, Iteration 40, Current loss 2.7161948680877686 Accuracy 67.96812749003983\n",
      "Training:: Epoch 23, Iteration 50, Current loss 2.614499568939209 Accuracy 64.69380304827963\n",
      "Training:: Epoch 23, Iteration 60, Current loss 3.1052968502044678 Accuracy 74.76693119654827\n",
      "Training:: Epoch 23, Iteration 70, Current loss 2.5110597610473633 Accuracy 73.8566262497341\n",
      "Training:: Epoch 23, Iteration 80, Current loss 1.8359748125076294 Accuracy 66.73534798534799\n",
      "Training:: Epoch 23, Iteration 90, Current loss 2.6401400566101074 Accuracy 67.2981663335361\n",
      "Training:: Epoch 23, Iteration 100, Current loss 2.8058485984802246 Accuracy 64.05533476001223\n",
      "Training:: Epoch 23, Iteration 110, Current loss 2.835466146469116 Accuracy 53.592100783112016\n",
      "Training:: Epoch 23, Iteration 120, Current loss 3.425004005432129 Accuracy 56.05343133790374\n",
      "Training:: Epoch 23, Iteration 130, Current loss 3.1848230361938477 Accuracy 72.05403163694531\n",
      "Training:: Epoch 23, Iteration 140, Current loss 2.660637378692627 Accuracy 69.03407044586905\n",
      "Training:: Epoch 23, Iteration 150, Current loss 2.5891199111938477 Accuracy 63.862834089762984\n",
      "Training:: Epoch 23, Iteration 160, Current loss 4.0574846267700195 Accuracy 58.02593133674215\n",
      "Training:: Epoch 23, Iteration 170, Current loss 2.6569714546203613 Accuracy 67.36143455985095\n",
      "Training:: Epoch 23, Iteration 180, Current loss 2.551953077316284 Accuracy 66.16980933319287\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 23, Probability Accuracy 55.5177653525173\n",
      "Starting Training\n",
      "Training:: Epoch 24, Iteration 0, Current loss 2.833557367324829 Accuracy 66.41389847773188\n",
      "Training:: Epoch 24, Iteration 10, Current loss 2.3537707328796387 Accuracy 66.74511854951186\n",
      "Training:: Epoch 24, Iteration 20, Current loss 3.0935561656951904 Accuracy 56.69249868331954\n",
      "Training:: Epoch 24, Iteration 30, Current loss 3.2339353561401367 Accuracy 59.48242059861456\n",
      "Training:: Epoch 24, Iteration 40, Current loss 2.831336259841919 Accuracy 63.58244961551993\n",
      "Training:: Epoch 24, Iteration 50, Current loss 2.6795108318328857 Accuracy 53.43849367167529\n",
      "Training:: Epoch 24, Iteration 60, Current loss 2.5774855613708496 Accuracy 61.068215174526195\n",
      "Training:: Epoch 24, Iteration 70, Current loss 3.4501731395721436 Accuracy 60.9882005899705\n",
      "Training:: Epoch 24, Iteration 80, Current loss 2.1503963470458984 Accuracy 67.79612209637166\n",
      "Training:: Epoch 24, Iteration 90, Current loss 2.9636197090148926 Accuracy 58.58592558201234\n",
      "Training:: Epoch 24, Iteration 100, Current loss 2.6685802936553955 Accuracy 70.38018185723492\n",
      "Training:: Epoch 24, Iteration 110, Current loss 2.9065308570861816 Accuracy 73.9691532892666\n",
      "Training:: Epoch 24, Iteration 120, Current loss 2.9426331520080566 Accuracy 61.68544830965213\n",
      "Training:: Epoch 24, Iteration 130, Current loss 1.9990390539169312 Accuracy 67.94512317244141\n",
      "Training:: Epoch 24, Iteration 140, Current loss 3.1144607067108154 Accuracy 55.32598714416896\n",
      "Training:: Epoch 24, Iteration 150, Current loss 3.8344566822052 Accuracy 56.39619752910599\n",
      "Training:: Epoch 24, Iteration 160, Current loss 3.5966501235961914 Accuracy 63.176648606433346\n",
      "Training:: Epoch 24, Iteration 170, Current loss 3.121424436569214 Accuracy 69.63110667996013\n",
      "Training:: Epoch 24, Iteration 180, Current loss 2.530245065689087 Accuracy 58.576005695977216\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 24, Probability Accuracy 53.19040326697294\n",
      "Starting Training\n",
      "Training:: Epoch 25, Iteration 0, Current loss 3.040536880493164 Accuracy 61.66262225163615\n",
      "Training:: Epoch 25, Iteration 10, Current loss 3.6884894371032715 Accuracy 47.66842984409799\n",
      "Training:: Epoch 25, Iteration 20, Current loss 3.5065603256225586 Accuracy 67.66630055871258\n",
      "Training:: Epoch 25, Iteration 30, Current loss 2.7898757457733154 Accuracy 61.40785284754156\n",
      "Training:: Epoch 25, Iteration 40, Current loss 3.011701822280884 Accuracy 61.42636854279105\n",
      "Training:: Epoch 25, Iteration 50, Current loss 3.6092565059661865 Accuracy 57.37748579545455\n",
      "Training:: Epoch 25, Iteration 60, Current loss 2.9601545333862305 Accuracy 66.32151724866607\n",
      "Training:: Epoch 25, Iteration 70, Current loss 2.2172327041625977 Accuracy 58.67657685557964\n",
      "Training:: Epoch 25, Iteration 80, Current loss 2.8995156288146973 Accuracy 66.28069384996621\n",
      "Training:: Epoch 25, Iteration 90, Current loss 3.1680331230163574 Accuracy 64.24040425760671\n",
      "Training:: Epoch 25, Iteration 100, Current loss 2.6463489532470703 Accuracy 65.91816743274809\n",
      "Training:: Epoch 25, Iteration 110, Current loss 3.465472936630249 Accuracy 57.93620728843094\n",
      "Training:: Epoch 25, Iteration 120, Current loss 2.796009063720703 Accuracy 58.55304788019405\n",
      "Training:: Epoch 25, Iteration 130, Current loss 3.6379570960998535 Accuracy 62.80800035012473\n",
      "Training:: Epoch 25, Iteration 140, Current loss 2.822650909423828 Accuracy 74.6821793416572\n",
      "Training:: Epoch 25, Iteration 150, Current loss 3.5373406410217285 Accuracy 62.38906212520988\n",
      "Training:: Epoch 25, Iteration 160, Current loss 2.8141868114471436 Accuracy 73.87472035794184\n",
      "Training:: Epoch 25, Iteration 170, Current loss 3.2159290313720703 Accuracy 55.26524518266225\n",
      "Training:: Epoch 25, Iteration 180, Current loss 2.9344661235809326 Accuracy 66.69188861985472\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 25, Probability Accuracy 52.82219610543269\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Completed 160 videos selected frames calculation\n",
      "Completed 170 videos selected frames calculation\n",
      "Completed 180 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.18361153262519\n",
      "Calculating Expectation\n",
      "Epoch 25 iter 0\n",
      "Epoch 25 iter 10\n",
      "Epoch 25 iter 20\n",
      "Epoch 25 iter 30\n",
      "Epoch 25 iter 40\n",
      "Epoch 25 iter 50\n",
      "Epoch 25 iter 60\n",
      "Epoch 25 iter 70\n",
      "Epoch 25 iter 80\n",
      "Epoch 25 iter 90\n",
      "Epoch 25 iter 100\n",
      "Epoch 25 iter 110\n",
      "Epoch 25 iter 120\n",
      "Epoch 25 iter 130\n",
      "Epoch 25 iter 140\n",
      "Epoch 25 iter 150\n",
      "Epoch 25 iter 160\n",
      "Epoch 25 iter 170\n",
      "Epoch 25 iter 180\n",
      "Train Boundary avergage error = 300.518\n",
      "Train From boundary avergage accuracy = 59.812\n",
      "Starting Training\n",
      "Training:: Epoch 26, Iteration 0, Current loss 2.358101186301617 Accuracy 60.58071131739435\n",
      "Training:: Epoch 26, Iteration 10, Current loss 2.8845717088431373 Accuracy 60.35259549461313\n",
      "Training:: Epoch 26, Iteration 20, Current loss 3.7535273064358465 Accuracy 55.66995232384685\n",
      "Training:: Epoch 26, Iteration 30, Current loss 3.326857553870533 Accuracy 64.50110695472937\n",
      "Training:: Epoch 26, Iteration 40, Current loss 2.000859430866249 Accuracy 73.90934844192634\n",
      "Training:: Epoch 26, Iteration 50, Current loss 1.8417869328760068 Accuracy 71.47618114095276\n",
      "Training:: Epoch 26, Iteration 60, Current loss 1.4603723409372145 Accuracy 67.67784518967932\n",
      "Training:: Epoch 26, Iteration 70, Current loss 1.8309304358822134 Accuracy 63.12723172336027\n",
      "Training:: Epoch 26, Iteration 80, Current loss 1.4960984803202184 Accuracy 67.14481424772343\n",
      "Training:: Epoch 26, Iteration 90, Current loss 2.0056966122528106 Accuracy 62.246169179020804\n",
      "Training:: Epoch 26, Iteration 100, Current loss 2.2117645621624438 Accuracy 61.88253597821859\n",
      "Training:: Epoch 26, Iteration 110, Current loss 2.3124966412873516 Accuracy 68.58716089175397\n",
      "Training:: Epoch 26, Iteration 120, Current loss 2.230087515802665 Accuracy 60.0909681611436\n",
      "Training:: Epoch 26, Iteration 130, Current loss 1.6580133505263404 Accuracy 63.459265213485274\n",
      "Training:: Epoch 26, Iteration 140, Current loss 2.1690636890370394 Accuracy 55.37013801756587\n",
      "Training:: Epoch 26, Iteration 150, Current loss 2.68131865531456 Accuracy 43.9885307494562\n",
      "Training:: Epoch 26, Iteration 160, Current loss 1.6177246005871022 Accuracy 65.24547803617571\n",
      "Training:: Epoch 26, Iteration 170, Current loss 1.8080619467854906 Accuracy 61.454322716135806\n",
      "Training:: Epoch 26, Iteration 180, Current loss 1.723744126119215 Accuracy 54.29936886651344\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 26, Probability Accuracy 55.182402032361075\n",
      "Starting Training\n",
      "Training:: Epoch 27, Iteration 0, Current loss 1.507860465554232 Accuracy 59.97058205505358\n",
      "Training:: Epoch 27, Iteration 10, Current loss 1.864144258719661 Accuracy 59.66638152266895\n",
      "Training:: Epoch 27, Iteration 20, Current loss 1.5754988913581405 Accuracy 67.22638843603956\n",
      "Training:: Epoch 27, Iteration 30, Current loss 1.2139220974865876 Accuracy 68.75\n",
      "Training:: Epoch 27, Iteration 40, Current loss 1.504593026544927 Accuracy 47.91071892032183\n",
      "Training:: Epoch 27, Iteration 50, Current loss 2.6077946017923135 Accuracy 50.85472595899665\n",
      "Training:: Epoch 27, Iteration 60, Current loss 1.614665999890666 Accuracy 50.813034256700305\n",
      "Training:: Epoch 27, Iteration 70, Current loss 1.6818967349203233 Accuracy 53.944071364137514\n",
      "Training:: Epoch 27, Iteration 80, Current loss 3.690013068740109 Accuracy 51.67994092515428\n",
      "Training:: Epoch 27, Iteration 90, Current loss 1.9371739093820093 Accuracy 60.88091572394404\n",
      "Training:: Epoch 27, Iteration 100, Current loss 3.492434464890137 Accuracy 50.10816753555343\n",
      "Training:: Epoch 27, Iteration 110, Current loss 1.9438269877063352 Accuracy 58.57939754555597\n",
      "Training:: Epoch 27, Iteration 120, Current loss 1.5403899960790224 Accuracy 63.17695473251029\n",
      "Training:: Epoch 27, Iteration 130, Current loss 1.4426546163063165 Accuracy 75.88058203712995\n",
      "Training:: Epoch 27, Iteration 140, Current loss 1.8938949088011654 Accuracy 62.00593918608055\n",
      "Training:: Epoch 27, Iteration 150, Current loss 1.4503142383811842 Accuracy 57.016039544033084\n",
      "Training:: Epoch 27, Iteration 160, Current loss 2.1392152245981872 Accuracy 54.518289541473465\n",
      "Training:: Epoch 27, Iteration 170, Current loss 1.9170317000372532 Accuracy 54.98613719703068\n",
      "Training:: Epoch 27, Iteration 180, Current loss 1.9286736314263297 Accuracy 54.962269060629716\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 27, Probability Accuracy 44.33305237999137\n",
      "Starting Training\n",
      "Training:: Epoch 28, Iteration 0, Current loss 1.8579646349900711 Accuracy 58.352929884340355\n",
      "Training:: Epoch 28, Iteration 10, Current loss 1.646080774477507 Accuracy 68.23495865412033\n",
      "Training:: Epoch 28, Iteration 20, Current loss 2.411054082130428 Accuracy 55.94674177442069\n",
      "Training:: Epoch 28, Iteration 30, Current loss 2.0870179835907834 Accuracy 59.1187871056376\n",
      "Training:: Epoch 28, Iteration 40, Current loss 3.0698320952310096 Accuracy 36.08744340036029\n",
      "Training:: Epoch 28, Iteration 50, Current loss 2.4068254563077307 Accuracy 63.01851025869759\n",
      "Training:: Epoch 28, Iteration 60, Current loss 2.2839228552021167 Accuracy 59.9978383052313\n",
      "Training:: Epoch 28, Iteration 70, Current loss 1.3462003247312122 Accuracy 65.46650510645664\n",
      "Training:: Epoch 28, Iteration 80, Current loss 1.7698976931105643 Accuracy 65.04868692829743\n",
      "Training:: Epoch 28, Iteration 90, Current loss 1.9208922868300462 Accuracy 52.47327604275833\n",
      "Training:: Epoch 28, Iteration 100, Current loss 1.8438163413549937 Accuracy 60.249268246624496\n",
      "Training:: Epoch 28, Iteration 110, Current loss 1.6084279869666414 Accuracy 66.55125006364887\n",
      "Training:: Epoch 28, Iteration 120, Current loss 1.5659168682032893 Accuracy 58.81654723699828\n",
      "Training:: Epoch 28, Iteration 130, Current loss 1.899473685096342 Accuracy 58.164215229938556\n",
      "Training:: Epoch 28, Iteration 140, Current loss 2.2420472408657073 Accuracy 58.128480891108126\n",
      "Training:: Epoch 28, Iteration 150, Current loss 2.4992338325841654 Accuracy 60.890104425658876\n",
      "Training:: Epoch 28, Iteration 160, Current loss 1.2803896535887576 Accuracy 70.21011822141386\n",
      "Training:: Epoch 28, Iteration 170, Current loss 2.165691395077007 Accuracy 63.089889290224065\n",
      "Training:: Epoch 28, Iteration 180, Current loss 1.2690802667352594 Accuracy 69.54030226700252\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 28, Probability Accuracy 51.94530511137228\n",
      "Starting Training\n",
      "Training:: Epoch 29, Iteration 0, Current loss 2.9067412197303777 Accuracy 52.962210483543274\n",
      "Training:: Epoch 29, Iteration 10, Current loss 1.8551954245502218 Accuracy 58.94951061149336\n",
      "Training:: Epoch 29, Iteration 20, Current loss 1.9881493194873472 Accuracy 65.46950502807888\n",
      "Training:: Epoch 29, Iteration 30, Current loss 1.6431513080958786 Accuracy 67.3918776371308\n",
      "Training:: Epoch 29, Iteration 40, Current loss 1.8937388570058964 Accuracy 50.83794403014995\n",
      "Training:: Epoch 29, Iteration 50, Current loss 1.4852948943896442 Accuracy 48.315898379124036\n",
      "Training:: Epoch 29, Iteration 60, Current loss 1.4480791114860376 Accuracy 62.393990792343104\n",
      "Training:: Epoch 29, Iteration 70, Current loss 1.3029865824546976 Accuracy 67.39315029719785\n",
      "Training:: Epoch 29, Iteration 80, Current loss 1.8631948942490695 Accuracy 54.701842223506\n",
      "Training:: Epoch 29, Iteration 90, Current loss 1.480468659547382 Accuracy 53.53105824093013\n",
      "Training:: Epoch 29, Iteration 100, Current loss 1.4742871996579165 Accuracy 71.39087825103657\n",
      "Training:: Epoch 29, Iteration 110, Current loss 1.4923539604180083 Accuracy 66.31898971000935\n",
      "Training:: Epoch 29, Iteration 120, Current loss 2.3705070842798155 Accuracy 62.080415794412765\n",
      "Training:: Epoch 29, Iteration 130, Current loss 3.4468839985617974 Accuracy 69.22549378200439\n",
      "Training:: Epoch 29, Iteration 140, Current loss 2.494205012498592 Accuracy 61.01111213150886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 29, Iteration 150, Current loss 2.3164326515242823 Accuracy 63.53785103785104\n",
      "Training:: Epoch 29, Iteration 160, Current loss 1.412520962103732 Accuracy 56.59698292365419\n",
      "Training:: Epoch 29, Iteration 170, Current loss 3.370622935677599 Accuracy 50.38850518006907\n",
      "Training:: Epoch 29, Iteration 180, Current loss 2.3588398699571673 Accuracy 52.29637293786285\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 29, Probability Accuracy 51.937786641657866\n",
      "Starting Training\n",
      "Training:: Epoch 30, Iteration 0, Current loss 2.9037573351038866 Accuracy 49.84511599091347\n",
      "Training:: Epoch 30, Iteration 10, Current loss 1.607448407887253 Accuracy 71.26078958539692\n",
      "Training:: Epoch 30, Iteration 20, Current loss 1.4629818100448433 Accuracy 67.00591463739543\n",
      "Training:: Epoch 30, Iteration 30, Current loss 1.774445838102459 Accuracy 54.226383846104845\n",
      "Training:: Epoch 30, Iteration 40, Current loss 1.4608229033586613 Accuracy 70.96125100609406\n",
      "Training:: Epoch 30, Iteration 50, Current loss 1.4019296010417621 Accuracy 60.353794315851154\n",
      "Training:: Epoch 30, Iteration 60, Current loss 3.017855816599695 Accuracy 66.2477847591429\n",
      "Training:: Epoch 30, Iteration 70, Current loss 2.753814456219417 Accuracy 73.70361834524084\n",
      "Training:: Epoch 30, Iteration 80, Current loss 1.5723576222356483 Accuracy 71.57145143222915\n",
      "Training:: Epoch 30, Iteration 90, Current loss 1.4660460707228486 Accuracy 71.94503637298847\n",
      "Training:: Epoch 30, Iteration 100, Current loss 1.6606463033972876 Accuracy 55.181598062953995\n",
      "Training:: Epoch 30, Iteration 110, Current loss 3.670636610160122 Accuracy 51.26344366711914\n",
      "Training:: Epoch 30, Iteration 120, Current loss 4.260896152326607 Accuracy 47.30562736130443\n",
      "Training:: Epoch 30, Iteration 130, Current loss 3.34864323332007 Accuracy 65.16815954030758\n",
      "Training:: Epoch 30, Iteration 140, Current loss 3.2214409850743646 Accuracy 56.65422885572139\n",
      "Training:: Epoch 30, Iteration 150, Current loss 1.9496205637000106 Accuracy 65.39884108001479\n",
      "Training:: Epoch 30, Iteration 160, Current loss 2.1968268322232216 Accuracy 62.375926623947734\n",
      "Training:: Epoch 30, Iteration 170, Current loss 5.654820948361986 Accuracy 44.276165496234874\n",
      "Training:: Epoch 30, Iteration 180, Current loss 1.8936298554994284 Accuracy 72.44835344651258\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 30, Probability Accuracy 55.81375563390593\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Completed 160 videos selected frames calculation\n",
      "Completed 170 videos selected frames calculation\n",
      "Completed 180 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.19372787051088\n",
      "Calculating Expectation\n",
      "Epoch 30 iter 0\n",
      "Epoch 30 iter 10\n",
      "Epoch 30 iter 20\n",
      "Epoch 30 iter 30\n",
      "Epoch 30 iter 40\n",
      "Epoch 30 iter 50\n",
      "Epoch 30 iter 60\n",
      "Epoch 30 iter 70\n",
      "Epoch 30 iter 80\n",
      "Epoch 30 iter 90\n",
      "Epoch 30 iter 100\n",
      "Epoch 30 iter 110\n",
      "Epoch 30 iter 120\n",
      "Epoch 30 iter 130\n",
      "Epoch 30 iter 140\n",
      "Epoch 30 iter 150\n",
      "Epoch 30 iter 160\n",
      "Epoch 30 iter 170\n",
      "Epoch 30 iter 180\n",
      "Train Boundary avergage error = 289.201\n",
      "Train From boundary avergage accuracy = 61.373\n",
      "Starting Training\n",
      "Training:: Epoch 31, Iteration 0, Current loss 2.472277829438492 Accuracy 67.15610984825213\n",
      "Training:: Epoch 31, Iteration 10, Current loss 1.5845679213104302 Accuracy 51.557415155741516\n",
      "Training:: Epoch 31, Iteration 20, Current loss 2.4803827447048956 Accuracy 63.65122041225157\n",
      "Training:: Epoch 31, Iteration 30, Current loss 2.530026023067001 Accuracy 59.346523687257715\n",
      "Training:: Epoch 31, Iteration 40, Current loss 2.7147554332198083 Accuracy 57.10120391271633\n",
      "Training:: Epoch 31, Iteration 50, Current loss 1.2395408893807665 Accuracy 63.39452978643687\n",
      "Training:: Epoch 31, Iteration 60, Current loss 1.7590539914164274 Accuracy 66.50162682133258\n",
      "Training:: Epoch 31, Iteration 70, Current loss 1.4682796574627601 Accuracy 69.66185410334346\n",
      "Training:: Epoch 31, Iteration 80, Current loss 2.2618012909994554 Accuracy 53.44630616907845\n",
      "Validation:: Epoch 31, Probability Accuracy 55.560897626142115\n",
      "Starting Training\n",
      "Training:: Epoch 32, Iteration 0, Current loss 1.3368947119546994 Accuracy 65.16138165345413\n",
      "Training:: Epoch 32, Iteration 10, Current loss 1.9000969006819473 Accuracy 62.199838114938395\n",
      "Training:: Epoch 32, Iteration 20, Current loss 1.7018044214224983 Accuracy 57.49328349491882\n",
      "Training:: Epoch 32, Iteration 30, Current loss 1.6560652783643979 Accuracy 53.637035472972975\n",
      "Training:: Epoch 32, Iteration 40, Current loss 1.261232733827784 Accuracy 57.69138898841514\n",
      "Training:: Epoch 32, Iteration 50, Current loss 1.0367743610671334 Accuracy 67.27227476356396\n",
      "Training:: Epoch 32, Iteration 60, Current loss 1.0083132842862923 Accuracy 68.66853654512457\n",
      "Training:: Epoch 32, Iteration 70, Current loss 1.2393889564008604 Accuracy 65.32787246223631\n",
      "Training:: Epoch 32, Iteration 80, Current loss 1.3570575460345864 Accuracy 70.26452213212814\n",
      "Training:: Epoch 32, Iteration 90, Current loss 1.145713859392264 Accuracy 54.66224264080313\n",
      "Training:: Epoch 32, Iteration 100, Current loss 1.1778649239387118 Accuracy 63.74137742253367\n",
      "Training:: Epoch 32, Iteration 110, Current loss 1.309846146193021 Accuracy 63.27137546468401\n",
      "Training:: Epoch 32, Iteration 120, Current loss 2.1164836982932216 Accuracy 64.7544428434198\n",
      "Training:: Epoch 32, Iteration 130, Current loss 1.4252547821491008 Accuracy 73.64957011562407\n",
      "Training:: Epoch 32, Iteration 140, Current loss 1.2335014545244711 Accuracy 66.85180899483144\n",
      "Training:: Epoch 32, Iteration 150, Current loss 1.0352976050314227 Accuracy 67.5832610291664\n",
      "Training:: Epoch 32, Iteration 160, Current loss 1.2135649759134541 Accuracy 67.97220127141472\n",
      "Training:: Epoch 32, Iteration 170, Current loss 1.031701876629364 Accuracy 69.90125978890023\n",
      "Training:: Epoch 32, Iteration 180, Current loss 1.4844772619812177 Accuracy 73.62506473329881\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 32, Probability Accuracy 56.269018760560485\n",
      "Starting Training\n",
      "Training:: Epoch 33, Iteration 0, Current loss 1.1961334281905005 Accuracy 59.50959150240448\n",
      "Training:: Epoch 33, Iteration 10, Current loss 1.0888458655205915 Accuracy 68.44608068722196\n",
      "Training:: Epoch 33, Iteration 20, Current loss 1.1327813669219384 Accuracy 60.81969103066636\n",
      "Training:: Epoch 33, Iteration 30, Current loss 1.159725856703326 Accuracy 63.417319500317596\n",
      "Training:: Epoch 33, Iteration 40, Current loss 0.9681494894165419 Accuracy 57.0617110799439\n",
      "Training:: Epoch 33, Iteration 50, Current loss 1.6148222052637282 Accuracy 72.41824305183972\n",
      "Training:: Epoch 33, Iteration 60, Current loss 1.5583799439495494 Accuracy 70.26534701560507\n",
      "Training:: Epoch 33, Iteration 70, Current loss 1.640763370484837 Accuracy 59.39101447833225\n",
      "Training:: Epoch 33, Iteration 80, Current loss 1.271807643736297 Accuracy 62.88330622326646\n",
      "Training:: Epoch 33, Iteration 90, Current loss 0.7920042548714801 Accuracy 65.45739778409649\n",
      "Training:: Epoch 33, Iteration 100, Current loss 1.8863183304085802 Accuracy 59.393843224373214\n",
      "Training:: Epoch 33, Iteration 110, Current loss 1.2494713764181384 Accuracy 75.80666231221424\n",
      "Training:: Epoch 33, Iteration 120, Current loss 1.6226532316510758 Accuracy 70.06550141861361\n",
      "Training:: Epoch 33, Iteration 130, Current loss 1.7087346105165158 Accuracy 52.48275468901431\n",
      "Training:: Epoch 33, Iteration 140, Current loss 1.0765660564484905 Accuracy 72.17962155900038\n",
      "Training:: Epoch 33, Iteration 150, Current loss 0.9131064853240513 Accuracy 76.61702280739621\n",
      "Training:: Epoch 33, Iteration 160, Current loss 1.2569447175401822 Accuracy 53.735101561188515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 33, Iteration 170, Current loss 1.1888998344104547 Accuracy 70.61017300321144\n",
      "Training:: Epoch 33, Iteration 180, Current loss 1.3870120396515035 Accuracy 60.127505952838156\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 33, Probability Accuracy 57.55665562638745\n",
      "Starting Training\n",
      "Training:: Epoch 34, Iteration 0, Current loss 1.2530569890105427 Accuracy 63.84261746969968\n",
      "Training:: Epoch 34, Iteration 10, Current loss 0.8096014188396443 Accuracy 69.87420474262579\n",
      "Training:: Epoch 34, Iteration 20, Current loss 1.285113801370442 Accuracy 63.58921976899505\n",
      "Training:: Epoch 34, Iteration 30, Current loss 0.9297228411775617 Accuracy 75.1882602819077\n",
      "Training:: Epoch 34, Iteration 40, Current loss 1.2576088774350629 Accuracy 59.370499897140505\n",
      "Training:: Epoch 34, Iteration 50, Current loss 1.1631860565318834 Accuracy 73.39492851362287\n",
      "Training:: Epoch 34, Iteration 60, Current loss 0.806217894817916 Accuracy 72.46366876885111\n",
      "Training:: Epoch 34, Iteration 70, Current loss 1.2346025762658352 Accuracy 65.41697731387794\n",
      "Training:: Epoch 34, Iteration 80, Current loss 0.7047592101100311 Accuracy 68.9214098195833\n",
      "Training:: Epoch 34, Iteration 90, Current loss 1.0924567063457111 Accuracy 62.086092715231786\n",
      "Training:: Epoch 34, Iteration 100, Current loss 0.8223529274933996 Accuracy 62.99782766111513\n",
      "Training:: Epoch 34, Iteration 110, Current loss 1.1688934743153885 Accuracy 68.45114716603531\n",
      "Training:: Epoch 34, Iteration 120, Current loss 1.0059865670400747 Accuracy 59.509733237202596\n",
      "Training:: Epoch 34, Iteration 130, Current loss 1.4420262635963748 Accuracy 64.11061925841307\n",
      "Training:: Epoch 34, Iteration 140, Current loss 1.3010164475481205 Accuracy 73.89340560072267\n",
      "Training:: Epoch 34, Iteration 150, Current loss 1.295720289877528 Accuracy 57.132968782446184\n",
      "Training:: Epoch 34, Iteration 160, Current loss 1.2005637527843747 Accuracy 48.67451091579246\n",
      "Training:: Epoch 34, Iteration 170, Current loss 1.4519970629390813 Accuracy 52.44400850089913\n",
      "Training:: Epoch 34, Iteration 180, Current loss 1.244664847575856 Accuracy 63.68939117754284\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 34, Probability Accuracy 55.5235031320362\n",
      "Starting Training\n",
      "Training:: Epoch 35, Iteration 0, Current loss 1.096498917088728 Accuracy 63.524896044354406\n",
      "Training:: Epoch 35, Iteration 10, Current loss 1.1276865994499168 Accuracy 68.83340072786089\n",
      "Training:: Epoch 35, Iteration 20, Current loss 0.6843457267750165 Accuracy 70.9959549579097\n",
      "Training:: Epoch 35, Iteration 30, Current loss 1.2233944615080492 Accuracy 54.06967007201474\n",
      "Training:: Epoch 35, Iteration 40, Current loss 0.8646055998594699 Accuracy 73.22429061991686\n",
      "Training:: Epoch 35, Iteration 50, Current loss 1.0669168482433928 Accuracy 66.45005694379313\n",
      "Training:: Epoch 35, Iteration 60, Current loss 0.9647781506178472 Accuracy 64.8003402988249\n",
      "Training:: Epoch 35, Iteration 70, Current loss 0.9823448223890261 Accuracy 68.46862307648304\n",
      "Training:: Epoch 35, Iteration 80, Current loss 0.9265115454228231 Accuracy 71.56329923273657\n",
      "Training:: Epoch 35, Iteration 90, Current loss 1.0389310188357528 Accuracy 62.86311875435742\n",
      "Training:: Epoch 35, Iteration 100, Current loss 1.1262341707180017 Accuracy 57.406570709352614\n",
      "Training:: Epoch 35, Iteration 110, Current loss 0.9239031287063926 Accuracy 68.07766019498375\n",
      "Training:: Epoch 35, Iteration 120, Current loss 0.9850595900535908 Accuracy 64.42067121042187\n",
      "Training:: Epoch 35, Iteration 130, Current loss 1.2432414754365175 Accuracy 54.72837022132797\n",
      "Training:: Epoch 35, Iteration 140, Current loss 1.0990783187106925 Accuracy 66.99329551315111\n",
      "Training:: Epoch 35, Iteration 150, Current loss 0.9585415602735865 Accuracy 63.427845392537115\n",
      "Training:: Epoch 35, Iteration 160, Current loss 1.0188335731729738 Accuracy 70.4941343761109\n",
      "Training:: Epoch 35, Iteration 170, Current loss 0.8145041216733355 Accuracy 64.64548110117731\n",
      "Training:: Epoch 35, Iteration 180, Current loss 1.077095000858399 Accuracy 64.38188921445514\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 35, Probability Accuracy 57.42983091357321\n",
      "Calculating Expectation\n",
      "Epoch 35 iter 0\n",
      "Epoch 35 iter 10\n",
      "Epoch 35 iter 20\n",
      "Epoch 35 iter 30\n",
      "Epoch 35 iter 40\n",
      "Epoch 35 iter 50\n",
      "Epoch 35 iter 60\n",
      "Epoch 35 iter 70\n",
      "Epoch 35 iter 80\n",
      "Epoch 35 iter 90\n",
      "Epoch 35 iter 100\n",
      "Epoch 35 iter 110\n",
      "Epoch 35 iter 120\n",
      "Epoch 35 iter 130\n",
      "Epoch 35 iter 140\n",
      "Epoch 35 iter 150\n",
      "Epoch 35 iter 160\n",
      "Epoch 35 iter 170\n",
      "Epoch 35 iter 180\n",
      "Train Boundary avergage error = 291.946\n",
      "Train From boundary avergage accuracy = 61.371\n",
      "Starting Training\n",
      "Training:: Epoch 36, Iteration 0, Current loss 0.583608172975124 Accuracy 68.8993803481853\n",
      "Training:: Epoch 36, Iteration 10, Current loss 0.97511351789777 Accuracy 69.82777606483725\n",
      "Training:: Epoch 36, Iteration 20, Current loss 0.8911453503176825 Accuracy 59.47972456006121\n",
      "Training:: Epoch 36, Iteration 30, Current loss 0.9522260622389109 Accuracy 58.110882956878854\n",
      "Training:: Epoch 36, Iteration 40, Current loss 1.4038387453773418 Accuracy 69.87904580580133\n",
      "Training:: Epoch 36, Iteration 50, Current loss 1.065594041774579 Accuracy 50.99067081297201\n",
      "Training:: Epoch 36, Iteration 60, Current loss 1.0531735277990144 Accuracy 60.15484922575387\n",
      "Training:: Epoch 36, Iteration 70, Current loss 0.962579109529196 Accuracy 71.96081714668453\n",
      "Training:: Epoch 36, Iteration 80, Current loss 1.0275118111419834 Accuracy 60.1342442766391\n",
      "Training:: Epoch 36, Iteration 90, Current loss 1.0292405151403021 Accuracy 67.09839423775854\n",
      "Training:: Epoch 36, Iteration 100, Current loss 1.6538994102186202 Accuracy 61.30505457078721\n",
      "Training:: Epoch 36, Iteration 110, Current loss 1.0743219211544173 Accuracy 61.604129442128254\n",
      "Training:: Epoch 36, Iteration 120, Current loss 1.3181160908000134 Accuracy 68.88331242158092\n",
      "Training:: Epoch 36, Iteration 130, Current loss 0.8012738302839568 Accuracy 67.17839786295903\n",
      "Training:: Epoch 36, Iteration 140, Current loss 1.1472077969297392 Accuracy 69.54696772325951\n",
      "Training:: Epoch 36, Iteration 150, Current loss 0.989120252403482 Accuracy 76.20646454522677\n",
      "Training:: Epoch 36, Iteration 160, Current loss 1.150019842566028 Accuracy 66.7232265222215\n",
      "Training:: Epoch 36, Iteration 170, Current loss 0.9327918319972903 Accuracy 62.6230975828111\n",
      "Training:: Epoch 36, Iteration 180, Current loss 1.3550461868964367 Accuracy 69.46994991652754\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 36, Probability Accuracy 56.501695612775066\n",
      "Starting Training\n",
      "Training:: Epoch 37, Iteration 0, Current loss 1.014893620415725 Accuracy 66.83707490553456\n",
      "Training:: Epoch 37, Iteration 10, Current loss 0.7341741576844928 Accuracy 70.00150897842161\n",
      "Training:: Epoch 37, Iteration 20, Current loss 0.9061574330364578 Accuracy 65.22879363356846\n",
      "Training:: Epoch 37, Iteration 30, Current loss 1.255613989791557 Accuracy 55.00647309043832\n",
      "Training:: Epoch 37, Iteration 40, Current loss 0.7603350410893808 Accuracy 69.66342290866886\n",
      "Training:: Epoch 37, Iteration 50, Current loss 0.7803135706895269 Accuracy 72.42890027474567\n",
      "Training:: Epoch 37, Iteration 60, Current loss 1.3619829067812392 Accuracy 55.59767500631792\n",
      "Training:: Epoch 37, Iteration 70, Current loss 2.3409879650501715 Accuracy 55.20328235732936\n",
      "Training:: Epoch 37, Iteration 80, Current loss 1.1153558503102345 Accuracy 72.75718275373963\n",
      "Training:: Epoch 37, Iteration 90, Current loss 1.2658025336298284 Accuracy 66.14096916299559\n",
      "Training:: Epoch 37, Iteration 100, Current loss 0.9176471167541443 Accuracy 64.1555653418474\n",
      "Training:: Epoch 37, Iteration 110, Current loss 1.1252657871539198 Accuracy 62.177582714382176\n",
      "Training:: Epoch 37, Iteration 120, Current loss 1.0810084931958617 Accuracy 59.157975069956755\n",
      "Training:: Epoch 37, Iteration 130, Current loss 0.8315285464509581 Accuracy 68.2392304475115\n",
      "Training:: Epoch 37, Iteration 140, Current loss 0.980847540326383 Accuracy 54.84079521577501\n",
      "Training:: Epoch 37, Iteration 150, Current loss 1.4492733924654506 Accuracy 65.48864437096861\n",
      "Training:: Epoch 37, Iteration 160, Current loss 0.7015756513112319 Accuracy 71.00499375780275\n",
      "Training:: Epoch 37, Iteration 170, Current loss 1.051356290016866 Accuracy 62.62492554106824\n",
      "Training:: Epoch 37, Iteration 180, Current loss 0.8414383234287952 Accuracy 63.473249238799475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 37, Probability Accuracy 56.579056709047094\n",
      "Starting Training\n",
      "Training:: Epoch 38, Iteration 0, Current loss 0.589387362211237 Accuracy 75.37403767007214\n",
      "Training:: Epoch 38, Iteration 10, Current loss 1.1318702554424407 Accuracy 55.205525606469\n",
      "Training:: Epoch 38, Iteration 20, Current loss 0.7661411392512337 Accuracy 56.22042436269272\n",
      "Training:: Epoch 38, Iteration 30, Current loss 1.018981950586215 Accuracy 63.870850276142505\n",
      "Training:: Epoch 38, Iteration 40, Current loss 0.9156420709626674 Accuracy 64.56681665595315\n",
      "Training:: Epoch 38, Iteration 50, Current loss 1.0731662965188788 Accuracy 67.14992408287212\n",
      "Training:: Epoch 38, Iteration 60, Current loss 0.9492875594223977 Accuracy 67.35698175107648\n",
      "Training:: Epoch 38, Iteration 70, Current loss 1.1415254958426384 Accuracy 67.56215086776683\n",
      "Training:: Epoch 38, Iteration 80, Current loss 1.3009411011849175 Accuracy 62.1868978805395\n",
      "Training:: Epoch 38, Iteration 90, Current loss 1.077754682773198 Accuracy 65.79875897311108\n",
      "Training:: Epoch 38, Iteration 100, Current loss 0.973872028683816 Accuracy 57.1201437854279\n",
      "Training:: Epoch 38, Iteration 110, Current loss 0.8809408188351109 Accuracy 71.74133273300315\n",
      "Training:: Epoch 38, Iteration 120, Current loss 0.7165757004686963 Accuracy 66.94854814060112\n",
      "Training:: Epoch 38, Iteration 130, Current loss 1.26467431071151 Accuracy 55.02120829989683\n",
      "Training:: Epoch 38, Iteration 140, Current loss 1.2913468796633185 Accuracy 68.1587373459685\n",
      "Training:: Epoch 38, Iteration 150, Current loss 1.3913590355239045 Accuracy 56.587227896420096\n",
      "Training:: Epoch 38, Iteration 160, Current loss 1.078012259054424 Accuracy 70.48434856175973\n",
      "Training:: Epoch 38, Iteration 170, Current loss 1.1333748817132856 Accuracy 64.15125225077755\n",
      "Training:: Epoch 38, Iteration 180, Current loss 1.0859188037168792 Accuracy 50.53449951409135\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 38, Probability Accuracy 55.87192484695957\n",
      "Starting Training\n",
      "Training:: Epoch 39, Iteration 0, Current loss 0.7599856710787803 Accuracy 58.69932432432432\n",
      "Training:: Epoch 39, Iteration 10, Current loss 0.9450932065404837 Accuracy 56.523317002358915\n",
      "Training:: Epoch 39, Iteration 20, Current loss 0.8610933317755038 Accuracy 64.25053533190578\n",
      "Training:: Epoch 39, Iteration 30, Current loss 0.7886975443906072 Accuracy 71.79199401421624\n",
      "Training:: Epoch 39, Iteration 40, Current loss 0.8971662540203118 Accuracy 61.52391593966221\n",
      "Training:: Epoch 39, Iteration 50, Current loss 0.7970813387976778 Accuracy 77.39164388910582\n",
      "Training:: Epoch 39, Iteration 60, Current loss 1.1618950950174458 Accuracy 67.40269212916915\n",
      "Training:: Epoch 39, Iteration 70, Current loss 0.9160967486000671 Accuracy 72.50643877312105\n",
      "Training:: Epoch 39, Iteration 80, Current loss 1.087790353476573 Accuracy 57.468732793203806\n",
      "Training:: Epoch 39, Iteration 90, Current loss 1.023612597299781 Accuracy 56.90928789520339\n",
      "Training:: Epoch 39, Iteration 100, Current loss 1.1251553407516062 Accuracy 58.18190869716732\n",
      "Training:: Epoch 39, Iteration 110, Current loss 0.8030615146809968 Accuracy 68.50383116010217\n",
      "Training:: Epoch 39, Iteration 120, Current loss 0.7955359265115145 Accuracy 68.7182813752051\n",
      "Training:: Epoch 39, Iteration 130, Current loss 0.7510963972085596 Accuracy 63.77208389296415\n",
      "Training:: Epoch 39, Iteration 140, Current loss 0.9172139882076809 Accuracy 66.22648207312744\n",
      "Training:: Epoch 39, Iteration 150, Current loss 0.6780214277590378 Accuracy 74.74402730375427\n",
      "Training:: Epoch 39, Iteration 160, Current loss 0.8555652790403638 Accuracy 60.54852320675106\n",
      "Training:: Epoch 39, Iteration 170, Current loss 0.6887315574129365 Accuracy 73.35898422470181\n",
      "Training:: Epoch 39, Iteration 180, Current loss 0.8483059542322904 Accuracy 69.28818776452482\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 39, Probability Accuracy 55.820482685755664\n",
      "Starting Training\n",
      "Training:: Epoch 40, Iteration 0, Current loss 1.3111637382896033 Accuracy 48.604291383601264\n",
      "Training:: Epoch 40, Iteration 10, Current loss 0.7116279606195463 Accuracy 66.00436152168645\n",
      "Training:: Epoch 40, Iteration 20, Current loss 1.3293012553366197 Accuracy 57.896766728803755\n",
      "Training:: Epoch 40, Iteration 30, Current loss 0.8033961237891146 Accuracy 64.79746070133011\n",
      "Training:: Epoch 40, Iteration 40, Current loss 0.9537219947584612 Accuracy 65.28602266594712\n",
      "Training:: Epoch 40, Iteration 50, Current loss 0.8601911972646206 Accuracy 74.1713062098501\n",
      "Training:: Epoch 40, Iteration 60, Current loss 1.4526418843332962 Accuracy 55.17818703659412\n",
      "Training:: Epoch 40, Iteration 70, Current loss 0.8269461592798246 Accuracy 69.24497133417549\n",
      "Training:: Epoch 40, Iteration 80, Current loss 0.6399007641317572 Accuracy 72.40076712965653\n",
      "Training:: Epoch 40, Iteration 90, Current loss 0.7343838008865817 Accuracy 63.34077806056199\n",
      "Training:: Epoch 40, Iteration 100, Current loss 0.6858658342945665 Accuracy 64.48998885775062\n",
      "Training:: Epoch 40, Iteration 110, Current loss 0.992010775348248 Accuracy 64.86321125775719\n",
      "Training:: Epoch 40, Iteration 120, Current loss 0.8446490581839649 Accuracy 71.09155706941685\n",
      "Training:: Epoch 40, Iteration 130, Current loss 0.7109613500296619 Accuracy 73.1876592745215\n",
      "Training:: Epoch 40, Iteration 140, Current loss 0.8051497537323493 Accuracy 72.998712998713\n",
      "Training:: Epoch 40, Iteration 150, Current loss 1.0425089580619094 Accuracy 60.94731480957501\n",
      "Training:: Epoch 40, Iteration 160, Current loss 0.8861276107287057 Accuracy 52.40297043575732\n",
      "Training:: Epoch 40, Iteration 170, Current loss 0.8101305549559402 Accuracy 62.19208281414742\n",
      "Training:: Epoch 40, Iteration 180, Current loss 0.7403517580560509 Accuracy 75.5544643587855\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 40, Probability Accuracy 56.30621540020023\n",
      "Calculating Expectation\n",
      "Epoch 40 iter 0\n",
      "Epoch 40 iter 10\n",
      "Epoch 40 iter 20\n",
      "Epoch 40 iter 30\n",
      "Epoch 40 iter 40\n",
      "Epoch 40 iter 50\n",
      "Epoch 40 iter 60\n",
      "Epoch 40 iter 70\n",
      "Epoch 40 iter 80\n",
      "Epoch 40 iter 90\n",
      "Epoch 40 iter 100\n",
      "Epoch 40 iter 110\n",
      "Epoch 40 iter 120\n",
      "Epoch 40 iter 130\n",
      "Epoch 40 iter 140\n",
      "Epoch 40 iter 150\n",
      "Epoch 40 iter 160\n",
      "Epoch 40 iter 170\n",
      "Epoch 40 iter 180\n",
      "Train Boundary avergage error = 295.104\n",
      "Train From boundary avergage accuracy = 60.870\n",
      "Starting Training\n",
      "Training:: Epoch 41, Iteration 0, Current loss 0.827862127393866 Accuracy 70.51028806584362\n",
      "Training:: Epoch 41, Iteration 10, Current loss 0.7326878761924388 Accuracy 68.14802104781515\n",
      "Training:: Epoch 41, Iteration 20, Current loss 0.816447653533483 Accuracy 51.49402390438247\n",
      "Training:: Epoch 41, Iteration 30, Current loss 1.666192496242097 Accuracy 58.78225855652492\n",
      "Training:: Epoch 41, Iteration 40, Current loss 1.219475262316105 Accuracy 59.357555114012676\n",
      "Training:: Epoch 41, Iteration 50, Current loss 1.0817156345129886 Accuracy 63.56593178036606\n",
      "Training:: Epoch 41, Iteration 60, Current loss 0.9185222107063039 Accuracy 66.16404048836482\n",
      "Training:: Epoch 41, Iteration 70, Current loss 0.8490243456498321 Accuracy 68.28967642526965\n",
      "Training:: Epoch 41, Iteration 80, Current loss 0.7854500692185402 Accuracy 63.101638100056924\n",
      "Training:: Epoch 41, Iteration 90, Current loss 0.7674821213581713 Accuracy 72.75382236729084\n",
      "Training:: Epoch 41, Iteration 100, Current loss 1.1301671290638342 Accuracy 65.19848418960055\n",
      "Training:: Epoch 41, Iteration 110, Current loss 0.7863973159490781 Accuracy 71.88541399641117\n",
      "Training:: Epoch 41, Iteration 120, Current loss 0.7028562751828834 Accuracy 66.6137845936894\n",
      "Training:: Epoch 41, Iteration 130, Current loss 0.9155720109084569 Accuracy 76.22197128569124\n",
      "Training:: Epoch 41, Iteration 140, Current loss 0.8795558286060572 Accuracy 65.89523711127183\n",
      "Training:: Epoch 41, Iteration 150, Current loss 0.969220488854222 Accuracy 66.2560257096947\n",
      "Training:: Epoch 41, Iteration 160, Current loss 0.7973765799079567 Accuracy 68.84882108183079\n",
      "Training:: Epoch 41, Iteration 170, Current loss 0.8034550922502411 Accuracy 46.711214878029146\n",
      "Training:: Epoch 41, Iteration 180, Current loss 0.6202601227272315 Accuracy 76.30288421577592\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 41, Probability Accuracy 56.472808860714416\n",
      "Starting Training\n",
      "Training:: Epoch 42, Iteration 0, Current loss 0.8170395539978863 Accuracy 65.81356916342847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 42, Iteration 10, Current loss 1.023484878111468 Accuracy 61.54692243389503\n",
      "Training:: Epoch 42, Iteration 20, Current loss 0.7447567477313984 Accuracy 71.57356349396628\n",
      "Training:: Epoch 42, Iteration 30, Current loss 0.7144491903772998 Accuracy 58.35665347872238\n",
      "Training:: Epoch 42, Iteration 40, Current loss 0.9249719003657311 Accuracy 48.9546935149541\n",
      "Training:: Epoch 42, Iteration 50, Current loss 0.8066167418629915 Accuracy 63.225806451612904\n",
      "Training:: Epoch 42, Iteration 60, Current loss 0.828696003713752 Accuracy 75.04764644539537\n",
      "Training:: Epoch 42, Iteration 70, Current loss 0.9133445627923586 Accuracy 61.740976645435246\n",
      "Training:: Epoch 42, Iteration 80, Current loss 0.8164950376053932 Accuracy 76.95672798186897\n",
      "Training:: Epoch 42, Iteration 90, Current loss 0.8132774525683033 Accuracy 66.96058091286307\n",
      "Training:: Epoch 42, Iteration 100, Current loss 0.8492081682886125 Accuracy 59.41664571284888\n",
      "Training:: Epoch 42, Iteration 110, Current loss 1.2469474723972849 Accuracy 62.754173383951326\n",
      "Training:: Epoch 42, Iteration 120, Current loss 1.0604378020384828 Accuracy 63.283224690701076\n",
      "Training:: Epoch 42, Iteration 130, Current loss 1.0289488725113458 Accuracy 63.63116883116883\n",
      "Training:: Epoch 42, Iteration 140, Current loss 0.9352106569198977 Accuracy 62.57075677087869\n",
      "Training:: Epoch 42, Iteration 150, Current loss 0.7562067289430762 Accuracy 54.89949748743719\n",
      "Training:: Epoch 42, Iteration 160, Current loss 1.0318116216828948 Accuracy 68.8098178450139\n",
      "Training:: Epoch 42, Iteration 170, Current loss 1.1528487073371525 Accuracy 48.63017535996414\n",
      "Training:: Epoch 42, Iteration 180, Current loss 0.8965364356926633 Accuracy 41.11773232404574\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 42, Probability Accuracy 55.79693800428157\n",
      "Starting Training\n",
      "Training:: Epoch 43, Iteration 0, Current loss 0.865861899094628 Accuracy 73.63992067320576\n",
      "Training:: Epoch 43, Iteration 10, Current loss 1.1531863660156318 Accuracy 63.656601404189736\n",
      "Training:: Epoch 43, Iteration 20, Current loss 1.9272055004888045 Accuracy 59.152394458383334\n",
      "Training:: Epoch 43, Iteration 30, Current loss 1.007017371033714 Accuracy 59.132267024231396\n",
      "Training:: Epoch 43, Iteration 40, Current loss 0.8141411876853344 Accuracy 55.72963294538943\n",
      "Training:: Epoch 43, Iteration 50, Current loss 0.7557035535430101 Accuracy 57.174795064999586\n",
      "Training:: Epoch 43, Iteration 60, Current loss 0.6594999146566554 Accuracy 66.43699759891429\n",
      "Training:: Epoch 43, Iteration 70, Current loss 0.7044066738503545 Accuracy 69.3056416615003\n",
      "Training:: Epoch 43, Iteration 80, Current loss 0.5908281925056866 Accuracy 52.66150238078317\n",
      "Training:: Epoch 43, Iteration 90, Current loss 0.8905790503877242 Accuracy 68.56424112550079\n",
      "Training:: Epoch 43, Iteration 100, Current loss 1.079070725840797 Accuracy 69.70811177735038\n",
      "Training:: Epoch 43, Iteration 110, Current loss 1.1959638390621756 Accuracy 61.044383436284605\n",
      "Training:: Epoch 43, Iteration 120, Current loss 1.0527161016077187 Accuracy 50.920212765957444\n",
      "Training:: Epoch 43, Iteration 130, Current loss 1.1210112127415646 Accuracy 58.42062852538275\n",
      "Training:: Epoch 43, Iteration 140, Current loss 1.1126971379525612 Accuracy 67.30014459822351\n",
      "Training:: Epoch 43, Iteration 150, Current loss 1.6376968806543484 Accuracy 59.83157894736842\n",
      "Training:: Epoch 43, Iteration 160, Current loss 1.109951358127689 Accuracy 65.59325696995894\n",
      "Training:: Epoch 43, Iteration 170, Current loss 1.0021671995625905 Accuracy 72.87774599890464\n",
      "Training:: Epoch 43, Iteration 180, Current loss 2.384078077943489 Accuracy 56.98204899335515\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 43, Probability Accuracy 56.066217932737395\n",
      "Starting Training\n",
      "Training:: Epoch 44, Iteration 0, Current loss 0.9063294474594602 Accuracy 66.84866534303993\n",
      "Training:: Epoch 44, Iteration 10, Current loss 1.3394211851283464 Accuracy 73.00298804780877\n",
      "Training:: Epoch 44, Iteration 20, Current loss 3.6440599104322304 Accuracy 52.90050590219224\n",
      "Training:: Epoch 44, Iteration 30, Current loss 2.686585368404069 Accuracy 53.91313415715105\n",
      "Training:: Epoch 44, Iteration 40, Current loss 2.323893522201862 Accuracy 64.12265469484562\n",
      "Training:: Epoch 44, Iteration 50, Current loss 1.8260280283679802 Accuracy 66.58976510067114\n",
      "Training:: Epoch 44, Iteration 60, Current loss 1.5740212126156368 Accuracy 61.31016765819362\n",
      "Training:: Epoch 44, Iteration 70, Current loss 5.616666131532193 Accuracy 57.58844396152248\n",
      "Training:: Epoch 44, Iteration 80, Current loss 6.002669258981525 Accuracy 45.313372240548084\n",
      "Training:: Epoch 44, Iteration 90, Current loss 2.0996016027333653 Accuracy 66.03843116609634\n",
      "Training:: Epoch 44, Iteration 100, Current loss 1.7801517391696717 Accuracy 66.12143742255266\n",
      "Training:: Epoch 44, Iteration 110, Current loss 2.1979221462321163 Accuracy 69.24614632846163\n",
      "Training:: Epoch 44, Iteration 120, Current loss 2.9568303603410158 Accuracy 57.096793818823386\n",
      "Training:: Epoch 44, Iteration 130, Current loss 2.289386903903231 Accuracy 57.19166758514273\n",
      "Training:: Epoch 44, Iteration 140, Current loss 2.7415293603405755 Accuracy 56.91737718229801\n",
      "Training:: Epoch 44, Iteration 150, Current loss 1.7380838109437184 Accuracy 61.65405558305636\n",
      "Training:: Epoch 44, Iteration 160, Current loss 3.157940231116604 Accuracy 49.70702381858306\n",
      "Training:: Epoch 44, Iteration 170, Current loss 5.764678379124193 Accuracy 30.17737003058104\n",
      "Training:: Epoch 44, Iteration 180, Current loss 2.4034867315287864 Accuracy 66.37140876530847\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 44, Probability Accuracy 53.631420872063345\n",
      "Starting Training\n",
      "Training:: Epoch 45, Iteration 0, Current loss 2.116906166511026 Accuracy 70.35532994923858\n",
      "Training:: Epoch 45, Iteration 10, Current loss 1.8384493581779386 Accuracy 66.67191435768262\n",
      "Training:: Epoch 45, Iteration 20, Current loss 2.134915135184418 Accuracy 60.32849857606464\n",
      "Training:: Epoch 45, Iteration 30, Current loss 3.133874725684607 Accuracy 60.347551342812004\n",
      "Training:: Epoch 45, Iteration 40, Current loss 5.120937929464146 Accuracy 54.41465686781907\n",
      "Training:: Epoch 45, Iteration 50, Current loss 3.9459244249759484 Accuracy 62.06951871657754\n",
      "Training:: Epoch 45, Iteration 60, Current loss 1.693415028842167 Accuracy 62.57684426229508\n",
      "Training:: Epoch 45, Iteration 70, Current loss 4.705420737501148 Accuracy 45.757303818925116\n",
      "Training:: Epoch 45, Iteration 80, Current loss 2.1617735595697023 Accuracy 64.87952070669523\n",
      "Training:: Epoch 45, Iteration 90, Current loss 1.462487048121059 Accuracy 58.272704776045536\n",
      "Training:: Epoch 45, Iteration 100, Current loss 1.4454475999355991 Accuracy 58.022706232032355\n",
      "Training:: Epoch 45, Iteration 110, Current loss 1.3925284881775422 Accuracy 65.8425788416179\n",
      "Training:: Epoch 45, Iteration 120, Current loss 1.360451298842127 Accuracy 67.1725603278191\n",
      "Training:: Epoch 45, Iteration 130, Current loss 1.5425885939788664 Accuracy 61.54326772883474\n",
      "Training:: Epoch 45, Iteration 140, Current loss 0.877819426528083 Accuracy 55.856515373352856\n",
      "Training:: Epoch 45, Iteration 150, Current loss 0.8647686873571729 Accuracy 71.10909390988611\n",
      "Training:: Epoch 45, Iteration 160, Current loss 0.9448358171599593 Accuracy 70.99387933547071\n",
      "Training:: Epoch 45, Iteration 170, Current loss 0.731582520421422 Accuracy 68.28115015974441\n",
      "Training:: Epoch 45, Iteration 180, Current loss 1.1081119198892913 Accuracy 56.78911703265909\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 45, Probability Accuracy 56.064239388075706\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Completed 160 videos selected frames calculation\n",
      "Completed 170 videos selected frames calculation\n",
      "Completed 180 videos selected frames calculation\n",
      "Total correct pivots labels selected =  60.77895801719777\n",
      "Calculating Expectation\n",
      "Epoch 45 iter 0\n",
      "Epoch 45 iter 10\n",
      "Epoch 45 iter 20\n",
      "Epoch 45 iter 30\n",
      "Epoch 45 iter 40\n",
      "Epoch 45 iter 50\n",
      "Epoch 45 iter 60\n",
      "Epoch 45 iter 70\n",
      "Epoch 45 iter 80\n",
      "Epoch 45 iter 90\n",
      "Epoch 45 iter 100\n",
      "Epoch 45 iter 110\n",
      "Epoch 45 iter 120\n",
      "Epoch 45 iter 130\n",
      "Epoch 45 iter 140\n",
      "Epoch 45 iter 150\n",
      "Epoch 45 iter 160\n",
      "Epoch 45 iter 170\n",
      "Epoch 45 iter 180\n",
      "Train Boundary avergage error = 295.823\n",
      "Train From boundary avergage accuracy = 60.804\n",
      "Starting Training\n",
      "Training:: Epoch 46, Iteration 0, Current loss 0.7921825834144529 Accuracy 71.53745794135824\n",
      "Training:: Epoch 46, Iteration 10, Current loss 0.968022462107531 Accuracy 62.648388920293954\n",
      "Training:: Epoch 46, Iteration 20, Current loss 0.8736202483645423 Accuracy 54.36956663834238\n",
      "Training:: Epoch 46, Iteration 30, Current loss 1.051614369040289 Accuracy 60.429478778102634\n",
      "Training:: Epoch 46, Iteration 40, Current loss 0.780561413891144 Accuracy 58.10710830345455\n",
      "Training:: Epoch 46, Iteration 50, Current loss 1.0480206537912864 Accuracy 61.84311268880072\n",
      "Training:: Epoch 46, Iteration 60, Current loss 0.8775430617486337 Accuracy 63.492063492063494\n",
      "Training:: Epoch 46, Iteration 70, Current loss 0.9317571320775119 Accuracy 62.91729950266536\n",
      "Training:: Epoch 46, Iteration 80, Current loss 0.7223171161123871 Accuracy 69.62311355015737\n",
      "Training:: Epoch 46, Iteration 90, Current loss 0.855057606470361 Accuracy 67.99819566960706\n",
      "Training:: Epoch 46, Iteration 100, Current loss 0.759969935174185 Accuracy 70.1902142775295\n",
      "Training:: Epoch 46, Iteration 110, Current loss 1.0237017562398674 Accuracy 61.71466401853691\n",
      "Training:: Epoch 46, Iteration 120, Current loss 1.6022952823341345 Accuracy 63.04978619425779\n",
      "Training:: Epoch 46, Iteration 130, Current loss 0.7562200097425363 Accuracy 67.00262927256793\n",
      "Training:: Epoch 46, Iteration 140, Current loss 0.8539230320612313 Accuracy 60.482194204821944\n",
      "Training:: Epoch 46, Iteration 150, Current loss 0.949916686488991 Accuracy 71.78071228491396\n",
      "Training:: Epoch 46, Iteration 160, Current loss 0.7291214523596634 Accuracy 64.2153146322972\n",
      "Training:: Epoch 46, Iteration 170, Current loss 0.7127886511275939 Accuracy 73.23445881981698\n",
      "Training:: Epoch 46, Iteration 180, Current loss 0.6838208255454361 Accuracy 67.599451303155\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 46, Probability Accuracy 55.669321873602655\n",
      "Starting Training\n",
      "Training:: Epoch 47, Iteration 0, Current loss 0.8656222754328773 Accuracy 65.39955190440628\n",
      "Training:: Epoch 47, Iteration 10, Current loss 0.614700830451272 Accuracy 69.2663995993991\n",
      "Training:: Epoch 47, Iteration 20, Current loss 0.9108338742382994 Accuracy 62.758279082932354\n",
      "Training:: Epoch 47, Iteration 30, Current loss 0.632726878462231 Accuracy 50.9943009579241\n",
      "Training:: Epoch 47, Iteration 40, Current loss 0.6809278345083679 Accuracy 61.30862665129887\n",
      "Training:: Epoch 47, Iteration 50, Current loss 0.7720770308954799 Accuracy 73.81985652289434\n",
      "Training:: Epoch 47, Iteration 60, Current loss 0.7905085238857592 Accuracy 62.347145245007475\n",
      "Training:: Epoch 47, Iteration 70, Current loss 0.5522007180682516 Accuracy 73.78061998699329\n",
      "Training:: Epoch 47, Iteration 80, Current loss 0.8664381485645 Accuracy 49.9611801242236\n",
      "Training:: Epoch 47, Iteration 90, Current loss 0.7575684256483112 Accuracy 59.21333074985468\n",
      "Training:: Epoch 47, Iteration 100, Current loss 0.5445168651297263 Accuracy 51.07969999175801\n",
      "Training:: Epoch 47, Iteration 110, Current loss 0.7377840456661207 Accuracy 69.8180279305967\n",
      "Training:: Epoch 47, Iteration 120, Current loss 0.7863383406054053 Accuracy 63.069524818648624\n",
      "Training:: Epoch 47, Iteration 130, Current loss 0.8976333402378958 Accuracy 55.210107113430375\n",
      "Training:: Epoch 47, Iteration 140, Current loss 0.7916876649994269 Accuracy 57.54641556364928\n",
      "Training:: Epoch 47, Iteration 150, Current loss 0.6245894277482761 Accuracy 57.606428659060235\n",
      "Training:: Epoch 47, Iteration 160, Current loss 0.5523155297846344 Accuracy 63.881010903132285\n",
      "Training:: Epoch 47, Iteration 170, Current loss 0.6965580973917691 Accuracy 56.00631205207443\n",
      "Training:: Epoch 47, Iteration 180, Current loss 0.6921101295123961 Accuracy 59.823662575956156\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 47, Probability Accuracy 55.341279168694676\n",
      "Starting Training\n",
      "Training:: Epoch 48, Iteration 0, Current loss 0.5363115609275654 Accuracy 69.77761025254429\n",
      "Training:: Epoch 48, Iteration 10, Current loss 0.6003573641517512 Accuracy 61.87516054456717\n",
      "Training:: Epoch 48, Iteration 20, Current loss 0.664639485533178 Accuracy 61.01141021380303\n",
      "Training:: Epoch 48, Iteration 30, Current loss 0.6744682737555212 Accuracy 66.35106382978724\n",
      "Training:: Epoch 48, Iteration 40, Current loss 0.917385669596281 Accuracy 43.924443191429376\n",
      "Training:: Epoch 48, Iteration 50, Current loss 0.6427385588920358 Accuracy 64.10942610764198\n",
      "Training:: Epoch 48, Iteration 60, Current loss 0.6751473446352738 Accuracy 70.05844094636629\n",
      "Training:: Epoch 48, Iteration 70, Current loss 0.736988327241588 Accuracy 57.393715341959336\n",
      "Training:: Epoch 48, Iteration 80, Current loss 0.9944753340472179 Accuracy 61.24849326076634\n",
      "Training:: Epoch 48, Iteration 90, Current loss 0.7638653743279381 Accuracy 63.977649729352194\n",
      "Training:: Epoch 48, Iteration 100, Current loss 0.8033402038995558 Accuracy 51.248642779587406\n",
      "Training:: Epoch 48, Iteration 110, Current loss 0.4938875552341917 Accuracy 60.12235534030079\n",
      "Training:: Epoch 48, Iteration 120, Current loss 0.7030668015518499 Accuracy 65.90143862871136\n",
      "Training:: Epoch 48, Iteration 130, Current loss 0.758034899271327 Accuracy 65.60082516761217\n",
      "Training:: Epoch 48, Iteration 140, Current loss 0.7169913453325769 Accuracy 70.67257860186571\n",
      "Training:: Epoch 48, Iteration 150, Current loss 0.5879300824568464 Accuracy 66.18594043466595\n",
      "Training:: Epoch 48, Iteration 160, Current loss 0.8512724274050799 Accuracy 52.943502824858754\n",
      "Training:: Epoch 48, Iteration 170, Current loss 0.7094512106550024 Accuracy 53.00905521275743\n",
      "Training:: Epoch 48, Iteration 180, Current loss 0.8213821300355688 Accuracy 50.57663311463385\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 48, Probability Accuracy 55.42892869720748\n",
      "Starting Training\n",
      "Training:: Epoch 49, Iteration 0, Current loss 0.6069619204982839 Accuracy 59.57068952204463\n",
      "Training:: Epoch 49, Iteration 10, Current loss 0.7144410554001308 Accuracy 66.14125287511838\n",
      "Training:: Epoch 49, Iteration 20, Current loss 0.4953262310285672 Accuracy 60.515914291658\n",
      "Training:: Epoch 49, Iteration 30, Current loss 0.6514827739328259 Accuracy 57.585804629459076\n",
      "Training:: Epoch 49, Iteration 40, Current loss 0.7022700495081323 Accuracy 62.57718007273957\n",
      "Training:: Epoch 49, Iteration 50, Current loss 0.6411240664013175 Accuracy 58.56951871657754\n",
      "Training:: Epoch 49, Iteration 60, Current loss 0.6393438001381548 Accuracy 62.96011734301879\n",
      "Training:: Epoch 49, Iteration 70, Current loss 0.7105900869728025 Accuracy 57.22501797268153\n",
      "Training:: Epoch 49, Iteration 80, Current loss 0.6433680020102551 Accuracy 65.33143489954121\n",
      "Training:: Epoch 49, Iteration 90, Current loss 0.7506168599174874 Accuracy 71.68516188079167\n",
      "Training:: Epoch 49, Iteration 100, Current loss 0.5964287478947077 Accuracy 54.45147951931774\n",
      "Training:: Epoch 49, Iteration 110, Current loss 0.7211221226873568 Accuracy 59.523809523809526\n",
      "Training:: Epoch 49, Iteration 120, Current loss 0.8489331221090124 Accuracy 73.53517364203027\n",
      "Training:: Epoch 49, Iteration 130, Current loss 0.6652722202769666 Accuracy 57.51342642320086\n",
      "Training:: Epoch 49, Iteration 140, Current loss 0.4414482834757021 Accuracy 74.24281204675368\n",
      "Training:: Epoch 49, Iteration 150, Current loss 0.6056070488176472 Accuracy 71.41724336793541\n",
      "Training:: Epoch 49, Iteration 160, Current loss 0.5509284577828196 Accuracy 60.84230972982518\n",
      "Training:: Epoch 49, Iteration 170, Current loss 0.5922025875227239 Accuracy 70.35681917357591\n",
      "Training:: Epoch 49, Iteration 180, Current loss 0.7205319385649867 Accuracy 57.70657110712946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 49, Probability Accuracy 55.77616328533384\n",
      "Starting Training\n",
      "Training:: Epoch 50, Iteration 0, Current loss 0.6022743077798538 Accuracy 68.82917722362981\n",
      "Training:: Epoch 50, Iteration 10, Current loss 0.8315825912053993 Accuracy 62.49023075973839\n",
      "Training:: Epoch 50, Iteration 20, Current loss 0.6262790467261601 Accuracy 69.83314566485822\n",
      "Training:: Epoch 50, Iteration 30, Current loss 0.5639554467762642 Accuracy 74.51209992193598\n",
      "Training:: Epoch 50, Iteration 40, Current loss 0.5816930009987173 Accuracy 56.48475751402738\n",
      "Training:: Epoch 50, Iteration 50, Current loss 0.6000553675779824 Accuracy 67.92379745052469\n",
      "Training:: Epoch 50, Iteration 60, Current loss 0.6527944448183748 Accuracy 63.851407629518576\n",
      "Training:: Epoch 50, Iteration 70, Current loss 0.5771148384670708 Accuracy 57.32605383443372\n",
      "Training:: Epoch 50, Iteration 80, Current loss 0.5931846045707037 Accuracy 66.88135028593638\n",
      "Training:: Epoch 50, Iteration 90, Current loss 0.8640631059104963 Accuracy 63.83489173228347\n",
      "Training:: Epoch 50, Iteration 100, Current loss 0.6298975235885793 Accuracy 65.65382528486164\n",
      "Training:: Epoch 50, Iteration 110, Current loss 0.56721647958127 Accuracy 71.38086899865618\n",
      "Training:: Epoch 50, Iteration 120, Current loss 0.5909426008928587 Accuracy 58.107266743751666\n",
      "Training:: Epoch 50, Iteration 130, Current loss 0.7967509515124512 Accuracy 50.09077214260883\n",
      "Training:: Epoch 50, Iteration 140, Current loss 0.8008485817802219 Accuracy 60.56196422901894\n",
      "Training:: Epoch 50, Iteration 150, Current loss 0.47297390340720463 Accuracy 69.67461322468755\n",
      "Training:: Epoch 50, Iteration 160, Current loss 1.0745964016989513 Accuracy 60.88193456614509\n",
      "Training:: Epoch 50, Iteration 170, Current loss 0.6173382313004155 Accuracy 58.09564966868338\n",
      "Training:: Epoch 50, Iteration 180, Current loss 0.5722206995602881 Accuracy 67.95203142768531\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 50, Probability Accuracy 55.722742579468246\n",
      "Calculating Expectation\n",
      "Epoch 50 iter 0\n",
      "Epoch 50 iter 10\n",
      "Epoch 50 iter 20\n",
      "Epoch 50 iter 30\n",
      "Epoch 50 iter 40\n",
      "Epoch 50 iter 50\n",
      "Epoch 50 iter 60\n",
      "Epoch 50 iter 70\n",
      "Epoch 50 iter 80\n",
      "Epoch 50 iter 90\n",
      "Epoch 50 iter 100\n",
      "Epoch 50 iter 110\n",
      "Epoch 50 iter 120\n",
      "Epoch 50 iter 130\n",
      "Epoch 50 iter 140\n",
      "Epoch 50 iter 150\n",
      "Epoch 50 iter 160\n",
      "Epoch 50 iter 170\n",
      "Epoch 50 iter 180\n",
      "Train Boundary avergage error = 296.114\n",
      "Train From boundary avergage accuracy = 60.743\n",
      "Starting Training\n",
      "Training:: Epoch 51, Iteration 0, Current loss 0.6055392362000904 Accuracy 62.86434632886484\n",
      "Training:: Epoch 51, Iteration 10, Current loss 0.4909203577004039 Accuracy 68.52505596693645\n",
      "Training:: Epoch 51, Iteration 20, Current loss 0.6113393682228475 Accuracy 66.33368122856717\n",
      "Training:: Epoch 51, Iteration 30, Current loss 0.4835715920883715 Accuracy 59.94821249582359\n",
      "Training:: Epoch 51, Iteration 40, Current loss 0.41192776916149015 Accuracy 71.42017300747459\n",
      "Training:: Epoch 51, Iteration 50, Current loss 0.6696143818687779 Accuracy 75.78969684121263\n",
      "Training:: Epoch 51, Iteration 60, Current loss 0.5240701069806706 Accuracy 62.7263308500666\n",
      "Training:: Epoch 51, Iteration 70, Current loss 0.49929340702389785 Accuracy 68.1713384298022\n",
      "Training:: Epoch 51, Iteration 80, Current loss 0.7034578033012451 Accuracy 59.92977648368588\n",
      "Training:: Epoch 51, Iteration 90, Current loss 0.6406248284139233 Accuracy 64.22323019601491\n",
      "Training:: Epoch 51, Iteration 100, Current loss 0.6097173848913526 Accuracy 60.22546543175227\n",
      "Training:: Epoch 51, Iteration 110, Current loss 0.5025328502955442 Accuracy 67.518603827073\n",
      "Training:: Epoch 51, Iteration 120, Current loss 0.7106354511352592 Accuracy 67.52001685630005\n",
      "Training:: Epoch 51, Iteration 130, Current loss 0.6655477627642299 Accuracy 68.40551181102362\n",
      "Training:: Epoch 51, Iteration 140, Current loss 0.5769912395092769 Accuracy 67.06388316459099\n",
      "Training:: Epoch 51, Iteration 150, Current loss 0.7345242245205137 Accuracy 58.54412591343451\n",
      "Training:: Epoch 51, Iteration 160, Current loss 0.9123190399099154 Accuracy 67.4547983310153\n",
      "Training:: Epoch 51, Iteration 170, Current loss 1.120649837154152 Accuracy 70.46085508051083\n",
      "Training:: Epoch 51, Iteration 180, Current loss 1.855008072366153 Accuracy 57.55270958000112\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 51, Probability Accuracy 54.531262984199344\n",
      "Starting Training\n",
      "Training:: Epoch 52, Iteration 0, Current loss 0.8074252017579486 Accuracy 62.355432480860074\n",
      "Training:: Epoch 52, Iteration 10, Current loss 0.74518171027407 Accuracy 62.931111708322135\n",
      "Training:: Epoch 52, Iteration 20, Current loss 0.7556876533158361 Accuracy 65.27968596663395\n",
      "Training:: Epoch 52, Iteration 30, Current loss 2.4475054489888515 Accuracy 51.97550227798939\n",
      "Training:: Epoch 52, Iteration 40, Current loss 2.6510526603337334 Accuracy 56.444026340545626\n",
      "Training:: Epoch 52, Iteration 50, Current loss 1.61543406003565 Accuracy 68.41464850649605\n",
      "Training:: Epoch 52, Iteration 60, Current loss 1.4962250730222812 Accuracy 61.79113974389565\n",
      "Training:: Epoch 52, Iteration 70, Current loss 1.047508826018301 Accuracy 71.48212612130138\n",
      "Training:: Epoch 52, Iteration 80, Current loss 1.2923921740382034 Accuracy 66.30064054571167\n",
      "Training:: Epoch 52, Iteration 90, Current loss 0.9036879056845845 Accuracy 63.375151760420884\n",
      "Training:: Epoch 52, Iteration 100, Current loss 1.2547936634858572 Accuracy 61.83102275699712\n",
      "Training:: Epoch 52, Iteration 110, Current loss 0.9828402203965393 Accuracy 65.11028358636494\n",
      "Training:: Epoch 52, Iteration 120, Current loss 1.7318679887210495 Accuracy 64.88919667590028\n",
      "Training:: Epoch 52, Iteration 130, Current loss 1.0988013451608285 Accuracy 58.004031026690285\n",
      "Training:: Epoch 52, Iteration 140, Current loss 0.9617638968974663 Accuracy 64.2203321182665\n",
      "Training:: Epoch 52, Iteration 150, Current loss 0.801219920624301 Accuracy 59.73021018508836\n",
      "Training:: Epoch 52, Iteration 160, Current loss 0.737106272191906 Accuracy 68.59020655785065\n",
      "Training:: Epoch 52, Iteration 170, Current loss 0.7917700727470245 Accuracy 62.414754195576116\n",
      "Training:: Epoch 52, Iteration 180, Current loss 1.0841257589501687 Accuracy 55.58197529432233\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 52, Probability Accuracy 56.390303548321995\n",
      "Starting Training\n",
      "Training:: Epoch 53, Iteration 0, Current loss 1.7745643465974263 Accuracy 55.35487384280269\n",
      "Training:: Epoch 53, Iteration 10, Current loss 1.0290884844151822 Accuracy 63.482606188737265\n",
      "Training:: Epoch 53, Iteration 20, Current loss 1.3262389103037868 Accuracy 54.19047619047619\n",
      "Training:: Epoch 53, Iteration 30, Current loss 1.6612010411187148 Accuracy 68.08166313954936\n",
      "Training:: Epoch 53, Iteration 40, Current loss 1.0818019539690495 Accuracy 60.39009058975781\n",
      "Training:: Epoch 53, Iteration 50, Current loss 0.9141704514648854 Accuracy 56.71289635725384\n",
      "Training:: Epoch 53, Iteration 60, Current loss 1.0783938468561103 Accuracy 67.05546298500357\n",
      "Training:: Epoch 53, Iteration 70, Current loss 1.388751946655948 Accuracy 62.69899583639481\n",
      "Training:: Epoch 53, Iteration 80, Current loss 1.0090501839636659 Accuracy 48.66737739872068\n",
      "Training:: Epoch 53, Iteration 90, Current loss 0.7574208188184686 Accuracy 58.88572431820842\n",
      "Training:: Epoch 53, Iteration 100, Current loss 1.0172281744686609 Accuracy 66.44377520289929\n",
      "Training:: Epoch 53, Iteration 110, Current loss 0.6820295403545129 Accuracy 65.90323767476086\n",
      "Training:: Epoch 53, Iteration 120, Current loss 0.9273548586971953 Accuracy 62.96019235907026\n",
      "Training:: Epoch 53, Iteration 130, Current loss 0.4778881802697581 Accuracy 77.26545454545455\n",
      "Training:: Epoch 53, Iteration 140, Current loss 0.6189724017394428 Accuracy 65.62959477739223\n",
      "Training:: Epoch 53, Iteration 150, Current loss 0.999202862635481 Accuracy 71.3876432486298\n",
      "Training:: Epoch 53, Iteration 160, Current loss 0.7084251891794033 Accuracy 64.27581174753739\n",
      "Training:: Epoch 53, Iteration 170, Current loss 0.9644836168411531 Accuracy 66.95692450208429\n",
      "Training:: Epoch 53, Iteration 180, Current loss 0.7157026958700103 Accuracy 62.467801721429915\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 53, Probability Accuracy 57.34514920205294\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 54, Iteration 0, Current loss 0.6081746062316375 Accuracy 61.315630657815326\n",
      "Training:: Epoch 54, Iteration 10, Current loss 0.592183932300754 Accuracy 72.75874004845967\n",
      "Training:: Epoch 54, Iteration 20, Current loss 0.7279809307847799 Accuracy 57.214544893074965\n",
      "Training:: Epoch 54, Iteration 30, Current loss 0.7469364771023421 Accuracy 59.96587715776796\n",
      "Training:: Epoch 54, Iteration 40, Current loss 0.5508505470873223 Accuracy 67.08321499573985\n",
      "Training:: Epoch 54, Iteration 50, Current loss 0.5608999523634932 Accuracy 58.96481102215602\n",
      "Training:: Epoch 54, Iteration 60, Current loss 0.5925146524578605 Accuracy 69.3107932379714\n",
      "Training:: Epoch 54, Iteration 70, Current loss 0.5823858997515338 Accuracy 50.16021808790473\n",
      "Training:: Epoch 54, Iteration 80, Current loss 0.6455303022386856 Accuracy 68.5511579135246\n",
      "Training:: Epoch 54, Iteration 90, Current loss 0.5897100822914657 Accuracy 62.42569288967807\n",
      "Training:: Epoch 54, Iteration 100, Current loss 0.47541720747489635 Accuracy 72.58493182343425\n",
      "Training:: Epoch 54, Iteration 110, Current loss 0.7221093564463348 Accuracy 59.117460529390165\n",
      "Training:: Epoch 54, Iteration 120, Current loss 0.44971224234675006 Accuracy 58.37057097720605\n",
      "Training:: Epoch 54, Iteration 130, Current loss 0.5181469725234991 Accuracy 66.78212851405623\n",
      "Training:: Epoch 54, Iteration 140, Current loss 0.5536958468824599 Accuracy 64.52663107175414\n",
      "Training:: Epoch 54, Iteration 150, Current loss 0.5666965126550287 Accuracy 58.89654231739753\n",
      "Training:: Epoch 54, Iteration 160, Current loss 0.6234665693613959 Accuracy 65.89946181151953\n",
      "Training:: Epoch 54, Iteration 170, Current loss 0.5661108630880034 Accuracy 64.16809104931838\n",
      "Training:: Epoch 54, Iteration 180, Current loss 0.6967843664637992 Accuracy 74.55150291077581\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 54, Probability Accuracy 56.39861343590109\n",
      "Starting Training\n",
      "Training:: Epoch 55, Iteration 0, Current loss 0.49702480643417873 Accuracy 59.943890274314214\n",
      "Training:: Epoch 55, Iteration 10, Current loss 0.5437443057131688 Accuracy 64.42734689662295\n",
      "Training:: Epoch 55, Iteration 20, Current loss 0.6193320254298306 Accuracy 58.51360518579935\n",
      "Training:: Epoch 55, Iteration 30, Current loss 0.5806817680608767 Accuracy 60.310243380583046\n",
      "Training:: Epoch 55, Iteration 40, Current loss 0.5448949149339006 Accuracy 66.8437560007681\n",
      "Training:: Epoch 55, Iteration 50, Current loss 0.6312359998691107 Accuracy 72.89226412665722\n",
      "Training:: Epoch 55, Iteration 60, Current loss 0.5119132204753645 Accuracy 58.91081167789541\n",
      "Training:: Epoch 55, Iteration 70, Current loss 0.6223373039917767 Accuracy 62.103468389644185\n",
      "Training:: Epoch 55, Iteration 80, Current loss 0.5631395964669849 Accuracy 60.43010752688172\n",
      "Training:: Epoch 55, Iteration 90, Current loss 0.41507032120160425 Accuracy 66.63381785333004\n",
      "Training:: Epoch 55, Iteration 100, Current loss 0.6114189082463133 Accuracy 61.140601606097725\n",
      "Training:: Epoch 55, Iteration 110, Current loss 0.6534787064875112 Accuracy 67.61254941971687\n",
      "Training:: Epoch 55, Iteration 120, Current loss 0.6399743956191709 Accuracy 62.45657568238214\n",
      "Training:: Epoch 55, Iteration 130, Current loss 0.47799861549338496 Accuracy 76.14406542317818\n",
      "Training:: Epoch 55, Iteration 140, Current loss 0.5526012424152652 Accuracy 61.74210076857387\n",
      "Training:: Epoch 55, Iteration 150, Current loss 0.47315995823901974 Accuracy 64.4359528160824\n",
      "Training:: Epoch 55, Iteration 160, Current loss 0.4753798021876311 Accuracy 62.15016586459842\n",
      "Training:: Epoch 55, Iteration 170, Current loss 0.5765747187482493 Accuracy 70.63442958450335\n",
      "Training:: Epoch 55, Iteration 180, Current loss 0.6070185412139075 Accuracy 72.75564934493977\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 55, Probability Accuracy 56.373288064231474\n",
      "Calculating Expectation\n",
      "Epoch 55 iter 0\n",
      "Epoch 55 iter 10\n",
      "Epoch 55 iter 20\n",
      "Epoch 55 iter 30\n",
      "Epoch 55 iter 40\n",
      "Epoch 55 iter 50\n",
      "Epoch 55 iter 60\n",
      "Epoch 55 iter 70\n",
      "Epoch 55 iter 80\n",
      "Epoch 55 iter 90\n",
      "Epoch 55 iter 100\n",
      "Epoch 55 iter 110\n",
      "Epoch 55 iter 120\n",
      "Epoch 55 iter 130\n",
      "Epoch 55 iter 140\n",
      "Epoch 55 iter 150\n",
      "Epoch 55 iter 160\n",
      "Epoch 55 iter 170\n",
      "Epoch 55 iter 180\n",
      "Train Boundary avergage error = 296.422\n",
      "Train From boundary avergage accuracy = 60.585\n",
      "Starting Training\n",
      "Training:: Epoch 56, Iteration 0, Current loss 0.46948635574766967 Accuracy 61.012084592145015\n",
      "Training:: Epoch 56, Iteration 10, Current loss 0.39831043498962426 Accuracy 67.5894665766374\n",
      "Training:: Epoch 56, Iteration 20, Current loss 0.5370864621347561 Accuracy 75.43835427309126\n",
      "Training:: Epoch 56, Iteration 30, Current loss 0.5228703477312423 Accuracy 50.951050811386004\n",
      "Training:: Epoch 56, Iteration 40, Current loss 0.4484807829246169 Accuracy 62.5682677496149\n",
      "Training:: Epoch 56, Iteration 50, Current loss 0.6482163856652388 Accuracy 61.945851309948104\n",
      "Training:: Epoch 56, Iteration 60, Current loss 0.5409288650143286 Accuracy 67.40180798004988\n",
      "Training:: Epoch 56, Iteration 70, Current loss 0.4347066748464459 Accuracy 67.05987947172714\n",
      "Training:: Epoch 56, Iteration 80, Current loss 0.6286444078794057 Accuracy 55.778339122197664\n",
      "Training:: Epoch 56, Iteration 90, Current loss 0.6537354070713934 Accuracy 58.793184305143036\n",
      "Training:: Epoch 56, Iteration 100, Current loss 0.464289885647236 Accuracy 67.59458628114426\n",
      "Training:: Epoch 56, Iteration 110, Current loss 0.45429975674175693 Accuracy 69.07648725212465\n",
      "Training:: Epoch 56, Iteration 120, Current loss 0.6020557864465559 Accuracy 63.28832883288329\n",
      "Training:: Epoch 56, Iteration 130, Current loss 0.5192728870849276 Accuracy 63.72586141613025\n",
      "Training:: Epoch 56, Iteration 140, Current loss 0.48174543849699775 Accuracy 60.904081995378874\n",
      "Training:: Epoch 56, Iteration 150, Current loss 0.49554592240091994 Accuracy 66.54988852996041\n",
      "Training:: Epoch 56, Iteration 160, Current loss 0.5441746078438776 Accuracy 70.88438675239597\n",
      "Training:: Epoch 56, Iteration 170, Current loss 0.6533146481452108 Accuracy 59.914549923914315\n",
      "Training:: Epoch 56, Iteration 180, Current loss 0.4226496601764044 Accuracy 69.13267009414436\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 56, Probability Accuracy 55.90021803562172\n",
      "Starting Training\n",
      "Training:: Epoch 57, Iteration 0, Current loss 0.3687346211451994 Accuracy 78.28723001136794\n",
      "Training:: Epoch 57, Iteration 10, Current loss 0.3947381410634993 Accuracy 57.41422528591571\n",
      "Training:: Epoch 57, Iteration 20, Current loss 0.5558384356982309 Accuracy 65.2872381441974\n",
      "Training:: Epoch 57, Iteration 30, Current loss 0.4064398569069816 Accuracy 66.38781778968695\n",
      "Training:: Epoch 57, Iteration 40, Current loss 0.6479439805895566 Accuracy 65.08424008424008\n",
      "Training:: Epoch 57, Iteration 50, Current loss 0.518545958647842 Accuracy 68.55670103092784\n",
      "Training:: Epoch 57, Iteration 60, Current loss 0.6216455045515282 Accuracy 60.95133296653829\n",
      "Training:: Epoch 57, Iteration 70, Current loss 0.5015606245151415 Accuracy 70.25800176015564\n",
      "Training:: Epoch 57, Iteration 80, Current loss 0.5328696667076048 Accuracy 64.20657974734851\n",
      "Training:: Epoch 57, Iteration 90, Current loss 0.7178361513928562 Accuracy 57.50376695128077\n",
      "Training:: Epoch 57, Iteration 100, Current loss 0.4065032432811057 Accuracy 59.56057007125891\n",
      "Training:: Epoch 57, Iteration 110, Current loss 0.4430957784303602 Accuracy 73.56022491861498\n",
      "Training:: Epoch 57, Iteration 120, Current loss 0.5490784995053068 Accuracy 63.86861313868613\n",
      "Training:: Epoch 57, Iteration 130, Current loss 0.5557857522429693 Accuracy 64.60419169670271\n",
      "Training:: Epoch 57, Iteration 140, Current loss 0.5260419253717384 Accuracy 60.81933517612871\n",
      "Training:: Epoch 57, Iteration 150, Current loss 0.4758218933479417 Accuracy 61.94213803840166\n",
      "Training:: Epoch 57, Iteration 160, Current loss 0.5124380026571461 Accuracy 62.26625896742326\n",
      "Training:: Epoch 57, Iteration 170, Current loss 0.450162460862612 Accuracy 63.50161432345172\n",
      "Training:: Epoch 57, Iteration 180, Current loss 0.367905631230165 Accuracy 72.57190846105395\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 57, Probability Accuracy 55.92435628049432\n",
      "Starting Training\n",
      "Training:: Epoch 58, Iteration 0, Current loss 0.5015143783842235 Accuracy 61.60127464648476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 58, Iteration 10, Current loss 0.5313099926837291 Accuracy 52.335198248601316\n",
      "Training:: Epoch 58, Iteration 20, Current loss 0.4002745807550939 Accuracy 62.54868184541642\n",
      "Training:: Epoch 58, Iteration 30, Current loss 0.4738558654799829 Accuracy 67.05130481093556\n",
      "Training:: Epoch 58, Iteration 40, Current loss 0.536083798105744 Accuracy 61.26996647604023\n",
      "Training:: Epoch 58, Iteration 50, Current loss 0.6492008099517979 Accuracy 42.02297147091515\n",
      "Training:: Epoch 58, Iteration 60, Current loss 0.4137479852110646 Accuracy 66.71841413900167\n",
      "Training:: Epoch 58, Iteration 70, Current loss 0.4088337070325796 Accuracy 72.6299464705588\n",
      "Training:: Epoch 58, Iteration 80, Current loss 0.4444010189363466 Accuracy 73.31348132106118\n",
      "Training:: Epoch 58, Iteration 90, Current loss 0.4391534337730767 Accuracy 74.1438529144358\n",
      "Training:: Epoch 58, Iteration 100, Current loss 0.4352030595589179 Accuracy 72.43609725685785\n",
      "Training:: Epoch 58, Iteration 110, Current loss 0.570660423943661 Accuracy 62.98131370328426\n",
      "Training:: Epoch 58, Iteration 120, Current loss 0.6555296217804245 Accuracy 59.16051866756092\n",
      "Training:: Epoch 58, Iteration 130, Current loss 0.6553091418186787 Accuracy 50.353751629119344\n",
      "Training:: Epoch 58, Iteration 140, Current loss 0.4859313955993309 Accuracy 67.77145951800703\n",
      "Training:: Epoch 58, Iteration 150, Current loss 0.5082074686231354 Accuracy 70.64267060292948\n",
      "Training:: Epoch 58, Iteration 160, Current loss 0.45882424323164334 Accuracy 68.1534736996552\n",
      "Training:: Epoch 58, Iteration 170, Current loss 0.5551263383171285 Accuracy 63.76867100727691\n",
      "Training:: Epoch 58, Iteration 180, Current loss 0.45563768096279617 Accuracy 72.04778830963664\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 58, Probability Accuracy 56.25417967559782\n",
      "Starting Training\n",
      "Training:: Epoch 59, Iteration 0, Current loss 0.5138082791056126 Accuracy 66.36579297575652\n",
      "Training:: Epoch 59, Iteration 10, Current loss 0.621057048118975 Accuracy 71.14666666666666\n",
      "Training:: Epoch 59, Iteration 20, Current loss 0.5113877649435856 Accuracy 59.9390919158361\n",
      "Training:: Epoch 59, Iteration 30, Current loss 0.6455339925656428 Accuracy 65.30717604543108\n",
      "Training:: Epoch 59, Iteration 40, Current loss 0.46756480034909476 Accuracy 51.74774056353004\n",
      "Training:: Epoch 59, Iteration 50, Current loss 0.338506282445487 Accuracy 61.199123834751155\n",
      "Training:: Epoch 59, Iteration 60, Current loss 0.6670509850506664 Accuracy 64.23019773688422\n",
      "Training:: Epoch 59, Iteration 70, Current loss 0.4311223294167891 Accuracy 67.66858043453789\n",
      "Training:: Epoch 59, Iteration 80, Current loss 0.4479874728974417 Accuracy 68.24349101576824\n",
      "Training:: Epoch 59, Iteration 90, Current loss 0.4495600909566946 Accuracy 64.27029502191404\n",
      "Training:: Epoch 59, Iteration 100, Current loss 0.4134881980714433 Accuracy 73.48762874393276\n",
      "Training:: Epoch 59, Iteration 110, Current loss 0.5921382643942651 Accuracy 69.82840348881305\n",
      "Training:: Epoch 59, Iteration 120, Current loss 0.44840173580435694 Accuracy 68.820072521152\n",
      "Training:: Epoch 59, Iteration 130, Current loss 0.6166343452698968 Accuracy 62.482249360976994\n",
      "Training:: Epoch 59, Iteration 140, Current loss 0.624932263152499 Accuracy 64.95062793596011\n",
      "Training:: Epoch 59, Iteration 150, Current loss 0.43555871553788283 Accuracy 68.48313598851811\n",
      "Training:: Epoch 59, Iteration 160, Current loss 0.33237450477529035 Accuracy 67.94488188976378\n",
      "Training:: Epoch 59, Iteration 170, Current loss 0.5863339933474445 Accuracy 64.43164678458795\n",
      "Training:: Epoch 59, Iteration 180, Current loss 0.5468820343784785 Accuracy 70.22273647671392\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 59, Probability Accuracy 55.84620376635762\n",
      "Starting Training\n",
      "Training:: Epoch 60, Iteration 0, Current loss 0.3786426567224033 Accuracy 60.79833454018827\n",
      "Training:: Epoch 60, Iteration 10, Current loss 0.5952153894441771 Accuracy 58.114088411224046\n",
      "Training:: Epoch 60, Iteration 20, Current loss 0.4006053708430656 Accuracy 68.85772713993573\n",
      "Training:: Epoch 60, Iteration 30, Current loss 0.6011677722368108 Accuracy 55.70469798657718\n",
      "Training:: Epoch 60, Iteration 40, Current loss 0.5273228940334358 Accuracy 57.26468222043443\n",
      "Training:: Epoch 60, Iteration 50, Current loss 0.3898530231226499 Accuracy 65.82723279648609\n",
      "Training:: Epoch 60, Iteration 60, Current loss 0.38780799045133674 Accuracy 64.49864498644986\n",
      "Training:: Epoch 60, Iteration 70, Current loss 0.5871909228721469 Accuracy 55.805706745835394\n",
      "Training:: Epoch 60, Iteration 80, Current loss 0.3304650683489056 Accuracy 76.74676043498079\n",
      "Training:: Epoch 60, Iteration 90, Current loss 0.5959426347133414 Accuracy 70.67397045876945\n",
      "Training:: Epoch 60, Iteration 100, Current loss 0.6117588414671845 Accuracy 70.00885347498894\n",
      "Training:: Epoch 60, Iteration 110, Current loss 0.4501869557482118 Accuracy 66.86145823968354\n",
      "Training:: Epoch 60, Iteration 120, Current loss 0.5336851084628735 Accuracy 73.33426261499861\n",
      "Training:: Epoch 60, Iteration 130, Current loss 0.6195085686208182 Accuracy 58.44818785094436\n",
      "Training:: Epoch 60, Iteration 140, Current loss 0.5214618466482095 Accuracy 62.55408653846154\n",
      "Training:: Epoch 60, Iteration 150, Current loss 0.541841747096458 Accuracy 70.7926120463254\n",
      "Training:: Epoch 60, Iteration 160, Current loss 0.925309129513092 Accuracy 61.18490268279853\n",
      "Training:: Epoch 60, Iteration 170, Current loss 0.700987558287007 Accuracy 59.846547314578004\n",
      "Training:: Epoch 60, Iteration 180, Current loss 0.7902174930881527 Accuracy 61.80714112217634\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 60, Probability Accuracy 55.56366758866848\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Completed 160 videos selected frames calculation\n",
      "Completed 170 videos selected frames calculation\n",
      "Completed 180 videos selected frames calculation\n",
      "Total correct pivots labels selected =  60.13151239251391\n",
      "Calculating Expectation\n",
      "Epoch 60 iter 0\n",
      "Epoch 60 iter 10\n",
      "Epoch 60 iter 20\n",
      "Epoch 60 iter 30\n",
      "Epoch 60 iter 40\n",
      "Epoch 60 iter 50\n",
      "Epoch 60 iter 60\n",
      "Epoch 60 iter 70\n",
      "Epoch 60 iter 80\n",
      "Epoch 60 iter 90\n",
      "Epoch 60 iter 100\n",
      "Epoch 60 iter 110\n",
      "Epoch 60 iter 120\n",
      "Epoch 60 iter 130\n",
      "Epoch 60 iter 140\n",
      "Epoch 60 iter 150\n",
      "Epoch 60 iter 160\n",
      "Epoch 60 iter 170\n",
      "Epoch 60 iter 180\n",
      "Train Boundary avergage error = 295.535\n",
      "Train From boundary avergage accuracy = 60.448\n",
      "Starting Training\n",
      "Training:: Epoch 61, Iteration 0, Current loss 0.5568705100130656 Accuracy 58.950412439556274\n",
      "Training:: Epoch 61, Iteration 10, Current loss 0.9295109464458089 Accuracy 67.99422452171821\n",
      "Training:: Epoch 61, Iteration 20, Current loss 2.2429833689535243 Accuracy 60.18737339635381\n",
      "Training:: Epoch 61, Iteration 30, Current loss 1.3806742843345243 Accuracy 67.95701795368083\n",
      "Training:: Epoch 61, Iteration 40, Current loss 7.567541789493264 Accuracy 34.08350242882617\n",
      "Training:: Epoch 61, Iteration 50, Current loss 6.826339183055322 Accuracy 35.340720221606645\n",
      "Training:: Epoch 61, Iteration 60, Current loss 2.160715539873153 Accuracy 66.93783389995143\n",
      "Training:: Epoch 61, Iteration 70, Current loss 2.285407251035952 Accuracy 55.84263979143157\n",
      "Training:: Epoch 61, Iteration 80, Current loss 2.061454371018314 Accuracy 62.593057298201586\n",
      "Training:: Epoch 61, Iteration 90, Current loss 1.9943001240961409 Accuracy 56.630203435133396\n",
      "Training:: Epoch 61, Iteration 100, Current loss 1.7590065725953603 Accuracy 59.65048209366391\n",
      "Training:: Epoch 61, Iteration 110, Current loss 2.802882039328238 Accuracy 57.91333019312294\n",
      "Training:: Epoch 61, Iteration 120, Current loss 6.3000495055313035 Accuracy 51.76899063475546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 61, Iteration 130, Current loss 1.6534373128596274 Accuracy 72.76595744680851\n",
      "Training:: Epoch 61, Iteration 140, Current loss 2.2724162092270914 Accuracy 61.02977061981454\n",
      "Training:: Epoch 61, Iteration 150, Current loss 1.3353150368840145 Accuracy 58.64817645774186\n",
      "Training:: Epoch 61, Iteration 160, Current loss 1.4244456122488314 Accuracy 61.867676478994\n",
      "Training:: Epoch 61, Iteration 170, Current loss 7.093429486890868 Accuracy 55.96126082771896\n",
      "Training:: Epoch 61, Iteration 180, Current loss 1.8226431729262456 Accuracy 58.87875901483195\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 61, Probability Accuracy 50.584659947529\n",
      "Starting Training\n",
      "Training:: Epoch 62, Iteration 0, Current loss 1.4160961745993983 Accuracy 63.55004158580538\n",
      "Training:: Epoch 62, Iteration 10, Current loss 1.139499151853508 Accuracy 66.77704624254937\n",
      "Training:: Epoch 62, Iteration 20, Current loss 0.8453893105925199 Accuracy 64.37147121811928\n",
      "Training:: Epoch 62, Iteration 30, Current loss 0.9357057143867211 Accuracy 66.15728021978022\n",
      "Training:: Epoch 62, Iteration 40, Current loss 1.0763291378453905 Accuracy 61.1274575364451\n",
      "Training:: Epoch 62, Iteration 50, Current loss 0.959023291984932 Accuracy 60.2369401673346\n",
      "Training:: Epoch 62, Iteration 60, Current loss 1.216638072544644 Accuracy 66.95304845881378\n",
      "Training:: Epoch 62, Iteration 70, Current loss 0.9343507503846643 Accuracy 62.3161558324913\n",
      "Training:: Epoch 62, Iteration 80, Current loss 0.9762824344033051 Accuracy 60.21460481817043\n",
      "Training:: Epoch 62, Iteration 90, Current loss 0.8109309028053813 Accuracy 73.7393518065211\n",
      "Training:: Epoch 62, Iteration 100, Current loss 0.7644597155847241 Accuracy 64.30366027883147\n",
      "Training:: Epoch 62, Iteration 110, Current loss 1.4365218159124844 Accuracy 68.79494965638484\n",
      "Training:: Epoch 62, Iteration 120, Current loss 0.7547402402131753 Accuracy 62.897995283018865\n",
      "Training:: Epoch 62, Iteration 130, Current loss 0.7494932970798371 Accuracy 62.45330762742499\n",
      "Training:: Epoch 62, Iteration 140, Current loss 0.7062001562861766 Accuracy 56.74099897818116\n",
      "Training:: Epoch 62, Iteration 150, Current loss 0.8010347581208224 Accuracy 56.831279368738365\n",
      "Training:: Epoch 62, Iteration 160, Current loss 0.8796029654188151 Accuracy 60.187553282182435\n",
      "Training:: Epoch 62, Iteration 170, Current loss 1.040846812146119 Accuracy 66.25893413920468\n",
      "Training:: Epoch 62, Iteration 180, Current loss 2.1620337204777393 Accuracy 44.5790499484083\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 62, Probability Accuracy 51.217200675870856\n",
      "Starting Training\n",
      "Training:: Epoch 63, Iteration 0, Current loss 1.598592710486835 Accuracy 54.7109375\n",
      "Training:: Epoch 63, Iteration 10, Current loss 2.136127539231026 Accuracy 60.20155485171322\n",
      "Training:: Epoch 63, Iteration 20, Current loss 1.9411593173003832 Accuracy 69.40764674205708\n",
      "Training:: Epoch 63, Iteration 30, Current loss 0.649194054411051 Accuracy 60.71702748349455\n",
      "Training:: Epoch 63, Iteration 40, Current loss 0.8330534213681366 Accuracy 66.5729736335584\n",
      "Training:: Epoch 63, Iteration 50, Current loss 0.8280022549457737 Accuracy 68.0514729897446\n",
      "Training:: Epoch 63, Iteration 60, Current loss 0.628561872873122 Accuracy 61.800022444170125\n",
      "Training:: Epoch 63, Iteration 70, Current loss 0.7305525230329115 Accuracy 71.8681718863802\n",
      "Training:: Epoch 63, Iteration 80, Current loss 0.6924160915522487 Accuracy 59.97063861022755\n",
      "Training:: Epoch 63, Iteration 90, Current loss 0.6930521629461007 Accuracy 67.97850396265335\n",
      "Training:: Epoch 63, Iteration 100, Current loss 0.9508118898990954 Accuracy 56.79955549381859\n",
      "Training:: Epoch 63, Iteration 110, Current loss 0.7563536135866417 Accuracy 51.24849578820698\n",
      "Training:: Epoch 63, Iteration 120, Current loss 1.3070817243731125 Accuracy 64.17837207875851\n",
      "Training:: Epoch 63, Iteration 130, Current loss 3.5551212950549766 Accuracy 53.763712653556446\n",
      "Training:: Epoch 63, Iteration 140, Current loss 3.358389815731326 Accuracy 61.57325149410435\n",
      "Training:: Epoch 63, Iteration 150, Current loss 1.1976107137358825 Accuracy 67.95109873104302\n",
      "Training:: Epoch 63, Iteration 160, Current loss 2.9295066345392917 Accuracy 63.65410599009158\n",
      "Training:: Epoch 63, Iteration 170, Current loss 2.0311872330613543 Accuracy 57.291543465405084\n",
      "Training:: Epoch 63, Iteration 180, Current loss 2.1603849983720815 Accuracy 66.16807715016729\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 63, Probability Accuracy 51.94530511137228\n",
      "Starting Training\n",
      "Training:: Epoch 64, Iteration 0, Current loss 1.6303754357565514 Accuracy 63.74601414113406\n",
      "Training:: Epoch 64, Iteration 10, Current loss 2.285506503632866 Accuracy 53.360938578329886\n",
      "Training:: Epoch 64, Iteration 20, Current loss 1.3958528351200912 Accuracy 69.48294243070363\n",
      "Training:: Epoch 64, Iteration 30, Current loss 1.1098466065555779 Accuracy 63.626198083067095\n",
      "Training:: Epoch 64, Iteration 40, Current loss 1.361281429238399 Accuracy 64.54838709677419\n",
      "Training:: Epoch 64, Iteration 50, Current loss 0.8029066836932884 Accuracy 64.30730272831237\n",
      "Training:: Epoch 64, Iteration 60, Current loss 1.6586060137996645 Accuracy 69.58564715933362\n",
      "Training:: Epoch 64, Iteration 70, Current loss 0.7255997770867106 Accuracy 59.84677340143404\n",
      "Training:: Epoch 64, Iteration 80, Current loss 0.9579943418276109 Accuracy 57.674368152728064\n",
      "Training:: Epoch 64, Iteration 90, Current loss 1.0147784782377123 Accuracy 63.579498308546626\n",
      "Training:: Epoch 64, Iteration 100, Current loss 0.8288230338127107 Accuracy 61.91939487058267\n",
      "Training:: Epoch 64, Iteration 110, Current loss 0.8154635317326088 Accuracy 66.64624004202048\n",
      "Training:: Epoch 64, Iteration 120, Current loss 1.0435243123187306 Accuracy 65.52486187845304\n",
      "Training:: Epoch 64, Iteration 130, Current loss 0.6112538963282877 Accuracy 72.43342142711933\n",
      "Training:: Epoch 64, Iteration 140, Current loss 0.7014732665267512 Accuracy 65.73661586557249\n",
      "Training:: Epoch 64, Iteration 150, Current loss 0.7540227963490767 Accuracy 57.29326731546298\n",
      "Training:: Epoch 64, Iteration 160, Current loss 0.6013303057117734 Accuracy 67.84425736620565\n",
      "Training:: Epoch 64, Iteration 170, Current loss 0.9188611010952182 Accuracy 65.54396568531878\n",
      "Training:: Epoch 64, Iteration 180, Current loss 0.7140471489716315 Accuracy 67.0564966893112\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 64, Probability Accuracy 54.980590476868834\n",
      "Starting Training\n",
      "Training:: Epoch 65, Iteration 0, Current loss 1.1135510559613422 Accuracy 61.918689675343664\n",
      "Training:: Epoch 65, Iteration 10, Current loss 0.6033914590814914 Accuracy 65.22523571179141\n",
      "Training:: Epoch 65, Iteration 20, Current loss 0.5807546806205262 Accuracy 66.1930029678928\n",
      "Training:: Epoch 65, Iteration 30, Current loss 0.5244111404307427 Accuracy 70.45504385964912\n",
      "Training:: Epoch 65, Iteration 40, Current loss 0.7009237990167407 Accuracy 62.844276204150894\n",
      "Training:: Epoch 65, Iteration 50, Current loss 0.4262859452520757 Accuracy 70.86736276232813\n",
      "Training:: Epoch 65, Iteration 60, Current loss 0.6372771810321616 Accuracy 59.11256700416915\n",
      "Training:: Epoch 65, Iteration 70, Current loss 0.445162493930359 Accuracy 65.62518562518562\n",
      "Training:: Epoch 65, Iteration 80, Current loss 0.607175266535483 Accuracy 65.78266822169262\n",
      "Training:: Epoch 65, Iteration 90, Current loss 0.6178912547745721 Accuracy 66.07919432364386\n",
      "Training:: Epoch 65, Iteration 100, Current loss 0.5156968914677904 Accuracy 61.30321317892677\n",
      "Training:: Epoch 65, Iteration 110, Current loss 0.7272345138176156 Accuracy 63.50275207869774\n",
      "Training:: Epoch 65, Iteration 120, Current loss 0.46243913581102214 Accuracy 59.95412844036697\n",
      "Training:: Epoch 65, Iteration 130, Current loss 0.6488276835974146 Accuracy 64.999339236157\n",
      "Training:: Epoch 65, Iteration 140, Current loss 0.5645657767858789 Accuracy 67.74119006354708\n",
      "Training:: Epoch 65, Iteration 150, Current loss 0.6163513662779829 Accuracy 60.80907644129575\n",
      "Training:: Epoch 65, Iteration 160, Current loss 0.4986742166261837 Accuracy 65.94848053181387\n",
      "Training:: Epoch 65, Iteration 170, Current loss 0.512708139361992 Accuracy 63.98898023438866\n",
      "Training:: Epoch 65, Iteration 180, Current loss 0.6225749578198914 Accuracy 62.52193695157621\n",
      "Calculating Validation Data Accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 65, Probability Accuracy 54.703000660833915\n",
      "Calculating Expectation\n",
      "Epoch 65 iter 0\n",
      "Epoch 65 iter 10\n",
      "Epoch 65 iter 20\n",
      "Epoch 65 iter 30\n",
      "Epoch 65 iter 40\n",
      "Epoch 65 iter 50\n",
      "Epoch 65 iter 60\n",
      "Epoch 65 iter 70\n",
      "Epoch 65 iter 80\n",
      "Epoch 65 iter 90\n",
      "Epoch 65 iter 100\n",
      "Epoch 65 iter 110\n",
      "Epoch 65 iter 120\n",
      "Epoch 65 iter 130\n",
      "Epoch 65 iter 140\n",
      "Epoch 65 iter 150\n",
      "Epoch 65 iter 160\n",
      "Epoch 65 iter 170\n",
      "Epoch 65 iter 180\n",
      "Train Boundary avergage error = 295.501\n",
      "Train From boundary avergage accuracy = 60.586\n",
      "Starting Training\n",
      "Training:: Epoch 66, Iteration 0, Current loss 0.3844088887391946 Accuracy 58.25436996056736\n",
      "Training:: Epoch 66, Iteration 10, Current loss 0.6902973220395825 Accuracy 60.756551141166526\n",
      "Training:: Epoch 66, Iteration 20, Current loss 0.3954437715266877 Accuracy 58.36447254958321\n",
      "Training:: Epoch 66, Iteration 30, Current loss 0.6129405886433776 Accuracy 67.36998269183219\n",
      "Training:: Epoch 66, Iteration 40, Current loss 0.45126025458656166 Accuracy 65.46617699324725\n",
      "Training:: Epoch 66, Iteration 50, Current loss 0.6356828249102056 Accuracy 68.06696474992201\n",
      "Training:: Epoch 66, Iteration 60, Current loss 0.5762676126286925 Accuracy 67.88105333630887\n",
      "Training:: Epoch 66, Iteration 70, Current loss 0.482805771722398 Accuracy 71.73047087928215\n",
      "Training:: Epoch 66, Iteration 80, Current loss 0.5455095356592512 Accuracy 59.984724751777215\n",
      "Training:: Epoch 66, Iteration 90, Current loss 0.5296670220114659 Accuracy 68.2975871313673\n",
      "Training:: Epoch 66, Iteration 100, Current loss 0.5127925108075216 Accuracy 68.92534474560152\n",
      "Training:: Epoch 66, Iteration 110, Current loss 0.4131817547281178 Accuracy 67.45511541749786\n",
      "Training:: Epoch 66, Iteration 120, Current loss 0.48037504118363417 Accuracy 61.69922480620155\n",
      "Training:: Epoch 66, Iteration 130, Current loss 0.397566322810129 Accuracy 60.19649984648449\n",
      "Training:: Epoch 66, Iteration 140, Current loss 0.6164760672283314 Accuracy 60.44097060195987\n",
      "Training:: Epoch 66, Iteration 150, Current loss 0.578627110797426 Accuracy 74.71933471933473\n",
      "Training:: Epoch 66, Iteration 160, Current loss 0.4261301006542914 Accuracy 72.75034159672067\n",
      "Training:: Epoch 66, Iteration 170, Current loss 0.6395922962073135 Accuracy 58.3293403609647\n",
      "Training:: Epoch 66, Iteration 180, Current loss 0.47498700993331433 Accuracy 65.4789596109114\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 66, Probability Accuracy 54.91035214137889\n",
      "Starting Training\n",
      "Training:: Epoch 67, Iteration 0, Current loss 0.5275063553126808 Accuracy 52.86790920167878\n",
      "Training:: Epoch 67, Iteration 10, Current loss 0.5167404231124247 Accuracy 60.81359423274974\n",
      "Training:: Epoch 67, Iteration 20, Current loss 0.42243660171168057 Accuracy 66.07594936708861\n",
      "Training:: Epoch 67, Iteration 30, Current loss 0.5554749555236861 Accuracy 64.34006289946231\n",
      "Training:: Epoch 67, Iteration 40, Current loss 0.4109796202344933 Accuracy 69.5824546604808\n",
      "Training:: Epoch 67, Iteration 50, Current loss 0.37955289189494945 Accuracy 55.60387313735722\n",
      "Training:: Epoch 67, Iteration 60, Current loss 0.5453226138401859 Accuracy 67.08688489363226\n",
      "Training:: Epoch 67, Iteration 70, Current loss 0.5277685630053406 Accuracy 52.41739642357789\n",
      "Training:: Epoch 67, Iteration 80, Current loss 0.393031855065877 Accuracy 66.34835372525615\n",
      "Training:: Epoch 67, Iteration 90, Current loss 0.5347139051101286 Accuracy 52.454606590450574\n",
      "Training:: Epoch 67, Iteration 100, Current loss 0.6848200990038746 Accuracy 65.29436476024725\n",
      "Training:: Epoch 67, Iteration 110, Current loss 0.4429165195519271 Accuracy 60.34763036138552\n",
      "Training:: Epoch 67, Iteration 120, Current loss 0.44758084208890353 Accuracy 58.26979770255159\n",
      "Training:: Epoch 67, Iteration 130, Current loss 0.4561445249820617 Accuracy 66.26012641324668\n",
      "Training:: Epoch 67, Iteration 140, Current loss 0.5043253373332038 Accuracy 58.715165737753004\n",
      "Training:: Epoch 67, Iteration 150, Current loss 0.3443067907828993 Accuracy 63.566265060240966\n",
      "Training:: Epoch 67, Iteration 160, Current loss 0.43067945247946104 Accuracy 64.1096521538816\n",
      "Training:: Epoch 67, Iteration 170, Current loss 0.44049063950160944 Accuracy 62.50583294447037\n",
      "Training:: Epoch 67, Iteration 180, Current loss 0.42859644337981884 Accuracy 51.91624202457928\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 67, Probability Accuracy 55.59769855684952\n",
      "Starting Training\n",
      "Training:: Epoch 68, Iteration 0, Current loss 0.5218922110701175 Accuracy 62.66615664148417\n",
      "Training:: Epoch 68, Iteration 10, Current loss 0.4234257916772779 Accuracy 65.29052929940231\n",
      "Training:: Epoch 68, Iteration 20, Current loss 0.5314969012345381 Accuracy 61.07655502392345\n",
      "Training:: Epoch 68, Iteration 30, Current loss 0.35011073800901216 Accuracy 66.56035461376291\n",
      "Training:: Epoch 68, Iteration 40, Current loss 0.4260404170458653 Accuracy 68.86878285483219\n",
      "Training:: Epoch 68, Iteration 50, Current loss 0.4168672985651991 Accuracy 58.17336989640463\n",
      "Training:: Epoch 68, Iteration 60, Current loss 0.4829821862954652 Accuracy 65.28037966779068\n",
      "Training:: Epoch 68, Iteration 70, Current loss 0.4621048251095463 Accuracy 56.861711474257596\n",
      "Training:: Epoch 68, Iteration 80, Current loss 0.4339607009774842 Accuracy 60.89268367503451\n",
      "Training:: Epoch 68, Iteration 90, Current loss 0.4556198588340813 Accuracy 69.01211089980983\n",
      "Training:: Epoch 68, Iteration 100, Current loss 0.48655785255260975 Accuracy 59.17580788615476\n",
      "Training:: Epoch 68, Iteration 110, Current loss 0.39775446552565275 Accuracy 65.30156366344006\n",
      "Training:: Epoch 68, Iteration 120, Current loss 0.4350659965606374 Accuracy 63.41559335365254\n",
      "Training:: Epoch 68, Iteration 130, Current loss 0.4554279255162214 Accuracy 64.5587213342599\n",
      "Training:: Epoch 68, Iteration 140, Current loss 0.41508915432192617 Accuracy 67.19659890679146\n",
      "Training:: Epoch 68, Iteration 150, Current loss 0.3872717760284829 Accuracy 68.48711166433276\n",
      "Training:: Epoch 68, Iteration 160, Current loss 0.3837758171121265 Accuracy 72.24251278305333\n",
      "Training:: Epoch 68, Iteration 170, Current loss 0.5513620817240477 Accuracy 71.5952709964686\n",
      "Training:: Epoch 68, Iteration 180, Current loss 0.40606116087801003 Accuracy 65.19819100824688\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 68, Probability Accuracy 55.339102769566814\n",
      "Starting Training\n",
      "Training:: Epoch 69, Iteration 0, Current loss 0.3564176645570667 Accuracy 64.49307726663689\n",
      "Training:: Epoch 69, Iteration 10, Current loss 0.40565187756345333 Accuracy 58.844570145156595\n",
      "Training:: Epoch 69, Iteration 20, Current loss 0.4200231857227748 Accuracy 64.61490513849391\n",
      "Training:: Epoch 69, Iteration 30, Current loss 0.3465147962618196 Accuracy 59.94940050599494\n",
      "Training:: Epoch 69, Iteration 40, Current loss 0.359878997735851 Accuracy 73.5947426067908\n",
      "Training:: Epoch 69, Iteration 50, Current loss 0.35376643953349446 Accuracy 61.12589559877175\n",
      "Training:: Epoch 69, Iteration 60, Current loss 0.39433527969017457 Accuracy 51.02462754636667\n",
      "Training:: Epoch 69, Iteration 70, Current loss 0.27314850419113396 Accuracy 68.15963427441774\n",
      "Training:: Epoch 69, Iteration 80, Current loss 0.47214564985945795 Accuracy 72.32371370576296\n",
      "Training:: Epoch 69, Iteration 90, Current loss 0.3691080101416416 Accuracy 65.10979435343326\n",
      "Training:: Epoch 69, Iteration 100, Current loss 0.3980762289411665 Accuracy 71.80017939695026\n",
      "Training:: Epoch 69, Iteration 110, Current loss 0.3086806754063202 Accuracy 70.09699161597896\n",
      "Training:: Epoch 69, Iteration 120, Current loss 0.36169172027342716 Accuracy 55.195618153364634\n",
      "Training:: Epoch 69, Iteration 130, Current loss 0.3706770542897917 Accuracy 64.33742059388388\n",
      "Training:: Epoch 69, Iteration 140, Current loss 0.5008694411970008 Accuracy 53.382023404431905\n",
      "Training:: Epoch 69, Iteration 150, Current loss 0.360447297644918 Accuracy 67.50801840747455\n",
      "Training:: Epoch 69, Iteration 160, Current loss 0.3730485497854136 Accuracy 67.11759639256219\n",
      "Training:: Epoch 69, Iteration 170, Current loss 0.354994265443802 Accuracy 55.248891079349434\n",
      "Training:: Epoch 69, Iteration 180, Current loss 0.4078362700274103 Accuracy 54.25039334681951\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 69, Probability Accuracy 55.126409218435285\n",
      "Starting Training\n",
      "Training:: Epoch 70, Iteration 0, Current loss 0.3350398523837201 Accuracy 58.70463357274519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 70, Iteration 10, Current loss 0.5363236673440889 Accuracy 68.0808418239519\n",
      "Training:: Epoch 70, Iteration 20, Current loss 0.32687441775518417 Accuracy 61.71341316402797\n",
      "Training:: Epoch 70, Iteration 30, Current loss 0.6213151943901971 Accuracy 59.16130021465808\n",
      "Training:: Epoch 70, Iteration 40, Current loss 0.47946928668824584 Accuracy 58.02776051377667\n",
      "Training:: Epoch 70, Iteration 50, Current loss 0.4202224973670608 Accuracy 64.15611814345992\n",
      "Training:: Epoch 70, Iteration 60, Current loss 0.49429537426214554 Accuracy 56.19118994087768\n",
      "Training:: Epoch 70, Iteration 70, Current loss 0.4304052671982119 Accuracy 56.52054669287379\n",
      "Training:: Epoch 70, Iteration 80, Current loss 0.4252636786103881 Accuracy 66.15522729127561\n",
      "Training:: Epoch 70, Iteration 90, Current loss 0.39449657163425617 Accuracy 62.27562080633137\n",
      "Training:: Epoch 70, Iteration 100, Current loss 0.3464980857039458 Accuracy 62.5817909889699\n",
      "Training:: Epoch 70, Iteration 110, Current loss 0.4086396728096764 Accuracy 67.25266875669669\n",
      "Training:: Epoch 70, Iteration 120, Current loss 0.4614693149233974 Accuracy 74.41296124473628\n",
      "Training:: Epoch 70, Iteration 130, Current loss 0.333958819969764 Accuracy 64.70455570590889\n",
      "Training:: Epoch 70, Iteration 140, Current loss 0.44230867450231837 Accuracy 49.79373469124661\n",
      "Training:: Epoch 70, Iteration 150, Current loss 0.5369649071527282 Accuracy 62.87269898885144\n",
      "Training:: Epoch 70, Iteration 160, Current loss 0.43874039022395633 Accuracy 68.7446036953894\n",
      "Training:: Epoch 70, Iteration 170, Current loss 0.4327957186710509 Accuracy 68.67749419953596\n",
      "Training:: Epoch 70, Iteration 180, Current loss 0.47887896684499415 Accuracy 59.13805580123824\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 70, Probability Accuracy 55.25145324105401\n",
      "Calculating Expectation\n",
      "Epoch 70 iter 0\n",
      "Epoch 70 iter 10\n",
      "Epoch 70 iter 20\n",
      "Epoch 70 iter 30\n",
      "Epoch 70 iter 40\n",
      "Epoch 70 iter 50\n",
      "Epoch 70 iter 60\n",
      "Epoch 70 iter 70\n",
      "Epoch 70 iter 80\n",
      "Epoch 70 iter 90\n",
      "Epoch 70 iter 100\n",
      "Epoch 70 iter 110\n",
      "Epoch 70 iter 120\n",
      "Epoch 70 iter 130\n",
      "Epoch 70 iter 140\n",
      "Epoch 70 iter 150\n",
      "Epoch 70 iter 160\n",
      "Epoch 70 iter 170\n",
      "Epoch 70 iter 180\n",
      "Train Boundary avergage error = 296.297\n",
      "Train From boundary avergage accuracy = 60.461\n",
      "Starting Training\n",
      "Training:: Epoch 71, Iteration 0, Current loss 0.29850001981498986 Accuracy 43.11645082436157\n",
      "Training:: Epoch 71, Iteration 10, Current loss 0.36737702975374764 Accuracy 58.59935311489242\n",
      "Training:: Epoch 71, Iteration 20, Current loss 0.42528055793840536 Accuracy 50.861126298523786\n",
      "Training:: Epoch 71, Iteration 30, Current loss 0.33423946964510515 Accuracy 71.91215068704648\n",
      "Training:: Epoch 71, Iteration 40, Current loss 0.3306091736008945 Accuracy 64.03867032001241\n",
      "Training:: Epoch 71, Iteration 50, Current loss 0.3726165373324661 Accuracy 51.62580085745942\n",
      "Training:: Epoch 71, Iteration 60, Current loss 0.4022716793218712 Accuracy 62.44439737343783\n",
      "Training:: Epoch 71, Iteration 70, Current loss 0.36792416681427464 Accuracy 73.14267623469819\n",
      "Training:: Epoch 71, Iteration 80, Current loss 0.5049149522491767 Accuracy 64.74380165289256\n",
      "Training:: Epoch 71, Iteration 90, Current loss 0.388594410447492 Accuracy 70.03719851205952\n",
      "Training:: Epoch 71, Iteration 100, Current loss 0.578424671585779 Accuracy 67.9498235985888\n",
      "Training:: Epoch 71, Iteration 110, Current loss 0.5161830727497478 Accuracy 62.16199903428296\n",
      "Training:: Epoch 71, Iteration 120, Current loss 0.38011594649768704 Accuracy 68.59294713873443\n",
      "Training:: Epoch 71, Iteration 130, Current loss 0.3967039186537485 Accuracy 65.57788944723617\n",
      "Training:: Epoch 71, Iteration 140, Current loss 0.40149574613280853 Accuracy 65.75018261504748\n",
      "Training:: Epoch 71, Iteration 150, Current loss 0.36320254690061315 Accuracy 54.92659865638218\n",
      "Training:: Epoch 71, Iteration 160, Current loss 0.3912550760581245 Accuracy 64.24794690066375\n",
      "Training:: Epoch 71, Iteration 170, Current loss 0.3400169225523044 Accuracy 69.0506965388482\n",
      "Training:: Epoch 71, Iteration 180, Current loss 0.37620819855610976 Accuracy 67.78704612365064\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 71, Probability Accuracy 55.15371313476659\n",
      "Starting Training\n",
      "Training:: Epoch 72, Iteration 0, Current loss 0.29589446210922205 Accuracy 69.71787159008402\n",
      "Training:: Epoch 72, Iteration 10, Current loss 0.41978944878870184 Accuracy 61.7226790133312\n",
      "Training:: Epoch 72, Iteration 20, Current loss 0.3883098055905015 Accuracy 73.02739931127414\n",
      "Training:: Epoch 72, Iteration 30, Current loss 0.32027617638569433 Accuracy 62.85884892747232\n",
      "Training:: Epoch 72, Iteration 40, Current loss 0.2835489727109253 Accuracy 65.86188744257274\n",
      "Training:: Epoch 72, Iteration 50, Current loss 0.41354558884655934 Accuracy 61.87397708674305\n",
      "Training:: Epoch 72, Iteration 60, Current loss 0.4455895150286572 Accuracy 65.7955383480826\n",
      "Training:: Epoch 72, Iteration 70, Current loss 0.3780964913410445 Accuracy 53.93354160749787\n",
      "Training:: Epoch 72, Iteration 80, Current loss 0.3396781244592034 Accuracy 67.11041503523884\n",
      "Training:: Epoch 72, Iteration 90, Current loss 0.34320597026856736 Accuracy 64.85169573456051\n",
      "Training:: Epoch 72, Iteration 100, Current loss 0.5843117042887085 Accuracy 57.728077945084145\n",
      "Training:: Epoch 72, Iteration 110, Current loss 0.36581173613148343 Accuracy 64.885748978916\n",
      "Training:: Epoch 72, Iteration 120, Current loss 0.4727655188090384 Accuracy 55.84143605086013\n",
      "Training:: Epoch 72, Iteration 130, Current loss 0.4722911688396372 Accuracy 59.64685615848406\n",
      "Training:: Epoch 72, Iteration 140, Current loss 0.4758231364273079 Accuracy 70.68400608005405\n",
      "Training:: Epoch 72, Iteration 150, Current loss 0.4433315477976088 Accuracy 68.98661567877629\n",
      "Training:: Epoch 72, Iteration 160, Current loss 0.3873766094130655 Accuracy 55.97680642283675\n",
      "Training:: Epoch 72, Iteration 170, Current loss 0.31893969940631667 Accuracy 68.11946096879932\n",
      "Training:: Epoch 72, Iteration 180, Current loss 0.3283116630763155 Accuracy 63.57153694431801\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 72, Probability Accuracy 54.741977990669184\n",
      "Starting Training\n",
      "Training:: Epoch 73, Iteration 0, Current loss 0.4340658526584096 Accuracy 56.47045544330944\n",
      "Training:: Epoch 73, Iteration 10, Current loss 0.4261796742797727 Accuracy 72.36895103285575\n",
      "Training:: Epoch 73, Iteration 20, Current loss 0.41506552036537003 Accuracy 57.014028056112224\n",
      "Training:: Epoch 73, Iteration 30, Current loss 0.3956980758117805 Accuracy 64.27858835266242\n",
      "Training:: Epoch 73, Iteration 40, Current loss 0.37656806134168824 Accuracy 69.41654710664754\n",
      "Training:: Epoch 73, Iteration 50, Current loss 0.36479742611788785 Accuracy 65.3761242845462\n",
      "Training:: Epoch 73, Iteration 60, Current loss 0.4006211962105026 Accuracy 60.66764132553606\n",
      "Training:: Epoch 73, Iteration 70, Current loss 0.32051479532432064 Accuracy 62.269854355592194\n",
      "Training:: Epoch 73, Iteration 80, Current loss 0.4842106846936681 Accuracy 52.621915393654525\n",
      "Training:: Epoch 73, Iteration 90, Current loss 0.4041240027203451 Accuracy 54.17811540326491\n",
      "Training:: Epoch 73, Iteration 100, Current loss 0.48310446912358507 Accuracy 62.88003358639751\n",
      "Training:: Epoch 73, Iteration 110, Current loss 0.40949544308287095 Accuracy 73.69879622412748\n",
      "Training:: Epoch 73, Iteration 120, Current loss 0.41077590180263474 Accuracy 74.29342782417953\n",
      "Training:: Epoch 73, Iteration 130, Current loss 0.34146331167280597 Accuracy 67.07198443579766\n",
      "Training:: Epoch 73, Iteration 140, Current loss 0.372555988686651 Accuracy 70.45413227647893\n",
      "Training:: Epoch 73, Iteration 150, Current loss 0.45022359790322497 Accuracy 64.37748939997431\n",
      "Training:: Epoch 73, Iteration 160, Current loss 0.6079225014716572 Accuracy 62.90528762347473\n",
      "Training:: Epoch 73, Iteration 170, Current loss 0.43867561327377314 Accuracy 65.04692387904066\n",
      "Training:: Epoch 73, Iteration 180, Current loss 0.3789018335873229 Accuracy 66.91691869774061\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 73, Probability Accuracy 54.00338726846081\n",
      "Starting Training\n",
      "Training:: Epoch 74, Iteration 0, Current loss 0.320876785598379 Accuracy 65.39380771319935\n",
      "Training:: Epoch 74, Iteration 10, Current loss 0.30458730204689627 Accuracy 52.93660531697341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 74, Iteration 20, Current loss 0.3555030711347598 Accuracy 62.95063145809414\n",
      "Training:: Epoch 74, Iteration 30, Current loss 0.3241771835128216 Accuracy 68.88994195000592\n",
      "Training:: Epoch 74, Iteration 40, Current loss 0.364281560075615 Accuracy 66.39507053012171\n",
      "Training:: Epoch 74, Iteration 50, Current loss 0.369122121789575 Accuracy 67.21454039481694\n",
      "Training:: Epoch 74, Iteration 60, Current loss 0.2893027196932198 Accuracy 67.27466466090009\n",
      "Training:: Epoch 74, Iteration 70, Current loss 0.2995890710065645 Accuracy 69.17998610145935\n",
      "Training:: Epoch 74, Iteration 80, Current loss 0.3507172916688569 Accuracy 71.92307692307692\n",
      "Training:: Epoch 74, Iteration 90, Current loss 0.3541383800754125 Accuracy 67.28525980911984\n",
      "Training:: Epoch 74, Iteration 100, Current loss 0.2932654574063572 Accuracy 66.08882962355113\n",
      "Training:: Epoch 74, Iteration 110, Current loss 0.4250417659278628 Accuracy 61.04197901049475\n",
      "Training:: Epoch 74, Iteration 120, Current loss 0.4046702207913906 Accuracy 71.01597143193501\n",
      "Training:: Epoch 74, Iteration 130, Current loss 0.3617587842549882 Accuracy 67.0491901261132\n",
      "Training:: Epoch 74, Iteration 140, Current loss 0.40409087923519066 Accuracy 65.53830491219139\n",
      "Training:: Epoch 74, Iteration 150, Current loss 0.36821557580115005 Accuracy 71.38405329894691\n",
      "Training:: Epoch 74, Iteration 160, Current loss 0.3762904262324842 Accuracy 62.0521099600879\n",
      "Training:: Epoch 74, Iteration 170, Current loss 0.38939071816583515 Accuracy 62.27033620492491\n",
      "Training:: Epoch 74, Iteration 180, Current loss 0.37385757096180033 Accuracy 60.72289156626506\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 74, Probability Accuracy 55.51222542746457\n",
      "Starting Training\n",
      "Training:: Epoch 75, Iteration 0, Current loss 0.3699520740050997 Accuracy 57.28369438318848\n",
      "Training:: Epoch 75, Iteration 10, Current loss 0.41096549136226934 Accuracy 58.397027600849256\n",
      "Training:: Epoch 75, Iteration 20, Current loss 0.3437054709767142 Accuracy 63.54430379746835\n",
      "Training:: Epoch 75, Iteration 30, Current loss 0.3527571802434934 Accuracy 64.41075120606479\n",
      "Training:: Epoch 75, Iteration 40, Current loss 0.5107260527952414 Accuracy 63.090313221941656\n",
      "Training:: Epoch 75, Iteration 50, Current loss 0.3340418580533409 Accuracy 65.95067621320605\n",
      "Training:: Epoch 75, Iteration 60, Current loss 0.4242016691899155 Accuracy 61.43577885221779\n",
      "Training:: Epoch 75, Iteration 70, Current loss 0.43726146882454336 Accuracy 63.50760885942444\n",
      "Training:: Epoch 75, Iteration 80, Current loss 0.4659035304964771 Accuracy 74.19067419067419\n",
      "Training:: Epoch 75, Iteration 90, Current loss 0.6134779309708529 Accuracy 63.944186046511625\n",
      "Training:: Epoch 75, Iteration 100, Current loss 0.42319455008984047 Accuracy 45.99066919376002\n",
      "Training:: Epoch 75, Iteration 110, Current loss 0.38256596882184135 Accuracy 58.95679080561388\n",
      "Training:: Epoch 75, Iteration 120, Current loss 0.32239764170328283 Accuracy 77.05312395589709\n",
      "Training:: Epoch 75, Iteration 130, Current loss 0.4394366674941591 Accuracy 64.63609704078912\n",
      "Training:: Epoch 75, Iteration 140, Current loss 0.3249176349414142 Accuracy 60.74603239030726\n",
      "Training:: Epoch 75, Iteration 150, Current loss 0.40012303585277836 Accuracy 68.23675496688742\n",
      "Training:: Epoch 75, Iteration 160, Current loss 0.26272395970687906 Accuracy 64.43015936788537\n",
      "Training:: Epoch 75, Iteration 170, Current loss 0.3469356465129381 Accuracy 61.79460217315107\n",
      "Training:: Epoch 75, Iteration 180, Current loss 0.3712424781615977 Accuracy 60.779885576633546\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 75, Probability Accuracy 54.80113647605367\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Completed 160 videos selected frames calculation\n",
      "Completed 170 videos selected frames calculation\n",
      "Completed 180 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.62569549822964\n",
      "Calculating Expectation\n",
      "Epoch 75 iter 0\n",
      "Epoch 75 iter 10\n",
      "Epoch 75 iter 20\n",
      "Epoch 75 iter 30\n",
      "Epoch 75 iter 40\n",
      "Epoch 75 iter 50\n",
      "Epoch 75 iter 60\n",
      "Epoch 75 iter 70\n",
      "Epoch 75 iter 80\n",
      "Epoch 75 iter 90\n",
      "Epoch 75 iter 100\n",
      "Epoch 75 iter 110\n",
      "Epoch 75 iter 120\n",
      "Epoch 75 iter 130\n",
      "Epoch 75 iter 140\n",
      "Epoch 75 iter 150\n",
      "Epoch 75 iter 160\n",
      "Epoch 75 iter 170\n",
      "Epoch 75 iter 180\n",
      "Train Boundary avergage error = 296.870\n",
      "Train From boundary avergage accuracy = 60.419\n",
      "Starting Training\n",
      "Training:: Epoch 76, Iteration 0, Current loss 0.3051790472426771 Accuracy 69.19971348570684\n",
      "Training:: Epoch 76, Iteration 10, Current loss 0.32236156154483364 Accuracy 66.05848537865533\n",
      "Training:: Epoch 76, Iteration 20, Current loss 0.41281153168702067 Accuracy 62.83904498944291\n",
      "Training:: Epoch 76, Iteration 30, Current loss 0.3650909713824965 Accuracy 71.83820814702383\n",
      "Training:: Epoch 76, Iteration 40, Current loss 0.3771961863115925 Accuracy 67.70618809453761\n",
      "Training:: Epoch 76, Iteration 50, Current loss 0.34059921496048445 Accuracy 70.61788980593353\n",
      "Training:: Epoch 76, Iteration 60, Current loss 0.3449595543202094 Accuracy 63.822840951090306\n",
      "Training:: Epoch 76, Iteration 70, Current loss 0.3550913360015238 Accuracy 64.02214022140221\n",
      "Training:: Epoch 76, Iteration 80, Current loss 0.33420017303609845 Accuracy 70.18733181535914\n",
      "Training:: Epoch 76, Iteration 90, Current loss 0.31077600774093017 Accuracy 59.53420669577875\n",
      "Training:: Epoch 76, Iteration 100, Current loss 0.6304353455080728 Accuracy 63.094914332336145\n",
      "Training:: Epoch 76, Iteration 110, Current loss 0.46109640956022546 Accuracy 63.96043133410569\n",
      "Training:: Epoch 76, Iteration 120, Current loss 0.4734783163340439 Accuracy 58.537328593194516\n",
      "Training:: Epoch 76, Iteration 130, Current loss 0.40386226479196463 Accuracy 55.96871846619576\n",
      "Training:: Epoch 76, Iteration 140, Current loss 0.54104103556547 Accuracy 68.26794559320702\n",
      "Training:: Epoch 76, Iteration 150, Current loss 0.36017625843211903 Accuracy 61.90579647171287\n",
      "Training:: Epoch 76, Iteration 160, Current loss 0.46963177409030854 Accuracy 69.91597835374537\n",
      "Training:: Epoch 76, Iteration 170, Current loss 0.42730198603154224 Accuracy 68.67704280155642\n",
      "Training:: Epoch 76, Iteration 180, Current loss 0.5756860958957177 Accuracy 61.199224382240345\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 76, Probability Accuracy 54.32252652239119\n",
      "Starting Training\n",
      "Training:: Epoch 77, Iteration 0, Current loss 0.441431201634047 Accuracy 70.36597551836122\n",
      "Training:: Epoch 77, Iteration 10, Current loss 0.6311417979729794 Accuracy 68.3088954056696\n",
      "Training:: Epoch 77, Iteration 20, Current loss 0.5000226548003728 Accuracy 66.05667060212515\n",
      "Training:: Epoch 77, Iteration 30, Current loss 0.5413529725455057 Accuracy 52.8786430960344\n",
      "Training:: Epoch 77, Iteration 40, Current loss 0.42112316249111625 Accuracy 71.45354538864964\n",
      "Training:: Epoch 77, Iteration 50, Current loss 0.48738518966413735 Accuracy 63.879665294195775\n",
      "Training:: Epoch 77, Iteration 60, Current loss 0.4875953142388394 Accuracy 73.81929515992444\n",
      "Training:: Epoch 77, Iteration 70, Current loss 0.5591110494269077 Accuracy 56.77672592934657\n",
      "Training:: Epoch 77, Iteration 80, Current loss 0.8952678726236358 Accuracy 60.774554417899125\n",
      "Training:: Epoch 77, Iteration 90, Current loss 0.5659247458106331 Accuracy 62.10078069552874\n",
      "Training:: Epoch 77, Iteration 100, Current loss 0.4010522418723237 Accuracy 73.72461792351295\n",
      "Training:: Epoch 77, Iteration 110, Current loss 0.5851608425019501 Accuracy 59.096329667417514\n",
      "Training:: Epoch 77, Iteration 120, Current loss 0.3370318328842863 Accuracy 67.96520976465429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 77, Iteration 130, Current loss 0.767502278115789 Accuracy 58.84597643309431\n",
      "Training:: Epoch 77, Iteration 140, Current loss 0.5295912884046854 Accuracy 66.28589394256969\n",
      "Training:: Epoch 77, Iteration 150, Current loss 0.5590368534073803 Accuracy 66.28937199953164\n",
      "Training:: Epoch 77, Iteration 160, Current loss 0.6208177733447992 Accuracy 62.91280148423006\n",
      "Training:: Epoch 77, Iteration 170, Current loss 0.5010480402182355 Accuracy 58.53460972017673\n",
      "Training:: Epoch 77, Iteration 180, Current loss 0.461822349753435 Accuracy 63.18483039170658\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 77, Probability Accuracy 53.646457811492176\n",
      "Starting Training\n",
      "Training:: Epoch 78, Iteration 0, Current loss 0.6031622479958351 Accuracy 59.48441708349365\n",
      "Training:: Epoch 78, Iteration 10, Current loss 0.42839027446476097 Accuracy 72.07947927372388\n",
      "Training:: Epoch 78, Iteration 20, Current loss 0.4815420617263083 Accuracy 64.97434801197093\n",
      "Training:: Epoch 78, Iteration 30, Current loss 0.5426442878554499 Accuracy 65.10073909081704\n",
      "Training:: Epoch 78, Iteration 40, Current loss 0.432314055237943 Accuracy 66.99933020763564\n",
      "Training:: Epoch 78, Iteration 50, Current loss 0.3568288206354421 Accuracy 48.67344998098136\n",
      "Training:: Epoch 78, Iteration 60, Current loss 0.4517057068816337 Accuracy 69.62897526501767\n",
      "Training:: Epoch 78, Iteration 70, Current loss 0.40826317068688434 Accuracy 58.4899425880798\n",
      "Training:: Epoch 78, Iteration 80, Current loss 0.5122009129496075 Accuracy 54.73231608200933\n",
      "Training:: Epoch 78, Iteration 90, Current loss 0.4620867726708449 Accuracy 65.3397499607679\n",
      "Training:: Epoch 78, Iteration 100, Current loss 0.2979777620651443 Accuracy 69.43282294587017\n",
      "Training:: Epoch 78, Iteration 110, Current loss 0.47371258739252475 Accuracy 58.362587763289866\n",
      "Training:: Epoch 78, Iteration 120, Current loss 0.37930770524677193 Accuracy 64.97612382677424\n",
      "Training:: Epoch 78, Iteration 130, Current loss 0.2954831204365662 Accuracy 49.26566917189547\n",
      "Training:: Epoch 78, Iteration 140, Current loss 0.4207876058037413 Accuracy 64.73165388828039\n",
      "Training:: Epoch 78, Iteration 150, Current loss 0.4032095092455915 Accuracy 61.48060840770051\n",
      "Training:: Epoch 78, Iteration 160, Current loss 0.357233605318556 Accuracy 67.601246105919\n",
      "Training:: Epoch 78, Iteration 170, Current loss 0.6806853748421442 Accuracy 61.12002853575887\n",
      "Training:: Epoch 78, Iteration 180, Current loss 0.22678726072280028 Accuracy 70.00052336839902\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 78, Probability Accuracy 54.05403801180004\n",
      "Starting Training\n",
      "Training:: Epoch 79, Iteration 0, Current loss 0.31898024024712274 Accuracy 55.228254164096235\n",
      "Training:: Epoch 79, Iteration 10, Current loss 0.3152199467028088 Accuracy 74.52008707698397\n",
      "Training:: Epoch 79, Iteration 20, Current loss 0.3071689808266332 Accuracy 71.43490905505989\n",
      "Training:: Epoch 79, Iteration 30, Current loss 0.3187094323482692 Accuracy 65.33101045296168\n",
      "Training:: Epoch 79, Iteration 40, Current loss 0.35207942726709396 Accuracy 72.67963581581188\n",
      "Training:: Epoch 79, Iteration 50, Current loss 0.2840858051450176 Accuracy 57.71578029642546\n",
      "Training:: Epoch 79, Iteration 60, Current loss 0.4592044287056063 Accuracy 57.36855736855737\n",
      "Training:: Epoch 79, Iteration 70, Current loss 0.3725884294587617 Accuracy 50.88222636637498\n",
      "Training:: Epoch 79, Iteration 80, Current loss 0.5456808368861248 Accuracy 62.77071158473702\n",
      "Training:: Epoch 79, Iteration 90, Current loss 0.38656452025847476 Accuracy 70.51779389441727\n",
      "Training:: Epoch 79, Iteration 100, Current loss 0.3281921993821567 Accuracy 64.89772288691624\n",
      "Training:: Epoch 79, Iteration 110, Current loss 0.34679271984542354 Accuracy 69.85021070638795\n",
      "Training:: Epoch 79, Iteration 120, Current loss 0.3611968418886233 Accuracy 67.72844272844273\n",
      "Training:: Epoch 79, Iteration 130, Current loss 0.4057403185471451 Accuracy 58.69249394673123\n",
      "Training:: Epoch 79, Iteration 140, Current loss 0.35169585616639654 Accuracy 69.84285714285714\n",
      "Training:: Epoch 79, Iteration 150, Current loss 0.2877096804726847 Accuracy 71.80201698513801\n",
      "Training:: Epoch 79, Iteration 160, Current loss 0.33040572346833663 Accuracy 71.37576825546913\n",
      "Training:: Epoch 79, Iteration 170, Current loss 0.4689728544351468 Accuracy 66.23492630638678\n",
      "Training:: Epoch 79, Iteration 180, Current loss 0.5695710485240911 Accuracy 51.260249013058\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 79, Probability Accuracy 54.9293461701311\n",
      "Starting Training\n",
      "Training:: Epoch 80, Iteration 0, Current loss 0.45236312349286345 Accuracy 64.7775342745018\n",
      "Training:: Epoch 80, Iteration 10, Current loss 0.41227349350875253 Accuracy 66.96079667212908\n",
      "Training:: Epoch 80, Iteration 20, Current loss 0.3764174981701854 Accuracy 48.343341872086675\n",
      "Training:: Epoch 80, Iteration 30, Current loss 0.4787842713832523 Accuracy 55.02603477186479\n",
      "Training:: Epoch 80, Iteration 40, Current loss 0.3968358137605817 Accuracy 65.33174486803519\n",
      "Training:: Epoch 80, Iteration 50, Current loss 0.5068644760896959 Accuracy 57.88576300085251\n",
      "Training:: Epoch 80, Iteration 60, Current loss 0.6430118298271738 Accuracy 75.63496751329002\n",
      "Training:: Epoch 80, Iteration 70, Current loss 0.4028883316587923 Accuracy 64.4251116858688\n",
      "Training:: Epoch 80, Iteration 80, Current loss 0.6063858542811248 Accuracy 61.3107119095143\n",
      "Training:: Epoch 80, Iteration 90, Current loss 0.40770477011954387 Accuracy 68.1767955801105\n",
      "Training:: Epoch 80, Iteration 100, Current loss 0.2577293656794721 Accuracy 68.79948914431674\n",
      "Training:: Epoch 80, Iteration 110, Current loss 0.345424796379354 Accuracy 62.6900651651995\n",
      "Training:: Epoch 80, Iteration 120, Current loss 0.3866502727985465 Accuracy 68.91013942623549\n",
      "Training:: Epoch 80, Iteration 130, Current loss 0.38638343678712045 Accuracy 62.19455970493315\n",
      "Training:: Epoch 80, Iteration 140, Current loss 0.35084004388246315 Accuracy 64.94042399546088\n",
      "Training:: Epoch 80, Iteration 150, Current loss 0.4884973090131647 Accuracy 60.616698292220114\n",
      "Training:: Epoch 80, Iteration 160, Current loss 0.30564937378043355 Accuracy 64.02837668660453\n",
      "Training:: Epoch 80, Iteration 170, Current loss 0.4279660773511267 Accuracy 74.17262051408393\n",
      "Training:: Epoch 80, Iteration 180, Current loss 0.40751559470614285 Accuracy 74.87374610861293\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 80, Probability Accuracy 54.60585411794501\n",
      "Calculating Expectation\n",
      "Epoch 80 iter 0\n",
      "Epoch 80 iter 10\n",
      "Epoch 80 iter 20\n",
      "Epoch 80 iter 30\n",
      "Epoch 80 iter 40\n",
      "Epoch 80 iter 50\n",
      "Epoch 80 iter 60\n",
      "Epoch 80 iter 70\n",
      "Epoch 80 iter 80\n",
      "Epoch 80 iter 90\n",
      "Epoch 80 iter 100\n",
      "Epoch 80 iter 110\n",
      "Epoch 80 iter 120\n",
      "Epoch 80 iter 130\n",
      "Epoch 80 iter 140\n",
      "Epoch 80 iter 150\n",
      "Epoch 80 iter 160\n",
      "Epoch 80 iter 170\n",
      "Epoch 80 iter 180\n",
      "Train Boundary avergage error = 296.475\n",
      "Train From boundary avergage accuracy = 60.404\n",
      "Starting Training\n",
      "Training:: Epoch 81, Iteration 0, Current loss 0.35197090961790545 Accuracy 60.42366839800387\n",
      "Training:: Epoch 81, Iteration 10, Current loss 0.3590192230176523 Accuracy 53.292591668745324\n",
      "Training:: Epoch 81, Iteration 20, Current loss 0.3177053507118371 Accuracy 63.572910771552536\n",
      "Training:: Epoch 81, Iteration 30, Current loss 0.3090191064806918 Accuracy 69.2852513656143\n",
      "Training:: Epoch 81, Iteration 40, Current loss 0.3227086032507794 Accuracy 68.7497453864016\n",
      "Training:: Epoch 81, Iteration 50, Current loss 0.38983968042708617 Accuracy 61.73417463871362\n",
      "Training:: Epoch 81, Iteration 60, Current loss 0.37457370145880803 Accuracy 64.94546298445115\n",
      "Training:: Epoch 81, Iteration 70, Current loss 0.7296043761949105 Accuracy 65.10070680767392\n",
      "Training:: Epoch 81, Iteration 80, Current loss 0.4945868969509323 Accuracy 68.97920492920197\n",
      "Training:: Epoch 81, Iteration 90, Current loss 0.4855300976970325 Accuracy 63.17662761382174\n",
      "Training:: Epoch 81, Iteration 100, Current loss 1.286501555824196 Accuracy 55.5025011368804\n",
      "Training:: Epoch 81, Iteration 110, Current loss 0.8440143956931087 Accuracy 63.86439003739505\n",
      "Training:: Epoch 81, Iteration 120, Current loss 0.5731717730885053 Accuracy 56.90784684815839\n",
      "Training:: Epoch 81, Iteration 130, Current loss 2.7375563153498184 Accuracy 50.14492753623188\n",
      "Training:: Epoch 81, Iteration 140, Current loss 1.0104312142962968 Accuracy 68.27412082957619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 81, Iteration 150, Current loss 1.4022798783024155 Accuracy 69.31506849315069\n",
      "Training:: Epoch 81, Iteration 160, Current loss 2.819958101182345 Accuracy 62.5714640815312\n",
      "Training:: Epoch 81, Iteration 170, Current loss 3.6623289407332287 Accuracy 49.74043221055173\n",
      "Training:: Epoch 81, Iteration 180, Current loss 3.956571498672396 Accuracy 46.197773601272225\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 81, Probability Accuracy 52.04680445251691\n",
      "Starting Training\n",
      "Training:: Epoch 82, Iteration 0, Current loss 4.03840642972752 Accuracy 58.71091257179324\n",
      "Training:: Epoch 82, Iteration 10, Current loss 1.5489369660063268 Accuracy 59.01655795283492\n",
      "Training:: Epoch 82, Iteration 20, Current loss 2.2235615414762746 Accuracy 59.0466141145801\n",
      "Training:: Epoch 82, Iteration 30, Current loss 1.017401559902274 Accuracy 69.6137388689719\n",
      "Training:: Epoch 82, Iteration 40, Current loss 2.568253285901274 Accuracy 47.68020322478213\n",
      "Training:: Epoch 82, Iteration 50, Current loss 6.2685287474264255 Accuracy 55.74126439103212\n",
      "Training:: Epoch 82, Iteration 60, Current loss 5.389386640996447 Accuracy 50.85227272727273\n",
      "Training:: Epoch 82, Iteration 70, Current loss 4.10168341610793 Accuracy 44.82236666369869\n",
      "Training:: Epoch 82, Iteration 80, Current loss 2.1046981179762363 Accuracy 56.040172166427546\n",
      "Training:: Epoch 82, Iteration 90, Current loss 2.388361189327789 Accuracy 57.059066501445685\n",
      "Training:: Epoch 82, Iteration 100, Current loss 1.9567416589529216 Accuracy 56.05475406111553\n",
      "Training:: Epoch 82, Iteration 110, Current loss 0.9683609502218091 Accuracy 66.58588306573766\n",
      "Training:: Epoch 82, Iteration 120, Current loss 1.0600010196582612 Accuracy 64.80006404354961\n",
      "Training:: Epoch 82, Iteration 130, Current loss 0.9919931269520628 Accuracy 58.31146710859458\n",
      "Training:: Epoch 82, Iteration 140, Current loss 0.7365162758484138 Accuracy 54.14235705950992\n",
      "Training:: Epoch 82, Iteration 150, Current loss 2.1628896745693638 Accuracy 52.65963748371046\n",
      "Training:: Epoch 82, Iteration 160, Current loss 1.395709156903856 Accuracy 51.18793948433838\n",
      "Training:: Epoch 82, Iteration 170, Current loss 0.9990288555319131 Accuracy 65.62632396554159\n",
      "Training:: Epoch 82, Iteration 180, Current loss 1.0190216214896615 Accuracy 67.4115957637767\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 82, Probability Accuracy 51.21680496693852\n",
      "Starting Training\n",
      "Training:: Epoch 83, Iteration 0, Current loss 3.4319220591658217 Accuracy 46.744624346783176\n",
      "Training:: Epoch 83, Iteration 10, Current loss 2.718345124784969 Accuracy 61.978266238577426\n",
      "Training:: Epoch 83, Iteration 20, Current loss 2.6121693364330274 Accuracy 53.21801801801802\n",
      "Training:: Epoch 83, Iteration 30, Current loss 1.7221536666258577 Accuracy 50.371492461949074\n",
      "Training:: Epoch 83, Iteration 40, Current loss 1.7981493551233412 Accuracy 58.911265379063856\n",
      "Training:: Epoch 83, Iteration 50, Current loss 0.9520982729378855 Accuracy 64.91881934627084\n",
      "Training:: Epoch 83, Iteration 60, Current loss 1.3268056754768414 Accuracy 65.6832298136646\n",
      "Training:: Epoch 83, Iteration 70, Current loss 1.1714333197354132 Accuracy 65.969058680258\n",
      "Training:: Epoch 83, Iteration 80, Current loss 1.0702842589397674 Accuracy 58.10566396953831\n",
      "Training:: Epoch 83, Iteration 90, Current loss 0.7611620030917765 Accuracy 74.19134707247169\n",
      "Training:: Epoch 83, Iteration 100, Current loss 0.8149100754037737 Accuracy 71.63257429563875\n",
      "Training:: Epoch 83, Iteration 110, Current loss 0.8460467336478777 Accuracy 72.2875514105312\n",
      "Training:: Epoch 83, Iteration 120, Current loss 1.1238243329096596 Accuracy 66.38491800724496\n",
      "Training:: Epoch 83, Iteration 130, Current loss 0.725825364265522 Accuracy 65.10997521685255\n",
      "Training:: Epoch 83, Iteration 140, Current loss 0.6975393749292146 Accuracy 57.277430314261444\n",
      "Training:: Epoch 83, Iteration 150, Current loss 0.5537472202522318 Accuracy 65.86293450977409\n",
      "Training:: Epoch 83, Iteration 160, Current loss 0.6354853025791718 Accuracy 67.4090230742739\n",
      "Training:: Epoch 83, Iteration 170, Current loss 0.9252716945199138 Accuracy 47.04026252682065\n",
      "Training:: Epoch 83, Iteration 180, Current loss 0.6317688426813175 Accuracy 53.83434963453539\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 83, Probability Accuracy 55.71898334461104\n",
      "Starting Training\n",
      "Training:: Epoch 84, Iteration 0, Current loss 0.5834343140644095 Accuracy 65.19746708881853\n",
      "Training:: Epoch 84, Iteration 10, Current loss 0.41728961795095926 Accuracy 61.551485986721914\n",
      "Training:: Epoch 84, Iteration 20, Current loss 0.4759819318238636 Accuracy 53.80735437683046\n",
      "Training:: Epoch 84, Iteration 30, Current loss 0.582190864543553 Accuracy 67.39858801005145\n",
      "Training:: Epoch 84, Iteration 40, Current loss 0.6488555365260026 Accuracy 58.29926410466067\n",
      "Training:: Epoch 84, Iteration 50, Current loss 0.4287351158727459 Accuracy 64.28308598062063\n",
      "Training:: Epoch 84, Iteration 60, Current loss 1.2679542312810168 Accuracy 55.252671094426795\n",
      "Training:: Epoch 84, Iteration 70, Current loss 0.45634789418484156 Accuracy 73.15595933376595\n",
      "Training:: Epoch 84, Iteration 80, Current loss 0.48358153285674654 Accuracy 56.14548494983278\n",
      "Training:: Epoch 84, Iteration 90, Current loss 0.5161240886151833 Accuracy 54.63754352643242\n",
      "Training:: Epoch 84, Iteration 100, Current loss 0.6309919785466462 Accuracy 59.90034093889326\n",
      "Training:: Epoch 84, Iteration 110, Current loss 0.3764629367213095 Accuracy 66.05649050290326\n",
      "Training:: Epoch 84, Iteration 120, Current loss 0.51092962870482 Accuracy 65.90287454198277\n",
      "Training:: Epoch 84, Iteration 130, Current loss 0.4129873950861833 Accuracy 63.35974376264329\n",
      "Training:: Epoch 84, Iteration 140, Current loss 0.5076022878678605 Accuracy 67.53260523804475\n",
      "Training:: Epoch 84, Iteration 150, Current loss 0.4053585994461383 Accuracy 64.45127604547895\n",
      "Training:: Epoch 84, Iteration 160, Current loss 0.44295707748562324 Accuracy 58.851341955221805\n",
      "Training:: Epoch 84, Iteration 170, Current loss 0.4239303601129589 Accuracy 68.8333274392616\n",
      "Training:: Epoch 84, Iteration 180, Current loss 0.3161303594143549 Accuracy 70.37124896216345\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 84, Probability Accuracy 55.10484308162288\n",
      "Starting Training\n",
      "Training:: Epoch 85, Iteration 0, Current loss 0.32454168492225866 Accuracy 68.33304799406494\n",
      "Training:: Epoch 85, Iteration 10, Current loss 0.3981337370610575 Accuracy 69.11475069969939\n",
      "Training:: Epoch 85, Iteration 20, Current loss 0.3518253296348009 Accuracy 68.81125158973592\n",
      "Training:: Epoch 85, Iteration 30, Current loss 0.3624957444090175 Accuracy 66.59274626225051\n",
      "Training:: Epoch 85, Iteration 40, Current loss 0.3851904524385364 Accuracy 56.400819706411276\n",
      "Training:: Epoch 85, Iteration 50, Current loss 0.3995636107722904 Accuracy 63.96791113853749\n",
      "Training:: Epoch 85, Iteration 60, Current loss 0.4512424443951274 Accuracy 62.296212382406544\n",
      "Training:: Epoch 85, Iteration 70, Current loss 0.3005735862900868 Accuracy 59.94382531485005\n",
      "Training:: Epoch 85, Iteration 80, Current loss 0.38077995581374735 Accuracy 62.7032263499284\n",
      "Training:: Epoch 85, Iteration 90, Current loss 0.3582005597550317 Accuracy 68.23837590045842\n",
      "Training:: Epoch 85, Iteration 100, Current loss 0.3777909381764693 Accuracy 61.22105906624895\n",
      "Training:: Epoch 85, Iteration 110, Current loss 0.3247581223678331 Accuracy 71.64272329793879\n",
      "Training:: Epoch 85, Iteration 120, Current loss 0.29546569438362397 Accuracy 66.37547105173005\n",
      "Training:: Epoch 85, Iteration 130, Current loss 0.37433514342307117 Accuracy 59.08106156345911\n",
      "Training:: Epoch 85, Iteration 140, Current loss 0.33579532345228275 Accuracy 57.95263017830214\n",
      "Training:: Epoch 85, Iteration 150, Current loss 0.5786917235045916 Accuracy 56.70151810502688\n",
      "Training:: Epoch 85, Iteration 160, Current loss 0.34155103240994517 Accuracy 65.68724884414294\n",
      "Training:: Epoch 85, Iteration 170, Current loss 0.3460171578924176 Accuracy 62.38471673254282\n",
      "Training:: Epoch 85, Iteration 180, Current loss 0.4761129942123025 Accuracy 60.3971119133574\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 85, Probability Accuracy 54.6713439462469\n",
      "Calculating Expectation\n",
      "Epoch 85 iter 0\n",
      "Epoch 85 iter 10\n",
      "Epoch 85 iter 20\n",
      "Epoch 85 iter 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 iter 40\n",
      "Epoch 85 iter 50\n",
      "Epoch 85 iter 60\n",
      "Epoch 85 iter 70\n",
      "Epoch 85 iter 80\n",
      "Epoch 85 iter 90\n",
      "Epoch 85 iter 100\n",
      "Epoch 85 iter 110\n",
      "Epoch 85 iter 120\n",
      "Epoch 85 iter 130\n",
      "Epoch 85 iter 140\n",
      "Epoch 85 iter 150\n",
      "Epoch 85 iter 160\n",
      "Epoch 85 iter 170\n",
      "Epoch 85 iter 180\n",
      "Train Boundary avergage error = 296.596\n",
      "Train From boundary avergage accuracy = 60.365\n",
      "Starting Training\n",
      "Training:: Epoch 86, Iteration 0, Current loss 0.44936642699289137 Accuracy 51.48382794264755\n",
      "Training:: Epoch 86, Iteration 10, Current loss 0.32913311935057915 Accuracy 61.213909714468016\n",
      "Training:: Epoch 86, Iteration 20, Current loss 0.23780964347755182 Accuracy 60.49633489357944\n",
      "Training:: Epoch 86, Iteration 30, Current loss 0.39653841956409275 Accuracy 58.47389558232932\n",
      "Training:: Epoch 86, Iteration 40, Current loss 0.27632995359377177 Accuracy 58.871310507674146\n",
      "Training:: Epoch 86, Iteration 50, Current loss 0.3229410703635734 Accuracy 65.8594935231649\n",
      "Training:: Epoch 86, Iteration 60, Current loss 0.34526043814310703 Accuracy 65.70896730333442\n",
      "Training:: Epoch 86, Iteration 70, Current loss 0.326281471767964 Accuracy 70.88075777251547\n",
      "Training:: Epoch 86, Iteration 80, Current loss 0.2653351259887478 Accuracy 70.80617964726792\n",
      "Training:: Epoch 86, Iteration 90, Current loss 0.4003223269594135 Accuracy 63.48039215686274\n",
      "Training:: Epoch 86, Iteration 100, Current loss 0.3185107290251984 Accuracy 59.92453763839921\n",
      "Training:: Epoch 86, Iteration 110, Current loss 0.4512128183222882 Accuracy 54.48629301228341\n",
      "Training:: Epoch 86, Iteration 120, Current loss 0.31025397731484206 Accuracy 57.161765552166656\n",
      "Training:: Epoch 86, Iteration 130, Current loss 0.3316414202033272 Accuracy 66.09150326797386\n",
      "Training:: Epoch 86, Iteration 140, Current loss 0.43975770950222676 Accuracy 67.6686942990522\n",
      "Training:: Epoch 86, Iteration 150, Current loss 0.35390140589544256 Accuracy 65.7478797224364\n",
      "Training:: Epoch 86, Iteration 160, Current loss 0.27346230980566927 Accuracy 67.39470800062627\n",
      "Training:: Epoch 86, Iteration 170, Current loss 0.31200029809063834 Accuracy 69.81132075471699\n",
      "Training:: Epoch 86, Iteration 180, Current loss 0.36350818649653033 Accuracy 65.41243791837616\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 86, Probability Accuracy 55.64597504659473\n",
      "Starting Training\n",
      "Training:: Epoch 87, Iteration 0, Current loss 0.2825661778006547 Accuracy 57.429692174722426\n",
      "Training:: Epoch 87, Iteration 10, Current loss 0.27535535759319496 Accuracy 73.5505873436908\n",
      "Training:: Epoch 87, Iteration 20, Current loss 0.4990104277768638 Accuracy 61.358665083432285\n",
      "Training:: Epoch 87, Iteration 30, Current loss 0.34956795003572205 Accuracy 62.9275999450474\n",
      "Training:: Epoch 87, Iteration 40, Current loss 0.3319720472889933 Accuracy 72.75447379020657\n",
      "Training:: Epoch 87, Iteration 50, Current loss 0.2798221881689589 Accuracy 63.530013424534935\n",
      "Training:: Epoch 87, Iteration 60, Current loss 0.33837448759349115 Accuracy 64.26308006478418\n",
      "Training:: Epoch 87, Iteration 70, Current loss 0.34287637096538826 Accuracy 55.22569840907361\n",
      "Training:: Epoch 87, Iteration 80, Current loss 0.299876870754417 Accuracy 68.55129603221206\n",
      "Training:: Epoch 87, Iteration 90, Current loss 0.291294602690001 Accuracy 62.212885154061624\n",
      "Training:: Epoch 87, Iteration 100, Current loss 0.4169749210136762 Accuracy 62.24996240036096\n",
      "Training:: Epoch 87, Iteration 110, Current loss 0.35152964194908926 Accuracy 62.94941046639949\n",
      "Training:: Epoch 87, Iteration 120, Current loss 0.31602225994433214 Accuracy 65.41960382782656\n",
      "Training:: Epoch 87, Iteration 130, Current loss 0.4531387412553056 Accuracy 60.68343146426017\n",
      "Training:: Epoch 87, Iteration 140, Current loss 0.3755666130743067 Accuracy 66.13331251951296\n",
      "Training:: Epoch 87, Iteration 150, Current loss 0.34237784958066925 Accuracy 66.13991769547324\n",
      "Training:: Epoch 87, Iteration 160, Current loss 0.36343704181632003 Accuracy 66.62557527942144\n",
      "Training:: Epoch 87, Iteration 170, Current loss 0.486396263532341 Accuracy 61.25145180023229\n",
      "Training:: Epoch 87, Iteration 180, Current loss 0.3223699353615209 Accuracy 58.125962031811184\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 87, Probability Accuracy 55.508466192607365\n",
      "Starting Training\n",
      "Training:: Epoch 88, Iteration 0, Current loss 0.41159107351172497 Accuracy 64.68778184519073\n",
      "Training:: Epoch 88, Iteration 10, Current loss 0.28749879805525896 Accuracy 63.41238065906991\n",
      "Training:: Epoch 88, Iteration 20, Current loss 0.3161400271872923 Accuracy 64.84531322148683\n",
      "Training:: Epoch 88, Iteration 30, Current loss 0.3119116859312127 Accuracy 59.16714864083285\n",
      "Training:: Epoch 88, Iteration 40, Current loss 0.23159658954535983 Accuracy 66.34033613445378\n",
      "Training:: Epoch 88, Iteration 50, Current loss 0.2835329524674316 Accuracy 63.8201871657754\n",
      "Training:: Epoch 88, Iteration 60, Current loss 0.3013756393096955 Accuracy 58.195285122650525\n",
      "Training:: Epoch 88, Iteration 70, Current loss 0.2361299124739132 Accuracy 71.1277685701371\n",
      "Training:: Epoch 88, Iteration 80, Current loss 0.3317816666519717 Accuracy 66.57841546388818\n",
      "Training:: Epoch 88, Iteration 90, Current loss 0.3073374785284128 Accuracy 61.058011755686174\n",
      "Training:: Epoch 88, Iteration 100, Current loss 0.2804986175424694 Accuracy 66.42864326661973\n",
      "Training:: Epoch 88, Iteration 110, Current loss 0.30316056876576775 Accuracy 67.07535885167464\n",
      "Training:: Epoch 88, Iteration 120, Current loss 0.2902955757639827 Accuracy 74.93305144467935\n",
      "Training:: Epoch 88, Iteration 130, Current loss 0.317812482745735 Accuracy 65.11835640911121\n",
      "Training:: Epoch 88, Iteration 140, Current loss 0.25916535979493455 Accuracy 66.29982700872317\n",
      "Training:: Epoch 88, Iteration 150, Current loss 0.36297470965862444 Accuracy 63.10236669518107\n",
      "Training:: Epoch 88, Iteration 160, Current loss 0.2798041579910359 Accuracy 69.65919986054215\n",
      "Training:: Epoch 88, Iteration 170, Current loss 0.20216576965981548 Accuracy 74.79935159925671\n",
      "Training:: Epoch 88, Iteration 180, Current loss 0.3255005225743865 Accuracy 64.95560936238903\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 88, Probability Accuracy 55.48511936559944\n",
      "Starting Training\n",
      "Training:: Epoch 89, Iteration 0, Current loss 0.3266979841079119 Accuracy 49.11900777635594\n",
      "Training:: Epoch 89, Iteration 10, Current loss 1.432179900869386 Accuracy 59.25899486007995\n",
      "Training:: Epoch 89, Iteration 20, Current loss 0.3144377389829338 Accuracy 65.21538912379118\n",
      "Training:: Epoch 89, Iteration 30, Current loss 0.3643806282321599 Accuracy 66.80445947638732\n",
      "Training:: Epoch 89, Iteration 40, Current loss 0.2808466122393781 Accuracy 63.75919603789008\n",
      "Training:: Epoch 89, Iteration 50, Current loss 0.3916036493251036 Accuracy 62.12952799121844\n",
      "Training:: Epoch 89, Iteration 60, Current loss 0.2760331514806113 Accuracy 63.52711919454368\n",
      "Training:: Epoch 89, Iteration 70, Current loss 0.4214640860445536 Accuracy 60.39813329444363\n",
      "Training:: Epoch 89, Iteration 80, Current loss 0.2894929039248961 Accuracy 67.02220287331302\n",
      "Training:: Epoch 89, Iteration 90, Current loss 0.4299337805682434 Accuracy 54.234548745797774\n",
      "Training:: Epoch 89, Iteration 100, Current loss 0.3995796292274515 Accuracy 62.825630252100844\n",
      "Training:: Epoch 89, Iteration 110, Current loss 0.3371213761251842 Accuracy 59.20986831138523\n",
      "Training:: Epoch 89, Iteration 120, Current loss 0.34604619271764764 Accuracy 56.6962816716025\n",
      "Training:: Epoch 89, Iteration 130, Current loss 0.2409574717423309 Accuracy 73.22864802757564\n",
      "Training:: Epoch 89, Iteration 140, Current loss 0.3603110106404581 Accuracy 61.87401348830535\n",
      "Training:: Epoch 89, Iteration 150, Current loss 0.26882050670016383 Accuracy 65.33695318999868\n",
      "Training:: Epoch 89, Iteration 160, Current loss 0.29971670617702373 Accuracy 64.66951214647572\n",
      "Training:: Epoch 89, Iteration 170, Current loss 0.4233016077911396 Accuracy 49.76205492804311\n",
      "Training:: Epoch 89, Iteration 180, Current loss 0.2674705336294978 Accuracy 60.08005591206557\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 89, Probability Accuracy 54.96001361238727\n",
      "Starting Training\n",
      "Training:: Epoch 90, Iteration 0, Current loss 0.43763843563529836 Accuracy 58.60910031023785\n",
      "Training:: Epoch 90, Iteration 10, Current loss 0.3543581265000313 Accuracy 71.11653447223917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 90, Iteration 20, Current loss 0.2811761780361644 Accuracy 60.61391269683077\n",
      "Training:: Epoch 90, Iteration 30, Current loss 0.2898795554186297 Accuracy 60.555386642343166\n",
      "Training:: Epoch 90, Iteration 40, Current loss 0.2503209955701911 Accuracy 68.58175248419151\n",
      "Training:: Epoch 90, Iteration 50, Current loss 0.31428986596763464 Accuracy 63.25277723640616\n",
      "Training:: Epoch 90, Iteration 60, Current loss 0.30329645173582276 Accuracy 61.99897225077081\n",
      "Training:: Epoch 90, Iteration 70, Current loss 0.32451713154849904 Accuracy 63.085061659192824\n",
      "Training:: Epoch 90, Iteration 80, Current loss 0.28952688563544055 Accuracy 66.05050505050505\n",
      "Training:: Epoch 90, Iteration 90, Current loss 0.3594822937293678 Accuracy 69.64240554347276\n",
      "Training:: Epoch 90, Iteration 100, Current loss 0.30756735303122795 Accuracy 65.0667629014796\n",
      "Training:: Epoch 90, Iteration 110, Current loss 0.2412985645713832 Accuracy 60.26727372370473\n",
      "Training:: Epoch 90, Iteration 120, Current loss 0.2552405624853339 Accuracy 65.79402217444458\n",
      "Training:: Epoch 90, Iteration 130, Current loss 0.26291038922290044 Accuracy 71.18596622189045\n",
      "Training:: Epoch 90, Iteration 140, Current loss 0.2503335730286709 Accuracy 63.792838481635165\n",
      "Training:: Epoch 90, Iteration 150, Current loss 0.2739825279949672 Accuracy 68.42635658914729\n",
      "Training:: Epoch 90, Iteration 160, Current loss 0.4416276124055112 Accuracy 58.36939588021465\n",
      "Training:: Epoch 90, Iteration 170, Current loss 0.3678277301187 Accuracy 57.37092048095383\n",
      "Training:: Epoch 90, Iteration 180, Current loss 0.2300645068893275 Accuracy 55.90647289926384\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 90, Probability Accuracy 55.40676899699657\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Completed 160 videos selected frames calculation\n",
      "Completed 170 videos selected frames calculation\n",
      "Completed 180 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.57511380880121\n",
      "Calculating Expectation\n",
      "Epoch 90 iter 0\n",
      "Epoch 90 iter 10\n",
      "Epoch 90 iter 20\n",
      "Epoch 90 iter 30\n",
      "Epoch 90 iter 40\n",
      "Epoch 90 iter 50\n",
      "Epoch 90 iter 60\n",
      "Epoch 90 iter 70\n",
      "Epoch 90 iter 80\n",
      "Epoch 90 iter 90\n",
      "Epoch 90 iter 100\n",
      "Epoch 90 iter 110\n",
      "Epoch 90 iter 120\n",
      "Epoch 90 iter 130\n",
      "Epoch 90 iter 140\n",
      "Epoch 90 iter 150\n",
      "Epoch 90 iter 160\n",
      "Epoch 90 iter 170\n",
      "Epoch 90 iter 180\n",
      "Train Boundary avergage error = 296.846\n",
      "Train From boundary avergage accuracy = 60.398\n",
      "Starting Training\n",
      "Training:: Epoch 91, Iteration 0, Current loss 0.2755339636770801 Accuracy 57.63332712485255\n",
      "Training:: Epoch 91, Iteration 10, Current loss 0.2842452334603914 Accuracy 63.93396226415094\n",
      "Training:: Epoch 91, Iteration 20, Current loss 0.23035997103878833 Accuracy 70.9955328653478\n",
      "Training:: Epoch 91, Iteration 30, Current loss 0.19277004434454625 Accuracy 71.67473378509196\n",
      "Training:: Epoch 91, Iteration 40, Current loss 0.380358638600821 Accuracy 59.71731448763251\n",
      "Training:: Epoch 91, Iteration 50, Current loss 0.29473794675088305 Accuracy 61.664190193164934\n",
      "Training:: Epoch 91, Iteration 60, Current loss 0.23524030762922343 Accuracy 71.3841471483393\n",
      "Training:: Epoch 91, Iteration 70, Current loss 0.23574631700172652 Accuracy 76.68708416939486\n",
      "Training:: Epoch 91, Iteration 80, Current loss 0.3041058124298956 Accuracy 55.80177276390008\n",
      "Training:: Epoch 91, Iteration 90, Current loss 0.22543955758640874 Accuracy 66.40528105621124\n",
      "Training:: Epoch 91, Iteration 100, Current loss 0.3248598619737967 Accuracy 61.92332683560754\n",
      "Training:: Epoch 91, Iteration 110, Current loss 0.2951588607311528 Accuracy 62.10842243481523\n",
      "Training:: Epoch 91, Iteration 120, Current loss 0.2648116488466535 Accuracy 57.521220586655204\n",
      "Training:: Epoch 91, Iteration 130, Current loss 0.2511835223535049 Accuracy 72.22372918135952\n",
      "Training:: Epoch 91, Iteration 140, Current loss 0.3072461275094763 Accuracy 61.8407719081817\n",
      "Training:: Epoch 91, Iteration 150, Current loss 0.2622967177170175 Accuracy 56.748140276301804\n",
      "Training:: Epoch 91, Iteration 160, Current loss 0.3271918575870433 Accuracy 65.42480690595184\n",
      "Training:: Epoch 91, Iteration 170, Current loss 0.35718942914439217 Accuracy 68.5380221349518\n",
      "Training:: Epoch 91, Iteration 180, Current loss 0.2841808554796158 Accuracy 60.366409284926384\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 91, Probability Accuracy 55.34444484015338\n",
      "Starting Training\n",
      "Training:: Epoch 92, Iteration 0, Current loss 0.47372049528497484 Accuracy 55.135037485322016\n",
      "Training:: Epoch 92, Iteration 10, Current loss 0.2674444092458774 Accuracy 60.420287565176174\n",
      "Training:: Epoch 92, Iteration 20, Current loss 0.2588555556457826 Accuracy 69.20958237253394\n",
      "Training:: Epoch 92, Iteration 30, Current loss 0.3086790414143849 Accuracy 60.978577486080894\n",
      "Training:: Epoch 92, Iteration 40, Current loss 0.22139115321904865 Accuracy 68.40008730765034\n",
      "Training:: Epoch 92, Iteration 50, Current loss 0.31160721448243345 Accuracy 59.8856416772554\n",
      "Training:: Epoch 92, Iteration 60, Current loss 0.2632500841901289 Accuracy 66.81127982646422\n",
      "Training:: Epoch 92, Iteration 70, Current loss 0.23792319537639048 Accuracy 68.99129291933629\n",
      "Training:: Epoch 92, Iteration 80, Current loss 0.2479274594400898 Accuracy 62.22638804653471\n",
      "Training:: Epoch 92, Iteration 90, Current loss 0.42967564555942295 Accuracy 69.63214837712519\n",
      "Training:: Epoch 92, Iteration 100, Current loss 0.32005727662286426 Accuracy 64.15963161933999\n",
      "Training:: Epoch 92, Iteration 110, Current loss 0.24290328874677247 Accuracy 69.63467028055707\n",
      "Training:: Epoch 92, Iteration 120, Current loss 0.25281120679921704 Accuracy 69.74762726488352\n",
      "Training:: Epoch 92, Iteration 130, Current loss 0.2876314155709461 Accuracy 60.20550893049279\n",
      "Training:: Epoch 92, Iteration 140, Current loss 0.3190241053966292 Accuracy 62.99902629016553\n",
      "Training:: Epoch 92, Iteration 150, Current loss 0.3379162729606702 Accuracy 63.18269230769231\n",
      "Training:: Epoch 92, Iteration 160, Current loss 0.3090256604441687 Accuracy 62.114192030793355\n",
      "Training:: Epoch 92, Iteration 170, Current loss 0.36224341317267233 Accuracy 73.53181632374982\n",
      "Training:: Epoch 92, Iteration 180, Current loss 0.26365367197388273 Accuracy 67.93608211348923\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 92, Probability Accuracy 55.21267376568491\n",
      "Starting Training\n",
      "Training:: Epoch 93, Iteration 0, Current loss 0.4580850219019675 Accuracy 50.892071365709256\n",
      "Training:: Epoch 93, Iteration 10, Current loss 0.24383284698498237 Accuracy 62.70032422417786\n",
      "Training:: Epoch 93, Iteration 20, Current loss 0.316279289656025 Accuracy 63.592890730852\n",
      "Training:: Epoch 93, Iteration 30, Current loss 0.338102001114979 Accuracy 68.51663846587705\n",
      "Training:: Epoch 93, Iteration 40, Current loss 0.3232305717004198 Accuracy 54.1470162862353\n",
      "Training:: Epoch 93, Iteration 50, Current loss 0.2883565863255556 Accuracy 72.90825788153158\n",
      "Training:: Epoch 93, Iteration 60, Current loss 0.3647381536557393 Accuracy 69.09512761020882\n",
      "Training:: Epoch 93, Iteration 70, Current loss 0.4230343905170427 Accuracy 63.33417402269861\n",
      "Training:: Epoch 93, Iteration 80, Current loss 0.29427199366628026 Accuracy 65.32264222985873\n",
      "Training:: Epoch 93, Iteration 90, Current loss 0.40772294302879303 Accuracy 60.25163919900762\n",
      "Training:: Epoch 93, Iteration 100, Current loss 0.3110546538789376 Accuracy 60.29480580252691\n",
      "Training:: Epoch 93, Iteration 110, Current loss 0.256369297320269 Accuracy 70.58737580362362\n",
      "Training:: Epoch 93, Iteration 120, Current loss 0.2918345427070189 Accuracy 69.78430529097278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 93, Iteration 130, Current loss 0.3079466066884242 Accuracy 64.40976591995972\n",
      "Training:: Epoch 93, Iteration 140, Current loss 0.3003507905027336 Accuracy 55.5939226519337\n",
      "Training:: Epoch 93, Iteration 150, Current loss 0.2730615445864695 Accuracy 64.8136489549232\n",
      "Training:: Epoch 93, Iteration 160, Current loss 0.3133982090218286 Accuracy 60.89691143383105\n",
      "Training:: Epoch 93, Iteration 170, Current loss 0.22734622104650004 Accuracy 69.8882886182584\n",
      "Training:: Epoch 93, Iteration 180, Current loss 0.26037640460266104 Accuracy 59.590179065903634\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 93, Probability Accuracy 55.44515276343333\n",
      "Starting Training\n",
      "Training:: Epoch 94, Iteration 0, Current loss 0.2848736550017085 Accuracy 60.99176742989452\n",
      "Training:: Epoch 94, Iteration 10, Current loss 0.2562234975778531 Accuracy 65.35779171306335\n",
      "Training:: Epoch 94, Iteration 20, Current loss 0.2577133046171334 Accuracy 66.77774616978908\n",
      "Training:: Epoch 94, Iteration 30, Current loss 0.29518133122809265 Accuracy 71.16129032258064\n",
      "Training:: Epoch 94, Iteration 40, Current loss 0.28779456464096514 Accuracy 58.36533957845433\n",
      "Training:: Epoch 94, Iteration 50, Current loss 0.331225609768125 Accuracy 59.13661101374412\n",
      "Training:: Epoch 94, Iteration 60, Current loss 0.2600633487699591 Accuracy 70.04136504653567\n",
      "Training:: Epoch 94, Iteration 70, Current loss 0.3061475974344436 Accuracy 61.88806079205027\n",
      "Training:: Epoch 94, Iteration 80, Current loss 0.3770048481036287 Accuracy 55.337944258029175\n",
      "Training:: Epoch 94, Iteration 90, Current loss 0.28882343711942127 Accuracy 69.48753391696104\n",
      "Training:: Epoch 94, Iteration 100, Current loss 0.29749942439940735 Accuracy 48.464119772844604\n",
      "Training:: Epoch 94, Iteration 110, Current loss 0.22658378166436927 Accuracy 62.26586749438082\n",
      "Training:: Epoch 94, Iteration 120, Current loss 0.3019940763917429 Accuracy 72.80012737501326\n",
      "Training:: Epoch 94, Iteration 130, Current loss 0.3989321606461015 Accuracy 61.511330570496426\n",
      "Training:: Epoch 94, Iteration 140, Current loss 0.3142551747072083 Accuracy 62.309368191721134\n",
      "Training:: Epoch 94, Iteration 150, Current loss 0.3154139363089306 Accuracy 70.45970149253732\n",
      "Training:: Epoch 94, Iteration 160, Current loss 0.36027401200561726 Accuracy 72.90986021102245\n",
      "Training:: Epoch 94, Iteration 170, Current loss 0.3250149405029901 Accuracy 67.51753277867317\n",
      "Training:: Epoch 94, Iteration 180, Current loss 0.3100453582463436 Accuracy 61.606036305314575\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 94, Probability Accuracy 54.70873844035282\n",
      "Starting Training\n",
      "Training:: Epoch 95, Iteration 0, Current loss 0.24791391999136894 Accuracy 61.82576038958359\n",
      "Training:: Epoch 95, Iteration 10, Current loss 0.5320504898697739 Accuracy 55.852954242558866\n",
      "Training:: Epoch 95, Iteration 20, Current loss 0.47179612206268134 Accuracy 59.73072215422277\n",
      "Training:: Epoch 95, Iteration 30, Current loss 0.4378996177008983 Accuracy 59.34053754502632\n",
      "Training:: Epoch 95, Iteration 40, Current loss 0.3673376692025199 Accuracy 60.27235587834771\n",
      "Training:: Epoch 95, Iteration 50, Current loss 0.42757340624125517 Accuracy 56.185869246555264\n",
      "Training:: Epoch 95, Iteration 60, Current loss 0.43041256664917005 Accuracy 64.9191299498048\n",
      "Training:: Epoch 95, Iteration 70, Current loss 0.4510185511026043 Accuracy 74.51475575438343\n",
      "Training:: Epoch 95, Iteration 80, Current loss 0.35983812947976873 Accuracy 61.69268762295425\n",
      "Training:: Epoch 95, Iteration 90, Current loss 0.6712669667608037 Accuracy 63.581047381546135\n",
      "Training:: Epoch 95, Iteration 100, Current loss 0.3640165996658885 Accuracy 57.10378898151824\n",
      "Training:: Epoch 95, Iteration 110, Current loss 0.7420364077455325 Accuracy 69.52435749904105\n",
      "Training:: Epoch 95, Iteration 120, Current loss 0.6845254826992195 Accuracy 61.99964099802549\n",
      "Training:: Epoch 95, Iteration 130, Current loss 0.41630748622356906 Accuracy 63.1686806586107\n",
      "Training:: Epoch 95, Iteration 140, Current loss 0.3269424118972467 Accuracy 70.01016604540834\n",
      "Training:: Epoch 95, Iteration 150, Current loss 0.2394430844413571 Accuracy 66.37757667169431\n",
      "Training:: Epoch 95, Iteration 160, Current loss 0.24298736123055126 Accuracy 70.52295675366736\n",
      "Training:: Epoch 95, Iteration 170, Current loss 0.30845836169682156 Accuracy 70.05004296618309\n",
      "Training:: Epoch 95, Iteration 180, Current loss 0.3327852587619723 Accuracy 59.75667137191638\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 95, Probability Accuracy 54.095389595229335\n",
      "Calculating Expectation\n",
      "Epoch 95 iter 0\n",
      "Epoch 95 iter 10\n",
      "Epoch 95 iter 20\n",
      "Epoch 95 iter 30\n",
      "Epoch 95 iter 40\n",
      "Epoch 95 iter 50\n",
      "Epoch 95 iter 60\n",
      "Epoch 95 iter 70\n",
      "Epoch 95 iter 80\n",
      "Epoch 95 iter 90\n",
      "Epoch 95 iter 100\n",
      "Epoch 95 iter 110\n",
      "Epoch 95 iter 120\n",
      "Epoch 95 iter 130\n",
      "Epoch 95 iter 140\n",
      "Epoch 95 iter 150\n",
      "Epoch 95 iter 160\n",
      "Epoch 95 iter 170\n",
      "Epoch 95 iter 180\n",
      "Train Boundary avergage error = 297.320\n",
      "Train From boundary avergage accuracy = 60.390\n",
      "Starting Training\n",
      "Training:: Epoch 96, Iteration 0, Current loss 0.24061331602227487 Accuracy 68.11215106061225\n",
      "Training:: Epoch 96, Iteration 10, Current loss 0.25045699425593304 Accuracy 65.89667297809035\n",
      "Training:: Epoch 96, Iteration 20, Current loss 0.3706808813813609 Accuracy 67.90590621830381\n",
      "Training:: Epoch 96, Iteration 30, Current loss 0.2513073733958717 Accuracy 73.26919773234839\n",
      "Training:: Epoch 96, Iteration 40, Current loss 0.3303281503422456 Accuracy 63.634621526668795\n",
      "Training:: Epoch 96, Iteration 50, Current loss 0.3222913158976777 Accuracy 59.68508404851408\n",
      "Training:: Epoch 96, Iteration 60, Current loss 0.3056691251348603 Accuracy 71.03392568659127\n",
      "Training:: Epoch 96, Iteration 70, Current loss 1.1596341504193326 Accuracy 65.03165968072773\n",
      "Training:: Epoch 96, Iteration 80, Current loss 1.1699869698742047 Accuracy 61.15619854151964\n",
      "Training:: Epoch 96, Iteration 90, Current loss 0.6656430598319895 Accuracy 48.870338067945845\n",
      "Training:: Epoch 96, Iteration 100, Current loss 2.9942094870554588 Accuracy 66.94970222300843\n",
      "Training:: Epoch 96, Iteration 110, Current loss 1.4712022974087235 Accuracy 68.96241542492862\n",
      "Training:: Epoch 96, Iteration 120, Current loss 1.3051062685654837 Accuracy 51.84507248499048\n",
      "Training:: Epoch 96, Iteration 130, Current loss 1.4474026850014325 Accuracy 62.588036901101084\n",
      "Training:: Epoch 96, Iteration 140, Current loss 1.7902128370937052 Accuracy 63.80764904386952\n",
      "Training:: Epoch 96, Iteration 150, Current loss 2.2415828550612895 Accuracy 58.991568296795954\n",
      "Training:: Epoch 96, Iteration 160, Current loss 1.7210928356164719 Accuracy 64.77821695213\n",
      "Training:: Epoch 96, Iteration 170, Current loss 2.5602477125457095 Accuracy 57.52742230347349\n",
      "Training:: Epoch 96, Iteration 180, Current loss 1.8962206595341835 Accuracy 63.28178968064191\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 96, Probability Accuracy 55.71284985615981\n",
      "Starting Training\n",
      "Training:: Epoch 97, Iteration 0, Current loss 1.0521830186852017 Accuracy 70.20725388601036\n",
      "Training:: Epoch 97, Iteration 10, Current loss 4.119587194721919 Accuracy 55.20557671206351\n",
      "Training:: Epoch 97, Iteration 20, Current loss 1.841952935933429 Accuracy 59.27357032457496\n",
      "Training:: Epoch 97, Iteration 30, Current loss 1.6553091154624329 Accuracy 69.32551902254892\n",
      "Training:: Epoch 97, Iteration 40, Current loss 1.6847883839898046 Accuracy 70.54255697101964\n",
      "Training:: Epoch 97, Iteration 50, Current loss 1.0089172682847434 Accuracy 72.25541159127938\n",
      "Training:: Epoch 97, Iteration 60, Current loss 1.0208775502523308 Accuracy 52.09835359948348\n",
      "Training:: Epoch 97, Iteration 70, Current loss 0.63426062566444 Accuracy 76.4508594358268\n",
      "Training:: Epoch 97, Iteration 80, Current loss 0.9342647614371881 Accuracy 70.264247055078\n",
      "Training:: Epoch 97, Iteration 90, Current loss 0.9711419314869225 Accuracy 50.96675026292371\n",
      "Training:: Epoch 97, Iteration 100, Current loss 0.6874991235288177 Accuracy 70.62973883740523\n",
      "Training:: Epoch 97, Iteration 110, Current loss 0.4027486182954667 Accuracy 69.15576298024835\n",
      "Training:: Epoch 97, Iteration 120, Current loss 0.8870818239871946 Accuracy 62.55469695559073\n",
      "Training:: Epoch 97, Iteration 130, Current loss 1.3879999321192436 Accuracy 45.47464984847244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 97, Iteration 140, Current loss 0.9251958657232837 Accuracy 59.29358279419479\n",
      "Training:: Epoch 97, Iteration 150, Current loss 1.0767948461798187 Accuracy 52.85322359396434\n",
      "Training:: Epoch 97, Iteration 160, Current loss 1.079958151196685 Accuracy 60.650988411724605\n",
      "Training:: Epoch 97, Iteration 170, Current loss 0.764794923226086 Accuracy 66.63518299881936\n",
      "Training:: Epoch 97, Iteration 180, Current loss 0.8371544798995256 Accuracy 63.99674048509251\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 97, Probability Accuracy 53.19139253930379\n",
      "Starting Training\n",
      "Training:: Epoch 98, Iteration 0, Current loss 0.5568841991773767 Accuracy 62.10702548521114\n",
      "Training:: Epoch 98, Iteration 10, Current loss 0.6498193603944145 Accuracy 69.12959381044487\n",
      "Training:: Epoch 98, Iteration 20, Current loss 0.4831289924650938 Accuracy 57.7183538808821\n",
      "Training:: Epoch 98, Iteration 30, Current loss 0.4494698369645058 Accuracy 70.87888439356117\n",
      "Training:: Epoch 98, Iteration 40, Current loss 0.41042044766524355 Accuracy 78.92493606779321\n",
      "Training:: Epoch 98, Iteration 50, Current loss 0.4629056682967184 Accuracy 74.71681014952424\n",
      "Training:: Epoch 98, Iteration 60, Current loss 0.5175081552924516 Accuracy 61.80151338766007\n",
      "Training:: Epoch 98, Iteration 70, Current loss 0.5276269159835989 Accuracy 59.447093387275444\n",
      "Training:: Epoch 98, Iteration 80, Current loss 0.4578979003808468 Accuracy 74.39233139335843\n",
      "Training:: Epoch 98, Iteration 90, Current loss 0.5240932403828341 Accuracy 61.34410002604845\n",
      "Training:: Epoch 98, Iteration 100, Current loss 0.503618843307781 Accuracy 74.71456061577935\n",
      "Training:: Epoch 98, Iteration 110, Current loss 0.4366853916287941 Accuracy 63.97306397306397\n",
      "Training:: Epoch 98, Iteration 120, Current loss 0.3758573645346334 Accuracy 62.6116499534221\n",
      "Training:: Epoch 98, Iteration 130, Current loss 0.5557210970344295 Accuracy 71.43444119795471\n",
      "Training:: Epoch 98, Iteration 140, Current loss 0.32868036211507295 Accuracy 61.450267122876525\n",
      "Training:: Epoch 98, Iteration 150, Current loss 0.46607547487280804 Accuracy 68.15926493108729\n",
      "Training:: Epoch 98, Iteration 160, Current loss 0.4254430263115046 Accuracy 65.81057810578106\n",
      "Training:: Epoch 98, Iteration 170, Current loss 0.32790908634046234 Accuracy 67.62219538549546\n",
      "Training:: Epoch 98, Iteration 180, Current loss 0.5809337310157314 Accuracy 60.037240645504525\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 98, Probability Accuracy 56.280494319598276\n",
      "Starting Training\n",
      "Training:: Epoch 99, Iteration 0, Current loss 0.334240655532571 Accuracy 68.68135570379354\n",
      "Training:: Epoch 99, Iteration 10, Current loss 0.4417998484719283 Accuracy 58.192272556289964\n",
      "Training:: Epoch 99, Iteration 20, Current loss 0.6337460292203385 Accuracy 61.15209988649262\n",
      "Training:: Epoch 99, Iteration 30, Current loss 0.37682782610682675 Accuracy 61.58502588610116\n",
      "Training:: Epoch 99, Iteration 40, Current loss 0.3638292713137579 Accuracy 59.99188551195043\n",
      "Training:: Epoch 99, Iteration 50, Current loss 0.2725743839064849 Accuracy 63.611144614642384\n",
      "Training:: Epoch 99, Iteration 60, Current loss 0.3215973551042065 Accuracy 67.93979467548286\n",
      "Training:: Epoch 99, Iteration 70, Current loss 0.35076206081881234 Accuracy 56.89542054848445\n",
      "Training:: Epoch 99, Iteration 80, Current loss 0.36347419636775624 Accuracy 70.5822870144097\n",
      "Training:: Epoch 99, Iteration 90, Current loss 0.3410175320151019 Accuracy 69.0805940263641\n",
      "Training:: Epoch 99, Iteration 100, Current loss 0.2711424174007132 Accuracy 62.30765633038679\n",
      "Training:: Epoch 99, Iteration 110, Current loss 0.4356201500870473 Accuracy 67.54242614707731\n",
      "Training:: Epoch 99, Iteration 120, Current loss 0.2688271802364774 Accuracy 63.89671963095848\n",
      "Training:: Epoch 99, Iteration 130, Current loss 0.325897036647907 Accuracy 61.076970348747885\n",
      "Training:: Epoch 99, Iteration 140, Current loss 0.45336356616322077 Accuracy 61.25537249283668\n",
      "Training:: Epoch 99, Iteration 150, Current loss 0.3850258945583671 Accuracy 63.25254104769351\n",
      "Training:: Epoch 99, Iteration 160, Current loss 0.352929380928196 Accuracy 66.29386991109031\n",
      "Training:: Epoch 99, Iteration 170, Current loss 0.29950094450784503 Accuracy 57.85951612148439\n",
      "Training:: Epoch 99, Iteration 180, Current loss 0.30022602998633496 Accuracy 68.23190371249365\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 99, Probability Accuracy 55.4427785098393\n",
      "Starting Training\n",
      "Training:: Epoch 100, Iteration 0, Current loss 0.3236765285195967 Accuracy 53.774931680058735\n",
      "Training:: Epoch 100, Iteration 10, Current loss 0.3910768264725589 Accuracy 66.40045963803504\n",
      "Training:: Epoch 100, Iteration 20, Current loss 0.38305084899161207 Accuracy 64.9055369264742\n",
      "Training:: Epoch 100, Iteration 30, Current loss 0.2961486852752539 Accuracy 56.48953679755467\n",
      "Training:: Epoch 100, Iteration 40, Current loss 0.39364321942710784 Accuracy 68.2667381782426\n",
      "Training:: Epoch 100, Iteration 50, Current loss 0.43427818786294675 Accuracy 67.3813169984686\n",
      "Training:: Epoch 100, Iteration 60, Current loss 0.3048245330897385 Accuracy 59.90232800720687\n",
      "Training:: Epoch 100, Iteration 70, Current loss 0.40850748866369346 Accuracy 54.99039336636667\n",
      "Training:: Epoch 100, Iteration 80, Current loss 0.2696842083582788 Accuracy 72.67955999712416\n",
      "Training:: Epoch 100, Iteration 90, Current loss 0.30225184004092265 Accuracy 57.26637845028267\n",
      "Training:: Epoch 100, Iteration 100, Current loss 0.3712530715590977 Accuracy 69.07062543921293\n",
      "Training:: Epoch 100, Iteration 110, Current loss 0.3380395492220216 Accuracy 64.91047275537808\n",
      "Training:: Epoch 100, Iteration 120, Current loss 0.3355503246769048 Accuracy 56.02655000754262\n",
      "Training:: Epoch 100, Iteration 130, Current loss 0.4133244379393747 Accuracy 73.74234677775674\n",
      "Training:: Epoch 100, Iteration 140, Current loss 0.2926385855113981 Accuracy 55.21840613537846\n",
      "Training:: Epoch 100, Iteration 150, Current loss 0.30487308416542114 Accuracy 65.34348961127203\n",
      "Training:: Epoch 100, Iteration 160, Current loss 0.26464517959481676 Accuracy 71.01260949080759\n",
      "Training:: Epoch 100, Iteration 170, Current loss 0.4088779332974129 Accuracy 59.11483463461707\n",
      "Training:: Epoch 100, Iteration 180, Current loss 0.3681363321564446 Accuracy 64.88098298288006\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 100, Probability Accuracy 55.78664957204079\n",
      "Calculating Expectation\n",
      "Epoch 100 iter 0\n",
      "Epoch 100 iter 10\n",
      "Epoch 100 iter 20\n",
      "Epoch 100 iter 30\n",
      "Epoch 100 iter 40\n",
      "Epoch 100 iter 50\n",
      "Epoch 100 iter 60\n",
      "Epoch 100 iter 70\n",
      "Epoch 100 iter 80\n",
      "Epoch 100 iter 90\n",
      "Epoch 100 iter 100\n",
      "Epoch 100 iter 110\n",
      "Epoch 100 iter 120\n",
      "Epoch 100 iter 130\n",
      "Epoch 100 iter 140\n",
      "Epoch 100 iter 150\n",
      "Epoch 100 iter 160\n",
      "Epoch 100 iter 170\n",
      "Epoch 100 iter 180\n",
      "Train Boundary avergage error = 297.364\n",
      "Train From boundary avergage accuracy = 60.419\n",
      "Starting Training\n",
      "Training:: Epoch 101, Iteration 0, Current loss 0.2568558174683891 Accuracy 61.51485855995965\n",
      "Training:: Epoch 101, Iteration 10, Current loss 0.2615842413227672 Accuracy 61.84738955823293\n",
      "Training:: Epoch 101, Iteration 20, Current loss 0.24679356707192188 Accuracy 69.43594228246612\n",
      "Training:: Epoch 101, Iteration 30, Current loss 0.23036547162368304 Accuracy 65.1315027227436\n",
      "Training:: Epoch 101, Iteration 40, Current loss 0.27570122515204637 Accuracy 65.17142574844382\n",
      "Training:: Epoch 101, Iteration 50, Current loss 0.24106355999856183 Accuracy 69.18390658713035\n",
      "Training:: Epoch 101, Iteration 60, Current loss 0.31720231830840484 Accuracy 54.45521831430375\n",
      "Training:: Epoch 101, Iteration 70, Current loss 0.2967983148311484 Accuracy 65.63024002299622\n",
      "Training:: Epoch 101, Iteration 80, Current loss 0.39230932832598303 Accuracy 50.87207126281908\n",
      "Training:: Epoch 101, Iteration 90, Current loss 0.4019352077866107 Accuracy 60.69545007598105\n",
      "Training:: Epoch 101, Iteration 100, Current loss 0.24700365763564971 Accuracy 65.94110889412903\n",
      "Training:: Epoch 101, Iteration 110, Current loss 0.26143138907556474 Accuracy 62.45472159043046\n",
      "Training:: Epoch 101, Iteration 120, Current loss 0.28038718227425885 Accuracy 72.78929414851746\n",
      "Training:: Epoch 101, Iteration 130, Current loss 0.3827819158987917 Accuracy 58.9571665220478\n",
      "Training:: Epoch 101, Iteration 140, Current loss 0.32820760495884416 Accuracy 63.60141704982287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 101, Iteration 150, Current loss 0.2781475204912534 Accuracy 70.8041014570966\n",
      "Training:: Epoch 101, Iteration 160, Current loss 0.24972961682665035 Accuracy 72.35081851786657\n",
      "Training:: Epoch 101, Iteration 170, Current loss 0.29718879555188554 Accuracy 45.18056859899257\n",
      "Training:: Epoch 101, Iteration 180, Current loss 0.3911122741025508 Accuracy 68.93004115226337\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 101, Probability Accuracy 55.70493567751305\n",
      "Starting Training\n",
      "Training:: Epoch 102, Iteration 0, Current loss 0.2737266095534924 Accuracy 66.01478112563957\n",
      "Training:: Epoch 102, Iteration 10, Current loss 0.27380380733272786 Accuracy 67.59826529909823\n",
      "Training:: Epoch 102, Iteration 20, Current loss 0.2439088671754725 Accuracy 72.21009294491923\n",
      "Training:: Epoch 102, Iteration 30, Current loss 0.23857804759726023 Accuracy 69.44609532865803\n",
      "Training:: Epoch 102, Iteration 40, Current loss 0.20712978522261744 Accuracy 74.38217593580605\n",
      "Training:: Epoch 102, Iteration 50, Current loss 0.2942413566360384 Accuracy 63.46107495782116\n",
      "Training:: Epoch 102, Iteration 60, Current loss 0.29691197569067423 Accuracy 68.95555112617102\n",
      "Training:: Epoch 102, Iteration 70, Current loss 0.28265024130942923 Accuracy 73.15450759829106\n",
      "Training:: Epoch 102, Iteration 80, Current loss 0.26543662329997864 Accuracy 62.921058292105826\n",
      "Training:: Epoch 102, Iteration 90, Current loss 0.31175045861066947 Accuracy 61.758334654197704\n",
      "Training:: Epoch 102, Iteration 100, Current loss 0.26028211278153046 Accuracy 60.220630246560894\n",
      "Training:: Epoch 102, Iteration 110, Current loss 0.29490731217628885 Accuracy 59.8277465529093\n",
      "Training:: Epoch 102, Iteration 120, Current loss 0.364759297069898 Accuracy 60.12505210504377\n",
      "Training:: Epoch 102, Iteration 130, Current loss 0.2160820389599478 Accuracy 63.668562306694604\n",
      "Training:: Epoch 102, Iteration 140, Current loss 0.24910660031110282 Accuracy 58.9801767375209\n",
      "Training:: Epoch 102, Iteration 150, Current loss 0.21720681313329995 Accuracy 57.93872878584148\n",
      "Training:: Epoch 102, Iteration 160, Current loss 0.2724157911671195 Accuracy 65.03589470885403\n",
      "Training:: Epoch 102, Iteration 170, Current loss 0.28857768569297354 Accuracy 61.472769495842385\n",
      "Training:: Epoch 102, Iteration 180, Current loss 0.3117826781421533 Accuracy 61.88570513846646\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 102, Probability Accuracy 55.64854715465492\n",
      "Starting Training\n",
      "Training:: Epoch 103, Iteration 0, Current loss 0.2864241740119518 Accuracy 63.85094366945021\n",
      "Training:: Epoch 103, Iteration 10, Current loss 0.26357845695495663 Accuracy 56.28026070763501\n",
      "Training:: Epoch 103, Iteration 20, Current loss 0.21652891602657307 Accuracy 67.3367411406582\n",
      "Training:: Epoch 103, Iteration 30, Current loss 0.21865670235446 Accuracy 62.630003741114855\n",
      "Training:: Epoch 103, Iteration 40, Current loss 0.2208801737449284 Accuracy 68.60839529301563\n",
      "Training:: Epoch 103, Iteration 50, Current loss 0.23429018980723712 Accuracy 72.6960549432998\n",
      "Training:: Epoch 103, Iteration 60, Current loss 0.3376080298286812 Accuracy 70.69213217273726\n",
      "Training:: Epoch 103, Iteration 70, Current loss 0.22786745160311872 Accuracy 72.02547427300603\n",
      "Training:: Epoch 103, Iteration 80, Current loss 0.25466077998794856 Accuracy 58.87487875848691\n",
      "Training:: Epoch 103, Iteration 90, Current loss 0.3088528558048951 Accuracy 60.1648624491012\n",
      "Training:: Epoch 103, Iteration 100, Current loss 0.25241309786848853 Accuracy 71.21997436326144\n",
      "Training:: Epoch 103, Iteration 110, Current loss 0.2474025099931827 Accuracy 71.21892055791389\n",
      "Training:: Epoch 103, Iteration 120, Current loss 0.3166829310404562 Accuracy 60.969947117244935\n",
      "Training:: Epoch 103, Iteration 130, Current loss 0.26692687504025414 Accuracy 66.39357344257063\n",
      "Training:: Epoch 103, Iteration 140, Current loss 0.2988598030419574 Accuracy 61.31580890496936\n",
      "Training:: Epoch 103, Iteration 150, Current loss 0.3175931912764305 Accuracy 63.739495798319325\n",
      "Training:: Epoch 103, Iteration 160, Current loss 0.38106440133396857 Accuracy 49.86456156644223\n",
      "Training:: Epoch 103, Iteration 170, Current loss 0.40018946561929125 Accuracy 62.206725051356905\n",
      "Training:: Epoch 103, Iteration 180, Current loss 0.21688924502918847 Accuracy 64.23466349017272\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 103, Probability Accuracy 55.910902176794835\n",
      "Starting Training\n",
      "Training:: Epoch 104, Iteration 0, Current loss 0.28029780596875004 Accuracy 62.96296296296296\n",
      "Training:: Epoch 104, Iteration 10, Current loss 0.31051072738197705 Accuracy 58.111954459203034\n",
      "Training:: Epoch 104, Iteration 20, Current loss 0.22466886121936136 Accuracy 54.92704377373576\n",
      "Training:: Epoch 104, Iteration 30, Current loss 0.24005957779436315 Accuracy 54.82852633089396\n",
      "Training:: Epoch 104, Iteration 40, Current loss 0.25642964044748473 Accuracy 64.03695334308122\n",
      "Training:: Epoch 104, Iteration 50, Current loss 0.25634180549520924 Accuracy 70.28768354809709\n",
      "Training:: Epoch 104, Iteration 60, Current loss 0.23054090146786327 Accuracy 65.45777777777778\n",
      "Training:: Epoch 104, Iteration 70, Current loss 0.3127589066474712 Accuracy 63.75203627878307\n",
      "Training:: Epoch 104, Iteration 80, Current loss 0.24855977866141574 Accuracy 61.16956612869419\n",
      "Training:: Epoch 104, Iteration 90, Current loss 0.23159096091807813 Accuracy 64.19909981466773\n",
      "Training:: Epoch 104, Iteration 100, Current loss 0.24908088528659494 Accuracy 52.34720416124838\n",
      "Training:: Epoch 104, Iteration 110, Current loss 0.2901829968620656 Accuracy 64.35766310243298\n",
      "Training:: Epoch 104, Iteration 120, Current loss 0.23261981116758557 Accuracy 66.01527403414195\n",
      "Training:: Epoch 104, Iteration 130, Current loss 0.21442543001743222 Accuracy 70.6332889910106\n",
      "Training:: Epoch 104, Iteration 140, Current loss 0.3021834541805801 Accuracy 54.85587583148559\n",
      "Training:: Epoch 104, Iteration 150, Current loss 0.30430295633917137 Accuracy 59.77541030809099\n",
      "Training:: Epoch 104, Iteration 160, Current loss 0.2531529763907189 Accuracy 56.770013882461825\n",
      "Training:: Epoch 104, Iteration 170, Current loss 0.24665049734102848 Accuracy 67.0995670995671\n",
      "Training:: Epoch 104, Iteration 180, Current loss 0.2673899844899393 Accuracy 71.55489530277306\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 104, Probability Accuracy 55.17963206983471\n",
      "Starting Training\n",
      "Training:: Epoch 105, Iteration 0, Current loss 0.270579525496105 Accuracy 56.78410337681336\n",
      "Training:: Epoch 105, Iteration 10, Current loss 0.25655129418321776 Accuracy 61.05009375837128\n",
      "Training:: Epoch 105, Iteration 20, Current loss 0.2996574303716309 Accuracy 63.482446676072705\n",
      "Training:: Epoch 105, Iteration 30, Current loss 0.21126329832118296 Accuracy 46.358447488584474\n",
      "Training:: Epoch 105, Iteration 40, Current loss 0.20394250558659457 Accuracy 72.35989803167705\n",
      "Training:: Epoch 105, Iteration 50, Current loss 0.21970674866152415 Accuracy 74.15772633163938\n",
      "Training:: Epoch 105, Iteration 60, Current loss 0.2883719782952566 Accuracy 63.30751297285102\n",
      "Training:: Epoch 105, Iteration 70, Current loss 0.21313647707813077 Accuracy 50.6578947368421\n",
      "Training:: Epoch 105, Iteration 80, Current loss 0.2882133255888045 Accuracy 64.61760307626575\n",
      "Training:: Epoch 105, Iteration 90, Current loss 0.2640661610647842 Accuracy 66.20215897939156\n",
      "Training:: Epoch 105, Iteration 100, Current loss 0.2602054209750476 Accuracy 61.41418871458675\n",
      "Training:: Epoch 105, Iteration 110, Current loss 0.33395313835836576 Accuracy 58.35746793545718\n",
      "Training:: Epoch 105, Iteration 120, Current loss 0.29148276521086297 Accuracy 64.99451754385964\n",
      "Training:: Epoch 105, Iteration 130, Current loss 0.29951818224074 Accuracy 64.30967741935484\n",
      "Training:: Epoch 105, Iteration 140, Current loss 0.21512802801955025 Accuracy 58.78823529411765\n",
      "Training:: Epoch 105, Iteration 150, Current loss 0.1757783361028354 Accuracy 72.1280184659091\n",
      "Training:: Epoch 105, Iteration 160, Current loss 0.24156803397840865 Accuracy 57.10270053207509\n",
      "Training:: Epoch 105, Iteration 170, Current loss 0.23373966219761239 Accuracy 66.56720466567205\n",
      "Training:: Epoch 105, Iteration 180, Current loss 0.3414398525005645 Accuracy 63.05308230816285\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 105, Probability Accuracy 55.84224667703424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Completed 160 videos selected frames calculation\n",
      "Completed 170 videos selected frames calculation\n",
      "Completed 180 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.524532119372786\n",
      "Calculating Expectation\n",
      "Epoch 105 iter 0\n",
      "Epoch 105 iter 10\n",
      "Epoch 105 iter 20\n",
      "Epoch 105 iter 30\n",
      "Epoch 105 iter 40\n",
      "Epoch 105 iter 50\n",
      "Epoch 105 iter 60\n",
      "Epoch 105 iter 70\n",
      "Epoch 105 iter 80\n",
      "Epoch 105 iter 90\n",
      "Epoch 105 iter 100\n",
      "Epoch 105 iter 110\n",
      "Epoch 105 iter 120\n",
      "Epoch 105 iter 130\n",
      "Epoch 105 iter 140\n",
      "Epoch 105 iter 150\n",
      "Epoch 105 iter 160\n",
      "Epoch 105 iter 170\n",
      "Epoch 105 iter 180\n",
      "Train Boundary avergage error = 297.103\n",
      "Train From boundary avergage accuracy = 60.452\n",
      "Starting Training\n",
      "Training:: Epoch 106, Iteration 0, Current loss 0.25422341453330827 Accuracy 64.346815048584\n",
      "Training:: Epoch 106, Iteration 10, Current loss 0.23684581758881523 Accuracy 70.73884418434528\n",
      "Training:: Epoch 106, Iteration 20, Current loss 0.264392241452725 Accuracy 74.88063660477454\n",
      "Training:: Epoch 106, Iteration 30, Current loss 0.2927822903576339 Accuracy 57.223418836890545\n",
      "Training:: Epoch 106, Iteration 40, Current loss 0.24910981395050405 Accuracy 63.11990301961649\n",
      "Training:: Epoch 106, Iteration 50, Current loss 0.2574835617991965 Accuracy 52.514713750668804\n",
      "Training:: Epoch 106, Iteration 60, Current loss 0.19748042702044064 Accuracy 59.62652596730809\n",
      "Training:: Epoch 106, Iteration 70, Current loss 0.25917144633726014 Accuracy 61.62570888468809\n",
      "Training:: Epoch 106, Iteration 80, Current loss 0.3858920931506322 Accuracy 63.56849001980802\n",
      "Training:: Epoch 106, Iteration 90, Current loss 0.23479599366108597 Accuracy 61.450519656574784\n",
      "Training:: Epoch 106, Iteration 100, Current loss 0.37228637448486823 Accuracy 66.88215736978205\n",
      "Training:: Epoch 106, Iteration 110, Current loss 0.2307191689084387 Accuracy 68.0319175799202\n",
      "Training:: Epoch 106, Iteration 120, Current loss 0.2537108291973446 Accuracy 71.01927951455565\n",
      "Training:: Epoch 106, Iteration 130, Current loss 0.2987013354864484 Accuracy 66.63616398243046\n",
      "Training:: Epoch 106, Iteration 140, Current loss 0.30624861184483243 Accuracy 62.7239302198232\n",
      "Training:: Epoch 106, Iteration 150, Current loss 0.26172650210226617 Accuracy 61.464564074678265\n",
      "Training:: Epoch 106, Iteration 160, Current loss 0.3261755784514311 Accuracy 51.74965181058496\n",
      "Training:: Epoch 106, Iteration 170, Current loss 0.31678041542429053 Accuracy 64.31259044862519\n",
      "Training:: Epoch 106, Iteration 180, Current loss 0.27446521103843935 Accuracy 64.53537536408908\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 106, Probability Accuracy 55.48215154860691\n",
      "Starting Training\n",
      "Training:: Epoch 107, Iteration 0, Current loss 0.27344119322389415 Accuracy 61.32208157524613\n",
      "Training:: Epoch 107, Iteration 10, Current loss 0.3084524745135681 Accuracy 67.498776309349\n",
      "Training:: Epoch 107, Iteration 20, Current loss 0.36704529285216353 Accuracy 66.566655854687\n",
      "Training:: Epoch 107, Iteration 30, Current loss 0.3610704648843872 Accuracy 54.61702845574176\n",
      "Training:: Epoch 107, Iteration 40, Current loss 0.2823137559200396 Accuracy 63.83208395802099\n",
      "Training:: Epoch 107, Iteration 50, Current loss 0.4993714256995242 Accuracy 52.92096219931271\n",
      "Training:: Epoch 107, Iteration 60, Current loss 0.3173971831180149 Accuracy 59.1100140102742\n",
      "Training:: Epoch 107, Iteration 70, Current loss 0.32775188806484207 Accuracy 60.26896125309151\n",
      "Training:: Epoch 107, Iteration 80, Current loss 0.35744644700143147 Accuracy 64.06463359126082\n",
      "Training:: Epoch 107, Iteration 90, Current loss 0.3075954137186749 Accuracy 68.26565677817518\n",
      "Training:: Epoch 107, Iteration 100, Current loss 0.2350606947981259 Accuracy 62.43581957709932\n",
      "Training:: Epoch 107, Iteration 110, Current loss 0.2054440202218321 Accuracy 70.0909435392194\n",
      "Training:: Epoch 107, Iteration 120, Current loss 0.3292388154068183 Accuracy 72.15351812366738\n",
      "Training:: Epoch 107, Iteration 130, Current loss 0.23008398513328318 Accuracy 59.47053918843802\n",
      "Training:: Epoch 107, Iteration 140, Current loss 0.19018379753579784 Accuracy 68.5781836725233\n",
      "Training:: Epoch 107, Iteration 150, Current loss 0.2231433835594952 Accuracy 60.899155489319426\n",
      "Training:: Epoch 107, Iteration 160, Current loss 0.2906246564614851 Accuracy 65.41065088757396\n",
      "Training:: Epoch 107, Iteration 170, Current loss 0.4272079351220007 Accuracy 64.78206872079957\n",
      "Training:: Epoch 107, Iteration 180, Current loss 0.21763061189506872 Accuracy 71.29171266783005\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 107, Probability Accuracy 55.804654328462156\n",
      "Starting Training\n",
      "Training:: Epoch 108, Iteration 0, Current loss 0.2647216798439147 Accuracy 65.41745730550285\n",
      "Training:: Epoch 108, Iteration 10, Current loss 0.364046745174309 Accuracy 62.86157275061776\n",
      "Training:: Epoch 108, Iteration 20, Current loss 0.2576202084362024 Accuracy 66.14827931326506\n",
      "Training:: Epoch 108, Iteration 30, Current loss 0.38993560118148374 Accuracy 59.584243850507086\n",
      "Training:: Epoch 108, Iteration 40, Current loss 0.3280013392926344 Accuracy 62.67563527653214\n",
      "Training:: Epoch 108, Iteration 50, Current loss 0.2868104818950069 Accuracy 66.40656874745002\n",
      "Training:: Epoch 108, Iteration 60, Current loss 0.2957169535356784 Accuracy 59.72989042724879\n",
      "Training:: Epoch 108, Iteration 70, Current loss 0.3404700037183511 Accuracy 60.96837278306022\n",
      "Training:: Epoch 108, Iteration 80, Current loss 0.4020015873317859 Accuracy 62.06950288296712\n",
      "Training:: Epoch 108, Iteration 90, Current loss 0.3211865975113986 Accuracy 61.9912743374357\n",
      "Training:: Epoch 108, Iteration 100, Current loss 0.3039353788638823 Accuracy 67.40615116652152\n",
      "Training:: Epoch 108, Iteration 110, Current loss 0.24986058348303902 Accuracy 56.63751987281399\n",
      "Training:: Epoch 108, Iteration 120, Current loss 0.2150526888166906 Accuracy 63.56506404306664\n",
      "Training:: Epoch 108, Iteration 130, Current loss 0.3067338634677714 Accuracy 62.056\n",
      "Training:: Epoch 108, Iteration 140, Current loss 0.23562422055372942 Accuracy 69.02449844728152\n",
      "Training:: Epoch 108, Iteration 150, Current loss 0.23276565230121216 Accuracy 69.25815639564992\n",
      "Training:: Epoch 108, Iteration 160, Current loss 0.23074915383749767 Accuracy 62.12216845501087\n",
      "Training:: Epoch 108, Iteration 170, Current loss 0.2452657392768121 Accuracy 60.12585466206813\n",
      "Training:: Epoch 108, Iteration 180, Current loss 0.41751122082773745 Accuracy 60.009372071227745\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 108, Probability Accuracy 56.12834423511442\n",
      "Starting Training\n",
      "Training:: Epoch 109, Iteration 0, Current loss 0.2622509814557525 Accuracy 63.99264132010258\n",
      "Training:: Epoch 109, Iteration 10, Current loss 0.40427084932737 Accuracy 69.62379257752923\n",
      "Training:: Epoch 109, Iteration 20, Current loss 0.3097930350320917 Accuracy 59.969232827235636\n",
      "Training:: Epoch 109, Iteration 30, Current loss 0.27366874916062056 Accuracy 64.18392252578538\n",
      "Training:: Epoch 109, Iteration 40, Current loss 0.24522474915761172 Accuracy 69.29171180931745\n",
      "Training:: Epoch 109, Iteration 50, Current loss 0.20956888244860905 Accuracy 68.22297679683079\n",
      "Training:: Epoch 109, Iteration 60, Current loss 0.33244826473827443 Accuracy 64.22365783025172\n",
      "Training:: Epoch 109, Iteration 70, Current loss 0.30734554458166247 Accuracy 63.2861871802588\n",
      "Training:: Epoch 109, Iteration 80, Current loss 0.2941966780217647 Accuracy 71.65656738072886\n",
      "Training:: Epoch 109, Iteration 90, Current loss 0.29297503811045233 Accuracy 73.03413641853665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 109, Iteration 100, Current loss 0.22773973548352708 Accuracy 68.65683051754453\n",
      "Training:: Epoch 109, Iteration 110, Current loss 0.23931984533582418 Accuracy 59.34601664684899\n",
      "Training:: Epoch 109, Iteration 120, Current loss 0.39740944816840296 Accuracy 51.94687305909894\n",
      "Training:: Epoch 109, Iteration 130, Current loss 0.2482832069739183 Accuracy 65.72785561624318\n",
      "Training:: Epoch 109, Iteration 140, Current loss 0.2507453259712667 Accuracy 62.9230070406541\n",
      "Training:: Epoch 109, Iteration 150, Current loss 0.26106031045745326 Accuracy 66.67310167310167\n",
      "Training:: Epoch 109, Iteration 160, Current loss 0.23831460002380256 Accuracy 69.92729180721085\n",
      "Training:: Epoch 109, Iteration 170, Current loss 0.2735422641538763 Accuracy 56.757436112274824\n",
      "Training:: Epoch 109, Iteration 180, Current loss 0.3047482741839181 Accuracy 58.80873688748383\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 109, Probability Accuracy 55.222368634527186\n",
      "Starting Training\n",
      "Training:: Epoch 110, Iteration 0, Current loss 0.41027753493459784 Accuracy 63.18126414765802\n",
      "Training:: Epoch 110, Iteration 10, Current loss 0.2913753777099598 Accuracy 64.4072822155014\n",
      "Training:: Epoch 110, Iteration 20, Current loss 0.3186431429441014 Accuracy 63.10223872897968\n",
      "Training:: Epoch 110, Iteration 30, Current loss 0.37678822269814105 Accuracy 70.13040700514864\n",
      "Training:: Epoch 110, Iteration 40, Current loss 0.3339041794792786 Accuracy 66.70900008466684\n",
      "Training:: Epoch 110, Iteration 50, Current loss 0.4141332626250497 Accuracy 67.97024228410577\n",
      "Training:: Epoch 110, Iteration 60, Current loss 0.3421137304757126 Accuracy 64.59690553745928\n",
      "Training:: Epoch 110, Iteration 70, Current loss 0.39927306379739286 Accuracy 70.93901780895844\n",
      "Training:: Epoch 110, Iteration 80, Current loss 0.3003209874287 Accuracy 59.16576770945703\n",
      "Training:: Epoch 110, Iteration 90, Current loss 0.21336327448464615 Accuracy 54.908383176682804\n",
      "Training:: Epoch 110, Iteration 100, Current loss 0.3263898683054186 Accuracy 64.60039305601047\n",
      "Training:: Epoch 110, Iteration 110, Current loss 0.24340257792861003 Accuracy 67.2930704086048\n",
      "Training:: Epoch 110, Iteration 120, Current loss 0.35796282364678556 Accuracy 72.92871457200114\n",
      "Training:: Epoch 110, Iteration 130, Current loss 0.30299216763189846 Accuracy 56.413662239089184\n",
      "Training:: Epoch 110, Iteration 140, Current loss 0.39271268394175185 Accuracy 61.833080965529525\n",
      "Training:: Epoch 110, Iteration 150, Current loss 0.2686002902625572 Accuracy 65.82827960421321\n",
      "Training:: Epoch 110, Iteration 160, Current loss 0.39968175421831714 Accuracy 70.20243425616447\n",
      "Training:: Epoch 110, Iteration 170, Current loss 0.2853547515705933 Accuracy 58.51925630810093\n",
      "Training:: Epoch 110, Iteration 180, Current loss 0.2700174532351803 Accuracy 67.34231916863875\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 110, Probability Accuracy 55.31615165149123\n",
      "Calculating Expectation\n",
      "Epoch 110 iter 0\n",
      "Epoch 110 iter 10\n",
      "Epoch 110 iter 20\n",
      "Epoch 110 iter 30\n",
      "Epoch 110 iter 40\n",
      "Epoch 110 iter 50\n",
      "Epoch 110 iter 60\n",
      "Epoch 110 iter 70\n",
      "Epoch 110 iter 80\n",
      "Epoch 110 iter 90\n",
      "Epoch 110 iter 100\n",
      "Epoch 110 iter 110\n",
      "Epoch 110 iter 120\n",
      "Epoch 110 iter 130\n",
      "Epoch 110 iter 140\n",
      "Epoch 110 iter 150\n",
      "Epoch 110 iter 160\n",
      "Epoch 110 iter 170\n",
      "Epoch 110 iter 180\n",
      "Train Boundary avergage error = 297.089\n",
      "Train From boundary avergage accuracy = 60.448\n",
      "Starting Training\n",
      "Training:: Epoch 111, Iteration 0, Current loss 0.3304188261929684 Accuracy 62.23853211009175\n",
      "Training:: Epoch 111, Iteration 10, Current loss 0.3485709127201208 Accuracy 68.99812382739212\n",
      "Training:: Epoch 111, Iteration 20, Current loss 0.2427528405224115 Accuracy 63.10361368724017\n",
      "Training:: Epoch 111, Iteration 30, Current loss 0.31031775137459566 Accuracy 65.57522647877316\n",
      "Training:: Epoch 111, Iteration 40, Current loss 0.36081862877490445 Accuracy 52.72248913292153\n",
      "Training:: Epoch 111, Iteration 50, Current loss 0.30965503108683107 Accuracy 62.87261618218848\n",
      "Training:: Epoch 111, Iteration 60, Current loss 0.24161538568873214 Accuracy 66.64955635403682\n",
      "Training:: Epoch 111, Iteration 70, Current loss 0.19526767508369763 Accuracy 72.85686888704213\n",
      "Training:: Epoch 111, Iteration 80, Current loss 0.2590724079316338 Accuracy 67.39793971766501\n",
      "Training:: Epoch 111, Iteration 90, Current loss 0.3581320085589408 Accuracy 63.483530446681655\n",
      "Training:: Epoch 111, Iteration 100, Current loss 0.22624449541657599 Accuracy 73.30223258913695\n",
      "Training:: Epoch 111, Iteration 110, Current loss 0.27188502095225553 Accuracy 67.76869737493809\n",
      "Training:: Epoch 111, Iteration 120, Current loss 0.25991273418721983 Accuracy 66.45095800025378\n",
      "Training:: Epoch 111, Iteration 130, Current loss 0.3510590784153992 Accuracy 62.39552862515671\n",
      "Training:: Epoch 111, Iteration 140, Current loss 0.33015449264363994 Accuracy 67.13387043372695\n",
      "Training:: Epoch 111, Iteration 150, Current loss 0.195368753030761 Accuracy 66.19953984522067\n",
      "Training:: Epoch 111, Iteration 160, Current loss 0.2761575442282005 Accuracy 64.24684431977559\n",
      "Training:: Epoch 111, Iteration 170, Current loss 0.27595371214120734 Accuracy 60.75478600170711\n",
      "Training:: Epoch 111, Iteration 180, Current loss 0.24740868528743062 Accuracy 67.74263999301127\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 111, Probability Accuracy 55.43466647672638\n",
      "Starting Training\n",
      "Training:: Epoch 112, Iteration 0, Current loss 0.26232865675712247 Accuracy 73.46339170290281\n",
      "Training:: Epoch 112, Iteration 10, Current loss 0.26850609973990713 Accuracy 60.380302855161254\n",
      "Training:: Epoch 112, Iteration 20, Current loss 0.18560224345696863 Accuracy 66.5489404641776\n",
      "Training:: Epoch 112, Iteration 30, Current loss 0.25298877096700734 Accuracy 70.98238605411295\n",
      "Training:: Epoch 112, Iteration 40, Current loss 0.3871511967960436 Accuracy 61.09048040082523\n",
      "Training:: Epoch 112, Iteration 50, Current loss 0.19875970856608038 Accuracy 75.01139471285323\n",
      "Training:: Epoch 112, Iteration 60, Current loss 0.24386901881298179 Accuracy 70.91078066914498\n",
      "Training:: Epoch 112, Iteration 70, Current loss 0.2588100818042063 Accuracy 68.87164108896337\n",
      "Training:: Epoch 112, Iteration 80, Current loss 0.2847609673047605 Accuracy 55.80001016208526\n",
      "Training:: Epoch 112, Iteration 90, Current loss 0.23998849244547032 Accuracy 64.35014105773433\n",
      "Training:: Epoch 112, Iteration 100, Current loss 0.4634064001205375 Accuracy 61.542635658914726\n",
      "Training:: Epoch 112, Iteration 110, Current loss 0.48471419399953986 Accuracy 68.96673209522372\n",
      "Training:: Epoch 112, Iteration 120, Current loss 0.9018622420831048 Accuracy 60.176798782696906\n",
      "Training:: Epoch 112, Iteration 130, Current loss 0.6608153058873525 Accuracy 56.14263226336322\n",
      "Training:: Epoch 112, Iteration 140, Current loss 0.4238803778108923 Accuracy 57.73995271867612\n",
      "Training:: Epoch 112, Iteration 150, Current loss 1.1622441538349955 Accuracy 66.73335667483619\n",
      "Training:: Epoch 112, Iteration 160, Current loss 0.3531712574565297 Accuracy 67.01213570732571\n",
      "Training:: Epoch 112, Iteration 170, Current loss 0.5039681710359898 Accuracy 64.54437869822485\n",
      "Training:: Epoch 112, Iteration 180, Current loss 0.7136081141464812 Accuracy 63.12107077671872\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 112, Probability Accuracy 55.70315498731753\n",
      "Starting Training\n",
      "Training:: Epoch 113, Iteration 0, Current loss 0.36008730219186874 Accuracy 51.14448696656798\n",
      "Training:: Epoch 113, Iteration 10, Current loss 0.5471015336652195 Accuracy 66.87261198276563\n",
      "Training:: Epoch 113, Iteration 20, Current loss 0.5823009989634395 Accuracy 66.66484028272423\n",
      "Training:: Epoch 113, Iteration 30, Current loss 0.4397078206888941 Accuracy 75.42492392191791\n",
      "Training:: Epoch 113, Iteration 40, Current loss 0.5347515813915094 Accuracy 65.73244032285763\n",
      "Training:: Epoch 113, Iteration 50, Current loss 0.6688633391192453 Accuracy 61.10319181902696\n",
      "Training:: Epoch 113, Iteration 60, Current loss 0.6147344323628416 Accuracy 66.92276587141124\n",
      "Training:: Epoch 113, Iteration 70, Current loss 0.5204093041566719 Accuracy 71.79994010182689\n",
      "Training:: Epoch 113, Iteration 80, Current loss 0.6330594859557794 Accuracy 58.258323392256806\n",
      "Training:: Epoch 113, Iteration 90, Current loss 0.6816427586160605 Accuracy 52.43468332325878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 113, Iteration 100, Current loss 0.6687468432388621 Accuracy 65.82815671320499\n",
      "Training:: Epoch 113, Iteration 110, Current loss 0.4760350435877987 Accuracy 68.45039826212889\n",
      "Training:: Epoch 113, Iteration 120, Current loss 0.3420596431054591 Accuracy 60.54326396495071\n",
      "Training:: Epoch 113, Iteration 130, Current loss 0.5131246745740959 Accuracy 66.65953349026321\n",
      "Training:: Epoch 113, Iteration 140, Current loss 0.2905693301399933 Accuracy 70.46024838801893\n",
      "Training:: Epoch 113, Iteration 150, Current loss 0.4412043437369505 Accuracy 64.03955034052679\n",
      "Training:: Epoch 113, Iteration 160, Current loss 0.328544508380492 Accuracy 60.95397978175979\n",
      "Training:: Epoch 113, Iteration 170, Current loss 0.3396607134391308 Accuracy 67.64820745137858\n",
      "Training:: Epoch 113, Iteration 180, Current loss 0.38889207331783443 Accuracy 57.97936371453138\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 113, Probability Accuracy 54.77719608564724\n",
      "Starting Training\n",
      "Training:: Epoch 114, Iteration 0, Current loss 0.2745948451607356 Accuracy 54.63703874273214\n",
      "Training:: Epoch 114, Iteration 10, Current loss 0.31914379742156057 Accuracy 55.95667870036101\n",
      "Training:: Epoch 114, Iteration 20, Current loss 0.47596191842542196 Accuracy 67.95784362412404\n",
      "Training:: Epoch 114, Iteration 30, Current loss 0.3806427810923582 Accuracy 58.01269337564459\n",
      "Training:: Epoch 114, Iteration 40, Current loss 0.3123040552211146 Accuracy 59.294871794871796\n",
      "Training:: Epoch 114, Iteration 50, Current loss 0.3008218404830754 Accuracy 67.15408517638457\n",
      "Training:: Epoch 114, Iteration 60, Current loss 0.48900818385874156 Accuracy 68.20000721006525\n",
      "Training:: Epoch 114, Iteration 70, Current loss 0.3165056847473002 Accuracy 61.36651407421837\n",
      "Training:: Epoch 114, Iteration 80, Current loss 0.39147512449000604 Accuracy 56.01326584046081\n",
      "Training:: Epoch 114, Iteration 90, Current loss 0.2355837278121708 Accuracy 62.07686091407022\n",
      "Training:: Epoch 114, Iteration 100, Current loss 0.3924280185637918 Accuracy 53.295914371491975\n",
      "Training:: Epoch 114, Iteration 110, Current loss 0.45158486307259804 Accuracy 53.78338682478377\n",
      "Training:: Epoch 114, Iteration 120, Current loss 0.3202776436389995 Accuracy 70.26562611870838\n",
      "Training:: Epoch 114, Iteration 130, Current loss 0.3581515659313303 Accuracy 67.34515211205954\n",
      "Training:: Epoch 114, Iteration 140, Current loss 0.2411814982194091 Accuracy 72.77691525242251\n",
      "Training:: Epoch 114, Iteration 150, Current loss 0.23623856041757124 Accuracy 63.804359271348844\n",
      "Training:: Epoch 114, Iteration 160, Current loss 0.3526652201882104 Accuracy 57.711908476339055\n",
      "Training:: Epoch 114, Iteration 170, Current loss 0.2660114168012064 Accuracy 65.79284632412909\n",
      "Training:: Epoch 114, Iteration 180, Current loss 0.33828596679491607 Accuracy 59.93147751605996\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 114, Probability Accuracy 55.62243036512063\n",
      "Starting Training\n",
      "Training:: Epoch 115, Iteration 0, Current loss 0.27522104049783847 Accuracy 62.56539668861944\n",
      "Training:: Epoch 115, Iteration 10, Current loss 0.29758810490598164 Accuracy 69.50582955266111\n",
      "Training:: Epoch 115, Iteration 20, Current loss 0.3191701161762091 Accuracy 65.95481821390752\n",
      "Training:: Epoch 115, Iteration 30, Current loss 0.27089543838873076 Accuracy 65.31082118188795\n",
      "Training:: Epoch 115, Iteration 40, Current loss 0.23228683549820578 Accuracy 53.09364548494983\n",
      "Training:: Epoch 115, Iteration 50, Current loss 0.284014352743226 Accuracy 52.18680055653016\n",
      "Training:: Epoch 115, Iteration 60, Current loss 0.20887181236738422 Accuracy 71.94207517105633\n",
      "Training:: Epoch 115, Iteration 70, Current loss 0.2633025611710774 Accuracy 55.230554261760595\n",
      "Training:: Epoch 115, Iteration 80, Current loss 0.24991952735630146 Accuracy 57.808323787705234\n",
      "Training:: Epoch 115, Iteration 90, Current loss 0.2564126452145996 Accuracy 60.74962986051586\n",
      "Training:: Epoch 115, Iteration 100, Current loss 0.24278436040529378 Accuracy 75.72183503101785\n",
      "Training:: Epoch 115, Iteration 110, Current loss 0.2622860311556805 Accuracy 66.80911680911682\n",
      "Training:: Epoch 115, Iteration 120, Current loss 1.0593316879756691 Accuracy 49.279131565556625\n",
      "Training:: Epoch 115, Iteration 130, Current loss 0.4443633483529219 Accuracy 67.95674160116157\n",
      "Training:: Epoch 115, Iteration 140, Current loss 0.3468506254580886 Accuracy 61.963656088961216\n",
      "Training:: Epoch 115, Iteration 150, Current loss 0.3860341292121426 Accuracy 67.5498298492951\n",
      "Training:: Epoch 115, Iteration 160, Current loss 0.3139283228879415 Accuracy 64.13314981903451\n",
      "Training:: Epoch 115, Iteration 170, Current loss 0.4582173691388279 Accuracy 61.91586905815169\n",
      "Training:: Epoch 115, Iteration 180, Current loss 0.29205494692872275 Accuracy 66.57835268448531\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 115, Probability Accuracy 55.73085461258117\n",
      "Calculating Expectation\n",
      "Epoch 115 iter 0\n",
      "Epoch 115 iter 10\n",
      "Epoch 115 iter 20\n",
      "Epoch 115 iter 30\n",
      "Epoch 115 iter 40\n",
      "Epoch 115 iter 50\n",
      "Epoch 115 iter 60\n",
      "Epoch 115 iter 70\n",
      "Epoch 115 iter 80\n",
      "Epoch 115 iter 90\n",
      "Epoch 115 iter 100\n",
      "Epoch 115 iter 110\n",
      "Epoch 115 iter 120\n",
      "Epoch 115 iter 130\n",
      "Epoch 115 iter 140\n",
      "Epoch 115 iter 150\n",
      "Epoch 115 iter 160\n",
      "Epoch 115 iter 170\n",
      "Epoch 115 iter 180\n",
      "Train Boundary avergage error = 297.056\n",
      "Train From boundary avergage accuracy = 60.517\n",
      "Starting Training\n",
      "Training:: Epoch 116, Iteration 0, Current loss 0.2916014792560371 Accuracy 64.83768525052929\n",
      "Training:: Epoch 116, Iteration 10, Current loss 0.4194359342350217 Accuracy 75.81037277147487\n",
      "Training:: Epoch 116, Iteration 20, Current loss 0.6230910702232081 Accuracy 68.43763223470779\n",
      "Training:: Epoch 116, Iteration 30, Current loss 0.6298479639843358 Accuracy 57.61163996594691\n",
      "Training:: Epoch 116, Iteration 40, Current loss 0.552311841114708 Accuracy 67.0438269836723\n",
      "Training:: Epoch 116, Iteration 50, Current loss 0.46165486740663486 Accuracy 64.28264420183959\n",
      "Training:: Epoch 116, Iteration 60, Current loss 0.3871361862681655 Accuracy 56.97953693918724\n",
      "Training:: Epoch 116, Iteration 70, Current loss 0.2777015338026416 Accuracy 56.82448225254117\n",
      "Training:: Epoch 116, Iteration 80, Current loss 0.2945090840010615 Accuracy 55.28005034612964\n",
      "Training:: Epoch 116, Iteration 90, Current loss 0.39021656528217236 Accuracy 67.61501210653753\n",
      "Training:: Epoch 116, Iteration 100, Current loss 0.27792818377781026 Accuracy 65.04477782214363\n",
      "Training:: Epoch 116, Iteration 110, Current loss 0.31289888177304964 Accuracy 60.537006474546146\n",
      "Training:: Epoch 116, Iteration 120, Current loss 0.30255469843497407 Accuracy 70.97996751488901\n",
      "Training:: Epoch 116, Iteration 130, Current loss 0.3057426525904669 Accuracy 63.46729093510209\n",
      "Training:: Epoch 116, Iteration 140, Current loss 0.2787206647736022 Accuracy 62.191494493126456\n",
      "Training:: Epoch 116, Iteration 150, Current loss 0.36949456736178415 Accuracy 63.885735906167234\n",
      "Training:: Epoch 116, Iteration 160, Current loss 0.4066496309560742 Accuracy 58.79231789607244\n",
      "Training:: Epoch 116, Iteration 170, Current loss 0.3391909134264926 Accuracy 61.92667587053229\n",
      "Training:: Epoch 116, Iteration 180, Current loss 0.19383638367900946 Accuracy 67.91009899307474\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 116, Probability Accuracy 55.97421560596887\n",
      "Starting Training\n",
      "Training:: Epoch 117, Iteration 0, Current loss 0.3590417481361211 Accuracy 67.21554421208629\n",
      "Training:: Epoch 117, Iteration 10, Current loss 0.3578945375790961 Accuracy 60.71578505457599\n",
      "Training:: Epoch 117, Iteration 20, Current loss 0.2098948771305173 Accuracy 75.26071493158116\n",
      "Training:: Epoch 117, Iteration 30, Current loss 0.36368855718218224 Accuracy 61.11721730135126\n",
      "Training:: Epoch 117, Iteration 40, Current loss 0.2993129409700516 Accuracy 67.49065537004735\n",
      "Training:: Epoch 117, Iteration 50, Current loss 0.23047994839665079 Accuracy 65.79025329580803\n",
      "Training:: Epoch 117, Iteration 60, Current loss 0.3031923916991813 Accuracy 59.121971422654795\n",
      "Training:: Epoch 117, Iteration 70, Current loss 0.33066942860755705 Accuracy 68.04435896386627\n",
      "Training:: Epoch 117, Iteration 80, Current loss 0.3163606404274132 Accuracy 67.88170563961485\n",
      "Training:: Epoch 117, Iteration 90, Current loss 0.28502051315097654 Accuracy 63.62014021669854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 117, Iteration 100, Current loss 0.36154747716471664 Accuracy 64.08305921052632\n",
      "Training:: Epoch 117, Iteration 110, Current loss 0.42606771464652804 Accuracy 62.324386377302794\n",
      "Training:: Epoch 117, Iteration 120, Current loss 0.2721908433777067 Accuracy 41.829847512707275\n",
      "Training:: Epoch 117, Iteration 130, Current loss 0.2387631301680758 Accuracy 62.486740764654336\n",
      "Training:: Epoch 117, Iteration 140, Current loss 0.3179442050573699 Accuracy 62.720648989709304\n",
      "Training:: Epoch 117, Iteration 150, Current loss 0.36628246025690814 Accuracy 53.74505823271717\n",
      "Training:: Epoch 117, Iteration 160, Current loss 0.315432331042028 Accuracy 60.206686173193056\n",
      "Training:: Epoch 117, Iteration 170, Current loss 0.20194199251033298 Accuracy 75.0233107478088\n",
      "Training:: Epoch 117, Iteration 180, Current loss 0.5078575070053756 Accuracy 50.78363311244346\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 117, Probability Accuracy 55.9943967615181\n",
      "Starting Training\n",
      "Training:: Epoch 118, Iteration 0, Current loss 0.24441135046548249 Accuracy 67.17192908842966\n",
      "Training:: Epoch 118, Iteration 10, Current loss 0.40218058810489343 Accuracy 62.51478789927328\n",
      "Training:: Epoch 118, Iteration 20, Current loss 0.36831143123667676 Accuracy 59.27756653992395\n",
      "Training:: Epoch 118, Iteration 30, Current loss 0.2606811528974489 Accuracy 61.90921561291932\n",
      "Training:: Epoch 118, Iteration 40, Current loss 0.23811269354384432 Accuracy 59.3803481853054\n",
      "Training:: Epoch 118, Iteration 50, Current loss 0.2536981723450523 Accuracy 68.76512190582542\n",
      "Training:: Epoch 118, Iteration 60, Current loss 0.32535504622883443 Accuracy 48.3568580971878\n",
      "Training:: Epoch 118, Iteration 70, Current loss 0.21451694990838274 Accuracy 59.13689195006457\n",
      "Training:: Epoch 118, Iteration 80, Current loss 0.23495647109308826 Accuracy 71.78441056474125\n",
      "Training:: Epoch 118, Iteration 90, Current loss 0.2625764145555181 Accuracy 66.86800894854586\n",
      "Training:: Epoch 118, Iteration 100, Current loss 0.3074106841721506 Accuracy 58.62156663275687\n",
      "Training:: Epoch 118, Iteration 110, Current loss 0.29398840164289103 Accuracy 70.53093312065626\n",
      "Training:: Epoch 118, Iteration 120, Current loss 0.2600557608314127 Accuracy 69.08136186550732\n",
      "Training:: Epoch 118, Iteration 130, Current loss 0.2641291665612448 Accuracy 51.10100866600369\n",
      "Training:: Epoch 118, Iteration 140, Current loss 0.2986227971280089 Accuracy 69.40023379192519\n",
      "Training:: Epoch 118, Iteration 150, Current loss 0.2851511209809517 Accuracy 57.06679195051288\n",
      "Training:: Epoch 118, Iteration 160, Current loss 0.3115483958028943 Accuracy 67.06341063000205\n",
      "Training:: Epoch 118, Iteration 170, Current loss 0.23222617575973575 Accuracy 67.85369455330266\n",
      "Training:: Epoch 118, Iteration 180, Current loss 0.28795352036948557 Accuracy 64.5163782447466\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 118, Probability Accuracy 55.99954097763849\n",
      "Starting Training\n",
      "Training:: Epoch 119, Iteration 0, Current loss 0.23864463725063165 Accuracy 65.66999571104712\n",
      "Training:: Epoch 119, Iteration 10, Current loss 0.24002400634330268 Accuracy 70.94371324558946\n",
      "Training:: Epoch 119, Iteration 20, Current loss 0.2799307213563565 Accuracy 58.43100189035917\n",
      "Training:: Epoch 119, Iteration 30, Current loss 0.32685595865110423 Accuracy 55.91820684231223\n",
      "Training:: Epoch 119, Iteration 40, Current loss 0.29352877221254975 Accuracy 57.732769639170186\n",
      "Training:: Epoch 119, Iteration 50, Current loss 0.22767672844383866 Accuracy 68.59264041316979\n",
      "Training:: Epoch 119, Iteration 60, Current loss 0.2050737193428425 Accuracy 62.65865514447745\n",
      "Training:: Epoch 119, Iteration 70, Current loss 0.1846606627252066 Accuracy 67.1048632218845\n",
      "Training:: Epoch 119, Iteration 80, Current loss 0.2747212918840419 Accuracy 69.4586239125746\n",
      "Training:: Epoch 119, Iteration 90, Current loss 0.3012607993753847 Accuracy 62.06083376633758\n",
      "Training:: Epoch 119, Iteration 100, Current loss 0.2585776541920412 Accuracy 70.28217378321887\n",
      "Training:: Epoch 119, Iteration 110, Current loss 0.3855491775320767 Accuracy 67.80952380952381\n",
      "Training:: Epoch 119, Iteration 120, Current loss 0.32881531973242334 Accuracy 66.13032984714401\n",
      "Training:: Epoch 119, Iteration 130, Current loss 0.30445412646374326 Accuracy 67.30402878713046\n",
      "Training:: Epoch 119, Iteration 140, Current loss 0.274953428107213 Accuracy 65.1631230093828\n",
      "Training:: Epoch 119, Iteration 150, Current loss 0.20636551368286163 Accuracy 58.20301968185495\n",
      "Training:: Epoch 119, Iteration 160, Current loss 0.3138004081828265 Accuracy 58.055447848003105\n",
      "Training:: Epoch 119, Iteration 170, Current loss 0.27611968827099603 Accuracy 59.37385349150055\n",
      "Training:: Epoch 119, Iteration 180, Current loss 0.19998058576670497 Accuracy 58.869629356444776\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 119, Probability Accuracy 55.52864734815659\n",
      "Starting Training\n",
      "Training:: Epoch 120, Iteration 0, Current loss 0.2237572785876282 Accuracy 63.20627671409333\n",
      "Training:: Epoch 120, Iteration 10, Current loss 0.22781289044960817 Accuracy 66.97472519778758\n",
      "Training:: Epoch 120, Iteration 20, Current loss 0.32550175178057195 Accuracy 54.60976322712657\n",
      "Training:: Epoch 120, Iteration 30, Current loss 0.2887370543563544 Accuracy 55.99650635951744\n",
      "Training:: Epoch 120, Iteration 40, Current loss 0.4265925413953379 Accuracy 68.64807668367982\n",
      "Training:: Epoch 120, Iteration 50, Current loss 0.33403831310787735 Accuracy 65.45986574100637\n",
      "Training:: Epoch 120, Iteration 60, Current loss 0.23013479515951288 Accuracy 66.2688685330925\n",
      "Training:: Epoch 120, Iteration 70, Current loss 0.29017239432519787 Accuracy 70.32279314888011\n",
      "Training:: Epoch 120, Iteration 80, Current loss 0.392194539704656 Accuracy 69.44613924479697\n",
      "Training:: Epoch 120, Iteration 90, Current loss 0.3046668215989646 Accuracy 50.98476688721342\n",
      "Training:: Epoch 120, Iteration 100, Current loss 0.2946246677119682 Accuracy 71.32340052585451\n",
      "Training:: Epoch 120, Iteration 110, Current loss 0.2784491860022846 Accuracy 71.46565711195241\n",
      "Training:: Epoch 120, Iteration 120, Current loss 0.28267279093642256 Accuracy 63.92881016042781\n",
      "Training:: Epoch 120, Iteration 130, Current loss 0.24543563938295423 Accuracy 64.56560563084358\n",
      "Training:: Epoch 120, Iteration 140, Current loss 0.2310020017294357 Accuracy 64.80586478414337\n",
      "Training:: Epoch 120, Iteration 150, Current loss 0.25172674255573657 Accuracy 60.86581021267408\n",
      "Training:: Epoch 120, Iteration 160, Current loss 0.307276845910288 Accuracy 65.76371027959844\n",
      "Training:: Epoch 120, Iteration 170, Current loss 0.19689786264277576 Accuracy 73.4708584812179\n",
      "Training:: Epoch 120, Iteration 180, Current loss 0.24118540785114906 Accuracy 56.17394061917786\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 120, Probability Accuracy 55.46256395645619\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Completed 160 videos selected frames calculation\n",
      "Completed 170 videos selected frames calculation\n",
      "Completed 180 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.75720789074355\n",
      "Calculating Expectation\n",
      "Epoch 120 iter 0\n",
      "Epoch 120 iter 10\n",
      "Epoch 120 iter 20\n",
      "Epoch 120 iter 30\n",
      "Epoch 120 iter 40\n",
      "Epoch 120 iter 50\n",
      "Epoch 120 iter 60\n",
      "Epoch 120 iter 70\n",
      "Epoch 120 iter 80\n",
      "Epoch 120 iter 90\n",
      "Epoch 120 iter 100\n",
      "Epoch 120 iter 110\n",
      "Epoch 120 iter 120\n",
      "Epoch 120 iter 130\n",
      "Epoch 120 iter 140\n",
      "Epoch 120 iter 150\n",
      "Epoch 120 iter 160\n",
      "Epoch 120 iter 170\n",
      "Epoch 120 iter 180\n",
      "Train Boundary avergage error = 297.059\n",
      "Train From boundary avergage accuracy = 60.477\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 121, Iteration 0, Current loss 0.2427073169710342 Accuracy 66.57507534125155\n",
      "Training:: Epoch 121, Iteration 10, Current loss 0.21113130507104996 Accuracy 55.76387400899936\n",
      "Training:: Epoch 121, Iteration 20, Current loss 0.2287946530802492 Accuracy 59.34897804693414\n",
      "Training:: Epoch 121, Iteration 30, Current loss 0.271398708180233 Accuracy 67.24264952113053\n",
      "Training:: Epoch 121, Iteration 40, Current loss 0.24346040191993276 Accuracy 60.828267477203646\n",
      "Training:: Epoch 121, Iteration 50, Current loss 0.2078240137497891 Accuracy 59.50462907298305\n",
      "Training:: Epoch 121, Iteration 60, Current loss 0.23268803616093572 Accuracy 59.85260482846252\n",
      "Training:: Epoch 121, Iteration 70, Current loss 0.23732406348755403 Accuracy 69.49211908931699\n",
      "Training:: Epoch 121, Iteration 80, Current loss 0.21583294216983345 Accuracy 66.36184469846275\n",
      "Training:: Epoch 121, Iteration 90, Current loss 0.19847021513679805 Accuracy 67.43404554117765\n",
      "Training:: Epoch 121, Iteration 100, Current loss 0.23982905281869904 Accuracy 69.60180137473336\n",
      "Training:: Epoch 121, Iteration 110, Current loss 0.27557128496126654 Accuracy 63.88521657982736\n",
      "Training:: Epoch 121, Iteration 120, Current loss 0.3285585166448418 Accuracy 61.61685560517577\n",
      "Training:: Epoch 121, Iteration 130, Current loss 0.2692742552723527 Accuracy 63.340050377833755\n",
      "Training:: Epoch 121, Iteration 140, Current loss 0.21137416463829986 Accuracy 63.49932547363482\n",
      "Training:: Epoch 121, Iteration 150, Current loss 0.2101395225090279 Accuracy 67.75875518331486\n",
      "Training:: Epoch 121, Iteration 160, Current loss 0.2170375795110718 Accuracy 63.97917994476312\n",
      "Training:: Epoch 121, Iteration 170, Current loss 0.2687368008230632 Accuracy 59.15966386554622\n",
      "Training:: Epoch 121, Iteration 180, Current loss 0.24187192391671997 Accuracy 54.20565633331591\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 121, Probability Accuracy 55.46770817257658\n",
      "Starting Training\n",
      "Training:: Epoch 122, Iteration 0, Current loss 0.2802891399639589 Accuracy 69.72911102632582\n",
      "Training:: Epoch 122, Iteration 10, Current loss 0.20316432665817785 Accuracy 63.27795240233498\n",
      "Training:: Epoch 122, Iteration 20, Current loss 0.27608890484718357 Accuracy 64.97652113098212\n",
      "Training:: Epoch 122, Iteration 30, Current loss 0.21439303202218393 Accuracy 66.68549161348619\n",
      "Training:: Epoch 122, Iteration 40, Current loss 0.28590940767384976 Accuracy 55.460022226121545\n",
      "Training:: Epoch 122, Iteration 50, Current loss 0.21464090063988145 Accuracy 69.71685730358148\n",
      "Training:: Epoch 122, Iteration 60, Current loss 0.29742699788331545 Accuracy 66.02360184710108\n",
      "Training:: Epoch 122, Iteration 70, Current loss 0.2917566372629395 Accuracy 60.49255145096013\n",
      "Training:: Epoch 122, Iteration 80, Current loss 0.24395760363978933 Accuracy 66.42030608435984\n",
      "Training:: Epoch 122, Iteration 90, Current loss 0.2062528427214332 Accuracy 57.935076645626694\n",
      "Training:: Epoch 122, Iteration 100, Current loss 0.1938121570219618 Accuracy 62.66102611406215\n",
      "Training:: Epoch 122, Iteration 110, Current loss 0.2198497870862582 Accuracy 57.71864225707765\n",
      "Training:: Epoch 122, Iteration 120, Current loss 0.22382240444580354 Accuracy 74.80705852905594\n",
      "Training:: Epoch 122, Iteration 130, Current loss 0.21806225347852765 Accuracy 63.69084638435009\n",
      "Training:: Epoch 122, Iteration 140, Current loss 0.2342212487818196 Accuracy 62.87481444829292\n",
      "Training:: Epoch 122, Iteration 150, Current loss 0.3404488058042261 Accuracy 64.51076795235787\n",
      "Training:: Epoch 122, Iteration 160, Current loss 0.21898253382589722 Accuracy 54.17415146071665\n",
      "Training:: Epoch 122, Iteration 170, Current loss 0.3004725159855598 Accuracy 57.4911774141803\n",
      "Training:: Epoch 122, Iteration 180, Current loss 0.3228008443564238 Accuracy 64.91218411055442\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 122, Probability Accuracy 54.6719375096454\n",
      "Starting Training\n",
      "Training:: Epoch 123, Iteration 0, Current loss 0.21059743673554845 Accuracy 69.10482670635764\n",
      "Training:: Epoch 123, Iteration 10, Current loss 0.2214600993780771 Accuracy 68.28669612174767\n",
      "Training:: Epoch 123, Iteration 20, Current loss 0.27508442333731525 Accuracy 60.852544584602\n",
      "Training:: Epoch 123, Iteration 30, Current loss 0.194500734549687 Accuracy 44.07434226405986\n",
      "Training:: Epoch 123, Iteration 40, Current loss 0.20707026744146026 Accuracy 57.27124715076522\n",
      "Training:: Epoch 123, Iteration 50, Current loss 0.21536860490332696 Accuracy 58.53035143769968\n",
      "Training:: Epoch 123, Iteration 60, Current loss 0.2538670536678864 Accuracy 65.70455001002205\n",
      "Training:: Epoch 123, Iteration 70, Current loss 0.3060496794833792 Accuracy 65.41877459246768\n",
      "Training:: Epoch 123, Iteration 80, Current loss 0.264693369872557 Accuracy 67.01417535438387\n",
      "Training:: Epoch 123, Iteration 90, Current loss 0.2546571805232356 Accuracy 52.34885893500601\n",
      "Training:: Epoch 123, Iteration 100, Current loss 0.20120424290309938 Accuracy 65.24316049770381\n",
      "Training:: Epoch 123, Iteration 110, Current loss 0.2348539632577534 Accuracy 55.22174535050072\n",
      "Training:: Epoch 123, Iteration 120, Current loss 0.23704035260370948 Accuracy 69.4751720747296\n",
      "Training:: Epoch 123, Iteration 130, Current loss 0.18438093959410384 Accuracy 70.64120283117644\n",
      "Training:: Epoch 123, Iteration 140, Current loss 0.22431647886983516 Accuracy 68.39956023244856\n",
      "Training:: Epoch 123, Iteration 150, Current loss 0.2634436830751433 Accuracy 70.10093065932625\n",
      "Training:: Epoch 123, Iteration 160, Current loss 0.19456237764405482 Accuracy 66.07164060953889\n",
      "Training:: Epoch 123, Iteration 170, Current loss 0.22079119582864454 Accuracy 65.48167142607377\n",
      "Training:: Epoch 123, Iteration 180, Current loss 0.3527995109840214 Accuracy 71.41215977377165\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 123, Probability Accuracy 54.888786004566484\n",
      "Starting Training\n",
      "Training:: Epoch 124, Iteration 0, Current loss 0.2692135504637061 Accuracy 75.91513781410312\n",
      "Training:: Epoch 124, Iteration 10, Current loss 0.24608445030109308 Accuracy 70.57031324383509\n",
      "Training:: Epoch 124, Iteration 20, Current loss 0.32202273327650044 Accuracy 67.69411045445283\n",
      "Training:: Epoch 124, Iteration 30, Current loss 0.41891742701827284 Accuracy 64.29811433702484\n",
      "Training:: Epoch 124, Iteration 40, Current loss 0.2999960527205914 Accuracy 62.74121067935501\n",
      "Training:: Epoch 124, Iteration 50, Current loss 0.3911878816436156 Accuracy 73.1682628669314\n",
      "Training:: Epoch 124, Iteration 60, Current loss 0.21752508672654303 Accuracy 74.49924450815544\n",
      "Training:: Epoch 124, Iteration 70, Current loss 0.3024396158880672 Accuracy 74.00222965440356\n",
      "Training:: Epoch 124, Iteration 80, Current loss 0.31540532965497364 Accuracy 58.44418052256532\n",
      "Training:: Epoch 124, Iteration 90, Current loss 0.2434357312165465 Accuracy 74.25697491514198\n",
      "Training:: Epoch 124, Iteration 100, Current loss 0.30686268655015336 Accuracy 64.94077635745279\n",
      "Training:: Epoch 124, Iteration 110, Current loss 0.2654675699650504 Accuracy 57.54240420551152\n",
      "Training:: Epoch 124, Iteration 120, Current loss 0.18634392503263983 Accuracy 55.65644059247031\n",
      "Training:: Epoch 124, Iteration 130, Current loss 0.2608443217296209 Accuracy 59.061892867055235\n",
      "Training:: Epoch 124, Iteration 140, Current loss 0.2725908332278447 Accuracy 71.26377851832864\n",
      "Training:: Epoch 124, Iteration 150, Current loss 0.2729072065125818 Accuracy 48.05889457640766\n",
      "Training:: Epoch 124, Iteration 160, Current loss 0.2113714899133445 Accuracy 68.43411648906577\n",
      "Training:: Epoch 124, Iteration 170, Current loss 0.2950665652108602 Accuracy 69.90451941438575\n",
      "Training:: Epoch 124, Iteration 180, Current loss 0.297123506915249 Accuracy 57.3517264166529\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 124, Probability Accuracy 54.97643553307929\n",
      "Starting Training\n",
      "Training:: Epoch 125, Iteration 0, Current loss 0.19252890578482798 Accuracy 64.84544695071011\n",
      "Training:: Epoch 125, Iteration 10, Current loss 0.27540867728960133 Accuracy 67.48787584869059\n",
      "Training:: Epoch 125, Iteration 20, Current loss 0.277911827709344 Accuracy 63.97961740873778\n",
      "Training:: Epoch 125, Iteration 30, Current loss 0.3353273177130229 Accuracy 66.19064205271101\n",
      "Training:: Epoch 125, Iteration 40, Current loss 0.19587420776140482 Accuracy 71.489207983383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 125, Iteration 50, Current loss 0.19893635941990914 Accuracy 63.417217207120885\n",
      "Training:: Epoch 125, Iteration 60, Current loss 0.2627488068920992 Accuracy 64.0629390278168\n",
      "Training:: Epoch 125, Iteration 70, Current loss 0.30727371164824835 Accuracy 63.140385894876914\n",
      "Training:: Epoch 125, Iteration 80, Current loss 0.2176522334928792 Accuracy 61.57648848326814\n",
      "Training:: Epoch 125, Iteration 90, Current loss 0.23455643564774162 Accuracy 62.22529910888628\n",
      "Training:: Epoch 125, Iteration 100, Current loss 0.21657517423413636 Accuracy 62.1123025481379\n",
      "Training:: Epoch 125, Iteration 110, Current loss 0.23057190188333376 Accuracy 65.38296173453719\n",
      "Training:: Epoch 125, Iteration 120, Current loss 0.32175233268456466 Accuracy 41.818558409279206\n",
      "Training:: Epoch 125, Iteration 130, Current loss 0.2708746905963383 Accuracy 67.41465535986084\n",
      "Training:: Epoch 125, Iteration 140, Current loss 0.3537269755925771 Accuracy 50.074294205052006\n",
      "Training:: Epoch 125, Iteration 150, Current loss 0.3846148614577406 Accuracy 58.40805933798295\n",
      "Training:: Epoch 125, Iteration 160, Current loss 0.23914600895433702 Accuracy 50.27319357716325\n",
      "Training:: Epoch 125, Iteration 170, Current loss 0.3035398152048736 Accuracy 68.40746293519906\n",
      "Training:: Epoch 125, Iteration 180, Current loss 0.2522694459845327 Accuracy 64.76209841398942\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 125, Probability Accuracy 55.559512644878936\n",
      "Calculating Expectation\n",
      "Epoch 125 iter 0\n",
      "Epoch 125 iter 10\n",
      "Epoch 125 iter 20\n",
      "Epoch 125 iter 30\n",
      "Epoch 125 iter 40\n",
      "Epoch 125 iter 50\n",
      "Epoch 125 iter 60\n",
      "Epoch 125 iter 70\n",
      "Epoch 125 iter 80\n",
      "Epoch 125 iter 90\n",
      "Epoch 125 iter 100\n",
      "Epoch 125 iter 110\n",
      "Epoch 125 iter 120\n",
      "Epoch 125 iter 130\n",
      "Epoch 125 iter 140\n",
      "Epoch 125 iter 150\n",
      "Epoch 125 iter 160\n",
      "Epoch 125 iter 170\n",
      "Epoch 125 iter 180\n",
      "Train Boundary avergage error = 296.899\n",
      "Train From boundary avergage accuracy = 60.389\n",
      "Starting Training\n",
      "Training:: Epoch 126, Iteration 0, Current loss 0.2329435226769908 Accuracy 64.69455627516191\n",
      "Training:: Epoch 126, Iteration 10, Current loss 0.21080163269346844 Accuracy 69.8355754857997\n",
      "Training:: Epoch 126, Iteration 20, Current loss 0.3463656734460944 Accuracy 60.371778622729195\n",
      "Training:: Epoch 126, Iteration 30, Current loss 0.23452396348946428 Accuracy 67.10467706013362\n",
      "Training:: Epoch 126, Iteration 40, Current loss 0.2269771898112138 Accuracy 69.51141579039098\n",
      "Training:: Epoch 126, Iteration 50, Current loss 0.23071857367281678 Accuracy 68.14528593508501\n",
      "Training:: Epoch 126, Iteration 60, Current loss 0.3636644508498058 Accuracy 66.42241933410465\n",
      "Training:: Epoch 126, Iteration 70, Current loss 0.349966300586683 Accuracy 73.39496334077144\n",
      "Training:: Epoch 126, Iteration 80, Current loss 0.43749049821926583 Accuracy 60.32513771328765\n",
      "Training:: Epoch 126, Iteration 90, Current loss 0.29865773768558507 Accuracy 48.146646118906645\n",
      "Training:: Epoch 126, Iteration 100, Current loss 0.3287121601484693 Accuracy 66.64397549353302\n",
      "Training:: Epoch 126, Iteration 110, Current loss 0.5494945563115858 Accuracy 59.14784756527876\n",
      "Training:: Epoch 126, Iteration 120, Current loss 0.28576677278419454 Accuracy 56.028955532574976\n",
      "Training:: Epoch 126, Iteration 130, Current loss 0.5532105193064272 Accuracy 56.35387699670181\n",
      "Training:: Epoch 126, Iteration 140, Current loss 0.34107994726953966 Accuracy 58.9369909987141\n",
      "Training:: Epoch 126, Iteration 150, Current loss 0.3877401655265405 Accuracy 66.00526777875329\n",
      "Training:: Epoch 126, Iteration 160, Current loss 0.4325141297461448 Accuracy 41.30098089829634\n",
      "Training:: Epoch 126, Iteration 170, Current loss 0.5235421610674457 Accuracy 68.62221597695496\n",
      "Training:: Epoch 126, Iteration 180, Current loss 0.3906647294309325 Accuracy 68.59019142098644\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 126, Probability Accuracy 54.90619719758934\n",
      "Starting Training\n",
      "Training:: Epoch 127, Iteration 0, Current loss 0.5165843298960737 Accuracy 70.91535433070867\n",
      "Training:: Epoch 127, Iteration 10, Current loss 0.3015250652111683 Accuracy 72.01252853426766\n",
      "Training:: Epoch 127, Iteration 20, Current loss 0.31376223273759646 Accuracy 66.22667910447761\n",
      "Training:: Epoch 127, Iteration 30, Current loss 0.3351914165919915 Accuracy 66.32530776773069\n",
      "Training:: Epoch 127, Iteration 40, Current loss 0.7096966124465531 Accuracy 52.43131330087852\n",
      "Training:: Epoch 127, Iteration 50, Current loss 0.6236320877149654 Accuracy 67.54123768404739\n",
      "Training:: Epoch 127, Iteration 60, Current loss 0.9469257518403057 Accuracy 49.675760286225405\n",
      "Training:: Epoch 127, Iteration 70, Current loss 1.8750689073783886 Accuracy 62.1935621402686\n",
      "Training:: Epoch 127, Iteration 80, Current loss 3.8182147073851564 Accuracy 64.24513364999534\n",
      "Training:: Epoch 127, Iteration 90, Current loss 3.1340442527675973 Accuracy 60.85234093637455\n",
      "Training:: Epoch 127, Iteration 100, Current loss 2.6517138455725355 Accuracy 62.486144101346\n",
      "Training:: Epoch 127, Iteration 110, Current loss 3.4637922438786166 Accuracy 56.55221745350501\n",
      "Training:: Epoch 127, Iteration 120, Current loss 5.00961750847385 Accuracy 53.87770798615562\n",
      "Training:: Epoch 127, Iteration 130, Current loss 2.4417520358826867 Accuracy 62.772858029217666\n",
      "Training:: Epoch 127, Iteration 140, Current loss 2.747489724133754 Accuracy 61.16587175410705\n",
      "Training:: Epoch 127, Iteration 150, Current loss 3.717895955013153 Accuracy 55.21277315472566\n",
      "Training:: Epoch 127, Iteration 160, Current loss 1.5811961099573346 Accuracy 73.60216671682215\n",
      "Training:: Epoch 127, Iteration 170, Current loss 1.2592504504332314 Accuracy 69.80383825508109\n",
      "Training:: Epoch 127, Iteration 180, Current loss 1.032022512889141 Accuracy 51.83604861649858\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 127, Probability Accuracy 51.94787721943248\n",
      "Starting Training\n",
      "Training:: Epoch 128, Iteration 0, Current loss 0.9319537721652587 Accuracy 61.735230860751386\n",
      "Training:: Epoch 128, Iteration 10, Current loss 4.789654887446953 Accuracy 56.713854481107525\n",
      "Training:: Epoch 128, Iteration 20, Current loss 3.783548900798162 Accuracy 56.68957543837112\n",
      "Training:: Epoch 128, Iteration 30, Current loss 1.0973646580669236 Accuracy 65.3488989121783\n",
      "Training:: Epoch 128, Iteration 40, Current loss 0.5872390852306462 Accuracy 78.55936972425437\n",
      "Training:: Epoch 128, Iteration 50, Current loss 1.8682723907800185 Accuracy 59.15883986059425\n",
      "Training:: Epoch 128, Iteration 60, Current loss 1.15490681289576 Accuracy 67.60116131373617\n",
      "Training:: Epoch 128, Iteration 70, Current loss 1.1408409246806528 Accuracy 60.378060117756434\n",
      "Training:: Epoch 128, Iteration 80, Current loss 0.6905415111920574 Accuracy 64.2443156486848\n",
      "Training:: Epoch 128, Iteration 90, Current loss 1.0063115789023012 Accuracy 69.22238654938896\n",
      "Training:: Epoch 128, Iteration 100, Current loss 0.5255173429152197 Accuracy 61.52481010861077\n",
      "Training:: Epoch 128, Iteration 110, Current loss 0.5579689284771261 Accuracy 70.95252138012386\n",
      "Training:: Epoch 128, Iteration 120, Current loss 0.4724558100671864 Accuracy 59.09418260382492\n",
      "Training:: Epoch 128, Iteration 130, Current loss 0.4443839560186207 Accuracy 61.829619362405374\n",
      "Training:: Epoch 128, Iteration 140, Current loss 0.5838591609888175 Accuracy 57.06133113311331\n",
      "Training:: Epoch 128, Iteration 150, Current loss 0.484533208941884 Accuracy 69.1854103343465\n",
      "Training:: Epoch 128, Iteration 160, Current loss 0.5270166529697671 Accuracy 62.144663631765305\n",
      "Training:: Epoch 128, Iteration 170, Current loss 0.5423765876552231 Accuracy 67.54105839416059\n",
      "Training:: Epoch 128, Iteration 180, Current loss 0.47522560153643756 Accuracy 68.30475517058511\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 128, Probability Accuracy 54.60783266260669\n",
      "Starting Training\n",
      "Training:: Epoch 129, Iteration 0, Current loss 0.4634694496345174 Accuracy 65.83877177332269\n",
      "Training:: Epoch 129, Iteration 10, Current loss 0.5003354259195855 Accuracy 53.79359515180322\n",
      "Training:: Epoch 129, Iteration 20, Current loss 0.4357070462192366 Accuracy 67.52660706683695\n",
      "Training:: Epoch 129, Iteration 30, Current loss 0.3602094112632477 Accuracy 70.19050326983225\n",
      "Training:: Epoch 129, Iteration 40, Current loss 0.3548324317387064 Accuracy 60.95650957907985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 129, Iteration 50, Current loss 0.3570963402683853 Accuracy 62.237219012477546\n",
      "Training:: Epoch 129, Iteration 60, Current loss 0.4534775123209905 Accuracy 63.41881513987932\n",
      "Training:: Epoch 129, Iteration 70, Current loss 0.3056246773069838 Accuracy 71.77524733992907\n",
      "Training:: Epoch 129, Iteration 80, Current loss 0.30228064220125234 Accuracy 71.00719424460432\n",
      "Training:: Epoch 129, Iteration 90, Current loss 0.283380839288621 Accuracy 67.3244405247492\n",
      "Training:: Epoch 129, Iteration 100, Current loss 0.4366655457193929 Accuracy 54.92736189506801\n",
      "Training:: Epoch 129, Iteration 110, Current loss 0.34231820241291033 Accuracy 67.57131431618235\n",
      "Training:: Epoch 129, Iteration 120, Current loss 0.4131250644001707 Accuracy 67.703978944109\n",
      "Training:: Epoch 129, Iteration 130, Current loss 0.28409616114829694 Accuracy 66.11533524242125\n",
      "Training:: Epoch 129, Iteration 140, Current loss 0.30426102891811746 Accuracy 62.998001332445035\n",
      "Training:: Epoch 129, Iteration 150, Current loss 0.35917466864848463 Accuracy 46.88162445609729\n",
      "Training:: Epoch 129, Iteration 160, Current loss 0.4124398971556392 Accuracy 65.07235712533726\n",
      "Training:: Epoch 129, Iteration 170, Current loss 0.3546608929452153 Accuracy 63.740371545083825\n",
      "Training:: Epoch 129, Iteration 180, Current loss 0.2781646898137746 Accuracy 66.42558278541541\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 129, Probability Accuracy 56.563624060685925\n",
      "Starting Training\n",
      "Training:: Epoch 130, Iteration 0, Current loss 0.22913184619259508 Accuracy 71.91824705279343\n",
      "Training:: Epoch 130, Iteration 10, Current loss 0.335391637310963 Accuracy 68.70824053452115\n",
      "Training:: Epoch 130, Iteration 20, Current loss 0.2573163118953201 Accuracy 64.46776009004662\n",
      "Training:: Epoch 130, Iteration 30, Current loss 0.23535220520973196 Accuracy 66.89176939811458\n",
      "Training:: Epoch 130, Iteration 40, Current loss 0.33745938336134834 Accuracy 62.5313847936651\n",
      "Training:: Epoch 130, Iteration 50, Current loss 0.20268005312530332 Accuracy 69.53508518625469\n",
      "Training:: Epoch 130, Iteration 60, Current loss 0.2620628606739738 Accuracy 71.35423119811671\n",
      "Training:: Epoch 130, Iteration 70, Current loss 0.3585012750687289 Accuracy 51.533742331288344\n",
      "Training:: Epoch 130, Iteration 80, Current loss 0.297864287285823 Accuracy 56.03276068717539\n",
      "Training:: Epoch 130, Iteration 90, Current loss 0.2782519929173146 Accuracy 64.90674786580392\n",
      "Training:: Epoch 130, Iteration 100, Current loss 0.2993173219342795 Accuracy 61.652461030484524\n",
      "Training:: Epoch 130, Iteration 110, Current loss 0.2775333900097996 Accuracy 61.126554498902706\n",
      "Training:: Epoch 130, Iteration 120, Current loss 0.26694292204121167 Accuracy 57.697582719012516\n",
      "Training:: Epoch 130, Iteration 130, Current loss 0.25132046398948316 Accuracy 56.95255900911428\n",
      "Training:: Epoch 130, Iteration 140, Current loss 0.24960569254444748 Accuracy 59.24222917049843\n",
      "Training:: Epoch 130, Iteration 150, Current loss 0.298331431763747 Accuracy 68.28995378253467\n",
      "Training:: Epoch 130, Iteration 160, Current loss 0.23851200836648911 Accuracy 74.84382508409419\n",
      "Training:: Epoch 130, Iteration 170, Current loss 0.2753339056436252 Accuracy 65.87819675908149\n",
      "Training:: Epoch 130, Iteration 180, Current loss 0.3176295369909425 Accuracy 67.32751784298176\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 130, Probability Accuracy 56.318878086035035\n",
      "Calculating Expectation\n",
      "Epoch 130 iter 0\n",
      "Epoch 130 iter 10\n",
      "Epoch 130 iter 20\n",
      "Epoch 130 iter 30\n",
      "Epoch 130 iter 40\n",
      "Epoch 130 iter 50\n",
      "Epoch 130 iter 60\n",
      "Epoch 130 iter 70\n",
      "Epoch 130 iter 80\n",
      "Epoch 130 iter 90\n",
      "Epoch 130 iter 100\n",
      "Epoch 130 iter 110\n",
      "Epoch 130 iter 120\n",
      "Epoch 130 iter 130\n",
      "Epoch 130 iter 140\n",
      "Epoch 130 iter 150\n",
      "Epoch 130 iter 160\n",
      "Epoch 130 iter 170\n",
      "Epoch 130 iter 180\n",
      "Train Boundary avergage error = 296.753\n",
      "Train From boundary avergage accuracy = 60.404\n",
      "Starting Training\n",
      "Training:: Epoch 131, Iteration 0, Current loss 0.2056888753426021 Accuracy 59.094627761112626\n",
      "Training:: Epoch 131, Iteration 10, Current loss 0.21701243903604733 Accuracy 67.31987623397671\n",
      "Training:: Epoch 131, Iteration 20, Current loss 0.25438230826929187 Accuracy 64.29124709527498\n",
      "Training:: Epoch 131, Iteration 30, Current loss 0.22402571986727876 Accuracy 66.86321613161535\n",
      "Training:: Epoch 131, Iteration 40, Current loss 0.2535219168141627 Accuracy 66.34174311926606\n",
      "Training:: Epoch 131, Iteration 50, Current loss 0.45740137264654757 Accuracy 61.220220801859384\n",
      "Training:: Epoch 131, Iteration 60, Current loss 0.23264371108704843 Accuracy 61.77755710029791\n",
      "Training:: Epoch 131, Iteration 70, Current loss 0.17016543248904847 Accuracy 76.85736988478347\n",
      "Training:: Epoch 131, Iteration 80, Current loss 0.2547893088375846 Accuracy 60.29998522240284\n",
      "Training:: Epoch 131, Iteration 90, Current loss 0.17187513139675045 Accuracy 64.53398738612474\n",
      "Training:: Epoch 131, Iteration 100, Current loss 0.18968368102937289 Accuracy 59.58644036781188\n",
      "Training:: Epoch 131, Iteration 110, Current loss 0.21711199050732807 Accuracy 59.47043888284367\n",
      "Training:: Epoch 131, Iteration 120, Current loss 0.2350102832524676 Accuracy 66.35245901639344\n",
      "Training:: Epoch 131, Iteration 130, Current loss 0.20852702055349462 Accuracy 59.95816524727327\n",
      "Training:: Epoch 131, Iteration 140, Current loss 0.3109186881175123 Accuracy 63.01479943748745\n",
      "Training:: Epoch 131, Iteration 150, Current loss 0.23208368645231245 Accuracy 57.07278930907023\n",
      "Training:: Epoch 131, Iteration 160, Current loss 0.2505826680518211 Accuracy 67.45571284907558\n",
      "Training:: Epoch 131, Iteration 170, Current loss 0.27135540257076085 Accuracy 66.59509342592169\n",
      "Training:: Epoch 131, Iteration 180, Current loss 0.29094876656785157 Accuracy 61.36279242480505\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 131, Probability Accuracy 56.1685086917467\n",
      "Starting Training\n",
      "Training:: Epoch 132, Iteration 0, Current loss 0.27293426815489163 Accuracy 51.48061953294278\n",
      "Training:: Epoch 132, Iteration 10, Current loss 0.2651267671173562 Accuracy 63.732567678424935\n",
      "Training:: Epoch 132, Iteration 20, Current loss 0.2515758480942989 Accuracy 62.72324998667164\n",
      "Training:: Epoch 132, Iteration 30, Current loss 0.23221031221013594 Accuracy 65.62846487249269\n",
      "Training:: Epoch 132, Iteration 40, Current loss 0.18245362194757095 Accuracy 63.43947875562081\n",
      "Training:: Epoch 132, Iteration 50, Current loss 0.332051335731739 Accuracy 55.29940340281358\n",
      "Training:: Epoch 132, Iteration 60, Current loss 0.23220861675227872 Accuracy 57.18816067653277\n",
      "Training:: Epoch 132, Iteration 70, Current loss 0.20726045382435734 Accuracy 68.95282175353705\n",
      "Training:: Epoch 132, Iteration 80, Current loss 0.23803913703549404 Accuracy 53.171052631578945\n",
      "Training:: Epoch 132, Iteration 90, Current loss 0.18851332653294783 Accuracy 78.55916717426214\n",
      "Training:: Epoch 132, Iteration 100, Current loss 0.2522978054244214 Accuracy 59.10988578180386\n",
      "Training:: Epoch 132, Iteration 110, Current loss 0.18915693389242247 Accuracy 61.443901657724034\n",
      "Training:: Epoch 132, Iteration 120, Current loss 0.2487243259851111 Accuracy 65.65157750342935\n",
      "Training:: Epoch 132, Iteration 130, Current loss 0.21016308896769928 Accuracy 66.52795226130654\n",
      "Training:: Epoch 132, Iteration 140, Current loss 0.25075135930758846 Accuracy 65.74339114329011\n",
      "Training:: Epoch 132, Iteration 150, Current loss 0.2567825855506607 Accuracy 61.0369311838521\n",
      "Training:: Epoch 132, Iteration 160, Current loss 0.16226933555414716 Accuracy 55.29361641695662\n",
      "Training:: Epoch 132, Iteration 170, Current loss 0.3255482192098542 Accuracy 52.867608581894295\n",
      "Training:: Epoch 132, Iteration 180, Current loss 0.2745790634534686 Accuracy 56.59932445350838\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 132, Probability Accuracy 56.05751233622597\n",
      "Starting Training\n",
      "Training:: Epoch 133, Iteration 0, Current loss 0.15928178985015157 Accuracy 69.26671980291283\n",
      "Training:: Epoch 133, Iteration 10, Current loss 0.18617467090672726 Accuracy 58.62172622402585\n",
      "Training:: Epoch 133, Iteration 20, Current loss 0.14756478552415733 Accuracy 62.62169151201704\n",
      "Training:: Epoch 133, Iteration 30, Current loss 0.1943109165726135 Accuracy 63.66395532354012\n",
      "Training:: Epoch 133, Iteration 40, Current loss 0.17819365125123937 Accuracy 66.2426296485445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 133, Iteration 50, Current loss 0.2156681015875747 Accuracy 46.27997540479606\n",
      "Training:: Epoch 133, Iteration 60, Current loss 0.22883494582030584 Accuracy 62.86644951140065\n",
      "Training:: Epoch 133, Iteration 70, Current loss 0.15841839007417294 Accuracy 71.68420490358422\n",
      "Training:: Epoch 133, Iteration 80, Current loss 0.26821214931041654 Accuracy 68.80048354305181\n",
      "Training:: Epoch 133, Iteration 90, Current loss 0.19930251180493558 Accuracy 75.37667071688944\n",
      "Training:: Epoch 133, Iteration 100, Current loss 0.3140749893281016 Accuracy 62.50675310642896\n",
      "Training:: Epoch 133, Iteration 110, Current loss 0.22684471941797874 Accuracy 67.63879128601546\n",
      "Training:: Epoch 133, Iteration 120, Current loss 0.23029455410877006 Accuracy 64.18017782426779\n",
      "Training:: Epoch 133, Iteration 130, Current loss 0.15687537096808432 Accuracy 65.05894192064405\n",
      "Training:: Epoch 133, Iteration 140, Current loss 0.21090312668609235 Accuracy 68.64475237680979\n",
      "Training:: Epoch 133, Iteration 150, Current loss 0.18649272719829585 Accuracy 52.292885450084924\n",
      "Training:: Epoch 133, Iteration 160, Current loss 0.21643872899455865 Accuracy 69.56547098279381\n",
      "Training:: Epoch 133, Iteration 170, Current loss 0.19350046607463767 Accuracy 71.98206484249253\n",
      "Training:: Epoch 133, Iteration 180, Current loss 0.3500206580652673 Accuracy 66.72324055216112\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 133, Probability Accuracy 55.98252549354797\n",
      "Starting Training\n",
      "Training:: Epoch 134, Iteration 0, Current loss 0.2635577719734533 Accuracy 61.11160436828553\n",
      "Training:: Epoch 134, Iteration 10, Current loss 0.19376800551182102 Accuracy 62.96210631818357\n",
      "Training:: Epoch 134, Iteration 20, Current loss 0.1897679763552193 Accuracy 73.50851893393153\n",
      "Training:: Epoch 134, Iteration 30, Current loss 0.2391666901813761 Accuracy 65.11965531775394\n",
      "Training:: Epoch 134, Iteration 40, Current loss 0.1975399488460818 Accuracy 60.86224564485434\n",
      "Training:: Epoch 134, Iteration 50, Current loss 0.23201743422632792 Accuracy 52.072594501718214\n",
      "Training:: Epoch 134, Iteration 60, Current loss 0.3486909422468702 Accuracy 64.4300461234351\n",
      "Training:: Epoch 134, Iteration 70, Current loss 0.2509692306045464 Accuracy 65.79436096572682\n",
      "Training:: Epoch 134, Iteration 80, Current loss 0.20177227065911119 Accuracy 62.34529255959547\n",
      "Training:: Epoch 134, Iteration 90, Current loss 0.17982613200049832 Accuracy 64.67338631517735\n",
      "Training:: Epoch 134, Iteration 100, Current loss 0.19995575302306356 Accuracy 65.45087323274326\n",
      "Training:: Epoch 134, Iteration 110, Current loss 0.1972665725504142 Accuracy 65.39794608472401\n",
      "Training:: Epoch 134, Iteration 120, Current loss 0.2514431385776164 Accuracy 59.573744473415715\n",
      "Training:: Epoch 134, Iteration 130, Current loss 0.27971941281855506 Accuracy 67.02339472374315\n",
      "Training:: Epoch 134, Iteration 140, Current loss 0.23376201850210984 Accuracy 64.87127371273712\n",
      "Training:: Epoch 134, Iteration 150, Current loss 0.16172208247759945 Accuracy 68.41885035828234\n",
      "Training:: Epoch 134, Iteration 160, Current loss 0.22324038429552429 Accuracy 72.05950720595072\n",
      "Training:: Epoch 134, Iteration 170, Current loss 0.20488296140965517 Accuracy 71.46994563284386\n",
      "Training:: Epoch 134, Iteration 180, Current loss 0.23764853026470376 Accuracy 70.50985892253115\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 134, Probability Accuracy 56.367748139178744\n",
      "Starting Training\n",
      "Training:: Epoch 135, Iteration 0, Current loss 0.2995609009763316 Accuracy 47.46136865342164\n",
      "Training:: Epoch 135, Iteration 10, Current loss 0.336539994215891 Accuracy 65.69937048978966\n",
      "Training:: Epoch 135, Iteration 20, Current loss 0.23553496848714653 Accuracy 64.89602169981917\n",
      "Training:: Epoch 135, Iteration 30, Current loss 0.1626848821526473 Accuracy 74.03631590461606\n",
      "Training:: Epoch 135, Iteration 40, Current loss 0.19224006541477606 Accuracy 74.45710765439705\n",
      "Training:: Epoch 135, Iteration 50, Current loss 0.18146814229893643 Accuracy 65.42034724337496\n",
      "Training:: Epoch 135, Iteration 60, Current loss 0.21992754194136319 Accuracy 65.45502321100113\n",
      "Training:: Epoch 135, Iteration 70, Current loss 0.2654120039724956 Accuracy 50.415768401601476\n",
      "Training:: Epoch 135, Iteration 80, Current loss 0.19110054232938203 Accuracy 58.1870695401022\n",
      "Training:: Epoch 135, Iteration 90, Current loss 0.22082321776304104 Accuracy 55.001822157434404\n",
      "Training:: Epoch 135, Iteration 100, Current loss 0.24607403321417648 Accuracy 57.73708963061048\n",
      "Training:: Epoch 135, Iteration 110, Current loss 0.19995095849915484 Accuracy 65.34987353968445\n",
      "Training:: Epoch 135, Iteration 120, Current loss 0.2224963188593211 Accuracy 52.41664638598199\n",
      "Training:: Epoch 135, Iteration 130, Current loss 0.22116721619528332 Accuracy 68.60995640271723\n",
      "Training:: Epoch 135, Iteration 140, Current loss 0.15177564842138686 Accuracy 61.90055398837644\n",
      "Training:: Epoch 135, Iteration 150, Current loss 0.18204035897120402 Accuracy 69.38059701492537\n",
      "Training:: Epoch 135, Iteration 160, Current loss 0.2092378891685386 Accuracy 61.3447559709242\n",
      "Training:: Epoch 135, Iteration 170, Current loss 0.158250155363514 Accuracy 67.04848286502408\n",
      "Training:: Epoch 135, Iteration 180, Current loss 0.17088064870404202 Accuracy 74.43340404153176\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 135, Probability Accuracy 56.05137884777473\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Completed 160 videos selected frames calculation\n",
      "Completed 170 videos selected frames calculation\n",
      "Completed 180 videos selected frames calculation\n",
      "Total correct pivots labels selected =  59.88872028325746\n",
      "Calculating Expectation\n",
      "Epoch 135 iter 0\n",
      "Epoch 135 iter 10\n",
      "Epoch 135 iter 20\n",
      "Epoch 135 iter 30\n",
      "Epoch 135 iter 40\n",
      "Epoch 135 iter 50\n",
      "Epoch 135 iter 60\n",
      "Epoch 135 iter 70\n",
      "Epoch 135 iter 80\n",
      "Epoch 135 iter 90\n",
      "Epoch 135 iter 100\n",
      "Epoch 135 iter 110\n",
      "Epoch 135 iter 120\n",
      "Epoch 135 iter 130\n",
      "Epoch 135 iter 140\n",
      "Epoch 135 iter 150\n",
      "Epoch 135 iter 160\n",
      "Epoch 135 iter 170\n",
      "Epoch 135 iter 180\n",
      "Train Boundary avergage error = 297.026\n",
      "Train From boundary avergage accuracy = 60.330\n",
      "Starting Training\n",
      "Training:: Epoch 136, Iteration 0, Current loss 0.159248184141461 Accuracy 52.20426890085777\n",
      "Training:: Epoch 136, Iteration 10, Current loss 0.18445558797300743 Accuracy 64.52680344142952\n",
      "Training:: Epoch 136, Iteration 20, Current loss 0.21574018430551217 Accuracy 61.97078942503235\n",
      "Training:: Epoch 136, Iteration 30, Current loss 0.15419260475891075 Accuracy 66.3333898209343\n",
      "Training:: Epoch 136, Iteration 40, Current loss 0.32200456029366564 Accuracy 66.20330147697655\n",
      "Training:: Epoch 136, Iteration 50, Current loss 0.23835245211844963 Accuracy 72.6608727810651\n",
      "Training:: Epoch 136, Iteration 60, Current loss 0.18611715574453197 Accuracy 68.48890541713152\n",
      "Training:: Epoch 136, Iteration 70, Current loss 0.2255958811746164 Accuracy 53.08531967030519\n",
      "Training:: Epoch 136, Iteration 80, Current loss 0.30576930378084644 Accuracy 67.72366039814305\n",
      "Training:: Epoch 136, Iteration 90, Current loss 0.20818256111811553 Accuracy 76.25999304831421\n",
      "Training:: Epoch 136, Iteration 100, Current loss 0.2683666190774785 Accuracy 62.19278033794163\n",
      "Training:: Epoch 136, Iteration 110, Current loss 0.24626083671122068 Accuracy 68.78378378378379\n",
      "Training:: Epoch 136, Iteration 120, Current loss 0.21277076974046416 Accuracy 47.69791824950615\n",
      "Training:: Epoch 136, Iteration 130, Current loss 0.22158347820994062 Accuracy 60.85941790225151\n",
      "Training:: Epoch 136, Iteration 140, Current loss 0.15399612474318541 Accuracy 61.27874805464292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 136, Iteration 150, Current loss 0.1793765931970741 Accuracy 72.70785496876168\n",
      "Training:: Epoch 136, Iteration 160, Current loss 0.17682866249530022 Accuracy 68.26268394465188\n",
      "Training:: Epoch 136, Iteration 170, Current loss 0.2728875424565323 Accuracy 56.093307172443865\n",
      "Training:: Epoch 136, Iteration 180, Current loss 0.3252608001323536 Accuracy 56.9833923223523\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 136, Probability Accuracy 56.045245359323495\n",
      "Starting Training\n",
      "Training:: Epoch 137, Iteration 0, Current loss 0.1949290708495059 Accuracy 68.9250058045043\n",
      "Training:: Epoch 137, Iteration 10, Current loss 0.30845707496883773 Accuracy 70.50700335371869\n",
      "Training:: Epoch 137, Iteration 20, Current loss 0.21953213896042031 Accuracy 59.41091539127924\n",
      "Training:: Epoch 137, Iteration 30, Current loss 0.2827178502847473 Accuracy 48.956751139179794\n",
      "Training:: Epoch 137, Iteration 40, Current loss 0.26491426667622325 Accuracy 63.415900326312666\n",
      "Training:: Epoch 137, Iteration 50, Current loss 0.16646182806142612 Accuracy 65.81764286106385\n",
      "Training:: Epoch 137, Iteration 60, Current loss 0.21354132174878213 Accuracy 65.21791840940777\n",
      "Training:: Epoch 137, Iteration 70, Current loss 0.20848148607570952 Accuracy 66.99741515884266\n",
      "Training:: Epoch 137, Iteration 80, Current loss 0.193456822011294 Accuracy 64.14623655913978\n",
      "Training:: Epoch 137, Iteration 90, Current loss 0.22409538770024817 Accuracy 63.43756386674842\n",
      "Training:: Epoch 137, Iteration 100, Current loss 0.2171165640944103 Accuracy 64.72073039742213\n",
      "Training:: Epoch 137, Iteration 110, Current loss 0.1760494463027352 Accuracy 76.72040729741197\n",
      "Training:: Epoch 137, Iteration 120, Current loss 0.17415493858711545 Accuracy 56.789224608664\n",
      "Training:: Epoch 137, Iteration 130, Current loss 0.32406076535903616 Accuracy 73.6356080893896\n",
      "Training:: Epoch 137, Iteration 140, Current loss 0.24682046511994113 Accuracy 63.15649867374005\n",
      "Training:: Epoch 137, Iteration 150, Current loss 0.21593683043432393 Accuracy 61.8645948945616\n",
      "Training:: Epoch 137, Iteration 160, Current loss 0.2775708655794265 Accuracy 60.381011867582764\n",
      "Training:: Epoch 137, Iteration 170, Current loss 0.2109714467712511 Accuracy 67.6328502415459\n",
      "Training:: Epoch 137, Iteration 180, Current loss 0.1782350771741879 Accuracy 63.934569629111266\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 137, Probability Accuracy 55.97916196762309\n",
      "Starting Training\n",
      "Training:: Epoch 138, Iteration 0, Current loss 0.2720496999962243 Accuracy 66.45574445376229\n",
      "Training:: Epoch 138, Iteration 10, Current loss 0.15878121422975328 Accuracy 73.44271412680756\n",
      "Training:: Epoch 138, Iteration 20, Current loss 0.2254214470673586 Accuracy 69.66070326958668\n",
      "Training:: Epoch 138, Iteration 30, Current loss 0.2620517347267329 Accuracy 58.06002928257686\n",
      "Training:: Epoch 138, Iteration 40, Current loss 0.22371111425407017 Accuracy 67.89102666030635\n",
      "Training:: Epoch 138, Iteration 50, Current loss 0.2893908814937952 Accuracy 56.88871575120114\n",
      "Training:: Epoch 138, Iteration 60, Current loss 0.28915313678293897 Accuracy 73.18682686920252\n",
      "Training:: Epoch 138, Iteration 70, Current loss 0.20050033617604834 Accuracy 60.89761280529874\n",
      "Training:: Epoch 138, Iteration 80, Current loss 0.22162550884764973 Accuracy 59.59866220735786\n",
      "Training:: Epoch 138, Iteration 90, Current loss 0.2322457475780249 Accuracy 62.19665157877515\n",
      "Training:: Epoch 138, Iteration 100, Current loss 0.16591223146072004 Accuracy 66.58042744656917\n",
      "Training:: Epoch 138, Iteration 110, Current loss 0.2463461017318859 Accuracy 62.71519921298574\n",
      "Training:: Epoch 138, Iteration 120, Current loss 0.3379761212542857 Accuracy 64.52797202797203\n",
      "Training:: Epoch 138, Iteration 130, Current loss 0.24781322552014565 Accuracy 68.17667718316567\n",
      "Training:: Epoch 138, Iteration 140, Current loss 0.23801898426113477 Accuracy 66.91347816282041\n",
      "Training:: Epoch 138, Iteration 150, Current loss 0.25770829964615716 Accuracy 52.11804740671204\n",
      "Training:: Epoch 138, Iteration 160, Current loss 0.24890827300427248 Accuracy 63.52878841398799\n",
      "Training:: Epoch 138, Iteration 170, Current loss 0.23661550573426798 Accuracy 67.97673499350613\n",
      "Training:: Epoch 138, Iteration 180, Current loss 0.26293616063584513 Accuracy 56.27131287297528\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 138, Probability Accuracy 55.75697140211546\n",
      "Starting Training\n",
      "Training:: Epoch 139, Iteration 0, Current loss 0.30616251245530135 Accuracy 52.51065557134159\n",
      "Training:: Epoch 139, Iteration 10, Current loss 0.17610963667921936 Accuracy 70.2006493160892\n",
      "Training:: Epoch 139, Iteration 20, Current loss 0.17299543069552853 Accuracy 68.34024114544084\n",
      "Training:: Epoch 139, Iteration 30, Current loss 0.26879994066694807 Accuracy 64.94508486883906\n",
      "Training:: Epoch 139, Iteration 40, Current loss 0.2788588331992628 Accuracy 61.30643487285937\n",
      "Training:: Epoch 139, Iteration 50, Current loss 0.1312180463413228 Accuracy 66.1363811877365\n",
      "Training:: Epoch 139, Iteration 60, Current loss 0.19183622734621505 Accuracy 63.89593265037022\n",
      "Training:: Epoch 139, Iteration 70, Current loss 0.2666247350651868 Accuracy 51.566800762227395\n",
      "Training:: Epoch 139, Iteration 80, Current loss 0.22639160375367967 Accuracy 59.41700928535132\n",
      "Training:: Epoch 139, Iteration 90, Current loss 0.22223863054822368 Accuracy 63.25256975036711\n",
      "Training:: Epoch 139, Iteration 100, Current loss 0.176499895000314 Accuracy 61.44687336286136\n",
      "Training:: Epoch 139, Iteration 110, Current loss 0.23768567769267976 Accuracy 58.72771578812364\n",
      "Training:: Epoch 139, Iteration 120, Current loss 0.1791633539302365 Accuracy 55.52182009553882\n",
      "Training:: Epoch 139, Iteration 130, Current loss 0.20841061891280654 Accuracy 62.43190115136198\n",
      "Training:: Epoch 139, Iteration 140, Current loss 0.23781542281680695 Accuracy 62.09510235812387\n",
      "Training:: Epoch 139, Iteration 150, Current loss 0.17218740418328443 Accuracy 59.14622293067921\n",
      "Training:: Epoch 139, Iteration 160, Current loss 0.24898495386805478 Accuracy 56.65658940768111\n",
      "Training:: Epoch 139, Iteration 170, Current loss 0.16621537051426455 Accuracy 62.1380993207149\n",
      "Training:: Epoch 139, Iteration 180, Current loss 0.22795903158056594 Accuracy 67.31263263710488\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 139, Probability Accuracy 56.078682764106034\n",
      "Starting Training\n",
      "Training:: Epoch 140, Iteration 0, Current loss 0.17579718604907515 Accuracy 58.78065982289789\n",
      "Training:: Epoch 140, Iteration 10, Current loss 0.20757934019967253 Accuracy 61.05133722717491\n",
      "Training:: Epoch 140, Iteration 20, Current loss 0.15494551320101263 Accuracy 69.6256038647343\n",
      "Training:: Epoch 140, Iteration 30, Current loss 0.19008639669195596 Accuracy 57.64624306606152\n",
      "Training:: Epoch 140, Iteration 40, Current loss 0.1815338258624704 Accuracy 66.7796365734064\n",
      "Training:: Epoch 140, Iteration 50, Current loss 0.21302708433502912 Accuracy 66.32138550915269\n",
      "Training:: Epoch 140, Iteration 60, Current loss 0.15262028711748543 Accuracy 57.77766543653\n",
      "Training:: Epoch 140, Iteration 70, Current loss 0.1877651457902139 Accuracy 68.32149889611551\n",
      "Training:: Epoch 140, Iteration 80, Current loss 0.16059821081430734 Accuracy 70.10927035600987\n",
      "Training:: Epoch 140, Iteration 90, Current loss 0.18457980280978686 Accuracy 71.04262359855781\n",
      "Training:: Epoch 140, Iteration 100, Current loss 0.18597535878991753 Accuracy 67.71249044748238\n",
      "Training:: Epoch 140, Iteration 110, Current loss 0.21170167856529465 Accuracy 58.601077025473465\n",
      "Training:: Epoch 140, Iteration 120, Current loss 0.28896604620066946 Accuracy 58.47953216374269\n",
      "Training:: Epoch 140, Iteration 130, Current loss 0.18192150509389238 Accuracy 71.15384615384616\n",
      "Training:: Epoch 140, Iteration 140, Current loss 0.2125370054951136 Accuracy 66.47660704522377\n",
      "Training:: Epoch 140, Iteration 150, Current loss 0.16570696434622106 Accuracy 67.58084322554237\n",
      "Training:: Epoch 140, Iteration 160, Current loss 0.19093482794908712 Accuracy 49.67507645259939\n",
      "Training:: Epoch 140, Iteration 170, Current loss 0.18190184631705736 Accuracy 51.705297061022605\n",
      "Training:: Epoch 140, Iteration 180, Current loss 0.1880076690842483 Accuracy 62.656488549618324\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 140, Probability Accuracy 55.46889529937359\n",
      "Calculating Expectation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 iter 0\n",
      "Epoch 140 iter 10\n",
      "Epoch 140 iter 20\n",
      "Epoch 140 iter 30\n",
      "Epoch 140 iter 40\n",
      "Epoch 140 iter 50\n",
      "Epoch 140 iter 60\n",
      "Epoch 140 iter 70\n",
      "Epoch 140 iter 80\n",
      "Epoch 140 iter 90\n",
      "Epoch 140 iter 100\n",
      "Epoch 140 iter 110\n",
      "Epoch 140 iter 120\n",
      "Epoch 140 iter 130\n",
      "Epoch 140 iter 140\n",
      "Epoch 140 iter 150\n",
      "Epoch 140 iter 160\n",
      "Epoch 140 iter 170\n",
      "Epoch 140 iter 180\n",
      "Train Boundary avergage error = 296.937\n",
      "Train From boundary avergage accuracy = 60.296\n",
      "Starting Training\n",
      "Training:: Epoch 141, Iteration 0, Current loss 0.19915309808771645 Accuracy 66.36310792482077\n",
      "Training:: Epoch 141, Iteration 10, Current loss 0.2410833005324822 Accuracy 55.95844155844156\n",
      "Training:: Epoch 141, Iteration 20, Current loss 0.2124473653171136 Accuracy 62.717908082408876\n",
      "Training:: Epoch 141, Iteration 30, Current loss 0.25111771442708836 Accuracy 60.80267120597093\n",
      "Training:: Epoch 141, Iteration 40, Current loss 0.22560004731766156 Accuracy 66.12551672303645\n",
      "Training:: Epoch 141, Iteration 50, Current loss 0.19634657106442038 Accuracy 51.8109480038414\n",
      "Training:: Epoch 141, Iteration 60, Current loss 0.16305253154808083 Accuracy 63.41620443740095\n",
      "Training:: Epoch 141, Iteration 70, Current loss 0.19625766937304134 Accuracy 63.46045559252624\n",
      "Training:: Epoch 141, Iteration 80, Current loss 0.23664485031611862 Accuracy 66.42861617490446\n",
      "Training:: Epoch 141, Iteration 90, Current loss 0.24927586385488443 Accuracy 45.65090862057816\n",
      "Training:: Epoch 141, Iteration 100, Current loss 0.17599472911337552 Accuracy 57.07296810818295\n",
      "Training:: Epoch 141, Iteration 110, Current loss 0.18368573998816773 Accuracy 56.531749320808586\n",
      "Training:: Epoch 141, Iteration 120, Current loss 0.24297378804714626 Accuracy 59.05474964904071\n",
      "Training:: Epoch 141, Iteration 130, Current loss 0.1978984064977521 Accuracy 64.91045779597825\n",
      "Training:: Epoch 141, Iteration 140, Current loss 0.20999753083681325 Accuracy 67.85976235880887\n",
      "Training:: Epoch 141, Iteration 150, Current loss 0.20041717378606347 Accuracy 66.9882100750268\n",
      "Training:: Epoch 141, Iteration 160, Current loss 0.23187285782785294 Accuracy 67.84452296819788\n",
      "Training:: Epoch 141, Iteration 170, Current loss 0.22353329927966753 Accuracy 48.21860220704151\n",
      "Training:: Epoch 141, Iteration 180, Current loss 0.28261587331859717 Accuracy 64.42636400929851\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 141, Probability Accuracy 55.84026813237255\n",
      "Starting Training\n",
      "Training:: Epoch 142, Iteration 0, Current loss 0.34884643692768746 Accuracy 58.038832239139545\n",
      "Training:: Epoch 142, Iteration 10, Current loss 0.22822305677780994 Accuracy 72.872847748607\n",
      "Training:: Epoch 142, Iteration 20, Current loss 0.25184358935759804 Accuracy 67.7214796394156\n",
      "Training:: Epoch 142, Iteration 30, Current loss 0.2132088070043756 Accuracy 62.643627751951584\n",
      "Training:: Epoch 142, Iteration 40, Current loss 0.25645445886657087 Accuracy 65.50331125827815\n",
      "Training:: Epoch 142, Iteration 50, Current loss 0.2816930137410023 Accuracy 62.813021702838064\n",
      "Training:: Epoch 142, Iteration 60, Current loss 0.22252236786998747 Accuracy 65.11246834500223\n",
      "Training:: Epoch 142, Iteration 70, Current loss 0.19766945500887406 Accuracy 63.021517553793885\n",
      "Training:: Epoch 142, Iteration 80, Current loss 0.20904479702276846 Accuracy 60.310360061851114\n",
      "Training:: Epoch 142, Iteration 90, Current loss 0.29727017110799653 Accuracy 61.53199197774471\n",
      "Training:: Epoch 142, Iteration 100, Current loss 0.18511150293486794 Accuracy 66.65267953482795\n",
      "Training:: Epoch 142, Iteration 110, Current loss 0.23717425631176198 Accuracy 71.93064182194617\n",
      "Training:: Epoch 142, Iteration 120, Current loss 0.1626879850791182 Accuracy 51.14060920399103\n",
      "Training:: Epoch 142, Iteration 130, Current loss 0.26679428872253735 Accuracy 63.796909492273734\n",
      "Training:: Epoch 142, Iteration 140, Current loss 0.19677073036305515 Accuracy 55.483405483405484\n",
      "Training:: Epoch 142, Iteration 150, Current loss 0.23432494082474103 Accuracy 67.86732494263264\n",
      "Training:: Epoch 142, Iteration 160, Current loss 0.22882144095922735 Accuracy 57.39007948485763\n",
      "Training:: Epoch 142, Iteration 170, Current loss 0.17991145143370588 Accuracy 53.28798185941043\n",
      "Training:: Epoch 142, Iteration 180, Current loss 0.25580346367866214 Accuracy 58.77055275551516\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 142, Probability Accuracy 55.71403698295681\n",
      "Starting Training\n",
      "Training:: Epoch 143, Iteration 0, Current loss 0.23614997542158242 Accuracy 57.964772435073286\n",
      "Training:: Epoch 143, Iteration 10, Current loss 0.1762979187193662 Accuracy 59.709994821336096\n",
      "Training:: Epoch 143, Iteration 20, Current loss 0.20642725091561934 Accuracy 65.8949724119304\n",
      "Training:: Epoch 143, Iteration 30, Current loss 0.21724723530299508 Accuracy 66.17428003972195\n",
      "Training:: Epoch 143, Iteration 40, Current loss 0.2516889432667293 Accuracy 65.80387791075239\n",
      "Training:: Epoch 143, Iteration 50, Current loss 0.19200159435947783 Accuracy 69.36519790888723\n",
      "Training:: Epoch 143, Iteration 60, Current loss 0.3187397226752799 Accuracy 62.00289435600579\n",
      "Training:: Epoch 143, Iteration 70, Current loss 0.21103648511366968 Accuracy 59.38775510204081\n",
      "Training:: Epoch 143, Iteration 80, Current loss 0.2553647120506602 Accuracy 64.74700399467376\n",
      "Training:: Epoch 143, Iteration 90, Current loss 0.15227012740157242 Accuracy 69.2509306389121\n",
      "Training:: Epoch 143, Iteration 100, Current loss 0.26613848459795775 Accuracy 65.66367662086977\n",
      "Training:: Epoch 143, Iteration 110, Current loss 0.21082441635365018 Accuracy 58.059355692850836\n",
      "Training:: Epoch 143, Iteration 120, Current loss 0.3436296569346763 Accuracy 60.65231026552373\n",
      "Training:: Epoch 143, Iteration 130, Current loss 0.21882475333826948 Accuracy 69.62938451356717\n",
      "Training:: Epoch 143, Iteration 140, Current loss 0.2032290866097734 Accuracy 65.37505357908273\n",
      "Training:: Epoch 143, Iteration 150, Current loss 0.19115736552226728 Accuracy 59.67957276368492\n",
      "Training:: Epoch 143, Iteration 160, Current loss 0.3619221403383563 Accuracy 57.499523537259385\n",
      "Training:: Epoch 143, Iteration 170, Current loss 0.21601520392121062 Accuracy 62.51817637498931\n",
      "Training:: Epoch 143, Iteration 180, Current loss 0.1650938264374322 Accuracy 54.08924763935425\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 143, Probability Accuracy 55.36343886890559\n",
      "Starting Training\n",
      "Training:: Epoch 144, Iteration 0, Current loss 0.3023011518542172 Accuracy 54.63700586201713\n",
      "Training:: Epoch 144, Iteration 10, Current loss 0.2152520632128216 Accuracy 69.69804303550872\n",
      "Training:: Epoch 144, Iteration 20, Current loss 0.2812342186432327 Accuracy 71.99823641796894\n",
      "Training:: Epoch 144, Iteration 30, Current loss 0.16736443471725668 Accuracy 65.63195048834736\n",
      "Training:: Epoch 144, Iteration 40, Current loss 0.25844018402062435 Accuracy 58.50849936026321\n",
      "Training:: Epoch 144, Iteration 50, Current loss 0.3954976442149359 Accuracy 54.22257300710339\n",
      "Training:: Epoch 144, Iteration 60, Current loss 0.21035446097733204 Accuracy 44.6347891566265\n",
      "Training:: Epoch 144, Iteration 70, Current loss 0.21288837812762018 Accuracy 56.6214345056771\n",
      "Training:: Epoch 144, Iteration 80, Current loss 0.2219443310730792 Accuracy 55.935135135135134\n",
      "Training:: Epoch 144, Iteration 90, Current loss 0.2695280514417442 Accuracy 61.13542213664741\n",
      "Training:: Epoch 144, Iteration 100, Current loss 0.19099518293567216 Accuracy 58.73648264086511\n",
      "Training:: Epoch 144, Iteration 110, Current loss 0.26960249565979416 Accuracy 62.39115620504278\n",
      "Training:: Epoch 144, Iteration 120, Current loss 0.25714869155844733 Accuracy 57.875728831259245\n",
      "Training:: Epoch 144, Iteration 130, Current loss 0.23484477086307642 Accuracy 70.2724071012722\n",
      "Training:: Epoch 144, Iteration 140, Current loss 0.3532210451366268 Accuracy 67.8643216080402\n",
      "Training:: Epoch 144, Iteration 150, Current loss 0.1934799894333136 Accuracy 57.449847835538165\n",
      "Training:: Epoch 144, Iteration 160, Current loss 0.2223176377037485 Accuracy 67.46288900610354\n",
      "Training:: Epoch 144, Iteration 170, Current loss 0.17260488104986604 Accuracy 66.0796618852459\n",
      "Training:: Epoch 144, Iteration 180, Current loss 0.1335973251158931 Accuracy 67.26377602467525\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 144, Probability Accuracy 55.09316966811892\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 145, Iteration 0, Current loss 0.18886402013814962 Accuracy 68.71628316635473\n",
      "Training:: Epoch 145, Iteration 10, Current loss 0.1840186075898274 Accuracy 61.13615870153291\n",
      "Training:: Epoch 145, Iteration 20, Current loss 0.23944595069780758 Accuracy 54.78993411815531\n",
      "Training:: Epoch 145, Iteration 30, Current loss 0.2337381302925742 Accuracy 70.7642769201629\n",
      "Training:: Epoch 145, Iteration 40, Current loss 0.23714020812985637 Accuracy 70.53403755868544\n",
      "Training:: Epoch 145, Iteration 50, Current loss 0.355052933505317 Accuracy 63.153588694682036\n",
      "Training:: Epoch 145, Iteration 60, Current loss 0.2545391676883057 Accuracy 58.47598668568711\n",
      "Training:: Epoch 145, Iteration 70, Current loss 0.3787743733167572 Accuracy 63.54969483672651\n",
      "Training:: Epoch 145, Iteration 80, Current loss 0.40310151932704136 Accuracy 60.82634730538922\n",
      "Training:: Epoch 145, Iteration 90, Current loss 0.32611079768120727 Accuracy 61.015312456890605\n",
      "Training:: Epoch 145, Iteration 100, Current loss 0.24352960177491279 Accuracy 65.27274225444957\n",
      "Training:: Epoch 145, Iteration 110, Current loss 0.33898142350514054 Accuracy 67.62095840728452\n",
      "Training:: Epoch 145, Iteration 120, Current loss 0.3050400090931612 Accuracy 67.89447127513876\n",
      "Training:: Epoch 145, Iteration 130, Current loss 0.18407185131366055 Accuracy 68.57658470561697\n",
      "Training:: Epoch 145, Iteration 140, Current loss 0.2787930199063659 Accuracy 70.61019311168624\n",
      "Training:: Epoch 145, Iteration 150, Current loss 0.636445192803312 Accuracy 70.71895424836602\n",
      "Training:: Epoch 145, Iteration 160, Current loss 0.6955017656953617 Accuracy 64.84147860999585\n",
      "Training:: Epoch 145, Iteration 170, Current loss 1.1490771858349214 Accuracy 67.22701253532352\n",
      "Training:: Epoch 145, Iteration 180, Current loss 1.0812734659395198 Accuracy 59.12837303827481\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 145, Probability Accuracy 49.811048984808735\n",
      "Calculating Expectation\n",
      "Epoch 145 iter 0\n",
      "Epoch 145 iter 10\n",
      "Epoch 145 iter 20\n",
      "Epoch 145 iter 30\n",
      "Epoch 145 iter 40\n",
      "Epoch 145 iter 50\n",
      "Epoch 145 iter 60\n",
      "Epoch 145 iter 70\n",
      "Epoch 145 iter 80\n",
      "Epoch 145 iter 90\n",
      "Epoch 145 iter 100\n",
      "Epoch 145 iter 110\n",
      "Epoch 145 iter 120\n",
      "Epoch 145 iter 130\n",
      "Epoch 145 iter 140\n",
      "Epoch 145 iter 150\n",
      "Epoch 145 iter 160\n",
      "Epoch 145 iter 170\n",
      "Epoch 145 iter 180\n",
      "Train Boundary avergage error = 297.411\n",
      "Train From boundary avergage accuracy = 59.912\n",
      "Starting Training\n",
      "Training:: Epoch 146, Iteration 0, Current loss 0.5388108747950552 Accuracy 65.10202660352392\n",
      "Training:: Epoch 146, Iteration 10, Current loss 3.21863558128796 Accuracy 48.14594192107223\n",
      "Training:: Epoch 146, Iteration 20, Current loss 0.6115132212614877 Accuracy 64.23754508860893\n",
      "Training:: Epoch 146, Iteration 30, Current loss 3.3583081456796497 Accuracy 51.68086754453912\n",
      "Training:: Epoch 146, Iteration 40, Current loss 1.0484010814672917 Accuracy 59.06981241539354\n",
      "Training:: Epoch 146, Iteration 50, Current loss 4.043884563025164 Accuracy 54.43037974683544\n",
      "Training:: Epoch 146, Iteration 60, Current loss 3.0088287277963963 Accuracy 45.518302339260664\n",
      "Training:: Epoch 146, Iteration 70, Current loss 4.336021710419577 Accuracy 50.561797752808985\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-876f4a471821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mmiddle_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mpsuedo_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_single_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmiddle_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtower_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_stages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mfinal_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dilated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    258\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 259\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initialize_epoch = 25\n",
    "expectation_cal_gap = 5\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(150):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        psuedo_l = get_single_random(predictions[-1], item[4])\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, psuedo_l)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)),\n",
    "                                                      min=0, max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                es_loss, _ = get_estimated_loss(prob, item_1, item[4])\n",
    "                loss += es_loss\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(predictions[-1], dim=1)\n",
    "                correct = float(torch.sum((pred == item_2) * src_mask).item())\n",
    "                total = float(torch.sum(src_mask).item())\n",
    "                print(f\"Training:: Epoch {epoch}, Iteration {i}, Current loss {loss.item()}\" +\n",
    "                      f\" Accuracy {correct * 100.0 / total}\")\n",
    "\n",
    "    # Calculating Expectation Step\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-last-model.wt\")\n",
    "    print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")\n",
    "\n",
    "    if (epoch == initialize_epoch) or ((epoch > initialize_epoch) and ((epoch % (3 * expectation_cal_gap)) == 0)):\n",
    "        torch.save(model.state_dict(), config.output_dir + f\"ms-tcn-initial-{initialize_epoch}-epochs.wt\")\n",
    "        selected_frames_dict = change_selected_frames(model)\n",
    "        get_new_selected_frame_acc(selected_frames_dict)\n",
    "\n",
    "    if (epoch == initialize_epoch) or ((epoch > initialize_epoch) and (epoch % expectation_cal_gap == 0)):\n",
    "        print(\"Calculating Expectation\")\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, item in enumerate(trainloader):\n",
    "            with torch.no_grad():\n",
    "                item_0 = item[0].to(device)\n",
    "                item_1 = item[1].to(device)\n",
    "                item_2 = item[2].to(device)\n",
    "                src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "                src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "                middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "                prob = torch.softmax(predictions[-1], dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                calculate_element_probb(prob, item_1, item[4])\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Epoch {epoch} iter {i}\")\n",
    "                    \n",
    "        get_boundary_err()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 146, Probability Accuracy 49.811048984808735\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.55665562638745"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-emmax-best-model.wt\"))\n",
    "# model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-initial-15-epochs.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.625639564561894\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Validation Data Accuracy\")\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "        pred = torch.argmax(predictions[-1], dim=1)\n",
    "        correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "        total += float(torch.sum(src_mask).item())\n",
    "\n",
    "print(f\"Validation:: Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration done\n",
      "11 iteration done\n",
      "21 iteration done\n",
      "31 iteration done\n",
      "41 iteration done\n",
      "51 iteration done\n",
      "61 iteration done\n",
      "71 iteration done\n",
      "81 iteration done\n",
      "91 iteration done\n",
      "101 iteration done\n",
      "111 iteration done\n",
      "121 iteration done\n",
      "131 iteration done\n",
      "141 iteration done\n",
      "151 iteration done\n",
      "161 iteration done\n",
      "171 iteration done\n",
      "181 iteration done\n",
      "Train Boundary avergage error = 307.224\n",
      "Train From boundary avergage accuracy = 57.704\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        prob = torch.softmax(predictions[-1], dim=1)\n",
    "        prob = prob.permute(0, 2, 1)\n",
    "        calculate_element_probb(prob, item_1, item[4])\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f'{i+1} iteration done')\n",
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    idx = 1\n",
    "\n",
    "    cur_vid_feat = torch.softmax(predictions[-1], dim=1).permute(0, 2, 1)[idx]\n",
    "    cur_vidid = item[4][idx]\n",
    "\n",
    "    selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "    selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "    selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "    \n",
    "    cumsum_feat = torch.cumsum(cur_vid_feat, dim=0)\n",
    "    prob_each_segment = prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 228, 481, 735, 1578, 2388, 2567, 2745]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_frames_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[88, 229, 578, 1128, 2241, 2479, 2720, 2810]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_frames_dict[cur_vidid + \".txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min prob 0 = 0.0\n",
      "Min prob 1 = 0.0\n",
      "Min prob 2 = 0.0\n",
      "Min prob 3 = 0.0\n",
      "Min prob 4 = 0.0\n",
      "Min prob 5 = 7.224189870987231e-126\n",
      "Min prob 6 = 4.631831900603335e-244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 2811)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ymax = 1\n",
    "\n",
    "plt.plot([0, item[1][idx].item()], [0, 0])\n",
    "\n",
    "for pivot in selected_frames_indices:\n",
    "    plt.plot([pivot, pivot], [0, ymax], '--')\n",
    "    \n",
    "for pivot in boundary_frames_dict[cur_vidid + \".txt\"]:\n",
    "    plt.plot([pivot, pivot], [0, ymax])\n",
    "    \n",
    "all_prob = []\n",
    "for i, segment in enumerate(prob_each_segment):\n",
    "    segment = segment.cpu().numpy()\n",
    "    print(f\"Min prob {i} = {np.min(segment).item()}\")\n",
    "    xs = np.arange(selected_frames_indices[i], \n",
    "                   selected_frames_indices[i+1])\n",
    "    plt.plot(xs, segment, '*')\n",
    "\n",
    "    \n",
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "\n",
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]])\n",
    "loss_arr = -loss_arr[0].detach().cpu().numpy()\n",
    "plt.plot(np.arange(selected_frames_indices[0] - 1, selected_frames_indices[-1] + 1), loss_arr/np.max(loss_arr), 'k+')\n",
    "\n",
    "plt.ylim([0, ymax])\n",
    "plt.xlim([0, item[1][idx].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1895, 48])\n"
     ]
    }
   ],
   "source": [
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "print(loss_prob.shape)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]], item_2[idx].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1387])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faf5b8ecb00>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "plt.plot(np.arange(selected_frames[0] - 1, selected_frames[-1] + 1), loss_arr[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3987, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([75, 345, 1305, 1415, 1440, 1519],\n",
       " [73, 282, 455, 1312, 1434, 1458],\n",
       " tensor(1520, device='cuda:0', dtype=torch.int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid], loaded_vidid_selected_frames[cur_vidid + \".txt\"], item_1[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_features_shortened = cur_vid_feat[:item[1][idx]]\n",
    "cur_features_shortened[:, item[2][idx][:item[1][idx]]].shape\n",
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47, 47, 47, 47, 47, 47, 47,  4,  4,  4,  4,  4,  4,  4,  4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[2][idx][video_id_boundary_frames[cur_vidid][1]-6:video_id_boundary_frames[cur_vidid][1]+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid][0]-6,video_id_boundary_frames[cur_vidid][0]+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0794, 13.3350],\n",
       "        [ 1.0831, 13.5102],\n",
       "        [ 1.1767, 13.7662],\n",
       "        [ 1.3750, 14.0177],\n",
       "        [ 1.7298, 14.1727],\n",
       "        [ 2.1706, 14.0367],\n",
       "        [ 2.7338, 13.4563],\n",
       "        [ 4.5600, 12.1745],\n",
       "        [ 7.8450, 10.3246],\n",
       "        [11.0151,  8.3563],\n",
       "        [13.4775,  6.6546],\n",
       "        [14.1836,  5.2898],\n",
       "        [11.2142,  4.2791],\n",
       "        [ 5.9829,  3.5694],\n",
       "        [ 2.3440,  2.9389],\n",
       "        [ 0.7406,  2.3515]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_vid_feat[video_id_boundary_frames[cur_vidid][1]-7:video_id_boundary_frames[cur_vidid][1]+9][:,[47,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frames_and_get_classification_value(model_output, count_list, video_ids_list, labels_all, p_criterion):\n",
    "    new_selected_frames = {}\n",
    "#     new_selected_frames_probs_values = {}\n",
    "#     new_selected_frames_labels = {}\n",
    "    \n",
    "    labels_arr = []\n",
    "    probs_arr = []\n",
    "    \n",
    "    for i, video_id in enumerate(video_ids_list):\n",
    "        current_boundary_frames = boundaries_dict[video_id]\n",
    "        current_video_logits = model_output[i].T\n",
    "        current_video_count = count_list[i]\n",
    "        current_selected_frames = loaded_vidid_selected_frames[video_id]\n",
    "        labels = labels_all[i]\n",
    "        cur_seg_start = 0\n",
    "        for seg_num, ele in enumerate(current_boundary_frames):\n",
    "            cur_seg_end = ele + 1\n",
    "            total_seg_len = cur_seg_end - cur_seg_start\n",
    "            per_frames_far_from_boundary = int(0.3 * total_seg_len)\n",
    "            new_frames_start = cur_seg_start + per_frames_far_from_boundary\n",
    "            new_frames_end = cur_seg_end - per_frames_far_from_boundary\n",
    "            \n",
    "            frames_added = list(range(new_frames_start, new_frames_end))\n",
    "            frames_added.append(current_selected_frames[seg_num])\n",
    "            frames_added = list(set(frames_added))\n",
    "            frames_added.sort()\n",
    "            new_selected_frames[video_id] = frames_added\n",
    "\n",
    "            \n",
    "            labels_seg = torch.stack([labels[current_selected_frames[seg_num]]] * len(frames_added))\n",
    "            frames_added = torch.tensor(np.array(frames_added), dtype=torch.long, device=current_video_logits.device)\n",
    "            prob_seg = current_video_logits[frames_added, :]\n",
    "            \n",
    "            labels_arr.append(labels_seg)\n",
    "            probs_arr.append(prob_seg)\n",
    "            \n",
    "            cur_seg_start = cur_seg_end\n",
    "            \n",
    "    labels_arr = torch.cat(labels_arr)\n",
    "    probs_arr = torch.cat(probs_arr)\n",
    "    loss = p_criterion(probs_arr, labels_arr)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mask_for_this_class(video_len, weakly_labels_video, old_index_label_pair_list, \n",
    "                             cur_ele_searched, cur_index_searched):\n",
    "    searched_label_index = np.where(cur_ele_searched == np.array(weakly_labels_video))[0]\n",
    "    if len(searched_label_index) <= 1:\n",
    "        mask = torch.ones(video_len)\n",
    "        return mask\n",
    "    else:\n",
    "        start = 0\n",
    "        for i, index in enumerate(searched_label_index[:-1]):\n",
    "            cur_index_frame_selected = old_index_label_pair_list[index][0]\n",
    "            next_index = searched_label_index[i + 1]\n",
    "            next_index_frame_selected = old_index_label_pair_list[next_index][0]\n",
    "            \n",
    "            mid_select = (cur_index_frame_selected + next_index_frame_selected) // 2\n",
    "            \n",
    "            if index == cur_index_searched:\n",
    "                mask = torch.zeros(video_len)\n",
    "                mask[start: mid_select + 1] = 1\n",
    "                return mask\n",
    "            \n",
    "            start = mid_select\n",
    "        if searched_label_index[-1] == cur_index_searched:\n",
    "            mask = torch.zeros(video_len)\n",
    "            mask[start: video_len] = 1\n",
    "            return mask\n",
    "        else:\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "            return \"Error 1\"\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2, 2, 2, 2, 3, 3, 4, 4, 3, 3, 2, 2, 2, 2]\n",
    "find_mask_for_this_class(12, [2, 3, 4, 3,  2], [3, 5, 7, 8, 10], 4, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
