{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=2,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/\",\n",
    "    project_name=\"breakfast-split-2\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = Breakfast(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = iter(trainloader).next()\n",
    "# print(item[0]) # -- data feature\n",
    "# print(item[1]) # -- valid count\n",
    "# item[2] # -- Actual labels\n",
    "# print(item[5]) # video names\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vidid_selected_frames = np.load(\"/home/dipika16/ar/TimestampActionSeg/data/breakfast_annotation_all.npy\", allow_pickle=True).item()\n",
    "# loaded_vidid_selected_frames\n",
    "video_id_boundary_frames = pickle.load(open(\"dump_dir/chunk_1_video_id_boundary_frames_dict.pkl\", \"rb\"))\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"dump_dir/mean_var_actions.pkl\", \"rb\"))\n",
    "def get_possion_prob(cur_len, cur_class):\n",
    "    mean_class, std_class = loaded_mean_var_actions[cur_class]\n",
    "    mean_class = mean_class * 10\n",
    "    prob = cur_len * torch.log(torch.tensor(mean_class, device=device) + 1e-5)\n",
    "    prob = prob - mean_class\n",
    "    factorials = torch.cumsum(torch.log(torch.arange(1, torch.max(cur_len)+1, 1).type(torch.float).to(device)), \n",
    "                              dim=0)[min(cur_len)-1:]\n",
    "    prob = prob - factorials\n",
    "    return prob\n",
    "\n",
    "# get_possion_prob(torch.arange(10, 21), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_video_each_segment_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels):\n",
    "    prob_each_segment = []\n",
    "    \n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    cur_boundary = 0\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[cur_ele]\n",
    "        label_next_ele = labels[next_ele]\n",
    "\n",
    "        indices = torch.arange(cur_ele, next_ele).to(cumsum_feat.device)\n",
    "        strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "        end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "        left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "        right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "\n",
    "        cur_boundary_len = indices - cur_boundary\n",
    "        len_prob = get_possion_prob(cur_boundary_len, label_cur_ele.item())\n",
    "\n",
    "        prob = torch.softmax((left_sum + right_sum + len_prob), dim=0)\n",
    "#         prob = torch.softmax((left_sum + right_sum), dim=0)\n",
    "\n",
    "        cur_boundary = round(np.sum(np.arange(cur_ele, next_ele, 1) * prob.detach().cpu().numpy()).item())\n",
    "        prob_each_segment.append(prob)\n",
    "    \n",
    "    return prob_each_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frames = torch.tensor([2, 10, 17, 21])\n",
    "cur_vid_feat = torch.randn((27, 48))\n",
    "labels = torch.tensor([47, 47, 47, 47, 47, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 10, 10])\n",
    "# print(len(labels))\n",
    "# probs_all_segs = prob_vals_per_segment_new(selected_frames, cur_vid_feat, labels)\n",
    "# print(probs_all_segs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_element_probb(data_feat, data_count, video_ids, labels_all): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        labels = labels_all[iter_num]\n",
    "        \n",
    "        selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "        prob_video = prob_vals_per_segment(selected_frames, cur_vid_feat, labels)\n",
    "        prob_video_each_segment_dict[cur_vidid] = prob_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_loss(data_feat, data_count, video_ids, labels_all): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    loss_arr = []\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        labels = labels_all[iter_num]\n",
    "        \n",
    "        selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "        prob_each_video = prob_video_each_segment_dict[cur_vidid]\n",
    "        \n",
    "        log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "        cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "        \n",
    "        \n",
    "        current_vid_prob_arr = []\n",
    "        # Start segment log probability\n",
    "        start_ele_idx = selected_frames[0]\n",
    "        if start_ele_idx > 0:\n",
    "            start_ele_label_idx = labels[selected_frames[0]]\n",
    "            first_segment_prob = (cumsum_feat[start_ele_idx - 1, :])[start_ele_label_idx]\n",
    "            current_vid_prob_arr.append(first_segment_prob.unsqueeze(0))\n",
    "        \n",
    "        for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "            next_ele = selected_frames[i + 1]\n",
    "            label_cur_ele = labels[cur_ele]\n",
    "            label_next_ele = labels[next_ele]\n",
    "\n",
    "            indices = torch.arange(cur_ele, next_ele)\n",
    "            strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "            end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "            left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "            right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "            current_vid_prob_arr.append((left_sum + right_sum)  * (prob_each_video[i]))\n",
    "        \n",
    "        # End segment log probability\n",
    "        end_index = cur_vid_count.item() - 1\n",
    "        last_ele_label_idx = labels[selected_frames[-1]]\n",
    "        last_segment_sum_prob = (cumsum_feat[end_index, :] - cumsum_feat[selected_frames[-1] - 1, :])[last_ele_label_idx]\n",
    "        current_vid_prob_arr.append(last_segment_sum_prob.unsqueeze(0))\n",
    "            \n",
    "        loss_arr.append(torch.cat(current_vid_prob_arr))\n",
    "    return -torch.mean(torch.cat(loss_arr)), loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_boundaries():\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames, video_id_boundary_frames\n",
    "    estimated_boundary_dict = {}\n",
    "    for ele in video_id_boundary_frames.keys():\n",
    "        \n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        selected_ele_list = loaded_vidid_selected_frames[ele + \".txt\"]\n",
    "        boundary_list = []\n",
    "        for i, segment in enumerate(estimated_boundary_probs):\n",
    "            estimated_boundary = np.sum(np.arange(selected_ele_list[i], selected_ele_list[i + 1], 1) \\\n",
    "                                        * segment.detach().cpu().numpy())\n",
    "            estimated_boundary = round(estimated_boundary.item())\n",
    "            \n",
    "            if (estimated_boundary < selected_ele_list[i]) or (estimated_boundary > selected_ele_list[i + 1]):\n",
    "                print(\"Estimated value wrong\")\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "            boundary_list.append(estimated_boundary)\n",
    "\n",
    "        estimated_boundary_dict[ele] = boundary_list\n",
    "    return estimated_boundary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_err():\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    err_list = []\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    estimated_boundar_dict = get_estimated_boundaries()\n",
    "    for ele in video_id_boundary_frames.keys():\n",
    "        \n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        estimated_boundary_list = estimated_boundar_dict[ele]\n",
    "        \n",
    "        estimated = np.array(estimated_boundary_list) #.detach().cpu().numpy()\n",
    "        actual = np.array(video_id_boundary_frames[ele][:-1])\n",
    "        if len(actual) != len(estimated):\n",
    "            print(ele)\n",
    "            continue\n",
    "        \n",
    "        mse_err = (actual - estimated)**2\n",
    "        err_list.append(mse_err)\n",
    "        \n",
    "        estimated_labels = []\n",
    "        actual_labels = []\n",
    "        start_v1 = 0\n",
    "        start_v2 = 0\n",
    "        for i, v1 in enumerate(estimated):\n",
    "            estimated_labels.extend([i] * (v1 - start_v1))\n",
    "            start_v1 = v1\n",
    "            v2 = actual[i]\n",
    "            actual_labels.extend([i] * (v2 - start_v2))\n",
    "            start_v2 = v2\n",
    "            \n",
    "        last_ele = video_id_boundary_frames[ele][-1]\n",
    "        estimated_labels.extend([i+1] * (last_ele - start_v1))\n",
    "        actual_labels.extend([i+1] * (last_ele - start_v2))\n",
    "        \n",
    "        correct += np.sum(np.array(actual_labels) == np.array(estimated_labels))\n",
    "        total += len(actual_labels)\n",
    "        \n",
    "    print(f\"Train Boundary avergage error = {np.sqrt(np.mean(np.concatenate(err_list))):.3f}\")\n",
    "    print(f\"Train From boundary avergage accuracy = {correct * 100.0 / total:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_random(labels_all, video_ids):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((labels_all.shape[0], labels_all.shape[1]), dtype=torch.long, device=labels_all.device) * (-100)\n",
    "    for iter_num, labels in enumerate(labels_all):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        frame_idx_tensor = torch.from_numpy(np.array(loaded_vidid_selected_frames[cur_vidid + \".txt\"]))\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = labels[frame_idx_tensor]\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/\"\n",
    "                            f\"/results/em-maximize-mstcn-speed/ms-tcn-em.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Training:: Epoch 15, Iteration 0, Current loss 1.670422911643982 Accuracy 73.96979430055354\n",
      "Training:: Epoch 15, Iteration 10, Current loss 3.0801100730895996 Accuracy 58.819281458747064\n",
      "Training:: Epoch 15, Iteration 20, Current loss 1.7788012027740479 Accuracy 81.82924435721296\n",
      "Training:: Epoch 15, Iteration 30, Current loss 1.8429172039031982 Accuracy 85.61742078497848\n",
      "Training:: Epoch 15, Iteration 40, Current loss 2.2868900299072266 Accuracy 81.84813539014527\n",
      "Training:: Epoch 15, Iteration 50, Current loss 1.8934496641159058 Accuracy 67.88126493713415\n",
      "Training:: Epoch 15, Iteration 60, Current loss 2.0426523685455322 Accuracy 71.8662797187186\n",
      "Training:: Epoch 15, Iteration 70, Current loss 1.8668643236160278 Accuracy 77.62562245359891\n",
      "Training:: Epoch 15, Iteration 80, Current loss 1.5906909704208374 Accuracy 71.88582617864137\n",
      "Training:: Epoch 15, Iteration 90, Current loss 1.8404302597045898 Accuracy 77.0093062605753\n",
      "Training:: Epoch 15, Iteration 100, Current loss 1.6636706590652466 Accuracy 69.03778649597356\n",
      "Training:: Epoch 15, Iteration 110, Current loss 1.9402567148208618 Accuracy 75.63328366402635\n",
      "Training:: Epoch 15, Iteration 120, Current loss 1.9688682556152344 Accuracy 69.82953218650269\n",
      "Training:: Epoch 15, Iteration 130, Current loss 2.1269822120666504 Accuracy 71.57977263818111\n",
      "Training:: Epoch 15, Iteration 140, Current loss 2.0340752601623535 Accuracy 74.76723408257313\n",
      "Training:: Epoch 15, Iteration 150, Current loss 1.9952226877212524 Accuracy 61.52886320352006\n",
      "Calculating Expectation\n",
      "Epoch 15 iter 0\n",
      "Epoch 15 iter 10\n",
      "Epoch 15 iter 20\n",
      "Epoch 15 iter 30\n",
      "Epoch 15 iter 40\n",
      "Epoch 15 iter 50\n",
      "Epoch 15 iter 60\n",
      "Epoch 15 iter 70\n",
      "Epoch 15 iter 80\n",
      "Epoch 15 iter 90\n",
      "Epoch 15 iter 100\n",
      "Epoch 15 iter 110\n",
      "Epoch 15 iter 120\n",
      "Epoch 15 iter 130\n",
      "Epoch 15 iter 140\n",
      "Epoch 15 iter 150\n",
      "Train Boundary avergage error = 101.468\n",
      "Train From boundary avergage accuracy = 88.919\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 15, Probability Accuracy 55.061938103326845\n",
      "Starting Training\n",
      "Training:: Epoch 16, Iteration 0, Current loss 2.4030890595328813 Accuracy 78.78746686603684\n",
      "Training:: Epoch 16, Iteration 10, Current loss 8.768900498422514 Accuracy 45.98796389167502\n",
      "Training:: Epoch 16, Iteration 20, Current loss 5.085819543856991 Accuracy 69.84209163862283\n",
      "Training:: Epoch 16, Iteration 30, Current loss 5.798213601120016 Accuracy 46.11704743595475\n",
      "Training:: Epoch 16, Iteration 40, Current loss 3.693473328403717 Accuracy 66.35566188197767\n",
      "Training:: Epoch 16, Iteration 50, Current loss 2.861717181775054 Accuracy 65.33721595340856\n",
      "Training:: Epoch 16, Iteration 60, Current loss 4.5389595879966596 Accuracy 57.13745080230094\n",
      "Training:: Epoch 16, Iteration 70, Current loss 6.141311376311239 Accuracy 70.70484581497797\n",
      "Training:: Epoch 16, Iteration 80, Current loss 6.199982137409118 Accuracy 60.2920057443753\n",
      "Training:: Epoch 16, Iteration 90, Current loss 3.7717849275911886 Accuracy 78.6400105221623\n",
      "Training:: Epoch 16, Iteration 100, Current loss 2.048464067180151 Accuracy 83.34165210880958\n",
      "Training:: Epoch 16, Iteration 110, Current loss 2.14942066503661 Accuracy 74.16999692591455\n",
      "Training:: Epoch 16, Iteration 120, Current loss 3.2210824742860655 Accuracy 73.2422749664129\n",
      "Training:: Epoch 16, Iteration 130, Current loss 4.872799426135017 Accuracy 68.5766483972762\n",
      "Training:: Epoch 16, Iteration 140, Current loss 5.5904807914942785 Accuracy 58.10985676676632\n",
      "Training:: Epoch 16, Iteration 150, Current loss 3.448921524652563 Accuracy 74.71656168951463\n",
      "Starting Training\n",
      "Training:: Epoch 17, Iteration 0, Current loss 2.1974116723375756 Accuracy 80.81935023205997\n",
      "Training:: Epoch 17, Iteration 10, Current loss 3.8112406699946817 Accuracy 72.95650036864095\n",
      "Training:: Epoch 17, Iteration 20, Current loss 2.9589824690381525 Accuracy 80.70890201670402\n",
      "Training:: Epoch 17, Iteration 30, Current loss 2.2448494622805906 Accuracy 75.2799803809368\n",
      "Training:: Epoch 17, Iteration 40, Current loss 2.570107607995381 Accuracy 76.52480737380284\n",
      "Training:: Epoch 17, Iteration 50, Current loss 2.2503538586066156 Accuracy 79.34599310799912\n",
      "Training:: Epoch 17, Iteration 60, Current loss 1.5994979979963808 Accuracy 87.66062207277531\n",
      "Training:: Epoch 17, Iteration 70, Current loss 1.9245500829170714 Accuracy 83.03666155841094\n",
      "Training:: Epoch 17, Iteration 80, Current loss 2.613342291071536 Accuracy 81.07311576301305\n",
      "Training:: Epoch 17, Iteration 90, Current loss 1.45134959252107 Accuracy 80.18423531874804\n",
      "Training:: Epoch 17, Iteration 100, Current loss 3.242354659594522 Accuracy 77.5574411288016\n",
      "Training:: Epoch 17, Iteration 110, Current loss 2.458466425176608 Accuracy 74.27310488058151\n",
      "Training:: Epoch 17, Iteration 120, Current loss 2.343194094467694 Accuracy 82.37481622416328\n",
      "Training:: Epoch 17, Iteration 130, Current loss 1.6164868920028908 Accuracy 85.81103678929766\n",
      "Training:: Epoch 17, Iteration 140, Current loss 2.1672834202167635 Accuracy 77.947542653425\n",
      "Training:: Epoch 17, Iteration 150, Current loss 2.344540865711262 Accuracy 79.81636333825217\n",
      "Starting Training\n",
      "Training:: Epoch 18, Iteration 0, Current loss 2.228578120588087 Accuracy 76.92935123603965\n",
      "Training:: Epoch 18, Iteration 10, Current loss 1.9996425564517895 Accuracy 86.24389720478567\n",
      "Training:: Epoch 18, Iteration 20, Current loss 1.5271277832468575 Accuracy 89.67929625268408\n",
      "Training:: Epoch 18, Iteration 30, Current loss 1.3880080895373108 Accuracy 84.56832087015636\n",
      "Training:: Epoch 18, Iteration 40, Current loss 4.297523841368035 Accuracy 71.42696059085527\n",
      "Training:: Epoch 18, Iteration 50, Current loss 1.8009201648462898 Accuracy 85.131547188028\n",
      "Training:: Epoch 18, Iteration 60, Current loss 1.973245591332732 Accuracy 79.73824914212753\n",
      "Training:: Epoch 18, Iteration 70, Current loss 2.7811180917701765 Accuracy 77.36037708898729\n",
      "Training:: Epoch 18, Iteration 80, Current loss 1.4654602046856209 Accuracy 88.2930733410943\n",
      "Training:: Epoch 18, Iteration 90, Current loss 1.7007776629868356 Accuracy 87.4692118226601\n",
      "Training:: Epoch 18, Iteration 100, Current loss 1.3385795616745786 Accuracy 87.8476943998022\n",
      "Training:: Epoch 18, Iteration 110, Current loss 2.2353056388811505 Accuracy 85.95956517321954\n",
      "Training:: Epoch 18, Iteration 120, Current loss 1.6634409760479163 Accuracy 80.05903908794788\n",
      "Training:: Epoch 18, Iteration 130, Current loss 1.4933204627625165 Accuracy 87.38076083208827\n",
      "Training:: Epoch 18, Iteration 140, Current loss 2.4480323323677426 Accuracy 83.98380156922298\n",
      "Training:: Epoch 18, Iteration 150, Current loss 1.5289610651641223 Accuracy 85.55900621118012\n",
      "Starting Training\n",
      "Training:: Epoch 19, Iteration 0, Current loss 1.9567093953512882 Accuracy 83.4126070194763\n",
      "Training:: Epoch 19, Iteration 10, Current loss 2.2668475632312743 Accuracy 80.69178233090989\n",
      "Training:: Epoch 19, Iteration 20, Current loss 1.851964526614228 Accuracy 83.81184386056493\n",
      "Training:: Epoch 19, Iteration 30, Current loss 2.8628764746382958 Accuracy 80.03610557768924\n",
      "Training:: Epoch 19, Iteration 40, Current loss 1.0368754962517786 Accuracy 88.4941975658081\n",
      "Training:: Epoch 19, Iteration 50, Current loss 1.9312672878677912 Accuracy 78.19084686619246\n",
      "Training:: Epoch 19, Iteration 60, Current loss 3.722702436604245 Accuracy 78.18958664546899\n",
      "Training:: Epoch 19, Iteration 70, Current loss 4.095920621234521 Accuracy 75.46470370174231\n",
      "Training:: Epoch 19, Iteration 80, Current loss 3.2450847594086305 Accuracy 78.15926009474397\n",
      "Training:: Epoch 19, Iteration 90, Current loss 3.8169528768076555 Accuracy 73.49582057436068\n",
      "Training:: Epoch 19, Iteration 100, Current loss 6.872219950221266 Accuracy 59.22737914887757\n",
      "Training:: Epoch 19, Iteration 110, Current loss 3.3706926721989134 Accuracy 72.37981487011048\n",
      "Training:: Epoch 19, Iteration 120, Current loss 5.602021433885603 Accuracy 56.430217892402034\n",
      "Training:: Epoch 19, Iteration 130, Current loss 5.125315369118636 Accuracy 62.67709129386867\n",
      "Training:: Epoch 19, Iteration 140, Current loss 2.9941205544331377 Accuracy 80.7584050039093\n",
      "Training:: Epoch 19, Iteration 150, Current loss 1.7939109917908453 Accuracy 85.46310832025118\n",
      "Starting Training\n",
      "Training:: Epoch 20, Iteration 0, Current loss 4.742851013962958 Accuracy 71.46957878315132\n",
      "Training:: Epoch 20, Iteration 10, Current loss 1.838742100169417 Accuracy 83.38828805064627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 20, Iteration 20, Current loss 1.5950919590826729 Accuracy 84.01692183722804\n",
      "Training:: Epoch 20, Iteration 30, Current loss 2.257718784381489 Accuracy 82.91512915129151\n",
      "Training:: Epoch 20, Iteration 40, Current loss 1.6229423470471473 Accuracy 85.77956090493703\n",
      "Training:: Epoch 20, Iteration 50, Current loss 1.3555144079187214 Accuracy 86.75067286518228\n",
      "Training:: Epoch 20, Iteration 60, Current loss 1.848327540206294 Accuracy 87.94089439846553\n",
      "Training:: Epoch 20, Iteration 70, Current loss 1.0717349031110714 Accuracy 75.06997742663657\n",
      "Training:: Epoch 20, Iteration 80, Current loss 2.9854681166418247 Accuracy 74.48166918975843\n",
      "Training:: Epoch 20, Iteration 90, Current loss 6.245092963307808 Accuracy 56.169212690951824\n",
      "Training:: Epoch 20, Iteration 100, Current loss 6.968438760675304 Accuracy 49.06951010964692\n",
      "Training:: Epoch 20, Iteration 110, Current loss 4.8866111408705875 Accuracy 71.38347407465866\n",
      "Training:: Epoch 20, Iteration 120, Current loss 2.986559698066301 Accuracy 76.48202137998057\n",
      "Training:: Epoch 20, Iteration 130, Current loss 1.981916552847206 Accuracy 87.31083481349911\n",
      "Training:: Epoch 20, Iteration 140, Current loss 3.9132588252881684 Accuracy 69.37732342007435\n",
      "Training:: Epoch 20, Iteration 150, Current loss 2.7706597101935184 Accuracy 76.00130516355331\n",
      "Calculating Expectation\n",
      "Epoch 20 iter 0\n",
      "Epoch 20 iter 10\n",
      "Epoch 20 iter 20\n",
      "Epoch 20 iter 30\n",
      "Epoch 20 iter 40\n",
      "Epoch 20 iter 50\n",
      "Epoch 20 iter 60\n",
      "Epoch 20 iter 70\n",
      "Epoch 20 iter 80\n",
      "Epoch 20 iter 90\n",
      "Epoch 20 iter 100\n",
      "Epoch 20 iter 110\n",
      "Epoch 20 iter 120\n",
      "Epoch 20 iter 130\n",
      "Epoch 20 iter 140\n",
      "Epoch 20 iter 150\n",
      "Train Boundary avergage error = 88.746\n",
      "Train From boundary avergage accuracy = 89.209\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 20, Probability Accuracy 62.90705141484029\n",
      "Starting Training\n",
      "Training:: Epoch 21, Iteration 0, Current loss 3.780853772649257 Accuracy 74.48581655002938\n",
      "Training:: Epoch 21, Iteration 10, Current loss 1.9509573128231394 Accuracy 82.91698309284943\n",
      "Training:: Epoch 21, Iteration 20, Current loss 1.369285052824927 Accuracy 87.14169498014068\n",
      "Training:: Epoch 21, Iteration 30, Current loss 1.7382738539097948 Accuracy 88.03332796651102\n",
      "Training:: Epoch 21, Iteration 40, Current loss 1.5503036847665381 Accuracy 88.19844470046083\n",
      "Training:: Epoch 21, Iteration 50, Current loss 1.8479768965437027 Accuracy 80.74804767776408\n",
      "Training:: Epoch 21, Iteration 60, Current loss 1.1055214578900334 Accuracy 89.69605246563249\n",
      "Training:: Epoch 21, Iteration 70, Current loss 1.5455728887413889 Accuracy 82.50985850150776\n",
      "Training:: Epoch 21, Iteration 80, Current loss 4.446146224465556 Accuracy 71.5900163171572\n",
      "Training:: Epoch 21, Iteration 90, Current loss 1.0997188606348318 Accuracy 87.2560528246515\n",
      "Training:: Epoch 21, Iteration 100, Current loss 1.1604533580836358 Accuracy 87.12849769084488\n",
      "Training:: Epoch 21, Iteration 110, Current loss 1.3618521149828045 Accuracy 85.98668825328296\n",
      "Training:: Epoch 21, Iteration 120, Current loss 1.538142192252781 Accuracy 84.32674940278505\n",
      "Training:: Epoch 21, Iteration 130, Current loss 1.1570860000978906 Accuracy 88.95373072113381\n",
      "Training:: Epoch 21, Iteration 140, Current loss 2.104607965188504 Accuracy 85.16422036464161\n",
      "Training:: Epoch 21, Iteration 150, Current loss 1.9955787880469706 Accuracy 81.6027376270494\n",
      "Starting Training\n",
      "Training:: Epoch 22, Iteration 0, Current loss 1.6123334779299903 Accuracy 80.02233923727461\n",
      "Training:: Epoch 22, Iteration 10, Current loss 1.5982930368848003 Accuracy 86.07004449547868\n",
      "Training:: Epoch 22, Iteration 20, Current loss 0.9399073387504646 Accuracy 89.71752621442329\n",
      "Training:: Epoch 22, Iteration 30, Current loss 1.5291984724951218 Accuracy 90.99601958182733\n",
      "Training:: Epoch 22, Iteration 40, Current loss 1.8165280889574795 Accuracy 83.76577840112202\n",
      "Training:: Epoch 22, Iteration 50, Current loss 3.2706563626572795 Accuracy 77.03868158141918\n",
      "Training:: Epoch 22, Iteration 60, Current loss 1.6432434421132953 Accuracy 89.86998916576381\n",
      "Training:: Epoch 22, Iteration 70, Current loss 2.683474389959197 Accuracy 79.51910080386996\n",
      "Training:: Epoch 22, Iteration 80, Current loss 1.670764653732933 Accuracy 84.31712336185421\n",
      "Training:: Epoch 22, Iteration 90, Current loss 1.8253445354754347 Accuracy 82.78709545058214\n",
      "Training:: Epoch 22, Iteration 100, Current loss 0.8264900536221063 Accuracy 89.51853971888316\n",
      "Training:: Epoch 22, Iteration 110, Current loss 1.4225764580658051 Accuracy 88.53067894815035\n",
      "Training:: Epoch 22, Iteration 120, Current loss 0.6407837151132865 Accuracy 91.34260910928766\n",
      "Training:: Epoch 22, Iteration 130, Current loss 0.8311829315866053 Accuracy 91.4238452729355\n",
      "Training:: Epoch 22, Iteration 140, Current loss 1.5542475957189357 Accuracy 84.69809760132341\n",
      "Training:: Epoch 22, Iteration 150, Current loss 1.3138688167759438 Accuracy 87.02170312908568\n",
      "Starting Training\n",
      "Training:: Epoch 23, Iteration 0, Current loss 1.0500634468862036 Accuracy 91.87970434664678\n",
      "Training:: Epoch 23, Iteration 10, Current loss 1.5025091589841981 Accuracy 82.48818611414032\n",
      "Training:: Epoch 23, Iteration 20, Current loss 0.7012842406033295 Accuracy 89.17191636994431\n",
      "Training:: Epoch 23, Iteration 30, Current loss 0.7763189447374828 Accuracy 88.26956573968407\n",
      "Training:: Epoch 23, Iteration 40, Current loss 0.9067611095575789 Accuracy 84.32914972600318\n",
      "Training:: Epoch 23, Iteration 50, Current loss 1.4112862020638812 Accuracy 81.56276855952932\n",
      "Training:: Epoch 23, Iteration 60, Current loss 1.6350912804813156 Accuracy 82.65836491608013\n",
      "Training:: Epoch 23, Iteration 70, Current loss 2.0156891787146174 Accuracy 76.82789651293588\n",
      "Training:: Epoch 23, Iteration 80, Current loss 1.5639284697598488 Accuracy 84.27022399771722\n",
      "Training:: Epoch 23, Iteration 90, Current loss 1.7486233028408127 Accuracy 84.05311491685282\n",
      "Training:: Epoch 23, Iteration 100, Current loss 1.0167816496061195 Accuracy 86.97845650395419\n",
      "Training:: Epoch 23, Iteration 110, Current loss 0.7229208890619707 Accuracy 91.74091359072267\n",
      "Training:: Epoch 23, Iteration 120, Current loss 1.2400155165342974 Accuracy 90.21562164952547\n",
      "Training:: Epoch 23, Iteration 130, Current loss 1.1163294360621188 Accuracy 86.3125\n",
      "Training:: Epoch 23, Iteration 140, Current loss 1.219894946305105 Accuracy 87.76973930397905\n",
      "Training:: Epoch 23, Iteration 150, Current loss 1.164430308243806 Accuracy 89.37479577388083\n",
      "Starting Training\n",
      "Training:: Epoch 24, Iteration 0, Current loss 0.8400066795242864 Accuracy 92.00278164116828\n",
      "Training:: Epoch 24, Iteration 10, Current loss 0.9354699016723943 Accuracy 89.79015714689\n",
      "Training:: Epoch 24, Iteration 20, Current loss 0.8333813429375625 Accuracy 90.14341273699563\n",
      "Training:: Epoch 24, Iteration 30, Current loss 0.9258290266970468 Accuracy 91.41109852774632\n",
      "Training:: Epoch 24, Iteration 40, Current loss 1.0072036289774178 Accuracy 86.05607017974357\n",
      "Training:: Epoch 24, Iteration 50, Current loss 1.5724991144455671 Accuracy 84.0224032586558\n",
      "Training:: Epoch 24, Iteration 60, Current loss 3.3780130521650866 Accuracy 78.92512077294685\n",
      "Training:: Epoch 24, Iteration 70, Current loss 3.887120982011026 Accuracy 70.72012532432565\n",
      "Training:: Epoch 24, Iteration 80, Current loss 1.2457477545467515 Accuracy 88.5656909876468\n",
      "Training:: Epoch 24, Iteration 90, Current loss 2.460270594581589 Accuracy 77.63888364364213\n",
      "Training:: Epoch 24, Iteration 100, Current loss 1.5384289176972505 Accuracy 85.7758082636375\n",
      "Training:: Epoch 24, Iteration 110, Current loss 1.2583073984164344 Accuracy 87.78690989275333\n",
      "Training:: Epoch 24, Iteration 120, Current loss 1.2549880553365305 Accuracy 81.52632886239444\n",
      "Training:: Epoch 24, Iteration 130, Current loss 1.6561885645033774 Accuracy 81.53793707996493\n",
      "Training:: Epoch 24, Iteration 140, Current loss 1.3474371447933648 Accuracy 88.60078747719197\n",
      "Training:: Epoch 24, Iteration 150, Current loss 0.8038548542632262 Accuracy 90.64973131411823\n",
      "Starting Training\n",
      "Training:: Epoch 25, Iteration 0, Current loss 1.31881603883926 Accuracy 88.99687146375557\n",
      "Training:: Epoch 25, Iteration 10, Current loss 1.3512040621111499 Accuracy 86.94615063510048\n",
      "Training:: Epoch 25, Iteration 20, Current loss 0.9275903879926456 Accuracy 84.60892620415378\n",
      "Training:: Epoch 25, Iteration 30, Current loss 1.44216845499747 Accuracy 86.28018587643787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 25, Iteration 40, Current loss 2.5312993565891833 Accuracy 78.37801427994073\n",
      "Training:: Epoch 25, Iteration 50, Current loss 3.195208930002285 Accuracy 72.98185874478952\n",
      "Training:: Epoch 25, Iteration 60, Current loss 2.9900177670297485 Accuracy 76.9878645172976\n",
      "Training:: Epoch 25, Iteration 70, Current loss 1.7160447624257638 Accuracy 86.2463465553236\n",
      "Training:: Epoch 25, Iteration 80, Current loss 0.996588885814818 Accuracy 87.77173913043478\n",
      "Training:: Epoch 25, Iteration 90, Current loss 1.6816926349983876 Accuracy 86.94635287238708\n",
      "Training:: Epoch 25, Iteration 100, Current loss 2.5123365974684484 Accuracy 77.78845164167839\n",
      "Training:: Epoch 25, Iteration 110, Current loss 1.812848368214991 Accuracy 79.31682062734748\n",
      "Training:: Epoch 25, Iteration 120, Current loss 1.2014691446116585 Accuracy 90.22138228941685\n",
      "Training:: Epoch 25, Iteration 130, Current loss 1.8208205290658688 Accuracy 89.35926773455378\n",
      "Training:: Epoch 25, Iteration 140, Current loss 1.143412401894198 Accuracy 88.33136012257121\n",
      "Training:: Epoch 25, Iteration 150, Current loss 1.9640118730398846 Accuracy 85.21606224815895\n",
      "Calculating Expectation\n",
      "Epoch 25 iter 0\n",
      "Epoch 25 iter 10\n",
      "Epoch 25 iter 20\n",
      "Epoch 25 iter 30\n",
      "Epoch 25 iter 40\n",
      "Epoch 25 iter 50\n",
      "Epoch 25 iter 60\n",
      "Epoch 25 iter 70\n",
      "Epoch 25 iter 80\n",
      "Epoch 25 iter 90\n",
      "Epoch 25 iter 100\n",
      "Epoch 25 iter 110\n",
      "Epoch 25 iter 120\n",
      "Epoch 25 iter 130\n",
      "Epoch 25 iter 140\n",
      "Epoch 25 iter 150\n",
      "Train Boundary avergage error = 88.182\n",
      "Train From boundary avergage accuracy = 89.037\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 25, Probability Accuracy 66.53882006877409\n",
      "Starting Training\n",
      "Training:: Epoch 26, Iteration 0, Current loss 0.7143858763298971 Accuracy 89.92266414141415\n",
      "Training:: Epoch 26, Iteration 10, Current loss 0.9364909361398829 Accuracy 92.33149931224209\n",
      "Training:: Epoch 26, Iteration 20, Current loss 3.4036507776523655 Accuracy 78.34686346863468\n",
      "Training:: Epoch 26, Iteration 30, Current loss 1.4266526205693777 Accuracy 83.26456395552137\n",
      "Training:: Epoch 26, Iteration 40, Current loss 0.9127483474888176 Accuracy 87.75453121503692\n",
      "Training:: Epoch 26, Iteration 50, Current loss 0.8042088907085958 Accuracy 90.71036327794987\n",
      "Training:: Epoch 26, Iteration 60, Current loss 1.1803251809838273 Accuracy 89.851150202977\n",
      "Training:: Epoch 26, Iteration 70, Current loss 1.0419212771200925 Accuracy 89.34728650969343\n",
      "Training:: Epoch 26, Iteration 80, Current loss 1.4424121447235665 Accuracy 85.4290527150218\n",
      "Training:: Epoch 26, Iteration 90, Current loss 1.3165504048500414 Accuracy 86.28359120521172\n",
      "Training:: Epoch 26, Iteration 100, Current loss 1.1927787382602428 Accuracy 88.21518868807941\n",
      "Training:: Epoch 26, Iteration 110, Current loss 1.4479710762059894 Accuracy 86.38513288483314\n",
      "Training:: Epoch 26, Iteration 120, Current loss 1.1974691272030944 Accuracy 88.15766726214487\n",
      "Training:: Epoch 26, Iteration 130, Current loss 2.117515429306495 Accuracy 80.48461034708579\n",
      "Training:: Epoch 26, Iteration 140, Current loss 1.929780429771243 Accuracy 80.34561912599074\n",
      "Training:: Epoch 26, Iteration 150, Current loss 6.493035350710741 Accuracy 56.28493986108758\n",
      "Starting Training\n",
      "Training:: Epoch 27, Iteration 0, Current loss 3.9021423924224874 Accuracy 74.81567714396586\n",
      "Training:: Epoch 27, Iteration 10, Current loss 2.0245213011065717 Accuracy 84.70593481071923\n",
      "Training:: Epoch 27, Iteration 20, Current loss 1.994249305821458 Accuracy 80.46949098956686\n",
      "Training:: Epoch 27, Iteration 30, Current loss 1.5199813594713993 Accuracy 87.33966903701734\n",
      "Training:: Epoch 27, Iteration 40, Current loss 2.2397513032269036 Accuracy 83.46194150709727\n",
      "Training:: Epoch 27, Iteration 50, Current loss 2.070750940529593 Accuracy 82.59323806204253\n",
      "Training:: Epoch 27, Iteration 60, Current loss 2.2491395839872057 Accuracy 76.14104716837124\n",
      "Training:: Epoch 27, Iteration 70, Current loss 1.2540754554227997 Accuracy 86.51556049539536\n",
      "Training:: Epoch 27, Iteration 80, Current loss 1.7543977568383253 Accuracy 86.46249445184199\n",
      "Training:: Epoch 27, Iteration 90, Current loss 0.9998262025002546 Accuracy 89.54771805534165\n",
      "Training:: Epoch 27, Iteration 100, Current loss 2.4957765680143735 Accuracy 79.82082866741321\n",
      "Training:: Epoch 27, Iteration 110, Current loss 0.9153819760622612 Accuracy 86.11017006572261\n",
      "Training:: Epoch 27, Iteration 120, Current loss 0.8603017160715442 Accuracy 86.83394417817874\n",
      "Training:: Epoch 27, Iteration 130, Current loss 2.4193574285816366 Accuracy 76.51924705269329\n",
      "Training:: Epoch 27, Iteration 140, Current loss 2.004137050538683 Accuracy 82.50382848392037\n",
      "Training:: Epoch 27, Iteration 150, Current loss 2.4488654107654764 Accuracy 77.55036519784895\n",
      "Starting Training\n",
      "Training:: Epoch 28, Iteration 0, Current loss 2.1908139671889852 Accuracy 75.6535491673644\n",
      "Training:: Epoch 28, Iteration 10, Current loss 0.9253561984258236 Accuracy 91.3675312644743\n",
      "Training:: Epoch 28, Iteration 20, Current loss 1.6089810872288703 Accuracy 87.20185568050023\n",
      "Training:: Epoch 28, Iteration 30, Current loss 1.4911381771509142 Accuracy 82.37970141603127\n",
      "Training:: Epoch 28, Iteration 40, Current loss 1.195451136322034 Accuracy 87.69307424015945\n",
      "Training:: Epoch 28, Iteration 50, Current loss 1.2903792023293248 Accuracy 87.21820967388925\n",
      "Training:: Epoch 28, Iteration 60, Current loss 1.1518664203868285 Accuracy 81.49751988032439\n",
      "Training:: Epoch 28, Iteration 70, Current loss 1.4606047694256947 Accuracy 85.99199210816457\n",
      "Training:: Epoch 28, Iteration 80, Current loss 1.2305589576887264 Accuracy 84.62765427175755\n",
      "Training:: Epoch 28, Iteration 90, Current loss 1.065135126742983 Accuracy 88.28100322193443\n",
      "Training:: Epoch 28, Iteration 100, Current loss 1.0674209453415637 Accuracy 90.15277010859562\n",
      "Training:: Epoch 28, Iteration 110, Current loss 0.899388634781777 Accuracy 88.56110776640578\n",
      "Training:: Epoch 28, Iteration 120, Current loss 0.9592581768142299 Accuracy 88.8406779661017\n",
      "Training:: Epoch 28, Iteration 130, Current loss 0.8744493192388413 Accuracy 92.3937751355132\n",
      "Training:: Epoch 28, Iteration 140, Current loss 0.8330645676120653 Accuracy 90.76539898457706\n",
      "Training:: Epoch 28, Iteration 150, Current loss 2.598804528707591 Accuracy 80.13275942540061\n",
      "Starting Training\n",
      "Training:: Epoch 29, Iteration 0, Current loss 2.750697299586865 Accuracy 67.63858476431946\n",
      "Training:: Epoch 29, Iteration 10, Current loss 1.342750278396545 Accuracy 88.72299724723557\n",
      "Training:: Epoch 29, Iteration 20, Current loss 1.247082167852378 Accuracy 87.28905824714208\n",
      "Training:: Epoch 29, Iteration 30, Current loss 0.7722676520432341 Accuracy 90.76667457868503\n",
      "Training:: Epoch 29, Iteration 40, Current loss 1.0666397313926492 Accuracy 88.05709292164288\n",
      "Training:: Epoch 29, Iteration 50, Current loss 0.9952066786430157 Accuracy 89.04723127035831\n",
      "Training:: Epoch 29, Iteration 60, Current loss 1.161843442376478 Accuracy 89.30958644184743\n",
      "Training:: Epoch 29, Iteration 70, Current loss 1.2894008545819462 Accuracy 86.26963919766503\n",
      "Training:: Epoch 29, Iteration 80, Current loss 1.4246218218100593 Accuracy 86.30659767141009\n",
      "Training:: Epoch 29, Iteration 90, Current loss 1.1211871127884332 Accuracy 85.04237288135593\n",
      "Training:: Epoch 29, Iteration 100, Current loss 0.7330556303304206 Accuracy 89.51883125586383\n",
      "Training:: Epoch 29, Iteration 110, Current loss 1.8232979718600508 Accuracy 83.82613361953314\n",
      "Training:: Epoch 29, Iteration 120, Current loss 1.7705422818605876 Accuracy 86.15194054500412\n",
      "Training:: Epoch 29, Iteration 130, Current loss 1.2848283890909495 Accuracy 89.8465769286438\n",
      "Training:: Epoch 29, Iteration 140, Current loss 0.9896738968794112 Accuracy 83.32294911734164\n",
      "Training:: Epoch 29, Iteration 150, Current loss 1.246637292776869 Accuracy 86.44883485309018\n",
      "Starting Training\n",
      "Training:: Epoch 30, Iteration 0, Current loss 1.4660884844048914 Accuracy 82.97702909647779\n",
      "Training:: Epoch 30, Iteration 10, Current loss 0.871960142325665 Accuracy 87.05566012368917\n",
      "Training:: Epoch 30, Iteration 20, Current loss 1.128692794662864 Accuracy 87.66286391122748\n",
      "Training:: Epoch 30, Iteration 30, Current loss 0.7155322333732115 Accuracy 91.18942731277534\n",
      "Training:: Epoch 30, Iteration 40, Current loss 1.077967343716076 Accuracy 81.92635270541082\n",
      "Training:: Epoch 30, Iteration 50, Current loss 1.045932712945305 Accuracy 84.60106382978724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 30, Iteration 60, Current loss 0.6208609048087266 Accuracy 87.13141158007764\n",
      "Training:: Epoch 30, Iteration 70, Current loss 0.7330033965763171 Accuracy 93.33333333333333\n",
      "Training:: Epoch 30, Iteration 80, Current loss 1.8539204349957608 Accuracy 79.97928616953473\n",
      "Training:: Epoch 30, Iteration 90, Current loss 0.9291879529168985 Accuracy 87.07854703508227\n",
      "Training:: Epoch 30, Iteration 100, Current loss 1.7716795745872784 Accuracy 82.11601605253557\n",
      "Training:: Epoch 30, Iteration 110, Current loss 1.2931347948299299 Accuracy 87.60825267447784\n",
      "Training:: Epoch 30, Iteration 120, Current loss 2.3502022095705604 Accuracy 83.67242263634809\n",
      "Training:: Epoch 30, Iteration 130, Current loss 3.776045247477245 Accuracy 82.92918274878335\n",
      "Training:: Epoch 30, Iteration 140, Current loss 1.2601718438290876 Accuracy 87.70328321571034\n",
      "Training:: Epoch 30, Iteration 150, Current loss 1.6770266828991804 Accuracy 84.188117842811\n",
      "Calculating Expectation\n",
      "Epoch 30 iter 0\n",
      "Epoch 30 iter 10\n",
      "Epoch 30 iter 20\n",
      "Epoch 30 iter 30\n",
      "Epoch 30 iter 40\n",
      "Epoch 30 iter 50\n",
      "Epoch 30 iter 60\n",
      "Epoch 30 iter 70\n",
      "Epoch 30 iter 80\n",
      "Epoch 30 iter 90\n",
      "Epoch 30 iter 100\n",
      "Epoch 30 iter 110\n",
      "Epoch 30 iter 120\n",
      "Epoch 30 iter 130\n",
      "Epoch 30 iter 140\n",
      "Epoch 30 iter 150\n",
      "Train Boundary avergage error = 88.162\n",
      "Train From boundary avergage accuracy = 88.821\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 30, Probability Accuracy 66.64767783900236\n",
      "Starting Training\n",
      "Training:: Epoch 31, Iteration 0, Current loss 1.049649319042825 Accuracy 88.06353809649355\n",
      "Training:: Epoch 31, Iteration 10, Current loss 1.2340315893540168 Accuracy 86.353711790393\n",
      "Training:: Epoch 31, Iteration 20, Current loss 1.5778340902636225 Accuracy 83.91355923461757\n",
      "Training:: Epoch 31, Iteration 30, Current loss 1.2584147592589359 Accuracy 87.48199844909715\n",
      "Training:: Epoch 31, Iteration 40, Current loss 1.2511673741414193 Accuracy 83.45579047333433\n",
      "Training:: Epoch 31, Iteration 50, Current loss 2.568831755014693 Accuracy 73.72304701307883\n",
      "Training:: Epoch 31, Iteration 60, Current loss 2.2340253004210235 Accuracy 75.84149086530911\n",
      "Training:: Epoch 31, Iteration 70, Current loss 1.3505433651382948 Accuracy 89.44598742873849\n",
      "Training:: Epoch 31, Iteration 80, Current loss 1.2804908576215572 Accuracy 89.16462549954879\n",
      "Training:: Epoch 31, Iteration 90, Current loss 1.4551744053050717 Accuracy 87.51910341314314\n",
      "Training:: Epoch 31, Iteration 100, Current loss 1.005771242794415 Accuracy 89.14298401420959\n",
      "Training:: Epoch 31, Iteration 110, Current loss 4.614952193183409 Accuracy 71.02401778379162\n",
      "Training:: Epoch 31, Iteration 120, Current loss 1.174616293777993 Accuracy 85.95543228768172\n",
      "Training:: Epoch 31, Iteration 130, Current loss 1.0176353398827445 Accuracy 85.9774511777733\n",
      "Training:: Epoch 31, Iteration 140, Current loss 1.5981799575910238 Accuracy 85.19435143397874\n",
      "Training:: Epoch 31, Iteration 150, Current loss 1.259225629499748 Accuracy 86.83441629235533\n",
      "Starting Training\n",
      "Training:: Epoch 32, Iteration 0, Current loss 1.1228680009855867 Accuracy 83.27629624846645\n",
      "Training:: Epoch 32, Iteration 10, Current loss 1.4249997354232748 Accuracy 88.36040453570334\n",
      "Training:: Epoch 32, Iteration 20, Current loss 0.8564509225652019 Accuracy 91.0527979766045\n",
      "Training:: Epoch 32, Iteration 30, Current loss 1.4543042292778197 Accuracy 85.74579317105048\n",
      "Training:: Epoch 32, Iteration 40, Current loss 1.1797819515829082 Accuracy 89.28494158372999\n",
      "Training:: Epoch 32, Iteration 50, Current loss 0.76685303487237 Accuracy 90.91767668817882\n",
      "Training:: Epoch 32, Iteration 60, Current loss 1.299240495492256 Accuracy 77.85934608266503\n",
      "Training:: Epoch 32, Iteration 70, Current loss 1.2456845824837355 Accuracy 88.53767560664113\n",
      "Training:: Epoch 32, Iteration 80, Current loss 1.011406827723795 Accuracy 90.52841034711474\n",
      "Training:: Epoch 32, Iteration 90, Current loss 1.7500738001322704 Accuracy 81.62819713038054\n",
      "Training:: Epoch 32, Iteration 100, Current loss 1.0294416643127795 Accuracy 88.63518036444775\n",
      "Training:: Epoch 32, Iteration 110, Current loss 0.6802727393055993 Accuracy 89.79639597472502\n",
      "Training:: Epoch 32, Iteration 120, Current loss 0.728680340908963 Accuracy 89.01908728887261\n",
      "Training:: Epoch 32, Iteration 130, Current loss 1.7467136079689136 Accuracy 82.11478923553227\n",
      "Training:: Epoch 32, Iteration 140, Current loss 1.3510979137140513 Accuracy 89.71752232953308\n",
      "Training:: Epoch 32, Iteration 150, Current loss 1.70100867635627 Accuracy 79.47589649284119\n",
      "Starting Training\n",
      "Training:: Epoch 33, Iteration 0, Current loss 2.4309134104899033 Accuracy 84.23584859345083\n",
      "Training:: Epoch 33, Iteration 10, Current loss 0.9713462214985573 Accuracy 90.00557628790803\n",
      "Training:: Epoch 33, Iteration 20, Current loss 1.2313797890160005 Accuracy 88.40466606424053\n",
      "Training:: Epoch 33, Iteration 30, Current loss 0.8489460151343308 Accuracy 85.09254627313656\n",
      "Training:: Epoch 33, Iteration 40, Current loss 1.3210577606058544 Accuracy 85.01790140457175\n",
      "Training:: Epoch 33, Iteration 50, Current loss 0.9523890360097315 Accuracy 90.97362422663628\n",
      "Training:: Epoch 33, Iteration 60, Current loss 0.8789801420515421 Accuracy 90.76809062516543\n",
      "Training:: Epoch 33, Iteration 70, Current loss 2.347335516502868 Accuracy 74.4605792107638\n",
      "Training:: Epoch 33, Iteration 80, Current loss 1.1916809319999309 Accuracy 86.32942077060474\n",
      "Training:: Epoch 33, Iteration 90, Current loss 0.7270340274699285 Accuracy 91.39277922443522\n",
      "Training:: Epoch 33, Iteration 100, Current loss 0.8836142438537643 Accuracy 88.59176410777835\n",
      "Training:: Epoch 33, Iteration 110, Current loss 0.671484339688348 Accuracy 90.1065114746898\n",
      "Training:: Epoch 33, Iteration 120, Current loss 0.8471419225678514 Accuracy 87.86201240453124\n",
      "Training:: Epoch 33, Iteration 130, Current loss 0.5072018841693089 Accuracy 90.01440831923824\n",
      "Training:: Epoch 33, Iteration 140, Current loss 0.7893144689310155 Accuracy 87.15533611849601\n",
      "Training:: Epoch 33, Iteration 150, Current loss 0.9773012721386118 Accuracy 83.60279997522146\n",
      "Starting Training\n",
      "Training:: Epoch 34, Iteration 0, Current loss 0.9426365356738005 Accuracy 87.96185935637664\n",
      "Training:: Epoch 34, Iteration 10, Current loss 1.0305891407746977 Accuracy 82.41065464261857\n",
      "Training:: Epoch 34, Iteration 20, Current loss 0.8129548682598251 Accuracy 89.69380403458213\n",
      "Training:: Epoch 34, Iteration 30, Current loss 0.5731195877053049 Accuracy 90.65934065934066\n",
      "Training:: Epoch 34, Iteration 40, Current loss 0.5930795961784705 Accuracy 89.92436520799568\n",
      "Training:: Epoch 34, Iteration 50, Current loss 0.6953037171375291 Accuracy 92.89225324419976\n",
      "Training:: Epoch 34, Iteration 60, Current loss 0.8668072307811661 Accuracy 85.25578890683899\n",
      "Training:: Epoch 34, Iteration 70, Current loss 0.763175965767793 Accuracy 84.35736677115987\n",
      "Training:: Epoch 34, Iteration 80, Current loss 0.830958899562986 Accuracy 89.03840952123343\n",
      "Training:: Epoch 34, Iteration 90, Current loss 0.6535333795423129 Accuracy 90.94683984356139\n",
      "Training:: Epoch 34, Iteration 100, Current loss 0.6304035459667343 Accuracy 91.17679680567879\n",
      "Training:: Epoch 34, Iteration 110, Current loss 0.5131604661455235 Accuracy 90.33000391696044\n",
      "Training:: Epoch 34, Iteration 120, Current loss 0.7717577481818981 Accuracy 89.11091608722069\n",
      "Training:: Epoch 34, Iteration 130, Current loss 0.6486912095450205 Accuracy 88.32025770249909\n",
      "Training:: Epoch 34, Iteration 140, Current loss 0.6018951588875924 Accuracy 88.62248696947134\n",
      "Training:: Epoch 34, Iteration 150, Current loss 0.8613077825480775 Accuracy 83.57820976491863\n",
      "Starting Training\n",
      "Training:: Epoch 35, Iteration 0, Current loss 0.6420630227083302 Accuracy 88.71545261273359\n",
      "Training:: Epoch 35, Iteration 10, Current loss 0.5718399942678802 Accuracy 83.85933273219116\n",
      "Training:: Epoch 35, Iteration 20, Current loss 0.6648649980099133 Accuracy 92.03813450141716\n",
      "Training:: Epoch 35, Iteration 30, Current loss 0.65704665449056 Accuracy 87.72589745686483\n",
      "Training:: Epoch 35, Iteration 40, Current loss 0.9784466392847964 Accuracy 89.7215329473394\n",
      "Training:: Epoch 35, Iteration 50, Current loss 0.8997667927509103 Accuracy 81.6952506596306\n",
      "Training:: Epoch 35, Iteration 60, Current loss 0.7430466051728915 Accuracy 84.8186889818689\n",
      "Training:: Epoch 35, Iteration 70, Current loss 1.0600110804163663 Accuracy 88.24511206485455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 35, Iteration 80, Current loss 0.7690584562697579 Accuracy 85.46600783779179\n",
      "Training:: Epoch 35, Iteration 90, Current loss 0.8066140539751923 Accuracy 88.57938718662953\n",
      "Training:: Epoch 35, Iteration 100, Current loss 0.523616942755202 Accuracy 87.419802897017\n",
      "Training:: Epoch 35, Iteration 110, Current loss 0.7822710170769791 Accuracy 83.6897458369851\n",
      "Training:: Epoch 35, Iteration 120, Current loss 0.6280725443669178 Accuracy 88.9962776725658\n",
      "Training:: Epoch 35, Iteration 130, Current loss 0.9864560823001924 Accuracy 85.34528202424882\n",
      "Training:: Epoch 35, Iteration 140, Current loss 0.8730031862086447 Accuracy 83.45832440539961\n",
      "Training:: Epoch 35, Iteration 150, Current loss 0.6944059660152636 Accuracy 89.4199535962877\n",
      "Calculating Expectation\n",
      "Epoch 35 iter 0\n",
      "Epoch 35 iter 10\n",
      "Epoch 35 iter 20\n",
      "Epoch 35 iter 30\n",
      "Epoch 35 iter 40\n",
      "Epoch 35 iter 50\n",
      "Epoch 35 iter 60\n",
      "Epoch 35 iter 70\n",
      "Epoch 35 iter 80\n",
      "Epoch 35 iter 90\n",
      "Epoch 35 iter 100\n",
      "Epoch 35 iter 110\n",
      "Epoch 35 iter 120\n",
      "Epoch 35 iter 130\n",
      "Epoch 35 iter 140\n",
      "Epoch 35 iter 150\n",
      "Train Boundary avergage error = 87.192\n",
      "Train From boundary avergage accuracy = 88.754\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 35, Probability Accuracy 67.97427186477192\n",
      "Starting Training\n",
      "Training:: Epoch 36, Iteration 0, Current loss 0.4886665709035145 Accuracy 89.84412662702877\n",
      "Training:: Epoch 36, Iteration 10, Current loss 0.796980793359374 Accuracy 84.35228220712668\n",
      "Training:: Epoch 36, Iteration 20, Current loss 0.5323253953963972 Accuracy 90.85117227319063\n",
      "Training:: Epoch 36, Iteration 30, Current loss 0.9532133382965224 Accuracy 82.47544869624112\n",
      "Training:: Epoch 36, Iteration 40, Current loss 0.4911449438945881 Accuracy 89.3274170948155\n",
      "Training:: Epoch 36, Iteration 50, Current loss 0.6250957305298049 Accuracy 92.2011146871811\n",
      "Training:: Epoch 36, Iteration 60, Current loss 0.5602580076901131 Accuracy 88.62176165803109\n",
      "Training:: Epoch 36, Iteration 70, Current loss 0.5715226011984813 Accuracy 89.37651109971426\n",
      "Training:: Epoch 36, Iteration 80, Current loss 0.7400140071186057 Accuracy 90.98149958365012\n",
      "Training:: Epoch 36, Iteration 90, Current loss 0.7354377574766497 Accuracy 87.89129945199309\n",
      "Training:: Epoch 36, Iteration 100, Current loss 0.8109583022412729 Accuracy 84.01754259831763\n",
      "Training:: Epoch 36, Iteration 110, Current loss 0.6722116669835785 Accuracy 90.10062358276645\n",
      "Training:: Epoch 36, Iteration 120, Current loss 1.2639552398781553 Accuracy 87.86536758193091\n",
      "Training:: Epoch 36, Iteration 130, Current loss 0.7941729038003325 Accuracy 87.03800492794744\n",
      "Training:: Epoch 36, Iteration 140, Current loss 0.6790892189221176 Accuracy 89.54550065942985\n",
      "Training:: Epoch 36, Iteration 150, Current loss 0.5638502991897097 Accuracy 89.94051867713537\n",
      "Starting Training\n",
      "Training:: Epoch 37, Iteration 0, Current loss 0.7558514124556696 Accuracy 85.76569678407351\n",
      "Training:: Epoch 37, Iteration 10, Current loss 0.6984498582419387 Accuracy 83.4553058024046\n",
      "Training:: Epoch 37, Iteration 20, Current loss 0.7388052752950747 Accuracy 86.83940105695831\n",
      "Training:: Epoch 37, Iteration 30, Current loss 0.42589306681198674 Accuracy 87.57758902319503\n",
      "Training:: Epoch 37, Iteration 40, Current loss 0.7716795294911061 Accuracy 84.7937804717354\n",
      "Training:: Epoch 37, Iteration 50, Current loss 0.5254043000950404 Accuracy 91.91578947368421\n",
      "Training:: Epoch 37, Iteration 60, Current loss 0.6822012133502895 Accuracy 90.12137559002024\n",
      "Training:: Epoch 37, Iteration 70, Current loss 0.49036536885962145 Accuracy 88.52375434530707\n",
      "Training:: Epoch 37, Iteration 80, Current loss 0.7271236697757386 Accuracy 85.4434947768281\n",
      "Training:: Epoch 37, Iteration 90, Current loss 0.6274595847322182 Accuracy 88.23454185050196\n",
      "Training:: Epoch 37, Iteration 100, Current loss 0.6318523366286221 Accuracy 88.9291632145816\n",
      "Training:: Epoch 37, Iteration 110, Current loss 0.46931926320986694 Accuracy 87.11865992887891\n",
      "Training:: Epoch 37, Iteration 120, Current loss 0.7091467392226957 Accuracy 88.39235917456776\n",
      "Training:: Epoch 37, Iteration 130, Current loss 1.4601840799346257 Accuracy 80.8385773881072\n",
      "Training:: Epoch 37, Iteration 140, Current loss 0.6372657207949957 Accuracy 88.26028390840328\n",
      "Training:: Epoch 37, Iteration 150, Current loss 1.09919755283522 Accuracy 86.43582772928889\n",
      "Starting Training\n",
      "Training:: Epoch 38, Iteration 0, Current loss 0.6396736745203666 Accuracy 90.6899789831418\n",
      "Training:: Epoch 38, Iteration 10, Current loss 0.6418904155417322 Accuracy 91.19954283339395\n",
      "Training:: Epoch 38, Iteration 20, Current loss 0.6089461712870763 Accuracy 88.10082063305978\n",
      "Training:: Epoch 38, Iteration 30, Current loss 0.7816173995066635 Accuracy 86.97164948453609\n",
      "Training:: Epoch 38, Iteration 40, Current loss 0.6542114645318543 Accuracy 89.34762539747666\n",
      "Training:: Epoch 38, Iteration 50, Current loss 0.6447796040910403 Accuracy 92.72981656130169\n",
      "Training:: Epoch 38, Iteration 60, Current loss 0.5772079085922684 Accuracy 92.3439114956169\n",
      "Training:: Epoch 38, Iteration 70, Current loss 0.6887961176425484 Accuracy 90.07280650475634\n",
      "Training:: Epoch 38, Iteration 80, Current loss 0.5609274705581624 Accuracy 88.30849268841395\n",
      "Training:: Epoch 38, Iteration 90, Current loss 0.5808891742744711 Accuracy 89.14289914730962\n",
      "Training:: Epoch 38, Iteration 100, Current loss 0.7508841952705751 Accuracy 91.5396658040193\n",
      "Training:: Epoch 38, Iteration 110, Current loss 0.5059985073195526 Accuracy 87.71708760203802\n",
      "Training:: Epoch 38, Iteration 120, Current loss 0.6942765989575527 Accuracy 88.02440884820747\n",
      "Training:: Epoch 38, Iteration 130, Current loss 0.642900972539999 Accuracy 93.65443798544283\n",
      "Training:: Epoch 38, Iteration 140, Current loss 0.5698390452533437 Accuracy 88.39899299176703\n",
      "Training:: Epoch 38, Iteration 150, Current loss 0.7489625248341879 Accuracy 86.76609848484848\n",
      "Starting Training\n",
      "Training:: Epoch 39, Iteration 0, Current loss 0.5027344349739865 Accuracy 86.01054481546574\n",
      "Training:: Epoch 39, Iteration 10, Current loss 0.7044609273765057 Accuracy 90.22056438533896\n",
      "Training:: Epoch 39, Iteration 20, Current loss 0.5053203409852116 Accuracy 89.66673239992112\n",
      "Training:: Epoch 39, Iteration 30, Current loss 0.41311856455131307 Accuracy 92.35161175211134\n",
      "Training:: Epoch 39, Iteration 40, Current loss 0.45763265825836325 Accuracy 92.62896424238923\n",
      "Training:: Epoch 39, Iteration 50, Current loss 0.9960214366489936 Accuracy 83.68376787216148\n",
      "Training:: Epoch 39, Iteration 60, Current loss 0.5136772811240571 Accuracy 84.18931956188638\n",
      "Training:: Epoch 39, Iteration 70, Current loss 0.46272825951926866 Accuracy 83.11599176389842\n",
      "Training:: Epoch 39, Iteration 80, Current loss 0.7177219953432286 Accuracy 90.29226955669569\n",
      "Training:: Epoch 39, Iteration 90, Current loss 0.6432256501779956 Accuracy 83.13167888368807\n",
      "Training:: Epoch 39, Iteration 100, Current loss 0.5409884387800368 Accuracy 88.28329577979417\n",
      "Training:: Epoch 39, Iteration 110, Current loss 0.5322015665940729 Accuracy 88.18244644091223\n",
      "Training:: Epoch 39, Iteration 120, Current loss 0.36168477919878395 Accuracy 92.02503681885125\n",
      "Training:: Epoch 39, Iteration 130, Current loss 0.49056258336852065 Accuracy 89.92813248619936\n",
      "Training:: Epoch 39, Iteration 140, Current loss 0.4914072339026444 Accuracy 89.62249081518556\n",
      "Training:: Epoch 39, Iteration 150, Current loss 0.46157627628108366 Accuracy 88.13322464190055\n",
      "Starting Training\n",
      "Training:: Epoch 40, Iteration 0, Current loss 0.38859602549851835 Accuracy 88.50592320261438\n",
      "Training:: Epoch 40, Iteration 10, Current loss 0.6093439141113872 Accuracy 90.81181191480604\n",
      "Training:: Epoch 40, Iteration 20, Current loss 0.404134830961502 Accuracy 91.98381677295481\n",
      "Training:: Epoch 40, Iteration 30, Current loss 0.5468464166786673 Accuracy 90.68978514888805\n",
      "Training:: Epoch 40, Iteration 40, Current loss 0.4346632184201963 Accuracy 88.22613300109018\n",
      "Training:: Epoch 40, Iteration 50, Current loss 0.7808695935018419 Accuracy 86.54933559513712\n",
      "Training:: Epoch 40, Iteration 60, Current loss 0.5056534998713494 Accuracy 85.68312930913184\n",
      "Training:: Epoch 40, Iteration 70, Current loss 0.3431720164037075 Accuracy 92.46617677357324\n",
      "Training:: Epoch 40, Iteration 80, Current loss 0.5485972624883418 Accuracy 89.62764560684838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 40, Iteration 90, Current loss 0.45145674230340094 Accuracy 87.57180410865544\n",
      "Training:: Epoch 40, Iteration 100, Current loss 0.5459233641583536 Accuracy 90.53144432335407\n",
      "Training:: Epoch 40, Iteration 110, Current loss 0.5033786748390967 Accuracy 87.6417004048583\n",
      "Training:: Epoch 40, Iteration 120, Current loss 0.6794927866224445 Accuracy 87.14568599717114\n",
      "Training:: Epoch 40, Iteration 130, Current loss 0.7098937502665462 Accuracy 86.96827337666517\n",
      "Training:: Epoch 40, Iteration 140, Current loss 0.33839786410726574 Accuracy 83.66160800774944\n",
      "Training:: Epoch 40, Iteration 150, Current loss 0.5793675587613307 Accuracy 83.89290267743307\n",
      "Calculating Expectation\n",
      "Epoch 40 iter 0\n",
      "Epoch 40 iter 10\n",
      "Epoch 40 iter 20\n",
      "Epoch 40 iter 30\n",
      "Epoch 40 iter 40\n",
      "Epoch 40 iter 50\n",
      "Epoch 40 iter 60\n",
      "Epoch 40 iter 70\n",
      "Epoch 40 iter 80\n",
      "Epoch 40 iter 90\n",
      "Epoch 40 iter 100\n",
      "Epoch 40 iter 110\n",
      "Epoch 40 iter 120\n",
      "Epoch 40 iter 130\n",
      "Epoch 40 iter 140\n",
      "Epoch 40 iter 150\n",
      "Train Boundary avergage error = 86.060\n",
      "Train From boundary avergage accuracy = 88.952\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 40, Probability Accuracy 68.06603969010233\n",
      "Starting Training\n",
      "Training:: Epoch 41, Iteration 0, Current loss 0.4124937283897542 Accuracy 87.49056318888721\n",
      "Training:: Epoch 41, Iteration 10, Current loss 0.41457176807709617 Accuracy 90.78896974339334\n",
      "Training:: Epoch 41, Iteration 20, Current loss 0.3671016549859208 Accuracy 90.99314625630416\n",
      "Training:: Epoch 41, Iteration 30, Current loss 0.4036625530338144 Accuracy 89.90438069824327\n",
      "Training:: Epoch 41, Iteration 40, Current loss 0.3375247608828945 Accuracy 87.78051450465243\n",
      "Training:: Epoch 41, Iteration 50, Current loss 0.6956269342562316 Accuracy 87.16900657543984\n",
      "Training:: Epoch 41, Iteration 60, Current loss 0.4732978057576302 Accuracy 92.07107486163706\n",
      "Training:: Epoch 41, Iteration 70, Current loss 0.5224775999807395 Accuracy 90.99390025116612\n",
      "Training:: Epoch 41, Iteration 80, Current loss 0.5080848273176689 Accuracy 92.56989856341075\n",
      "Training:: Epoch 41, Iteration 90, Current loss 0.5410082956054483 Accuracy 88.71473354231975\n",
      "Training:: Epoch 41, Iteration 100, Current loss 1.0405861111317898 Accuracy 79.86052303860524\n",
      "Training:: Epoch 41, Iteration 110, Current loss 0.4799740886312389 Accuracy 89.21701087306182\n",
      "Training:: Epoch 41, Iteration 120, Current loss 0.3318270968749518 Accuracy 91.46341463414635\n",
      "Training:: Epoch 41, Iteration 130, Current loss 0.4202866595266662 Accuracy 86.61121983039791\n",
      "Training:: Epoch 41, Iteration 140, Current loss 0.5702520055226337 Accuracy 84.62872559095581\n",
      "Training:: Epoch 41, Iteration 150, Current loss 0.42868995979317676 Accuracy 91.67240455971233\n",
      "Starting Training\n",
      "Training:: Epoch 42, Iteration 0, Current loss 0.45050617226801415 Accuracy 92.4192823672893\n",
      "Training:: Epoch 42, Iteration 10, Current loss 0.7570781979474541 Accuracy 87.93460741422979\n",
      "Training:: Epoch 42, Iteration 20, Current loss 1.877164788994901 Accuracy 81.47138964577657\n",
      "Training:: Epoch 42, Iteration 30, Current loss 1.2102666876122756 Accuracy 82.46243169398907\n",
      "Training:: Epoch 42, Iteration 40, Current loss 0.9732590487308306 Accuracy 77.65671962215544\n",
      "Training:: Epoch 42, Iteration 50, Current loss 0.762538509451613 Accuracy 89.93921349708472\n",
      "Training:: Epoch 42, Iteration 60, Current loss 0.48348249792785164 Accuracy 93.76122240608386\n",
      "Training:: Epoch 42, Iteration 70, Current loss 0.8276940506483367 Accuracy 86.62196418349824\n",
      "Training:: Epoch 42, Iteration 80, Current loss 0.43647811922579394 Accuracy 91.88709624420859\n",
      "Training:: Epoch 42, Iteration 90, Current loss 0.4926521337506289 Accuracy 90.23203592814372\n",
      "Training:: Epoch 42, Iteration 100, Current loss 0.5111473642462423 Accuracy 92.43578159287466\n",
      "Training:: Epoch 42, Iteration 110, Current loss 0.4966991270789955 Accuracy 87.6068376068376\n",
      "Training:: Epoch 42, Iteration 120, Current loss 0.8281373841833368 Accuracy 87.32167064747273\n",
      "Training:: Epoch 42, Iteration 130, Current loss 0.40715269628278006 Accuracy 93.12848574134483\n",
      "Training:: Epoch 42, Iteration 140, Current loss 0.4720370267717242 Accuracy 90.55808578614642\n",
      "Training:: Epoch 42, Iteration 150, Current loss 0.5862398182620959 Accuracy 89.33108487914559\n",
      "Starting Training\n",
      "Training:: Epoch 43, Iteration 0, Current loss 0.6270844349931015 Accuracy 87.55585344057194\n",
      "Training:: Epoch 43, Iteration 10, Current loss 0.38353907455128633 Accuracy 87.94465355457774\n",
      "Training:: Epoch 43, Iteration 20, Current loss 0.43256146995201816 Accuracy 85.70832898988846\n",
      "Training:: Epoch 43, Iteration 30, Current loss 0.4413521632983611 Accuracy 90.87446519878952\n",
      "Training:: Epoch 43, Iteration 40, Current loss 0.4731743558068241 Accuracy 88.47540983606558\n",
      "Training:: Epoch 43, Iteration 50, Current loss 0.4659646794645903 Accuracy 88.41366102776891\n",
      "Training:: Epoch 43, Iteration 60, Current loss 0.3478365137347029 Accuracy 91.62371134020619\n",
      "Training:: Epoch 43, Iteration 70, Current loss 0.5100886150746725 Accuracy 89.74749573004662\n",
      "Training:: Epoch 43, Iteration 80, Current loss 0.513503442041786 Accuracy 91.13553852359823\n",
      "Training:: Epoch 43, Iteration 90, Current loss 0.4490198258860199 Accuracy 90.80099448708248\n",
      "Training:: Epoch 43, Iteration 100, Current loss 0.8023423261483822 Accuracy 88.75078555966762\n",
      "Training:: Epoch 43, Iteration 110, Current loss 0.6863105726837112 Accuracy 83.93637327677625\n",
      "Training:: Epoch 43, Iteration 120, Current loss 0.6409420921052243 Accuracy 91.2015523668488\n",
      "Training:: Epoch 43, Iteration 130, Current loss 0.7245529696142992 Accuracy 88.20234761365667\n",
      "Training:: Epoch 43, Iteration 140, Current loss 0.45861243078874436 Accuracy 87.48187092095722\n",
      "Training:: Epoch 43, Iteration 150, Current loss 0.3996513841638018 Accuracy 86.26579902390189\n",
      "Starting Training\n",
      "Training:: Epoch 44, Iteration 0, Current loss 0.6076428482159664 Accuracy 92.00791465932554\n",
      "Training:: Epoch 44, Iteration 10, Current loss 0.5048880773056892 Accuracy 90.51249234878415\n",
      "Training:: Epoch 44, Iteration 20, Current loss 0.42951372976499597 Accuracy 88.00017154865549\n",
      "Training:: Epoch 44, Iteration 30, Current loss 0.5320106833750271 Accuracy 90.46800731261426\n",
      "Training:: Epoch 44, Iteration 40, Current loss 0.38108675305860373 Accuracy 85.24266936299293\n",
      "Training:: Epoch 44, Iteration 50, Current loss 0.4652665414975815 Accuracy 90.31554302133773\n",
      "Training:: Epoch 44, Iteration 60, Current loss 0.43575696958902127 Accuracy 93.55947234231238\n",
      "Training:: Epoch 44, Iteration 70, Current loss 0.7956847069813126 Accuracy 85.75685743311887\n",
      "Training:: Epoch 44, Iteration 80, Current loss 0.8445419612786889 Accuracy 90.86810507429728\n",
      "Training:: Epoch 44, Iteration 90, Current loss 1.1163246879427544 Accuracy 87.85557986870897\n",
      "Training:: Epoch 44, Iteration 100, Current loss 1.3143046973036467 Accuracy 82.09932690558486\n",
      "Training:: Epoch 44, Iteration 110, Current loss 0.7207454079496711 Accuracy 88.70188991585046\n",
      "Training:: Epoch 44, Iteration 120, Current loss 0.5867992618862475 Accuracy 91.37104909213181\n",
      "Training:: Epoch 44, Iteration 130, Current loss 2.542900906048425 Accuracy 75.95328549317574\n",
      "Training:: Epoch 44, Iteration 140, Current loss 1.3557694961362596 Accuracy 84.21651611067644\n",
      "Training:: Epoch 44, Iteration 150, Current loss 1.0222963840638488 Accuracy 90.6929091399299\n",
      "Starting Training\n",
      "Training:: Epoch 45, Iteration 0, Current loss 1.046560711265636 Accuracy 90.1415614139188\n",
      "Training:: Epoch 45, Iteration 10, Current loss 1.1960993149009116 Accuracy 85.55336746750689\n",
      "Training:: Epoch 45, Iteration 20, Current loss 1.6084014104123896 Accuracy 78.5576126001658\n",
      "Training:: Epoch 45, Iteration 30, Current loss 2.791885909317267 Accuracy 73.8838356815885\n",
      "Training:: Epoch 45, Iteration 40, Current loss 1.1167542346982013 Accuracy 85.22910060204973\n",
      "Training:: Epoch 45, Iteration 50, Current loss 3.684308432793875 Accuracy 69.38574938574939\n",
      "Training:: Epoch 45, Iteration 60, Current loss 2.293073655833675 Accuracy 82.19753086419753\n",
      "Training:: Epoch 45, Iteration 70, Current loss 1.4786625901661274 Accuracy 84.86851879364136\n",
      "Training:: Epoch 45, Iteration 80, Current loss 4.608643860331427 Accuracy 75.43892243381329\n",
      "Training:: Epoch 45, Iteration 90, Current loss 1.6920677693982187 Accuracy 86.8416680511713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 45, Iteration 100, Current loss 2.383732011042988 Accuracy 77.76865671641791\n",
      "Training:: Epoch 45, Iteration 110, Current loss 4.3915302026878 Accuracy 67.18991819588769\n",
      "Training:: Epoch 45, Iteration 120, Current loss 2.539319524138533 Accuracy 74.8145780051151\n",
      "Training:: Epoch 45, Iteration 130, Current loss 0.912827850895422 Accuracy 88.75427969449565\n",
      "Training:: Epoch 45, Iteration 140, Current loss 1.5961718944810745 Accuracy 85.89014706573322\n",
      "Training:: Epoch 45, Iteration 150, Current loss 2.3707689129501754 Accuracy 83.81936754029778\n",
      "Calculating Expectation\n",
      "Epoch 45 iter 0\n",
      "Epoch 45 iter 10\n",
      "Epoch 45 iter 20\n",
      "Epoch 45 iter 30\n",
      "Epoch 45 iter 40\n",
      "Epoch 45 iter 50\n",
      "Epoch 45 iter 60\n",
      "Epoch 45 iter 70\n",
      "Epoch 45 iter 80\n",
      "Epoch 45 iter 90\n",
      "Epoch 45 iter 100\n",
      "Epoch 45 iter 110\n",
      "Epoch 45 iter 120\n",
      "Epoch 45 iter 130\n",
      "Epoch 45 iter 140\n",
      "Epoch 45 iter 150\n",
      "Train Boundary avergage error = 107.241\n",
      "Train From boundary avergage accuracy = 86.719\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 45, Probability Accuracy 56.77300410158678\n",
      "Starting Training\n",
      "Training:: Epoch 46, Iteration 0, Current loss 1.602307155908747 Accuracy 77.38048202291584\n",
      "Training:: Epoch 46, Iteration 10, Current loss 5.942206313348467 Accuracy 80.47616241381343\n",
      "Training:: Epoch 46, Iteration 20, Current loss 4.303391783166806 Accuracy 89.1076827661059\n",
      "Training:: Epoch 46, Iteration 30, Current loss 1.2044840056198969 Accuracy 88.61326768920027\n",
      "Training:: Epoch 46, Iteration 40, Current loss 1.2828292608658238 Accuracy 84.4731977818854\n",
      "Training:: Epoch 46, Iteration 50, Current loss 1.3739027351370072 Accuracy 89.69363474122547\n",
      "Training:: Epoch 46, Iteration 60, Current loss 1.8010577236327772 Accuracy 78.66538500455327\n",
      "Training:: Epoch 46, Iteration 70, Current loss 1.3883024530460943 Accuracy 83.6733263231686\n",
      "Training:: Epoch 46, Iteration 80, Current loss 2.4893562700723866 Accuracy 79.6994768219978\n",
      "Training:: Epoch 46, Iteration 90, Current loss 1.6510297126903337 Accuracy 84.85745218332733\n",
      "Training:: Epoch 46, Iteration 100, Current loss 1.1421314345642428 Accuracy 85.64269843521014\n",
      "Training:: Epoch 46, Iteration 110, Current loss 1.1043431276046027 Accuracy 90.6679764243615\n",
      "Training:: Epoch 46, Iteration 120, Current loss 1.0968286724380274 Accuracy 88.38191803971272\n",
      "Training:: Epoch 46, Iteration 130, Current loss 1.2786368232030998 Accuracy 91.86422942349824\n",
      "Training:: Epoch 46, Iteration 140, Current loss 0.8185745546188469 Accuracy 85.04358569565515\n",
      "Training:: Epoch 46, Iteration 150, Current loss 2.5180094327186806 Accuracy 81.77929854576561\n",
      "Starting Training\n",
      "Training:: Epoch 47, Iteration 0, Current loss 0.869432002208996 Accuracy 88.72016591092833\n",
      "Training:: Epoch 47, Iteration 10, Current loss 0.8826902387114728 Accuracy 89.3958543983822\n",
      "Training:: Epoch 47, Iteration 20, Current loss 2.468677008688887 Accuracy 81.1932805560919\n",
      "Training:: Epoch 47, Iteration 30, Current loss 1.0066942698495898 Accuracy 87.06038951940592\n",
      "Training:: Epoch 47, Iteration 40, Current loss 0.6483885743039912 Accuracy 86.41856742697078\n",
      "Training:: Epoch 47, Iteration 50, Current loss 0.898962222155458 Accuracy 84.8993288590604\n",
      "Training:: Epoch 47, Iteration 60, Current loss 0.9711502180187501 Accuracy 89.74604914588471\n",
      "Training:: Epoch 47, Iteration 70, Current loss 3.5046563129803694 Accuracy 90.55486635840758\n",
      "Training:: Epoch 47, Iteration 80, Current loss 0.8736799783781285 Accuracy 86.71205446535843\n",
      "Training:: Epoch 47, Iteration 90, Current loss 1.1446787250504662 Accuracy 87.96359783082964\n",
      "Training:: Epoch 47, Iteration 100, Current loss 0.6436080387390425 Accuracy 86.78269436006896\n",
      "Training:: Epoch 47, Iteration 110, Current loss 0.6818134547651519 Accuracy 85.16524599970091\n",
      "Training:: Epoch 47, Iteration 120, Current loss 0.8477571917789068 Accuracy 85.15141087405368\n",
      "Training:: Epoch 47, Iteration 130, Current loss 0.8678789149401005 Accuracy 87.15633976200246\n",
      "Training:: Epoch 47, Iteration 140, Current loss 0.5801022338544779 Accuracy 92.44374009508716\n",
      "Training:: Epoch 47, Iteration 150, Current loss 0.8030331536349141 Accuracy 84.83452858740706\n",
      "Starting Training\n",
      "Training:: Epoch 48, Iteration 0, Current loss 0.6948854527573658 Accuracy 84.6694622594968\n",
      "Training:: Epoch 48, Iteration 10, Current loss 2.234554108359988 Accuracy 86.36783509164276\n",
      "Training:: Epoch 48, Iteration 20, Current loss 0.7907685141883694 Accuracy 87.10370768404084\n",
      "Training:: Epoch 48, Iteration 30, Current loss 0.7451089263703166 Accuracy 84.22180551834985\n",
      "Training:: Epoch 48, Iteration 40, Current loss 0.8490167515176541 Accuracy 85.83891144518819\n",
      "Training:: Epoch 48, Iteration 50, Current loss 0.6320593132057182 Accuracy 90.64748201438849\n",
      "Training:: Epoch 48, Iteration 60, Current loss 0.7864952607889717 Accuracy 87.70917484131564\n",
      "Training:: Epoch 48, Iteration 70, Current loss 0.9541256311948955 Accuracy 87.68835312887786\n",
      "Training:: Epoch 48, Iteration 80, Current loss 1.5000733087257911 Accuracy 82.69024651661307\n",
      "Training:: Epoch 48, Iteration 90, Current loss 1.268950333689265 Accuracy 85.46270522070101\n",
      "Training:: Epoch 48, Iteration 100, Current loss 0.808204546465976 Accuracy 87.58217677136597\n",
      "Training:: Epoch 48, Iteration 110, Current loss 1.600565851307547 Accuracy 84.44115638515821\n",
      "Training:: Epoch 48, Iteration 120, Current loss 1.5335516691087379 Accuracy 68.38362217772561\n",
      "Training:: Epoch 48, Iteration 130, Current loss 0.7281668591872192 Accuracy 91.26066923483647\n",
      "Training:: Epoch 48, Iteration 140, Current loss 0.7407941299773806 Accuracy 87.22305017386985\n",
      "Training:: Epoch 48, Iteration 150, Current loss 1.7713606161704794 Accuracy 83.49176596599277\n",
      "Starting Training\n",
      "Training:: Epoch 49, Iteration 0, Current loss 5.244350675550637 Accuracy 70.90226951227012\n",
      "Training:: Epoch 49, Iteration 10, Current loss 2.129352791655214 Accuracy 80.42952770546671\n",
      "Training:: Epoch 49, Iteration 20, Current loss 1.1728795825518763 Accuracy 86.52879301123195\n",
      "Training:: Epoch 49, Iteration 30, Current loss 0.7982002969879939 Accuracy 91.24796084828711\n",
      "Training:: Epoch 49, Iteration 40, Current loss 1.0752443219612349 Accuracy 82.3505995919789\n",
      "Training:: Epoch 49, Iteration 50, Current loss 1.1515788241321145 Accuracy 81.31794837590876\n",
      "Training:: Epoch 49, Iteration 60, Current loss 1.2237755384085645 Accuracy 89.09589740317745\n",
      "Training:: Epoch 49, Iteration 70, Current loss 0.8314450043497377 Accuracy 91.74418604651163\n",
      "Training:: Epoch 49, Iteration 80, Current loss 0.8828532635900019 Accuracy 88.02884972860436\n",
      "Training:: Epoch 49, Iteration 90, Current loss 1.176567018212567 Accuracy 84.4816218889072\n",
      "Training:: Epoch 49, Iteration 100, Current loss 0.7385599356522558 Accuracy 92.11498242335247\n",
      "Training:: Epoch 49, Iteration 110, Current loss 0.7739601904701656 Accuracy 86.71199011124845\n",
      "Training:: Epoch 49, Iteration 120, Current loss 1.5414835362356958 Accuracy 87.26247987117553\n",
      "Training:: Epoch 49, Iteration 130, Current loss 1.5385016723576808 Accuracy 84.17457305502846\n",
      "Training:: Epoch 49, Iteration 140, Current loss 2.698975908338999 Accuracy 84.29757785467127\n",
      "Training:: Epoch 49, Iteration 150, Current loss 0.9083302030422584 Accuracy 88.32476586155904\n",
      "Starting Training\n",
      "Training:: Epoch 50, Iteration 0, Current loss 1.3653055356053279 Accuracy 77.24633674315731\n",
      "Training:: Epoch 50, Iteration 10, Current loss 0.7482554811302904 Accuracy 84.1376924407542\n",
      "Training:: Epoch 50, Iteration 20, Current loss 1.5903055919887024 Accuracy 85.77370407455903\n",
      "Training:: Epoch 50, Iteration 30, Current loss 0.620637397121724 Accuracy 90.6468124709167\n",
      "Training:: Epoch 50, Iteration 40, Current loss 0.7592765405407966 Accuracy 82.44178197772528\n",
      "Training:: Epoch 50, Iteration 50, Current loss 1.1314966938750282 Accuracy 80.92983618975475\n",
      "Training:: Epoch 50, Iteration 60, Current loss 0.6727770174584349 Accuracy 88.87390788480207\n",
      "Training:: Epoch 50, Iteration 70, Current loss 0.5787945114460505 Accuracy 87.04057547487918\n",
      "Training:: Epoch 50, Iteration 80, Current loss 0.945380774899298 Accuracy 76.49000660224476\n",
      "Training:: Epoch 50, Iteration 90, Current loss 0.5624170441660945 Accuracy 89.09330792347724\n",
      "Training:: Epoch 50, Iteration 100, Current loss 1.192877536614696 Accuracy 86.28010405303348\n",
      "Training:: Epoch 50, Iteration 110, Current loss 0.5439263322603609 Accuracy 88.23397327944313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 50, Iteration 120, Current loss 0.5676703608273411 Accuracy 85.3167997282147\n",
      "Training:: Epoch 50, Iteration 130, Current loss 0.9161217586491471 Accuracy 83.50650833523636\n",
      "Training:: Epoch 50, Iteration 140, Current loss 0.5953239997056018 Accuracy 91.88800060622134\n",
      "Training:: Epoch 50, Iteration 150, Current loss 1.1427137101611413 Accuracy 90.21669853409816\n",
      "Calculating Expectation\n",
      "Epoch 50 iter 0\n",
      "Epoch 50 iter 10\n",
      "Epoch 50 iter 20\n",
      "Epoch 50 iter 30\n",
      "Epoch 50 iter 40\n",
      "Epoch 50 iter 50\n",
      "Epoch 50 iter 60\n",
      "Epoch 50 iter 70\n",
      "Epoch 50 iter 80\n",
      "Epoch 50 iter 90\n",
      "Epoch 50 iter 100\n",
      "Epoch 50 iter 110\n",
      "Epoch 50 iter 120\n",
      "Epoch 50 iter 130\n",
      "Epoch 50 iter 140\n",
      "Epoch 50 iter 150\n",
      "Train Boundary avergage error = 90.900\n",
      "Train From boundary avergage accuracy = 87.716\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 50, Probability Accuracy 66.27242407921449\n",
      "Starting Training\n",
      "Training:: Epoch 51, Iteration 0, Current loss 0.777753574328463 Accuracy 86.32530939752482\n",
      "Training:: Epoch 51, Iteration 10, Current loss 0.5596186660844582 Accuracy 89.90606004789096\n",
      "Training:: Epoch 51, Iteration 20, Current loss 0.3504532520443373 Accuracy 90.96134340132987\n",
      "Training:: Epoch 51, Iteration 30, Current loss 0.5211917631862706 Accuracy 89.53250139690817\n",
      "Training:: Epoch 51, Iteration 40, Current loss 0.5052237292030564 Accuracy 87.84839994101165\n",
      "Training:: Epoch 51, Iteration 50, Current loss 0.45988533206730003 Accuracy 88.81909547738694\n",
      "Training:: Epoch 51, Iteration 60, Current loss 0.5995980445145409 Accuracy 90.85331846068043\n",
      "Training:: Epoch 51, Iteration 70, Current loss 0.4510166097801174 Accuracy 86.60107010066201\n",
      "Training:: Epoch 51, Iteration 80, Current loss 0.4036280959619703 Accuracy 89.06691800188501\n",
      "Training:: Epoch 51, Iteration 90, Current loss 0.4561544010498266 Accuracy 85.06115130947045\n",
      "Training:: Epoch 51, Iteration 100, Current loss 1.031152395800565 Accuracy 82.07578435704816\n",
      "Training:: Epoch 51, Iteration 110, Current loss 0.5726087359169508 Accuracy 86.78363787375416\n",
      "Training:: Epoch 51, Iteration 120, Current loss 0.7824968882723143 Accuracy 87.50455152324311\n",
      "Training:: Epoch 51, Iteration 130, Current loss 0.4325721775143347 Accuracy 87.05317324185249\n",
      "Training:: Epoch 51, Iteration 140, Current loss 0.6604226791880754 Accuracy 82.54181888098442\n",
      "Training:: Epoch 51, Iteration 150, Current loss 0.6239876911655817 Accuracy 88.79242630947951\n",
      "Starting Training\n",
      "Training:: Epoch 52, Iteration 0, Current loss 0.6507705470148739 Accuracy 90.17503696284638\n",
      "Training:: Epoch 52, Iteration 10, Current loss 2.1418715607248977 Accuracy 83.8433540037746\n",
      "Training:: Epoch 52, Iteration 20, Current loss 2.237680709764277 Accuracy 73.57002831627096\n",
      "Training:: Epoch 52, Iteration 30, Current loss 1.2198514158314047 Accuracy 86.81764865108725\n",
      "Training:: Epoch 52, Iteration 40, Current loss 0.7703896773334996 Accuracy 89.6157184565612\n",
      "Training:: Epoch 52, Iteration 50, Current loss 0.7536315482476836 Accuracy 89.10724526859109\n",
      "Training:: Epoch 52, Iteration 60, Current loss 0.836282810789646 Accuracy 88.39611178614824\n",
      "Training:: Epoch 52, Iteration 70, Current loss 0.7038371639849315 Accuracy 88.33056754065716\n",
      "Training:: Epoch 52, Iteration 80, Current loss 0.5575787625881374 Accuracy 83.80430198228595\n",
      "Training:: Epoch 52, Iteration 90, Current loss 0.45532034900950685 Accuracy 90.25937525094355\n",
      "Training:: Epoch 52, Iteration 100, Current loss 3.0255101385637917 Accuracy 75.88265084647664\n",
      "Training:: Epoch 52, Iteration 110, Current loss 0.8796596793961428 Accuracy 86.62625355485706\n",
      "Training:: Epoch 52, Iteration 120, Current loss 2.114199620320829 Accuracy 75.5676422343089\n",
      "Training:: Epoch 52, Iteration 130, Current loss 1.4309115367742806 Accuracy 88.14512726761356\n",
      "Training:: Epoch 52, Iteration 140, Current loss 2.7701049638431448 Accuracy 70.47504025764896\n",
      "Training:: Epoch 52, Iteration 150, Current loss 0.8742012951948055 Accuracy 80.95423311292623\n",
      "Starting Training\n",
      "Training:: Epoch 53, Iteration 0, Current loss 1.3055606429072972 Accuracy 86.9195704241675\n",
      "Training:: Epoch 53, Iteration 10, Current loss 1.7216022591150755 Accuracy 85.28121030142049\n",
      "Training:: Epoch 53, Iteration 20, Current loss 1.657735899457271 Accuracy 81.96711290421175\n",
      "Training:: Epoch 53, Iteration 30, Current loss 0.7381032351598109 Accuracy 89.0448665015139\n",
      "Training:: Epoch 53, Iteration 40, Current loss 2.009292253548831 Accuracy 83.49231912784936\n",
      "Training:: Epoch 53, Iteration 50, Current loss 1.751264881726026 Accuracy 84.77404098791382\n",
      "Training:: Epoch 53, Iteration 60, Current loss 1.3745709300073412 Accuracy 78.52322350138944\n",
      "Training:: Epoch 53, Iteration 70, Current loss 1.2431312242586796 Accuracy 80.68588469184891\n",
      "Training:: Epoch 53, Iteration 80, Current loss 0.9511899462115783 Accuracy 88.60121049092132\n",
      "Training:: Epoch 53, Iteration 90, Current loss 1.2946552779645746 Accuracy 81.8542389687655\n",
      "Training:: Epoch 53, Iteration 100, Current loss 1.2970572137587146 Accuracy 81.17579471466871\n",
      "Training:: Epoch 53, Iteration 110, Current loss 0.7868652021263823 Accuracy 89.24297431760118\n",
      "Training:: Epoch 53, Iteration 120, Current loss 0.6373131913503449 Accuracy 86.24660689314798\n",
      "Training:: Epoch 53, Iteration 130, Current loss 0.5853543166570756 Accuracy 90.93280769899704\n",
      "Training:: Epoch 53, Iteration 140, Current loss 1.144998569096432 Accuracy 86.52112313240598\n",
      "Training:: Epoch 53, Iteration 150, Current loss 0.6757011356564211 Accuracy 90.39232781168265\n",
      "Starting Training\n",
      "Training:: Epoch 54, Iteration 0, Current loss 0.5161277747612667 Accuracy 81.7470664928292\n",
      "Training:: Epoch 54, Iteration 10, Current loss 0.8188814084456928 Accuracy 77.55227552275522\n",
      "Training:: Epoch 54, Iteration 20, Current loss 0.523734344741669 Accuracy 87.48430709802028\n",
      "Training:: Epoch 54, Iteration 30, Current loss 0.6048949109720428 Accuracy 89.22442913119849\n",
      "Training:: Epoch 54, Iteration 40, Current loss 0.4562584041236238 Accuracy 85.74797104628207\n",
      "Training:: Epoch 54, Iteration 50, Current loss 0.8197049154629255 Accuracy 84.31946584488958\n",
      "Training:: Epoch 54, Iteration 60, Current loss 0.5951117261971135 Accuracy 89.61335130092256\n",
      "Training:: Epoch 54, Iteration 70, Current loss 0.4355822173136423 Accuracy 91.25379170879677\n",
      "Training:: Epoch 54, Iteration 80, Current loss 0.5311185236963728 Accuracy 86.35708566853482\n",
      "Training:: Epoch 54, Iteration 90, Current loss 0.5289847309725079 Accuracy 88.55503343574914\n",
      "Training:: Epoch 54, Iteration 100, Current loss 0.4540313781855284 Accuracy 88.42109690444146\n",
      "Training:: Epoch 54, Iteration 110, Current loss 0.45680516740371524 Accuracy 89.02991840435176\n",
      "Training:: Epoch 54, Iteration 120, Current loss 1.4933291317330728 Accuracy 80.56493068175918\n",
      "Training:: Epoch 54, Iteration 130, Current loss 0.5267761671220578 Accuracy 89.68771910900168\n",
      "Training:: Epoch 54, Iteration 140, Current loss 0.6118457734736957 Accuracy 90.18287496455912\n",
      "Training:: Epoch 54, Iteration 150, Current loss 0.7329040421037772 Accuracy 85.5650720701901\n",
      "Starting Training\n",
      "Training:: Epoch 55, Iteration 0, Current loss 0.4215103769960965 Accuracy 86.77817180966495\n",
      "Training:: Epoch 55, Iteration 10, Current loss 0.4529967959053622 Accuracy 88.41262880947161\n",
      "Training:: Epoch 55, Iteration 20, Current loss 0.4517719619297874 Accuracy 89.45303826511731\n",
      "Training:: Epoch 55, Iteration 30, Current loss 0.36291583998747123 Accuracy 88.95394223263075\n",
      "Training:: Epoch 55, Iteration 40, Current loss 0.5031905349129444 Accuracy 84.24571140262361\n",
      "Training:: Epoch 55, Iteration 50, Current loss 0.3032283273836334 Accuracy 90.78768257238512\n",
      "Training:: Epoch 55, Iteration 60, Current loss 0.25946929939332275 Accuracy 93.40564332311561\n",
      "Training:: Epoch 55, Iteration 70, Current loss 0.3903289269877692 Accuracy 90.43056087900857\n",
      "Training:: Epoch 55, Iteration 80, Current loss 0.3059707450334239 Accuracy 91.1408723053785\n",
      "Training:: Epoch 55, Iteration 90, Current loss 0.4777456118616257 Accuracy 90.09092393967441\n",
      "Training:: Epoch 55, Iteration 100, Current loss 0.38438778511657135 Accuracy 86.89486552567237\n",
      "Training:: Epoch 55, Iteration 110, Current loss 0.36921503855533055 Accuracy 88.6181010784521\n",
      "Training:: Epoch 55, Iteration 120, Current loss 0.3324231692175428 Accuracy 91.482171483038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 55, Iteration 130, Current loss 0.5044805919403474 Accuracy 86.83664649956785\n",
      "Training:: Epoch 55, Iteration 140, Current loss 0.48355606762209646 Accuracy 86.63170982215254\n",
      "Training:: Epoch 55, Iteration 150, Current loss 0.4747769260008363 Accuracy 85.07796446271001\n",
      "Calculating Expectation\n",
      "Epoch 55 iter 0\n",
      "Epoch 55 iter 10\n",
      "Epoch 55 iter 20\n",
      "Epoch 55 iter 30\n",
      "Epoch 55 iter 40\n",
      "Epoch 55 iter 50\n",
      "Epoch 55 iter 60\n",
      "Epoch 55 iter 70\n",
      "Epoch 55 iter 80\n",
      "Epoch 55 iter 90\n",
      "Epoch 55 iter 100\n",
      "Epoch 55 iter 110\n",
      "Epoch 55 iter 120\n",
      "Epoch 55 iter 130\n",
      "Epoch 55 iter 140\n",
      "Epoch 55 iter 150\n",
      "Train Boundary avergage error = 89.283\n",
      "Train From boundary avergage accuracy = 87.981\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 55, Probability Accuracy 66.99289472593942\n",
      "Starting Training\n",
      "Training:: Epoch 56, Iteration 0, Current loss 0.2871670546486662 Accuracy 91.72409040793826\n",
      "Training:: Epoch 56, Iteration 10, Current loss 0.3581049207529407 Accuracy 88.57999294698483\n",
      "Training:: Epoch 56, Iteration 20, Current loss 0.35329276940850113 Accuracy 85.82818417380905\n",
      "Training:: Epoch 56, Iteration 30, Current loss 0.2710878044030759 Accuracy 91.63386933543237\n",
      "Training:: Epoch 56, Iteration 40, Current loss 0.32502488446941885 Accuracy 92.61159569009749\n",
      "Training:: Epoch 56, Iteration 50, Current loss 0.3952447816014279 Accuracy 88.70675054439874\n",
      "Training:: Epoch 56, Iteration 60, Current loss 0.3574958799915842 Accuracy 89.90672884743505\n",
      "Training:: Epoch 56, Iteration 70, Current loss 0.3897596714370837 Accuracy 88.5500340367597\n",
      "Training:: Epoch 56, Iteration 80, Current loss 0.33551528268090886 Accuracy 90.48095014111007\n",
      "Training:: Epoch 56, Iteration 90, Current loss 0.3987177918832911 Accuracy 88.00951086956522\n",
      "Training:: Epoch 56, Iteration 100, Current loss 0.311665921766843 Accuracy 93.43109682603455\n",
      "Training:: Epoch 56, Iteration 110, Current loss 0.344913846187134 Accuracy 90.75380207185364\n",
      "Training:: Epoch 56, Iteration 120, Current loss 0.42320375052697634 Accuracy 85.17039922103213\n",
      "Training:: Epoch 56, Iteration 130, Current loss 0.37290694957591997 Accuracy 90.91949910554561\n",
      "Training:: Epoch 56, Iteration 140, Current loss 0.5241983284934629 Accuracy 84.04334575008465\n",
      "Training:: Epoch 56, Iteration 150, Current loss 0.27805394697691654 Accuracy 91.13088728835929\n",
      "Starting Training\n",
      "Training:: Epoch 57, Iteration 0, Current loss 0.5369510259217425 Accuracy 82.72658035034273\n",
      "Training:: Epoch 57, Iteration 10, Current loss 0.376067708972212 Accuracy 85.64794141287845\n",
      "Training:: Epoch 57, Iteration 20, Current loss 0.33451339250419587 Accuracy 90.32886579677628\n",
      "Training:: Epoch 57, Iteration 30, Current loss 0.34214282928601947 Accuracy 77.83432874578031\n",
      "Training:: Epoch 57, Iteration 40, Current loss 0.32603997125889256 Accuracy 83.56338925461881\n",
      "Training:: Epoch 57, Iteration 50, Current loss 0.4024962196563375 Accuracy 86.06820854566837\n",
      "Training:: Epoch 57, Iteration 60, Current loss 0.40823826226280296 Accuracy 86.17026045635899\n",
      "Training:: Epoch 57, Iteration 70, Current loss 0.3335528617069226 Accuracy 90.58230683090706\n",
      "Training:: Epoch 57, Iteration 80, Current loss 0.5432155619101933 Accuracy 84.94497432134996\n",
      "Training:: Epoch 57, Iteration 90, Current loss 0.5297389730736375 Accuracy 85.76871953921135\n",
      "Training:: Epoch 57, Iteration 100, Current loss 0.4919094946827395 Accuracy 87.78275069553646\n",
      "Training:: Epoch 57, Iteration 110, Current loss 0.5833304450934561 Accuracy 86.57180321499685\n",
      "Training:: Epoch 57, Iteration 120, Current loss 0.5703651745241407 Accuracy 90.29925687889134\n",
      "Training:: Epoch 57, Iteration 130, Current loss 0.3174545884637854 Accuracy 91.08452335005789\n",
      "Training:: Epoch 57, Iteration 140, Current loss 0.4801117729171832 Accuracy 90.37150321799528\n",
      "Training:: Epoch 57, Iteration 150, Current loss 0.704310285392904 Accuracy 84.55540355677155\n",
      "Starting Training\n",
      "Training:: Epoch 58, Iteration 0, Current loss 0.4093074379343946 Accuracy 86.06981793886754\n",
      "Training:: Epoch 58, Iteration 10, Current loss 0.910034309514145 Accuracy 86.67294731502282\n",
      "Training:: Epoch 58, Iteration 20, Current loss 0.3846240306013119 Accuracy 89.71270718232044\n",
      "Training:: Epoch 58, Iteration 30, Current loss 0.6499699621054864 Accuracy 83.41175803616986\n",
      "Training:: Epoch 58, Iteration 40, Current loss 0.8018085769184459 Accuracy 82.1092461433977\n",
      "Training:: Epoch 58, Iteration 50, Current loss 0.5195708662853477 Accuracy 83.68466840661179\n",
      "Training:: Epoch 58, Iteration 60, Current loss 0.3473953741729827 Accuracy 87.79650032404408\n",
      "Training:: Epoch 58, Iteration 70, Current loss 0.36233754609186664 Accuracy 86.26350789692435\n",
      "Training:: Epoch 58, Iteration 80, Current loss 0.626683494656185 Accuracy 82.12429478921416\n",
      "Training:: Epoch 58, Iteration 90, Current loss 0.3364320353003054 Accuracy 92.67392421623137\n",
      "Training:: Epoch 58, Iteration 100, Current loss 0.35555818191193 Accuracy 87.9561288542457\n",
      "Training:: Epoch 58, Iteration 110, Current loss 0.3874323400069156 Accuracy 86.29420988442999\n",
      "Training:: Epoch 58, Iteration 120, Current loss 0.40267211311547263 Accuracy 88.22247706422019\n",
      "Training:: Epoch 58, Iteration 130, Current loss 0.741688156565482 Accuracy 76.6229378976409\n",
      "Training:: Epoch 58, Iteration 140, Current loss 0.618835613511378 Accuracy 90.990650675229\n",
      "Training:: Epoch 58, Iteration 150, Current loss 0.5965571605811787 Accuracy 87.83783783783784\n",
      "Starting Training\n",
      "Training:: Epoch 59, Iteration 0, Current loss 0.5871466690136434 Accuracy 89.73727789464262\n",
      "Training:: Epoch 59, Iteration 10, Current loss 0.3647395105486315 Accuracy 86.69283502874835\n",
      "Training:: Epoch 59, Iteration 20, Current loss 0.5840477588026202 Accuracy 86.98605901917769\n",
      "Training:: Epoch 59, Iteration 30, Current loss 0.46916892554879364 Accuracy 87.28992417728445\n",
      "Training:: Epoch 59, Iteration 40, Current loss 0.3243509616831879 Accuracy 91.39745651220582\n",
      "Training:: Epoch 59, Iteration 50, Current loss 0.4080863635804332 Accuracy 90.68123393316195\n",
      "Training:: Epoch 59, Iteration 60, Current loss 0.2683595086906427 Accuracy 87.38764739836728\n",
      "Training:: Epoch 59, Iteration 70, Current loss 0.2961036418744997 Accuracy 92.86680189317106\n",
      "Training:: Epoch 59, Iteration 80, Current loss 0.3527148168445158 Accuracy 88.87958630879093\n",
      "Training:: Epoch 59, Iteration 90, Current loss 0.3610765559295518 Accuracy 87.4080695623908\n",
      "Training:: Epoch 59, Iteration 100, Current loss 0.3161840113124075 Accuracy 88.89657698726037\n",
      "Training:: Epoch 59, Iteration 110, Current loss 0.4301510983734155 Accuracy 86.81576845369544\n",
      "Training:: Epoch 59, Iteration 120, Current loss 0.5195753975225722 Accuracy 81.32801367911085\n",
      "Training:: Epoch 59, Iteration 130, Current loss 0.4577441619433843 Accuracy 84.89329839011606\n",
      "Training:: Epoch 59, Iteration 140, Current loss 0.4901130929238946 Accuracy 85.28663373746446\n",
      "Training:: Epoch 59, Iteration 150, Current loss 0.33442392655552505 Accuracy 88.43897957741503\n",
      "Starting Training\n",
      "Training:: Epoch 60, Iteration 0, Current loss 0.8697483934344866 Accuracy 84.44330891954806\n",
      "Training:: Epoch 60, Iteration 10, Current loss 0.3005163711772733 Accuracy 91.07464028776978\n",
      "Training:: Epoch 60, Iteration 20, Current loss 0.33365516840203485 Accuracy 92.99559205361994\n",
      "Training:: Epoch 60, Iteration 30, Current loss 0.35566975609973145 Accuracy 87.72643611353288\n",
      "Training:: Epoch 60, Iteration 40, Current loss 0.5613049480356096 Accuracy 82.00836820083683\n",
      "Training:: Epoch 60, Iteration 50, Current loss 0.2618982031135008 Accuracy 88.42085614733698\n",
      "Training:: Epoch 60, Iteration 60, Current loss 0.31786965843495474 Accuracy 89.54153467089053\n",
      "Training:: Epoch 60, Iteration 70, Current loss 0.3140142874288719 Accuracy 89.3075501208588\n",
      "Training:: Epoch 60, Iteration 80, Current loss 0.2812924624401134 Accuracy 92.19998478045811\n",
      "Training:: Epoch 60, Iteration 90, Current loss 0.30379749768749814 Accuracy 92.26002166847238\n",
      "Training:: Epoch 60, Iteration 100, Current loss 0.28534915063730903 Accuracy 90.73317469582005\n",
      "Training:: Epoch 60, Iteration 110, Current loss 0.3158677362595718 Accuracy 90.91326559898972\n",
      "Training:: Epoch 60, Iteration 120, Current loss 0.4211598308594407 Accuracy 86.45250114731529\n",
      "Training:: Epoch 60, Iteration 130, Current loss 0.38484671786156227 Accuracy 87.60278304870336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 60, Iteration 140, Current loss 0.35752741969521806 Accuracy 89.04635576654566\n",
      "Training:: Epoch 60, Iteration 150, Current loss 0.4145514901843467 Accuracy 84.35361901332374\n",
      "Calculating Expectation\n",
      "Epoch 60 iter 0\n",
      "Epoch 60 iter 10\n",
      "Epoch 60 iter 20\n",
      "Epoch 60 iter 30\n",
      "Epoch 60 iter 40\n",
      "Epoch 60 iter 50\n",
      "Epoch 60 iter 60\n",
      "Epoch 60 iter 70\n",
      "Epoch 60 iter 80\n",
      "Epoch 60 iter 90\n",
      "Epoch 60 iter 100\n",
      "Epoch 60 iter 110\n",
      "Epoch 60 iter 120\n",
      "Epoch 60 iter 130\n",
      "Epoch 60 iter 140\n",
      "Epoch 60 iter 150\n",
      "Train Boundary avergage error = 89.514\n",
      "Train From boundary avergage accuracy = 88.093\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 60, Probability Accuracy 66.1026639598956\n",
      "Starting Training\n",
      "Training:: Epoch 61, Iteration 0, Current loss 0.27843619480179643 Accuracy 90.67197341473782\n",
      "Training:: Epoch 61, Iteration 10, Current loss 0.2896598137857795 Accuracy 86.55504500535028\n",
      "Training:: Epoch 61, Iteration 20, Current loss 0.30415290290696323 Accuracy 92.2708686546325\n",
      "Training:: Epoch 61, Iteration 30, Current loss 0.29032382091771214 Accuracy 90.05457234661091\n",
      "Training:: Epoch 61, Iteration 40, Current loss 0.23843325918297897 Accuracy 87.29234648472263\n",
      "Training:: Epoch 61, Iteration 50, Current loss 0.36507681731294495 Accuracy 80.26712948988832\n",
      "Training:: Epoch 61, Iteration 60, Current loss 0.2507959148819758 Accuracy 90.50035298270384\n",
      "Training:: Epoch 61, Iteration 70, Current loss 0.28306905133721105 Accuracy 87.71192187711922\n",
      "Training:: Epoch 61, Iteration 80, Current loss 0.3232775526552026 Accuracy 85.85771658060814\n",
      "Training:: Epoch 61, Iteration 90, Current loss 0.21646789410518336 Accuracy 91.64017800381437\n",
      "Training:: Epoch 61, Iteration 100, Current loss 0.33248889902465084 Accuracy 89.25154497596704\n",
      "Training:: Epoch 61, Iteration 110, Current loss 0.2900575437146814 Accuracy 89.00065890621568\n",
      "Training:: Epoch 61, Iteration 120, Current loss 0.32107577653684827 Accuracy 89.76260016475699\n",
      "Training:: Epoch 61, Iteration 130, Current loss 0.24576006525614932 Accuracy 91.07812265707003\n",
      "Training:: Epoch 61, Iteration 140, Current loss 0.30645329598091686 Accuracy 90.19943324600331\n",
      "Training:: Epoch 61, Iteration 150, Current loss 0.6283662324957711 Accuracy 86.19143211036604\n",
      "Starting Training\n",
      "Training:: Epoch 62, Iteration 0, Current loss 0.2728260151587894 Accuracy 87.46991004687698\n",
      "Training:: Epoch 62, Iteration 10, Current loss 0.32586191365028766 Accuracy 86.56328059950042\n",
      "Training:: Epoch 62, Iteration 20, Current loss 0.3523632757905787 Accuracy 86.74436565330338\n",
      "Training:: Epoch 62, Iteration 30, Current loss 0.3424119824114956 Accuracy 88.24339839265213\n",
      "Training:: Epoch 62, Iteration 40, Current loss 0.2659519741064579 Accuracy 89.72670902549184\n",
      "Training:: Epoch 62, Iteration 50, Current loss 0.19362675238292573 Accuracy 91.99108719414782\n",
      "Training:: Epoch 62, Iteration 60, Current loss 0.2323613408510979 Accuracy 92.04101285900414\n",
      "Training:: Epoch 62, Iteration 70, Current loss 0.43727425494142436 Accuracy 84.48027641808235\n",
      "Training:: Epoch 62, Iteration 80, Current loss 0.265826134071979 Accuracy 88.38530903625775\n",
      "Training:: Epoch 62, Iteration 90, Current loss 0.319145791620059 Accuracy 81.85414821375849\n",
      "Training:: Epoch 62, Iteration 100, Current loss 0.2580552876893666 Accuracy 88.15825980800177\n",
      "Training:: Epoch 62, Iteration 110, Current loss 0.4344224382327101 Accuracy 86.9556611243072\n",
      "Training:: Epoch 62, Iteration 120, Current loss 0.2868895973155105 Accuracy 89.8223667750813\n",
      "Training:: Epoch 62, Iteration 130, Current loss 0.3739388815638956 Accuracy 87.81223083548664\n",
      "Training:: Epoch 62, Iteration 140, Current loss 0.2871130926676471 Accuracy 90.05040050400504\n",
      "Training:: Epoch 62, Iteration 150, Current loss 0.3879223778056478 Accuracy 88.33050515598485\n",
      "Starting Training\n",
      "Training:: Epoch 63, Iteration 0, Current loss 0.4350095643410218 Accuracy 82.65741954581976\n",
      "Training:: Epoch 63, Iteration 10, Current loss 0.20759868864685938 Accuracy 90.4702769828843\n",
      "Training:: Epoch 63, Iteration 20, Current loss 0.2278978828433158 Accuracy 90.75078658999675\n",
      "Training:: Epoch 63, Iteration 30, Current loss 0.342532835294448 Accuracy 87.40759622737701\n",
      "Training:: Epoch 63, Iteration 40, Current loss 0.4468352686572413 Accuracy 87.21068520720885\n",
      "Training:: Epoch 63, Iteration 50, Current loss 0.3213814546476746 Accuracy 90.92485549132948\n",
      "Training:: Epoch 63, Iteration 60, Current loss 0.2666015559916849 Accuracy 91.25712337440943\n",
      "Training:: Epoch 63, Iteration 70, Current loss 0.24248264137011863 Accuracy 89.80672611234327\n",
      "Training:: Epoch 63, Iteration 80, Current loss 0.3903784123502149 Accuracy 85.98939738180245\n",
      "Training:: Epoch 63, Iteration 90, Current loss 0.2599913406564332 Accuracy 89.59791409359133\n",
      "Training:: Epoch 63, Iteration 100, Current loss 0.2625025458998956 Accuracy 88.0387370442995\n",
      "Training:: Epoch 63, Iteration 110, Current loss 0.25287966729445627 Accuracy 86.66516245487365\n",
      "Training:: Epoch 63, Iteration 120, Current loss 0.24816332694464538 Accuracy 91.94198600620916\n",
      "Training:: Epoch 63, Iteration 130, Current loss 0.26493880992105306 Accuracy 88.01769395294575\n",
      "Training:: Epoch 63, Iteration 140, Current loss 0.22836151074809194 Accuracy 89.20017850944612\n",
      "Training:: Epoch 63, Iteration 150, Current loss 0.43286032065588953 Accuracy 85.81310821901747\n",
      "Starting Training\n",
      "Training:: Epoch 64, Iteration 0, Current loss 0.1793879324596999 Accuracy 89.59717730079389\n",
      "Training:: Epoch 64, Iteration 10, Current loss 0.24843590613895994 Accuracy 90.15300420087101\n",
      "Training:: Epoch 64, Iteration 20, Current loss 0.20868103129168553 Accuracy 91.93789025805383\n",
      "Training:: Epoch 64, Iteration 30, Current loss 0.26969899324663277 Accuracy 89.23830147820355\n",
      "Training:: Epoch 64, Iteration 40, Current loss 0.2064994868814448 Accuracy 93.20155902004454\n",
      "Training:: Epoch 64, Iteration 50, Current loss 0.2551011757890483 Accuracy 89.62781669339185\n",
      "Training:: Epoch 64, Iteration 60, Current loss 0.4011036580028076 Accuracy 85.05747126436782\n",
      "Training:: Epoch 64, Iteration 70, Current loss 0.21928089047958996 Accuracy 91.77188101861759\n",
      "Training:: Epoch 64, Iteration 80, Current loss 0.3221898037486973 Accuracy 83.3886211428929\n",
      "Training:: Epoch 64, Iteration 90, Current loss 0.4806763947683715 Accuracy 88.32578744949126\n",
      "Training:: Epoch 64, Iteration 100, Current loss 0.5591995824097313 Accuracy 86.34118228223284\n",
      "Training:: Epoch 64, Iteration 110, Current loss 0.3264814937038273 Accuracy 86.8282498184459\n",
      "Training:: Epoch 64, Iteration 120, Current loss 0.30408901707401703 Accuracy 91.75282519836499\n",
      "Training:: Epoch 64, Iteration 130, Current loss 0.3777594790932295 Accuracy 83.88664927673702\n",
      "Training:: Epoch 64, Iteration 140, Current loss 0.40616367839264006 Accuracy 86.79283001266076\n",
      "Training:: Epoch 64, Iteration 150, Current loss 0.4480026692087816 Accuracy 83.58939112153311\n",
      "Starting Training\n",
      "Training:: Epoch 65, Iteration 0, Current loss 0.33780370460937786 Accuracy 88.15537467081637\n",
      "Training:: Epoch 65, Iteration 10, Current loss 0.33899868329701244 Accuracy 91.87459254430155\n",
      "Training:: Epoch 65, Iteration 20, Current loss 0.54444230407006 Accuracy 84.35307781649244\n",
      "Training:: Epoch 65, Iteration 30, Current loss 0.20008529588254148 Accuracy 92.4857772370022\n",
      "Training:: Epoch 65, Iteration 40, Current loss 0.28500116557121813 Accuracy 88.62338760837386\n",
      "Training:: Epoch 65, Iteration 50, Current loss 0.2817962704640264 Accuracy 87.85272585116213\n",
      "Training:: Epoch 65, Iteration 60, Current loss 0.32420164283157105 Accuracy 88.84347422201579\n",
      "Training:: Epoch 65, Iteration 70, Current loss 0.329243408104134 Accuracy 89.42039332770818\n",
      "Training:: Epoch 65, Iteration 80, Current loss 0.2452390980160591 Accuracy 90.31474898118442\n",
      "Training:: Epoch 65, Iteration 90, Current loss 0.2502494149994181 Accuracy 88.22314049586777\n",
      "Training:: Epoch 65, Iteration 100, Current loss 0.3760329038457459 Accuracy 81.82554685390224\n",
      "Training:: Epoch 65, Iteration 110, Current loss 0.2756996587854974 Accuracy 84.86803084223013\n",
      "Training:: Epoch 65, Iteration 120, Current loss 0.2691865024038714 Accuracy 89.5875916796922\n",
      "Training:: Epoch 65, Iteration 130, Current loss 0.3127868343120054 Accuracy 91.88168659534298\n",
      "Training:: Epoch 65, Iteration 140, Current loss 0.44838232990431326 Accuracy 84.93037526551805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 65, Iteration 150, Current loss 0.48898835219414194 Accuracy 89.14039846599944\n",
      "Calculating Expectation\n",
      "Epoch 65 iter 0\n",
      "Epoch 65 iter 10\n",
      "Epoch 65 iter 20\n",
      "Epoch 65 iter 30\n",
      "Epoch 65 iter 40\n",
      "Epoch 65 iter 50\n",
      "Epoch 65 iter 60\n",
      "Epoch 65 iter 70\n",
      "Epoch 65 iter 80\n",
      "Epoch 65 iter 90\n",
      "Epoch 65 iter 100\n",
      "Epoch 65 iter 110\n",
      "Epoch 65 iter 120\n",
      "Epoch 65 iter 130\n",
      "Epoch 65 iter 140\n",
      "Epoch 65 iter 150\n",
      "Train Boundary avergage error = 88.686\n",
      "Train From boundary avergage accuracy = 88.146\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 65, Probability Accuracy 66.4427020756515\n",
      "Starting Training\n",
      "Training:: Epoch 66, Iteration 0, Current loss 0.3160044608110207 Accuracy 88.2318532305238\n",
      "Training:: Epoch 66, Iteration 10, Current loss 0.46172317062539914 Accuracy 84.39847025756808\n",
      "Training:: Epoch 66, Iteration 20, Current loss 0.41119374378422463 Accuracy 87.42573451615529\n",
      "Training:: Epoch 66, Iteration 30, Current loss 0.40836165766224686 Accuracy 85.86436498150431\n",
      "Training:: Epoch 66, Iteration 40, Current loss 0.7602685035880901 Accuracy 86.1820386714276\n",
      "Training:: Epoch 66, Iteration 50, Current loss 0.560634322902901 Accuracy 91.15018054815604\n",
      "Training:: Epoch 66, Iteration 60, Current loss 0.46800489699453235 Accuracy 89.79209270620314\n",
      "Training:: Epoch 66, Iteration 70, Current loss 0.3882152643579697 Accuracy 87.29608700287878\n",
      "Training:: Epoch 66, Iteration 80, Current loss 0.7463146472678576 Accuracy 86.1266020937286\n",
      "Training:: Epoch 66, Iteration 90, Current loss 0.44030739537213015 Accuracy 88.99302374744556\n",
      "Training:: Epoch 66, Iteration 100, Current loss 0.3611304841474035 Accuracy 89.25506872199864\n",
      "Training:: Epoch 66, Iteration 110, Current loss 0.5085277201633608 Accuracy 80.48164517001894\n",
      "Training:: Epoch 66, Iteration 120, Current loss 0.6155143438899492 Accuracy 86.2504264756056\n",
      "Training:: Epoch 66, Iteration 130, Current loss 0.385611404711208 Accuracy 88.1300312772394\n",
      "Training:: Epoch 66, Iteration 140, Current loss 0.3536802766741582 Accuracy 89.39951273109445\n",
      "Training:: Epoch 66, Iteration 150, Current loss 0.496701441061917 Accuracy 83.55316558441558\n",
      "Starting Training\n",
      "Training:: Epoch 67, Iteration 0, Current loss 0.3394535018879182 Accuracy 88.22978232665417\n",
      "Training:: Epoch 67, Iteration 10, Current loss 0.48787079508538883 Accuracy 83.4379744757684\n",
      "Training:: Epoch 67, Iteration 20, Current loss 0.3600245225645701 Accuracy 89.83743613562471\n",
      "Training:: Epoch 67, Iteration 30, Current loss 0.3310665502609379 Accuracy 90.23018495970314\n",
      "Training:: Epoch 67, Iteration 40, Current loss 0.3620118586442523 Accuracy 86.02094734855633\n",
      "Training:: Epoch 67, Iteration 50, Current loss 2.4787943132192023 Accuracy 87.65446290016668\n",
      "Training:: Epoch 67, Iteration 60, Current loss 0.9829043928086642 Accuracy 86.91216187250825\n",
      "Training:: Epoch 67, Iteration 70, Current loss 0.9853182325319934 Accuracy 83.6687306501548\n",
      "Training:: Epoch 67, Iteration 80, Current loss 1.0922341882679376 Accuracy 82.66611920892356\n",
      "Training:: Epoch 67, Iteration 90, Current loss 1.6733375837234956 Accuracy 78.84777834093597\n",
      "Training:: Epoch 67, Iteration 100, Current loss 0.9833197675426784 Accuracy 86.16440668429641\n",
      "Training:: Epoch 67, Iteration 110, Current loss 1.1333844071450991 Accuracy 84.73772321428571\n",
      "Training:: Epoch 67, Iteration 120, Current loss 0.5983223129954588 Accuracy 92.13240186294078\n",
      "Training:: Epoch 67, Iteration 130, Current loss 1.3484191370505858 Accuracy 79.22899505766063\n",
      "Training:: Epoch 67, Iteration 140, Current loss 1.0354826122521612 Accuracy 89.8377920348626\n",
      "Training:: Epoch 67, Iteration 150, Current loss 0.8304246840366764 Accuracy 81.59843205574913\n",
      "Starting Training\n",
      "Training:: Epoch 68, Iteration 0, Current loss 0.7141376746151524 Accuracy 90.93953816322933\n",
      "Training:: Epoch 68, Iteration 10, Current loss 0.8809534111613175 Accuracy 89.83478973238667\n",
      "Training:: Epoch 68, Iteration 20, Current loss 0.7187478725596185 Accuracy 89.20518602029313\n",
      "Training:: Epoch 68, Iteration 30, Current loss 0.9375839623212606 Accuracy 87.22160698904885\n",
      "Training:: Epoch 68, Iteration 40, Current loss 4.482204989838832 Accuracy 74.31444877505568\n",
      "Training:: Epoch 68, Iteration 50, Current loss 1.8675205399055237 Accuracy 78.61597089901265\n",
      "Training:: Epoch 68, Iteration 60, Current loss 1.451450394776811 Accuracy 77.61790098079521\n",
      "Training:: Epoch 68, Iteration 70, Current loss 1.6202141326394128 Accuracy 82.89050289601913\n",
      "Training:: Epoch 68, Iteration 80, Current loss 1.1858368345061163 Accuracy 88.18575650836067\n",
      "Training:: Epoch 68, Iteration 90, Current loss 4.660370021476432 Accuracy 64.6439072198628\n",
      "Training:: Epoch 68, Iteration 100, Current loss 4.296974241081871 Accuracy 70.64650677789363\n",
      "Training:: Epoch 68, Iteration 110, Current loss 2.96020243564406 Accuracy 71.099044978435\n",
      "Training:: Epoch 68, Iteration 120, Current loss 3.9748660373930873 Accuracy 75.01355013550136\n",
      "Training:: Epoch 68, Iteration 130, Current loss 3.0894106624568147 Accuracy 78.86691086691087\n",
      "Training:: Epoch 68, Iteration 140, Current loss 4.238211413838064 Accuracy 70.00100633994163\n",
      "Training:: Epoch 68, Iteration 150, Current loss 2.6737731347537057 Accuracy 87.34295991242246\n",
      "Starting Training\n",
      "Training:: Epoch 69, Iteration 0, Current loss 1.1710148112840093 Accuracy 89.15829710688053\n",
      "Training:: Epoch 69, Iteration 10, Current loss 1.4135656569998214 Accuracy 84.23974096345735\n",
      "Training:: Epoch 69, Iteration 20, Current loss 1.0890064981877796 Accuracy 88.0907915529378\n",
      "Training:: Epoch 69, Iteration 30, Current loss 1.5291157769272874 Accuracy 80.92947474590736\n",
      "Training:: Epoch 69, Iteration 40, Current loss 0.9606089426809841 Accuracy 92.60995871770042\n",
      "Training:: Epoch 69, Iteration 50, Current loss 1.2366706168764605 Accuracy 88.6664771111743\n",
      "Training:: Epoch 69, Iteration 60, Current loss 0.9962578921048005 Accuracy 86.58643053130456\n",
      "Training:: Epoch 69, Iteration 70, Current loss 1.0498901638580922 Accuracy 87.3713199134483\n",
      "Training:: Epoch 69, Iteration 80, Current loss 0.8965835556213686 Accuracy 89.6930596285435\n",
      "Training:: Epoch 69, Iteration 90, Current loss 0.7295730943436598 Accuracy 90.0021675517503\n",
      "Training:: Epoch 69, Iteration 100, Current loss 4.345511646231903 Accuracy 67.90979154813014\n",
      "Training:: Epoch 69, Iteration 110, Current loss 1.5452008656971974 Accuracy 85.7308505558966\n",
      "Training:: Epoch 69, Iteration 120, Current loss 1.5844561773884718 Accuracy 82.45155855096883\n",
      "Training:: Epoch 69, Iteration 130, Current loss 0.8185876134981929 Accuracy 87.44771957777336\n",
      "Training:: Epoch 69, Iteration 140, Current loss 0.8388724220936665 Accuracy 85.90343407878731\n",
      "Training:: Epoch 69, Iteration 150, Current loss 1.0969878660543202 Accuracy 88.31595706435212\n",
      "Starting Training\n",
      "Training:: Epoch 70, Iteration 0, Current loss 0.7024813241746037 Accuracy 88.02450666096745\n",
      "Training:: Epoch 70, Iteration 10, Current loss 0.48538746259543836 Accuracy 89.62827426810478\n",
      "Training:: Epoch 70, Iteration 20, Current loss 0.6071266460314664 Accuracy 88.10740541509772\n",
      "Training:: Epoch 70, Iteration 30, Current loss 0.5039650341122656 Accuracy 85.0193809029863\n",
      "Training:: Epoch 70, Iteration 40, Current loss 0.5294937587093375 Accuracy 83.09464349421538\n",
      "Training:: Epoch 70, Iteration 50, Current loss 0.5451826802750841 Accuracy 87.42186897137125\n",
      "Training:: Epoch 70, Iteration 60, Current loss 0.7378640122961713 Accuracy 86.86920370962584\n",
      "Training:: Epoch 70, Iteration 70, Current loss 0.5791228265785798 Accuracy 85.7152145643693\n",
      "Training:: Epoch 70, Iteration 80, Current loss 0.5810590114828246 Accuracy 88.47222222222223\n",
      "Training:: Epoch 70, Iteration 90, Current loss 0.5596817295768064 Accuracy 90.53913845444414\n",
      "Training:: Epoch 70, Iteration 100, Current loss 0.58998408204666 Accuracy 82.14573416331014\n",
      "Training:: Epoch 70, Iteration 110, Current loss 0.4900391583316952 Accuracy 87.58865248226951\n",
      "Training:: Epoch 70, Iteration 120, Current loss 0.5633007146380969 Accuracy 88.37225274725274\n",
      "Training:: Epoch 70, Iteration 130, Current loss 0.49326287523061213 Accuracy 88.09343570887856\n",
      "Training:: Epoch 70, Iteration 140, Current loss 0.4877781210996226 Accuracy 89.73903207562414\n",
      "Training:: Epoch 70, Iteration 150, Current loss 0.6395116424649279 Accuracy 88.2119717628856\n",
      "Calculating Expectation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 iter 0\n",
      "Epoch 70 iter 10\n",
      "Epoch 70 iter 20\n",
      "Epoch 70 iter 30\n",
      "Epoch 70 iter 40\n",
      "Epoch 70 iter 50\n",
      "Epoch 70 iter 60\n",
      "Epoch 70 iter 70\n",
      "Epoch 70 iter 80\n",
      "Epoch 70 iter 90\n",
      "Epoch 70 iter 100\n",
      "Epoch 70 iter 110\n",
      "Epoch 70 iter 120\n",
      "Epoch 70 iter 130\n",
      "Epoch 70 iter 140\n",
      "Epoch 70 iter 150\n",
      "Train Boundary avergage error = 88.328\n",
      "Train From boundary avergage accuracy = 88.114\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 70, Probability Accuracy 66.71655549571197\n",
      "Starting Training\n",
      "Training:: Epoch 71, Iteration 0, Current loss 0.384750983694861 Accuracy 89.44513975803088\n",
      "Training:: Epoch 71, Iteration 10, Current loss 0.5597397720083269 Accuracy 90.02394253790902\n",
      "Training:: Epoch 71, Iteration 20, Current loss 0.3766035424790004 Accuracy 88.97953129635123\n",
      "Training:: Epoch 71, Iteration 30, Current loss 0.3773640893371916 Accuracy 87.15775749674054\n",
      "Training:: Epoch 71, Iteration 40, Current loss 0.36783612872128535 Accuracy 88.62489486963835\n",
      "Training:: Epoch 71, Iteration 50, Current loss 0.5690722900111131 Accuracy 84.48438383711431\n",
      "Training:: Epoch 71, Iteration 60, Current loss 0.4195285834903224 Accuracy 87.82115869017632\n",
      "Training:: Epoch 71, Iteration 70, Current loss 0.35848113384752367 Accuracy 88.37323813627131\n",
      "Training:: Epoch 71, Iteration 80, Current loss 0.32050827299539497 Accuracy 88.21210628055945\n",
      "Training:: Epoch 71, Iteration 90, Current loss 0.3193590254239918 Accuracy 87.15475089203119\n",
      "Training:: Epoch 71, Iteration 100, Current loss 0.34384451775689673 Accuracy 86.44039551160982\n",
      "Training:: Epoch 71, Iteration 110, Current loss 0.3912055935542844 Accuracy 87.97269876406567\n",
      "Training:: Epoch 71, Iteration 120, Current loss 0.7865108174127348 Accuracy 85.96131676700396\n",
      "Training:: Epoch 71, Iteration 130, Current loss 0.35248212102332455 Accuracy 87.10653431710813\n",
      "Training:: Epoch 71, Iteration 140, Current loss 0.3554722576467789 Accuracy 88.8805063078922\n",
      "Training:: Epoch 71, Iteration 150, Current loss 0.3493487268969552 Accuracy 92.34627531116477\n",
      "Starting Training\n",
      "Training:: Epoch 72, Iteration 0, Current loss 0.28204298571228203 Accuracy 88.4862623120788\n",
      "Training:: Epoch 72, Iteration 10, Current loss 0.37986491572341613 Accuracy 90.12357324780682\n",
      "Training:: Epoch 72, Iteration 20, Current loss 0.28413391092867346 Accuracy 90.0613082850554\n",
      "Training:: Epoch 72, Iteration 30, Current loss 0.4031979407825569 Accuracy 88.03159173754557\n",
      "Training:: Epoch 72, Iteration 40, Current loss 0.2996638446382821 Accuracy 91.35088419093206\n",
      "Training:: Epoch 72, Iteration 50, Current loss 0.3889141487945181 Accuracy 88.83526383526383\n",
      "Training:: Epoch 72, Iteration 60, Current loss 0.2934272091447037 Accuracy 88.00876643706951\n",
      "Training:: Epoch 72, Iteration 70, Current loss 0.3073299719854651 Accuracy 90.5791571271093\n",
      "Training:: Epoch 72, Iteration 80, Current loss 0.3637861697648537 Accuracy 85.23851503575277\n",
      "Training:: Epoch 72, Iteration 90, Current loss 0.3196444656156853 Accuracy 90.28807013881641\n",
      "Training:: Epoch 72, Iteration 100, Current loss 0.30162452810933776 Accuracy 88.3558387219475\n",
      "Training:: Epoch 72, Iteration 110, Current loss 0.3685028915694586 Accuracy 84.55591513843942\n",
      "Training:: Epoch 72, Iteration 120, Current loss 0.27476880284949534 Accuracy 88.12387909540266\n",
      "Training:: Epoch 72, Iteration 130, Current loss 0.2928963148420145 Accuracy 91.10544544929768\n",
      "Training:: Epoch 72, Iteration 140, Current loss 0.38033510965638373 Accuracy 86.0252808988764\n",
      "Training:: Epoch 72, Iteration 150, Current loss 0.4121091267276119 Accuracy 88.01135859437395\n",
      "Starting Training\n",
      "Training:: Epoch 73, Iteration 0, Current loss 0.23237868524108082 Accuracy 85.20698526545569\n",
      "Training:: Epoch 73, Iteration 10, Current loss 0.2686435465401882 Accuracy 90.17553618888682\n",
      "Training:: Epoch 73, Iteration 20, Current loss 0.28053506022172314 Accuracy 90.83941869712963\n",
      "Training:: Epoch 73, Iteration 30, Current loss 0.4018026264239236 Accuracy 84.12118607649334\n",
      "Training:: Epoch 73, Iteration 40, Current loss 0.27566664496474835 Accuracy 87.15290253041113\n",
      "Training:: Epoch 73, Iteration 50, Current loss 0.45187340132961024 Accuracy 72.99908328044566\n",
      "Training:: Epoch 73, Iteration 60, Current loss 0.7809066764975924 Accuracy 88.16929296262684\n",
      "Training:: Epoch 73, Iteration 70, Current loss 0.49247443900801935 Accuracy 88.29160530191459\n",
      "Training:: Epoch 73, Iteration 80, Current loss 0.45688003989504966 Accuracy 85.13011152416357\n",
      "Training:: Epoch 73, Iteration 90, Current loss 0.4956086453870151 Accuracy 84.93569336559277\n",
      "Training:: Epoch 73, Iteration 100, Current loss 0.322356361565462 Accuracy 88.40638478268883\n",
      "Training:: Epoch 73, Iteration 110, Current loss 0.3705034452538122 Accuracy 90.6849068490685\n",
      "Training:: Epoch 73, Iteration 120, Current loss 0.44201182929918725 Accuracy 90.9522091045007\n",
      "Training:: Epoch 73, Iteration 130, Current loss 0.2840623404322288 Accuracy 90.09114392942438\n",
      "Training:: Epoch 73, Iteration 140, Current loss 0.35451480220959913 Accuracy 89.13276641385123\n",
      "Training:: Epoch 73, Iteration 150, Current loss 0.4079487770913452 Accuracy 90.50052872752909\n",
      "Starting Training\n",
      "Training:: Epoch 74, Iteration 0, Current loss 0.31460218836683995 Accuracy 85.61915198516395\n",
      "Training:: Epoch 74, Iteration 10, Current loss 0.3454935028816019 Accuracy 90.66659623917177\n",
      "Training:: Epoch 74, Iteration 20, Current loss 0.4026118639194868 Accuracy 86.85983280577875\n",
      "Training:: Epoch 74, Iteration 30, Current loss 0.32073726271072645 Accuracy 88.62730349755547\n",
      "Training:: Epoch 74, Iteration 40, Current loss 0.36312556499233295 Accuracy 85.93772216692734\n",
      "Training:: Epoch 74, Iteration 50, Current loss 0.2693026078887328 Accuracy 90.12345679012346\n",
      "Training:: Epoch 74, Iteration 60, Current loss 0.28720847975220787 Accuracy 84.85162391079155\n",
      "Training:: Epoch 74, Iteration 70, Current loss 0.5329176267630232 Accuracy 82.76759242451746\n",
      "Training:: Epoch 74, Iteration 80, Current loss 0.38879994878362184 Accuracy 82.10493922141868\n",
      "Training:: Epoch 74, Iteration 90, Current loss 0.26481369520834974 Accuracy 89.3722194760257\n",
      "Training:: Epoch 74, Iteration 100, Current loss 0.31590163340977445 Accuracy 87.4588403722262\n",
      "Training:: Epoch 74, Iteration 110, Current loss 0.3049396219838372 Accuracy 85.62027567807915\n",
      "Training:: Epoch 74, Iteration 120, Current loss 0.4022520143103308 Accuracy 86.75508399646331\n",
      "Training:: Epoch 74, Iteration 130, Current loss 0.3744342740631865 Accuracy 87.17039663195214\n",
      "Training:: Epoch 74, Iteration 140, Current loss 0.44956365863049896 Accuracy 87.97192766763997\n",
      "Training:: Epoch 74, Iteration 150, Current loss 0.26837244616169575 Accuracy 87.30100774061633\n",
      "Starting Training\n",
      "Training:: Epoch 75, Iteration 0, Current loss 0.21035357063553195 Accuracy 89.27859490329185\n",
      "Training:: Epoch 75, Iteration 10, Current loss 0.3435772589167819 Accuracy 85.97690769528478\n",
      "Training:: Epoch 75, Iteration 20, Current loss 0.2651723244514329 Accuracy 91.49877963016588\n",
      "Training:: Epoch 75, Iteration 30, Current loss 0.251180263090084 Accuracy 87.07673568818514\n",
      "Training:: Epoch 75, Iteration 40, Current loss 0.3097510422058289 Accuracy 89.33128024637044\n",
      "Training:: Epoch 75, Iteration 50, Current loss 0.28407430212545265 Accuracy 88.90951782886474\n",
      "Training:: Epoch 75, Iteration 60, Current loss 0.2691666264605982 Accuracy 88.88670820862568\n",
      "Training:: Epoch 75, Iteration 70, Current loss 0.3551397083763132 Accuracy 82.64560419281021\n",
      "Training:: Epoch 75, Iteration 80, Current loss 0.320192992121109 Accuracy 91.25783279841052\n",
      "Training:: Epoch 75, Iteration 90, Current loss 0.29481724316355534 Accuracy 91.17056856187291\n",
      "Training:: Epoch 75, Iteration 100, Current loss 0.25985569376640877 Accuracy 91.01590485742943\n",
      "Training:: Epoch 75, Iteration 110, Current loss 0.2739174987927417 Accuracy 82.54389943627292\n",
      "Training:: Epoch 75, Iteration 120, Current loss 0.35213727374441456 Accuracy 84.10250463821892\n",
      "Training:: Epoch 75, Iteration 130, Current loss 0.28913839744824865 Accuracy 90.43554115521216\n",
      "Training:: Epoch 75, Iteration 140, Current loss 0.2948226702064779 Accuracy 92.18743040399092\n",
      "Training:: Epoch 75, Iteration 150, Current loss 0.27693478897474694 Accuracy 89.41375211161859\n",
      "Calculating Expectation\n",
      "Epoch 75 iter 0\n",
      "Epoch 75 iter 10\n",
      "Epoch 75 iter 20\n",
      "Epoch 75 iter 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 iter 40\n",
      "Epoch 75 iter 50\n",
      "Epoch 75 iter 60\n",
      "Epoch 75 iter 70\n",
      "Epoch 75 iter 80\n",
      "Epoch 75 iter 90\n",
      "Epoch 75 iter 100\n",
      "Epoch 75 iter 110\n",
      "Epoch 75 iter 120\n",
      "Epoch 75 iter 130\n",
      "Epoch 75 iter 140\n",
      "Epoch 75 iter 150\n",
      "Train Boundary avergage error = 88.599\n",
      "Train From boundary avergage accuracy = 88.104\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 75, Probability Accuracy 66.22519368604218\n",
      "Starting Training\n",
      "Training:: Epoch 76, Iteration 0, Current loss 0.21168994984716188 Accuracy 90.63797659494149\n",
      "Training:: Epoch 76, Iteration 10, Current loss 0.39485004098288384 Accuracy 86.4268680445151\n",
      "Training:: Epoch 76, Iteration 20, Current loss 0.2921516281257057 Accuracy 85.58481410119175\n",
      "Training:: Epoch 76, Iteration 30, Current loss 0.2892689101975435 Accuracy 91.72328086164043\n",
      "Training:: Epoch 76, Iteration 40, Current loss 0.21992425206582633 Accuracy 89.4180255168179\n",
      "Training:: Epoch 76, Iteration 50, Current loss 0.21709144255383858 Accuracy 87.8258960425929\n",
      "Training:: Epoch 76, Iteration 60, Current loss 0.34283317480591136 Accuracy 82.35813862163754\n",
      "Training:: Epoch 76, Iteration 70, Current loss 0.2721131298911721 Accuracy 91.13499654866384\n",
      "Training:: Epoch 76, Iteration 80, Current loss 0.28520591334969997 Accuracy 88.69639681180423\n",
      "Training:: Epoch 76, Iteration 90, Current loss 0.26707156511934166 Accuracy 80.72849577787319\n",
      "Training:: Epoch 76, Iteration 100, Current loss 0.25040951358145536 Accuracy 88.14279643008925\n",
      "Training:: Epoch 76, Iteration 110, Current loss 0.27266061248336104 Accuracy 88.97263932577602\n",
      "Training:: Epoch 76, Iteration 120, Current loss 0.3332041012558779 Accuracy 86.3394006251149\n",
      "Training:: Epoch 76, Iteration 130, Current loss 0.22509222331894901 Accuracy 87.83662110174348\n",
      "Training:: Epoch 76, Iteration 140, Current loss 0.2794887253240495 Accuracy 87.78403168647071\n",
      "Training:: Epoch 76, Iteration 150, Current loss 0.23809002422749265 Accuracy 90.49887763983692\n",
      "Starting Training\n",
      "Training:: Epoch 77, Iteration 0, Current loss 0.2139641362798965 Accuracy 88.0610355615144\n",
      "Training:: Epoch 77, Iteration 10, Current loss 0.25971489386786106 Accuracy 87.39508506616257\n",
      "Training:: Epoch 77, Iteration 20, Current loss 0.2831975254573283 Accuracy 88.73805932629462\n",
      "Training:: Epoch 77, Iteration 30, Current loss 0.22791268691968325 Accuracy 87.68142329501119\n",
      "Training:: Epoch 77, Iteration 40, Current loss 0.2502377596268226 Accuracy 90.37433155080214\n",
      "Training:: Epoch 77, Iteration 50, Current loss 0.21548429935559385 Accuracy 88.61044417767107\n",
      "Training:: Epoch 77, Iteration 60, Current loss 0.232805078828489 Accuracy 90.41250798957668\n",
      "Training:: Epoch 77, Iteration 70, Current loss 0.23773733773570652 Accuracy 90.15526164462335\n",
      "Training:: Epoch 77, Iteration 80, Current loss 0.27924923345947905 Accuracy 84.13976393340108\n",
      "Training:: Epoch 77, Iteration 90, Current loss 0.21033642493723562 Accuracy 90.22229329921637\n",
      "Training:: Epoch 77, Iteration 100, Current loss 0.2499738272531227 Accuracy 87.48414842586976\n",
      "Training:: Epoch 77, Iteration 110, Current loss 0.23145102456129685 Accuracy 90.08697195598154\n",
      "Training:: Epoch 77, Iteration 120, Current loss 0.20142319666515682 Accuracy 90.53720465499\n",
      "Training:: Epoch 77, Iteration 130, Current loss 0.19542900340633282 Accuracy 92.06069936221685\n",
      "Training:: Epoch 77, Iteration 140, Current loss 0.2415156036874566 Accuracy 74.8792270531401\n",
      "Training:: Epoch 77, Iteration 150, Current loss 0.21232074334058876 Accuracy 89.736946990833\n",
      "Starting Training\n",
      "Training:: Epoch 78, Iteration 0, Current loss 0.26159589273911277 Accuracy 88.10801649624315\n",
      "Training:: Epoch 78, Iteration 10, Current loss 0.28236627216292876 Accuracy 79.62655070980944\n",
      "Training:: Epoch 78, Iteration 20, Current loss 0.23789973852291127 Accuracy 84.36038117239387\n",
      "Training:: Epoch 78, Iteration 30, Current loss 0.2938437466559416 Accuracy 86.18840949706409\n",
      "Training:: Epoch 78, Iteration 40, Current loss 0.27286495265216304 Accuracy 87.33439021628355\n",
      "Training:: Epoch 78, Iteration 50, Current loss 0.3576162158024046 Accuracy 83.20132013201321\n",
      "Training:: Epoch 78, Iteration 60, Current loss 0.21163472948537895 Accuracy 85.52957000911182\n",
      "Training:: Epoch 78, Iteration 70, Current loss 0.2921021655055984 Accuracy 85.24754683318466\n",
      "Training:: Epoch 78, Iteration 80, Current loss 0.20082458134968442 Accuracy 90.27792797664107\n",
      "Training:: Epoch 78, Iteration 90, Current loss 0.2513787444473729 Accuracy 88.42753710148406\n",
      "Training:: Epoch 78, Iteration 100, Current loss 0.31333464176813786 Accuracy 83.31780923994039\n",
      "Training:: Epoch 78, Iteration 110, Current loss 0.23500902240979754 Accuracy 87.49711826634903\n",
      "Training:: Epoch 78, Iteration 120, Current loss 0.25084767496875277 Accuracy 86.69673683038201\n",
      "Training:: Epoch 78, Iteration 130, Current loss 0.23975426021155116 Accuracy 89.71397139713972\n",
      "Training:: Epoch 78, Iteration 140, Current loss 0.2200747868905302 Accuracy 88.97449066940592\n",
      "Training:: Epoch 78, Iteration 150, Current loss 0.21099019468940167 Accuracy 86.01018838908112\n",
      "Starting Training\n",
      "Training:: Epoch 79, Iteration 0, Current loss 0.2187529352829242 Accuracy 92.8560139086455\n",
      "Training:: Epoch 79, Iteration 10, Current loss 0.2566324482494989 Accuracy 87.70647482014388\n",
      "Training:: Epoch 79, Iteration 20, Current loss 0.1978790079930952 Accuracy 85.89492895320036\n",
      "Training:: Epoch 79, Iteration 30, Current loss 0.1875060260796492 Accuracy 91.80593273448925\n",
      "Training:: Epoch 79, Iteration 40, Current loss 0.3444051084285781 Accuracy 85.55973659454375\n",
      "Training:: Epoch 79, Iteration 50, Current loss 0.24741615710562495 Accuracy 77.48334342822533\n",
      "Training:: Epoch 79, Iteration 60, Current loss 0.25599766816140845 Accuracy 87.93542905692438\n",
      "Training:: Epoch 79, Iteration 70, Current loss 0.2771010295275574 Accuracy 84.49654112221369\n",
      "Training:: Epoch 79, Iteration 80, Current loss 0.17457065666034596 Accuracy 92.80417204918425\n",
      "Training:: Epoch 79, Iteration 90, Current loss 0.31980650167166014 Accuracy 85.54367907099498\n",
      "Training:: Epoch 79, Iteration 100, Current loss 0.22220626375601035 Accuracy 87.04221097938533\n",
      "Training:: Epoch 79, Iteration 110, Current loss 0.26110442765750413 Accuracy 91.93347768001105\n",
      "Training:: Epoch 79, Iteration 120, Current loss 0.2070263482245443 Accuracy 78.8978627006796\n",
      "Training:: Epoch 79, Iteration 130, Current loss 0.23760088244498465 Accuracy 85.38771342674004\n",
      "Training:: Epoch 79, Iteration 140, Current loss 0.29954412394764574 Accuracy 85.41101356743815\n",
      "Training:: Epoch 79, Iteration 150, Current loss 0.28776070393482156 Accuracy 87.51743375174337\n",
      "Starting Training\n",
      "Training:: Epoch 80, Iteration 0, Current loss 0.18618988836212735 Accuracy 90.55865676234012\n",
      "Training:: Epoch 80, Iteration 10, Current loss 0.41395207700656483 Accuracy 82.46703611695013\n",
      "Training:: Epoch 80, Iteration 20, Current loss 0.24831929268598033 Accuracy 89.09343200740055\n",
      "Training:: Epoch 80, Iteration 30, Current loss 0.27255030036716715 Accuracy 88.94680725032579\n",
      "Training:: Epoch 80, Iteration 40, Current loss 0.2273971612693251 Accuracy 90.35418236623964\n",
      "Training:: Epoch 80, Iteration 50, Current loss 0.22480933830432684 Accuracy 90.55703821475214\n",
      "Training:: Epoch 80, Iteration 60, Current loss 0.23260995312279847 Accuracy 88.70563674321504\n",
      "Training:: Epoch 80, Iteration 70, Current loss 0.19945958166243818 Accuracy 92.20388756817228\n",
      "Training:: Epoch 80, Iteration 80, Current loss 0.20886359183648273 Accuracy 92.53919814795327\n",
      "Training:: Epoch 80, Iteration 90, Current loss 0.2609831389903157 Accuracy 83.8364106118848\n",
      "Training:: Epoch 80, Iteration 100, Current loss 0.2709500598331041 Accuracy 88.79334849346219\n",
      "Training:: Epoch 80, Iteration 110, Current loss 0.22614429587646773 Accuracy 89.1891891891892\n",
      "Training:: Epoch 80, Iteration 120, Current loss 0.35317610332507116 Accuracy 90.15557476231633\n",
      "Training:: Epoch 80, Iteration 130, Current loss 0.19968270877374483 Accuracy 89.887551785362\n",
      "Training:: Epoch 80, Iteration 140, Current loss 0.2575282039254627 Accuracy 86.55486207060841\n",
      "Training:: Epoch 80, Iteration 150, Current loss 0.20837943835903253 Accuracy 91.89077178117518\n",
      "Calculating Expectation\n",
      "Epoch 80 iter 0\n",
      "Epoch 80 iter 10\n",
      "Epoch 80 iter 20\n",
      "Epoch 80 iter 30\n",
      "Epoch 80 iter 40\n",
      "Epoch 80 iter 50\n",
      "Epoch 80 iter 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 iter 70\n",
      "Epoch 80 iter 80\n",
      "Epoch 80 iter 90\n",
      "Epoch 80 iter 100\n",
      "Epoch 80 iter 110\n",
      "Epoch 80 iter 120\n",
      "Epoch 80 iter 130\n",
      "Epoch 80 iter 140\n",
      "Epoch 80 iter 150\n",
      "Train Boundary avergage error = 88.654\n",
      "Train From boundary avergage accuracy = 88.000\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 80, Probability Accuracy 65.27488917429672\n",
      "Starting Training\n",
      "Training:: Epoch 81, Iteration 0, Current loss 0.2330535409564874 Accuracy 89.6169275544718\n",
      "Training:: Epoch 81, Iteration 10, Current loss 0.15883315382201757 Accuracy 90.62750601443464\n",
      "Training:: Epoch 81, Iteration 20, Current loss 0.20848944252596407 Accuracy 86.54608916389022\n",
      "Training:: Epoch 81, Iteration 30, Current loss 0.27989775968078395 Accuracy 87.05432937181664\n",
      "Training:: Epoch 81, Iteration 40, Current loss 0.21295247681617058 Accuracy 88.57832294389705\n",
      "Training:: Epoch 81, Iteration 50, Current loss 0.28690550970412704 Accuracy 88.05817810665987\n",
      "Training:: Epoch 81, Iteration 60, Current loss 0.3586388259117707 Accuracy 88.55063254578015\n",
      "Training:: Epoch 81, Iteration 70, Current loss 0.44694280151921234 Accuracy 63.376784605834885\n",
      "Training:: Epoch 81, Iteration 80, Current loss 0.4957493190591097 Accuracy 86.04625056129322\n",
      "Training:: Epoch 81, Iteration 90, Current loss 0.30998799781541847 Accuracy 89.22510406660263\n",
      "Training:: Epoch 81, Iteration 100, Current loss 0.3011342004632423 Accuracy 89.32612906514426\n",
      "Training:: Epoch 81, Iteration 110, Current loss 0.3205156773371463 Accuracy 88.50686193686049\n",
      "Training:: Epoch 81, Iteration 120, Current loss 0.3654783206998305 Accuracy 87.14153561517114\n",
      "Training:: Epoch 81, Iteration 130, Current loss 0.6800742760509008 Accuracy 87.89280084077772\n",
      "Training:: Epoch 81, Iteration 140, Current loss 0.3315238905273361 Accuracy 88.43255928853755\n",
      "Training:: Epoch 81, Iteration 150, Current loss 0.3661221431794862 Accuracy 86.76424000506874\n",
      "Starting Training\n",
      "Training:: Epoch 82, Iteration 0, Current loss 0.52322092620375 Accuracy 84.06975128525775\n",
      "Training:: Epoch 82, Iteration 10, Current loss 0.3549858858266176 Accuracy 86.90557806170146\n",
      "Training:: Epoch 82, Iteration 20, Current loss 0.47326292100957035 Accuracy 91.16924337053342\n",
      "Training:: Epoch 82, Iteration 30, Current loss 0.3638358507335415 Accuracy 88.40357598978288\n",
      "Training:: Epoch 82, Iteration 40, Current loss 0.20936811476719153 Accuracy 89.86310931864894\n",
      "Training:: Epoch 82, Iteration 50, Current loss 0.31650415654013575 Accuracy 91.45444641154842\n",
      "Training:: Epoch 82, Iteration 60, Current loss 0.2374973181188415 Accuracy 87.85281579537806\n",
      "Training:: Epoch 82, Iteration 70, Current loss 0.23196102626080492 Accuracy 92.33333333333333\n",
      "Training:: Epoch 82, Iteration 80, Current loss 0.47592597398964565 Accuracy 90.4295310285327\n",
      "Training:: Epoch 82, Iteration 90, Current loss 0.3113946602932184 Accuracy 89.8678842043909\n",
      "Training:: Epoch 82, Iteration 100, Current loss 0.36087172875711093 Accuracy 84.71926083866383\n",
      "Training:: Epoch 82, Iteration 110, Current loss 0.34417188276023436 Accuracy 87.18180176927243\n",
      "Training:: Epoch 82, Iteration 120, Current loss 0.314587211283377 Accuracy 88.80242463958061\n",
      "Training:: Epoch 82, Iteration 130, Current loss 0.3790075482965017 Accuracy 86.31840796019901\n",
      "Training:: Epoch 82, Iteration 140, Current loss 0.4321357492760861 Accuracy 85.87684609797434\n",
      "Training:: Epoch 82, Iteration 150, Current loss 0.3584320309062829 Accuracy 91.52779215402133\n",
      "Starting Training\n",
      "Training:: Epoch 83, Iteration 0, Current loss 0.4065859001653663 Accuracy 82.55788190982608\n",
      "Training:: Epoch 83, Iteration 10, Current loss 1.3087440541254336 Accuracy 86.30241979634293\n",
      "Training:: Epoch 83, Iteration 20, Current loss 0.4957243487475299 Accuracy 85.53854565336249\n",
      "Training:: Epoch 83, Iteration 30, Current loss 0.422662313277427 Accuracy 86.1505623512027\n",
      "Training:: Epoch 83, Iteration 40, Current loss 0.4490067699317775 Accuracy 86.54101822163135\n",
      "Training:: Epoch 83, Iteration 50, Current loss 0.28272488890752945 Accuracy 92.3495904536194\n",
      "Training:: Epoch 83, Iteration 60, Current loss 0.340683448806343 Accuracy 85.26033119498732\n",
      "Training:: Epoch 83, Iteration 70, Current loss 0.34020836808431243 Accuracy 87.36437613019892\n",
      "Training:: Epoch 83, Iteration 80, Current loss 0.2762663439362271 Accuracy 92.04171862600612\n",
      "Training:: Epoch 83, Iteration 90, Current loss 0.3036875844157779 Accuracy 89.39778129952457\n",
      "Training:: Epoch 83, Iteration 100, Current loss 0.26124335655826064 Accuracy 86.88782489740082\n",
      "Training:: Epoch 83, Iteration 110, Current loss 0.3708038548823753 Accuracy 85.98183881952328\n",
      "Training:: Epoch 83, Iteration 120, Current loss 0.38319197574578145 Accuracy 87.88770968846285\n",
      "Training:: Epoch 83, Iteration 130, Current loss 0.29660972171573696 Accuracy 87.52265363281893\n",
      "Training:: Epoch 83, Iteration 140, Current loss 0.434166327170284 Accuracy 82.00585039699122\n",
      "Training:: Epoch 83, Iteration 150, Current loss 0.290285275402809 Accuracy 85.81704168203615\n",
      "Starting Training\n",
      "Training:: Epoch 84, Iteration 0, Current loss 0.23211468400990576 Accuracy 91.99147178359651\n",
      "Training:: Epoch 84, Iteration 10, Current loss 0.2756277891004428 Accuracy 86.90664556962025\n",
      "Training:: Epoch 84, Iteration 20, Current loss 0.3130574110057546 Accuracy 88.3568960100534\n",
      "Training:: Epoch 84, Iteration 30, Current loss 0.258195303630144 Accuracy 89.51757972199509\n",
      "Training:: Epoch 84, Iteration 40, Current loss 0.3518821885668918 Accuracy 88.8046544428773\n",
      "Training:: Epoch 84, Iteration 50, Current loss 0.41599256943189156 Accuracy 79.1125254132414\n",
      "Training:: Epoch 84, Iteration 60, Current loss 0.25216048064328567 Accuracy 87.187690432663\n",
      "Training:: Epoch 84, Iteration 70, Current loss 0.22846863592863303 Accuracy 91.59896138705084\n",
      "Training:: Epoch 84, Iteration 80, Current loss 0.31043392022275956 Accuracy 85.33009383378015\n",
      "Training:: Epoch 84, Iteration 90, Current loss 0.2606676577711361 Accuracy 85.87066840655358\n",
      "Training:: Epoch 84, Iteration 100, Current loss 0.47755221756056065 Accuracy 87.60558890718802\n",
      "Training:: Epoch 84, Iteration 110, Current loss 0.2257585501277662 Accuracy 90.85946180974926\n",
      "Training:: Epoch 84, Iteration 120, Current loss 0.3428631721032702 Accuracy 84.95909376966645\n",
      "Training:: Epoch 84, Iteration 130, Current loss 0.2676286898063375 Accuracy 85.98504021146167\n",
      "Training:: Epoch 84, Iteration 140, Current loss 0.3939017409219009 Accuracy 87.56894357233772\n",
      "Training:: Epoch 84, Iteration 150, Current loss 0.2304110412841927 Accuracy 86.76388423287518\n",
      "Starting Training\n",
      "Training:: Epoch 85, Iteration 0, Current loss 0.2551027885064441 Accuracy 87.10665969055984\n",
      "Training:: Epoch 85, Iteration 10, Current loss 0.38348764767688537 Accuracy 86.78144564598747\n",
      "Training:: Epoch 85, Iteration 20, Current loss 0.26616022526902894 Accuracy 85.5007557521133\n",
      "Training:: Epoch 85, Iteration 30, Current loss 0.20909975847381426 Accuracy 93.9686771076308\n",
      "Training:: Epoch 85, Iteration 40, Current loss 0.26866746298034294 Accuracy 87.01510531168002\n",
      "Training:: Epoch 85, Iteration 50, Current loss 0.22258953333411094 Accuracy 87.38382992301862\n",
      "Training:: Epoch 85, Iteration 60, Current loss 0.21757917279233993 Accuracy 89.92307692307692\n",
      "Training:: Epoch 85, Iteration 70, Current loss 0.30825581881075975 Accuracy 84.73247830029797\n",
      "Training:: Epoch 85, Iteration 80, Current loss 0.1932353498336815 Accuracy 92.29324665944384\n",
      "Training:: Epoch 85, Iteration 90, Current loss 0.19214274364602654 Accuracy 87.28334648776638\n",
      "Training:: Epoch 85, Iteration 100, Current loss 0.33905986943075883 Accuracy 86.35068930158369\n",
      "Training:: Epoch 85, Iteration 110, Current loss 0.22494331417568939 Accuracy 86.79750223015165\n",
      "Training:: Epoch 85, Iteration 120, Current loss 0.2052051171917948 Accuracy 85.41430743844437\n",
      "Training:: Epoch 85, Iteration 130, Current loss 0.25603554836035997 Accuracy 88.3364768012071\n",
      "Training:: Epoch 85, Iteration 140, Current loss 0.21238146584903353 Accuracy 91.51869646960517\n",
      "Training:: Epoch 85, Iteration 150, Current loss 0.21572173736936012 Accuracy 89.87283941216782\n",
      "Calculating Expectation\n",
      "Epoch 85 iter 0\n",
      "Epoch 85 iter 10\n",
      "Epoch 85 iter 20\n",
      "Epoch 85 iter 30\n",
      "Epoch 85 iter 40\n",
      "Epoch 85 iter 50\n",
      "Epoch 85 iter 60\n",
      "Epoch 85 iter 70\n",
      "Epoch 85 iter 80\n",
      "Epoch 85 iter 90\n",
      "Epoch 85 iter 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 iter 110\n",
      "Epoch 85 iter 120\n",
      "Epoch 85 iter 130\n",
      "Epoch 85 iter 140\n",
      "Epoch 85 iter 150\n",
      "Train Boundary avergage error = 89.035\n",
      "Train From boundary avergage accuracy = 87.876\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 85, Probability Accuracy 64.52458880556821\n",
      "Starting Training\n",
      "Training:: Epoch 86, Iteration 0, Current loss 0.22979921997095923 Accuracy 77.72362007640628\n",
      "Training:: Epoch 86, Iteration 10, Current loss 0.418823662934479 Accuracy 84.00129806912219\n",
      "Training:: Epoch 86, Iteration 20, Current loss 0.27305758797239843 Accuracy 83.02416524616464\n",
      "Training:: Epoch 86, Iteration 30, Current loss 0.19125765889430205 Accuracy 91.95211960635882\n",
      "Training:: Epoch 86, Iteration 40, Current loss 0.18319932365248523 Accuracy 87.7996594035195\n",
      "Training:: Epoch 86, Iteration 50, Current loss 0.19003038121265517 Accuracy 89.64249393726043\n",
      "Training:: Epoch 86, Iteration 60, Current loss 0.49991598177761754 Accuracy 82.04185058034984\n",
      "Training:: Epoch 86, Iteration 70, Current loss 0.23454722552036056 Accuracy 85.11075334480653\n",
      "Training:: Epoch 86, Iteration 80, Current loss 0.3275320223967032 Accuracy 79.66351372305783\n",
      "Training:: Epoch 86, Iteration 90, Current loss 0.23200514500685215 Accuracy 85.78677943467616\n",
      "Training:: Epoch 86, Iteration 100, Current loss 0.2172559849859666 Accuracy 89.75991510810452\n",
      "Training:: Epoch 86, Iteration 110, Current loss 0.18577454270599925 Accuracy 90.5971458920242\n",
      "Training:: Epoch 86, Iteration 120, Current loss 0.27460302688753835 Accuracy 87.29281767955801\n",
      "Training:: Epoch 86, Iteration 130, Current loss 0.2329582277023348 Accuracy 89.68590211833455\n",
      "Training:: Epoch 86, Iteration 140, Current loss 0.27743494866999713 Accuracy 90.64918187725205\n",
      "Training:: Epoch 86, Iteration 150, Current loss 0.3338764594022343 Accuracy 88.699468309562\n",
      "Starting Training\n",
      "Training:: Epoch 87, Iteration 0, Current loss 0.3899699484175992 Accuracy 72.19193711967546\n",
      "Training:: Epoch 87, Iteration 10, Current loss 0.20347408305788758 Accuracy 86.7896746882621\n",
      "Training:: Epoch 87, Iteration 20, Current loss 0.3545383368047347 Accuracy 83.65031925010189\n",
      "Training:: Epoch 87, Iteration 30, Current loss 0.2566048967234347 Accuracy 90.79389312977099\n",
      "Training:: Epoch 87, Iteration 40, Current loss 0.2264492599957761 Accuracy 74.93183367416496\n",
      "Training:: Epoch 87, Iteration 50, Current loss 0.2640305901965439 Accuracy 86.66105814170874\n",
      "Training:: Epoch 87, Iteration 60, Current loss 0.2293831975271252 Accuracy 89.6569150429558\n",
      "Training:: Epoch 87, Iteration 70, Current loss 0.21848319566494595 Accuracy 87.29239316744489\n",
      "Training:: Epoch 87, Iteration 80, Current loss 0.2869946180121478 Accuracy 85.90037611228328\n",
      "Training:: Epoch 87, Iteration 90, Current loss 0.24994548940835373 Accuracy 89.07812654718289\n",
      "Training:: Epoch 87, Iteration 100, Current loss 0.3646697338434772 Accuracy 85.79623495192696\n",
      "Training:: Epoch 87, Iteration 110, Current loss 0.250071094202846 Accuracy 85.79740662750748\n",
      "Training:: Epoch 87, Iteration 120, Current loss 0.230109984322186 Accuracy 86.07782101167315\n",
      "Training:: Epoch 87, Iteration 130, Current loss 0.20330346966324309 Accuracy 91.40966332562323\n",
      "Training:: Epoch 87, Iteration 140, Current loss 0.27988596624005446 Accuracy 91.39191073919108\n",
      "Training:: Epoch 87, Iteration 150, Current loss 0.22811588688080733 Accuracy 90.46563192904657\n",
      "Starting Training\n",
      "Training:: Epoch 88, Iteration 0, Current loss 0.3606226354989437 Accuracy 87.61388286334056\n",
      "Training:: Epoch 88, Iteration 10, Current loss 0.3700208037628193 Accuracy 82.92328906306699\n",
      "Training:: Epoch 88, Iteration 20, Current loss 0.3131817112116813 Accuracy 89.5745280360665\n",
      "Training:: Epoch 88, Iteration 30, Current loss 0.3616190413003054 Accuracy 86.21321657672335\n",
      "Training:: Epoch 88, Iteration 40, Current loss 0.21552141771956243 Accuracy 86.28198149156233\n",
      "Training:: Epoch 88, Iteration 50, Current loss 0.26524334323351 Accuracy 87.90584415584415\n",
      "Training:: Epoch 88, Iteration 60, Current loss 0.2928180005287002 Accuracy 90.22514825610614\n",
      "Training:: Epoch 88, Iteration 70, Current loss 1.241689478805599 Accuracy 81.64958227173076\n",
      "Training:: Epoch 88, Iteration 80, Current loss 0.4703896724213712 Accuracy 84.42721028140926\n",
      "Training:: Epoch 88, Iteration 90, Current loss 0.7373796141087211 Accuracy 82.81427310553524\n",
      "Training:: Epoch 88, Iteration 100, Current loss 0.8101743519611359 Accuracy 88.91389432485323\n",
      "Training:: Epoch 88, Iteration 110, Current loss 1.1202538444189123 Accuracy 87.42939303686967\n",
      "Training:: Epoch 88, Iteration 120, Current loss 2.0764379531768817 Accuracy 77.67775124012493\n",
      "Training:: Epoch 88, Iteration 130, Current loss 4.236313187167955 Accuracy 71.5375126163508\n",
      "Training:: Epoch 88, Iteration 140, Current loss 3.189188305890429 Accuracy 73.30536689306166\n",
      "Training:: Epoch 88, Iteration 150, Current loss 2.6366478691939284 Accuracy 72.99344066785928\n",
      "Starting Training\n",
      "Training:: Epoch 89, Iteration 0, Current loss 2.0996812320301386 Accuracy 81.13790596219098\n",
      "Training:: Epoch 89, Iteration 10, Current loss 2.3706211728552176 Accuracy 82.38196395532104\n",
      "Training:: Epoch 89, Iteration 20, Current loss 1.1910553628300415 Accuracy 86.76005118189777\n",
      "Training:: Epoch 89, Iteration 30, Current loss 1.4696887083877586 Accuracy 88.56645069962433\n",
      "Training:: Epoch 89, Iteration 40, Current loss 1.0996183131996693 Accuracy 77.56489093145187\n",
      "Training:: Epoch 89, Iteration 50, Current loss 0.6972765277565098 Accuracy 90.79631602029949\n",
      "Training:: Epoch 89, Iteration 60, Current loss 0.6494718953711658 Accuracy 85.76743556788203\n",
      "Training:: Epoch 89, Iteration 70, Current loss 0.681078827680802 Accuracy 88.12657819803363\n",
      "Training:: Epoch 89, Iteration 80, Current loss 0.8161854324993364 Accuracy 85.85206440299697\n",
      "Training:: Epoch 89, Iteration 90, Current loss 0.7673908280605467 Accuracy 84.98570974912671\n",
      "Training:: Epoch 89, Iteration 100, Current loss 0.6199660320446804 Accuracy 90.20869232242006\n",
      "Training:: Epoch 89, Iteration 110, Current loss 0.5774356890673246 Accuracy 85.95501890798116\n",
      "Training:: Epoch 89, Iteration 120, Current loss 0.4873036152956217 Accuracy 86.30557339613216\n",
      "Training:: Epoch 89, Iteration 130, Current loss 0.7981504102238174 Accuracy 87.84983244271352\n",
      "Training:: Epoch 89, Iteration 140, Current loss 0.43245763415853766 Accuracy 90.32911392405063\n",
      "Training:: Epoch 89, Iteration 150, Current loss 0.34843014421845875 Accuracy 90.95857786850387\n",
      "Starting Training\n",
      "Training:: Epoch 90, Iteration 0, Current loss 0.4484684336136855 Accuracy 90.71378463696948\n",
      "Training:: Epoch 90, Iteration 10, Current loss 0.6795180432415238 Accuracy 81.71032012536378\n",
      "Training:: Epoch 90, Iteration 20, Current loss 0.5107959085244123 Accuracy 86.23510466988728\n",
      "Training:: Epoch 90, Iteration 30, Current loss 0.42578481415686903 Accuracy 86.68244406196213\n",
      "Training:: Epoch 90, Iteration 40, Current loss 0.6790282189598773 Accuracy 85.72731418148655\n",
      "Training:: Epoch 90, Iteration 50, Current loss 0.36750978682533336 Accuracy 89.09310312819085\n",
      "Training:: Epoch 90, Iteration 60, Current loss 0.300225704349511 Accuracy 89.88473629060427\n",
      "Training:: Epoch 90, Iteration 70, Current loss 0.25779075319960587 Accuracy 88.161487452867\n",
      "Training:: Epoch 90, Iteration 80, Current loss 0.43287702224690205 Accuracy 91.4638783269962\n",
      "Training:: Epoch 90, Iteration 90, Current loss 0.28459371807201655 Accuracy 92.37304424710722\n",
      "Training:: Epoch 90, Iteration 100, Current loss 0.5131998926872336 Accuracy 81.85966125129623\n",
      "Training:: Epoch 90, Iteration 110, Current loss 0.2591077413289932 Accuracy 84.2876987189381\n",
      "Training:: Epoch 90, Iteration 120, Current loss 0.3952120017146927 Accuracy 83.91132756738601\n",
      "Training:: Epoch 90, Iteration 130, Current loss 0.43936744487740775 Accuracy 87.38507167572911\n",
      "Training:: Epoch 90, Iteration 140, Current loss 0.4400616624705788 Accuracy 86.21718655289784\n",
      "Training:: Epoch 90, Iteration 150, Current loss 0.30513801828725545 Accuracy 85.3981649575585\n",
      "Calculating Expectation\n",
      "Epoch 90 iter 0\n",
      "Epoch 90 iter 10\n",
      "Epoch 90 iter 20\n",
      "Epoch 90 iter 30\n",
      "Epoch 90 iter 40\n",
      "Epoch 90 iter 50\n",
      "Epoch 90 iter 60\n",
      "Epoch 90 iter 70\n",
      "Epoch 90 iter 80\n",
      "Epoch 90 iter 90\n",
      "Epoch 90 iter 100\n",
      "Epoch 90 iter 110\n",
      "Epoch 90 iter 120\n",
      "Epoch 90 iter 130\n",
      "Epoch 90 iter 140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 iter 150\n",
      "Train Boundary avergage error = 89.257\n",
      "Train From boundary avergage accuracy = 87.820\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 90, Probability Accuracy 66.51986576625099\n",
      "Starting Training\n",
      "Training:: Epoch 91, Iteration 0, Current loss 0.2637809630171982 Accuracy 86.12561425061425\n",
      "Training:: Epoch 91, Iteration 10, Current loss 0.28875146765706744 Accuracy 88.72478111914732\n",
      "Training:: Epoch 91, Iteration 20, Current loss 0.21635878924957297 Accuracy 83.37126202738851\n",
      "Training:: Epoch 91, Iteration 30, Current loss 0.2694709876274435 Accuracy 89.30684987415822\n",
      "Training:: Epoch 91, Iteration 40, Current loss 0.2757635074683119 Accuracy 88.26577089501252\n",
      "Training:: Epoch 91, Iteration 50, Current loss 0.29285147740004686 Accuracy 90.3506734788667\n",
      "Training:: Epoch 91, Iteration 60, Current loss 0.28325551655583625 Accuracy 90.81306990881458\n",
      "Training:: Epoch 91, Iteration 70, Current loss 0.2133852235415748 Accuracy 89.28231582110482\n",
      "Training:: Epoch 91, Iteration 80, Current loss 0.39486749109453984 Accuracy 84.36822393061306\n",
      "Training:: Epoch 91, Iteration 90, Current loss 0.19863428048412315 Accuracy 89.58203368683718\n",
      "Training:: Epoch 91, Iteration 100, Current loss 0.4694668527100306 Accuracy 85.60021293585308\n",
      "Training:: Epoch 91, Iteration 110, Current loss 0.2658860242728855 Accuracy 88.41963885987167\n",
      "Training:: Epoch 91, Iteration 120, Current loss 0.2082847938366382 Accuracy 92.17109401461266\n",
      "Training:: Epoch 91, Iteration 130, Current loss 0.29597499209892214 Accuracy 84.13221980489858\n",
      "Training:: Epoch 91, Iteration 140, Current loss 0.393872569276812 Accuracy 87.26576391738476\n",
      "Training:: Epoch 91, Iteration 150, Current loss 0.21821677441490048 Accuracy 92.66442424676161\n",
      "Starting Training\n",
      "Training:: Epoch 92, Iteration 0, Current loss 0.21032009945551353 Accuracy 89.24762686042423\n",
      "Training:: Epoch 92, Iteration 10, Current loss 0.25154941449954454 Accuracy 85.17946196530168\n",
      "Training:: Epoch 92, Iteration 20, Current loss 0.18447588274901672 Accuracy 91.15142915061828\n",
      "Training:: Epoch 92, Iteration 30, Current loss 0.23599691141782092 Accuracy 85.3458709617354\n",
      "Training:: Epoch 92, Iteration 40, Current loss 0.2288851425371392 Accuracy 90.87477684264218\n",
      "Training:: Epoch 92, Iteration 50, Current loss 0.19394946067325386 Accuracy 90.41067246570759\n",
      "Training:: Epoch 92, Iteration 60, Current loss 0.21068632587393146 Accuracy 86.95574695574696\n",
      "Training:: Epoch 92, Iteration 70, Current loss 0.23533273051083775 Accuracy 87.48353096179183\n",
      "Training:: Epoch 92, Iteration 80, Current loss 0.20567955416902334 Accuracy 92.34324758842443\n",
      "Training:: Epoch 92, Iteration 90, Current loss 0.29355302856454296 Accuracy 87.57798165137615\n",
      "Training:: Epoch 92, Iteration 100, Current loss 0.2020633960847593 Accuracy 89.6596366673627\n",
      "Training:: Epoch 92, Iteration 110, Current loss 0.1831961507338236 Accuracy 89.22285835453775\n",
      "Training:: Epoch 92, Iteration 120, Current loss 0.21994173565748787 Accuracy 86.37185114151883\n",
      "Training:: Epoch 92, Iteration 130, Current loss 0.2525234110223727 Accuracy 86.50851879025026\n",
      "Training:: Epoch 92, Iteration 140, Current loss 0.218689227475867 Accuracy 88.26454784497543\n",
      "Training:: Epoch 92, Iteration 150, Current loss 0.2062212296030536 Accuracy 88.34985133795837\n",
      "Starting Training\n",
      "Training:: Epoch 93, Iteration 0, Current loss 0.23363750900205876 Accuracy 87.34627629689743\n",
      "Training:: Epoch 93, Iteration 10, Current loss 0.22537704270619519 Accuracy 86.8962598529334\n",
      "Training:: Epoch 93, Iteration 20, Current loss 0.17731447487444293 Accuracy 92.11848518935133\n",
      "Training:: Epoch 93, Iteration 30, Current loss 0.24290136266893453 Accuracy 84.89218609165916\n",
      "Training:: Epoch 93, Iteration 40, Current loss 0.25297586991386267 Accuracy 88.53664416586307\n",
      "Training:: Epoch 93, Iteration 50, Current loss 0.2271680614636398 Accuracy 90.41875795939771\n",
      "Training:: Epoch 93, Iteration 60, Current loss 0.19286694839998314 Accuracy 89.71513666714705\n",
      "Training:: Epoch 93, Iteration 70, Current loss 0.18570665485252824 Accuracy 83.78851321792388\n",
      "Training:: Epoch 93, Iteration 80, Current loss 0.2291117281686195 Accuracy 87.3265238148107\n",
      "Training:: Epoch 93, Iteration 90, Current loss 0.2716953855671019 Accuracy 85.94147582697201\n",
      "Training:: Epoch 93, Iteration 100, Current loss 0.2525200250916372 Accuracy 85.818237524415\n",
      "Training:: Epoch 93, Iteration 110, Current loss 0.28321396866476733 Accuracy 86.18236472945891\n",
      "Training:: Epoch 93, Iteration 120, Current loss 0.31341226527513333 Accuracy 88.44012944983818\n",
      "Training:: Epoch 93, Iteration 130, Current loss 0.2526136729368946 Accuracy 87.85845927018062\n",
      "Training:: Epoch 93, Iteration 140, Current loss 0.1643908514332992 Accuracy 90.64794127034791\n",
      "Training:: Epoch 93, Iteration 150, Current loss 0.270958612030763 Accuracy 82.33772342427093\n",
      "Starting Training\n",
      "Training:: Epoch 94, Iteration 0, Current loss 0.20961326911910616 Accuracy 90.55353708057277\n",
      "Training:: Epoch 94, Iteration 10, Current loss 0.19725704032035837 Accuracy 88.12709030100335\n",
      "Training:: Epoch 94, Iteration 20, Current loss 0.28523766895072517 Accuracy 84.13379930104843\n",
      "Training:: Epoch 94, Iteration 30, Current loss 0.23921409368481236 Accuracy 87.75933609958506\n",
      "Training:: Epoch 94, Iteration 40, Current loss 0.26873012062990187 Accuracy 89.92400307403297\n",
      "Training:: Epoch 94, Iteration 50, Current loss 0.20248244945960028 Accuracy 85.97252349963847\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8f16d820455b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmiddle_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mboundary_target_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_single_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/c2f_active_learn/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmiddle_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtower_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_stages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/c2f_active_learn/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/c2f_active_learn/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mfinal_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/c2f_active_learn/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dilated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    258\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 259\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initialize_epoch = 15\n",
    "expectation_cal_gap = 5\n",
    "for epoch in range(15, 1000):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        boundary_target_tensor = get_single_random(item_2, item[4])\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, boundary_target_tensor)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                            max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                es_loss, _ = get_estimated_loss(prob, item_1, item[4], item_2)\n",
    "                loss += es_loss\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(predictions[-1], dim=1)\n",
    "                correct = float(torch.sum((pred == item_2) * src_mask).item())\n",
    "                total = float(torch.sum(src_mask).item())\n",
    "                print(f\"Training:: Epoch {epoch}, Iteration {i}, Current loss {loss.item()}\" +\n",
    "                      f\" Accuracy {correct * 100.0 / total}\")\n",
    "                \n",
    "    # Calculating Expectation Step\n",
    "    model.eval()\n",
    "    if (epoch >= initialize_epoch) and (epoch % expectation_cal_gap == 0):\n",
    "        print(\"Calculating Expectation\")\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, item in enumerate(trainloader):\n",
    "            with torch.no_grad():\n",
    "                item_0 = item[0].to(device)\n",
    "                item_1 = item[1].to(device)\n",
    "                item_2 = item[2].to(device)\n",
    "                src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "                src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "                middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "                prob = torch.softmax(predictions[-1], dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                calculate_element_probb(prob, item_1, item[4], item_2)\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "#                     pred = torch.argmax(prob, dim=2)\n",
    "#                     correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "#                     total += float(torch.sum(src_mask).item())\n",
    "                    print(f\"Epoch {epoch} iter {i}\")\n",
    "                    \n",
    "#         print(f\"Epoch {epoch} After Expectation}, train acc. {correct * 100.0 / total: .3f}\")\n",
    "        get_boundary_err()\n",
    "\n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "\n",
    "    print(f\"Validation:: Epoch {epoch}, Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/ms-tcn-emmax-last-model.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/\"\n",
    "                            f\"/results/em-maximize-mstcn-speed/ms-tcn-em.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 94, Probability Accuracy 66.43224095786552\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Validation Data Accuracy\")\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "        pred = torch.argmax(predictions[-1], dim=1)\n",
    "        correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "        total += float(torch.sum(src_mask).item())\n",
    "\n",
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_labels(labels_arr):\n",
    "    unique_ids = []\n",
    "    \n",
    "    prev_ele = None\n",
    "    start = 0\n",
    "    for i, ele in enumerate(labels_arr):\n",
    "        if prev_ele is not None and prev_ele != ele:\n",
    "            select_item = np.random.randint(start, i, 1)[0]\n",
    "            unique_ids.append(select_item)\n",
    "            start = i\n",
    "        prev_ele = ele\n",
    "    \n",
    "    select_item = np.random.randint(start, len(labels_arr), 1)[0]\n",
    "    unique_ids.append(select_item)\n",
    "    return unique_ids\n",
    "# get_selected_labels(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary(labels_arr):\n",
    "    unique_ids = []\n",
    "    \n",
    "    prev_ele = None\n",
    "    start = 0\n",
    "    for i, ele in enumerate(labels_arr):\n",
    "        if prev_ele is not None and prev_ele != ele:\n",
    "            unique_ids.append(i - 1)\n",
    "            start = i\n",
    "        prev_ele = ele\n",
    "    \n",
    "    unique_ids.append(len(labels_arr) - 1)\n",
    "    return unique_ids\n",
    "# get_boundary(np.array([2, 2, 2, 2, 3, 3, 4, 4, 4, 1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vidid_selected_frames = {}\n",
    "for batch in trainloader:\n",
    "    count_all = batch[1]\n",
    "    labels_all = batch[2]\n",
    "    video_ids = batch[5]\n",
    "    for i, count in enumerate(count_all):\n",
    "        video_id = video_ids[i]\n",
    "        labels = labels_all[i][:count]\n",
    "        selected_ids = get_selected_labels(labels)\n",
    "\n",
    "        loaded_vidid_selected_frames[video_id] = selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id_boundary_frames = {}\n",
    "for batch in trainloader:\n",
    "    count_all = batch[1]\n",
    "    labels_all = batch[2]\n",
    "    video_ids = batch[4]\n",
    "    for i, count in enumerate(count_all):\n",
    "        \n",
    "        labels = labels_all[i][:count]\n",
    "        selected_ids = get_boundary(labels)\n",
    "        video_id = video_ids[i]\n",
    "        video_id_boundary_frames[video_id] = selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in video_id_boundary_frames.keys():\n",
    "    if len(video_id_boundary_frames[ele]) != len(loaded_vidid_selected_frames[ele + \".txt\"]):\n",
    "        print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(video_id_boundary_frames, open(\"dump_dir/video_id_boundary_frames_dict.pkl\", \"wb\"))\n",
    "# pickle.dump(loaded_vidid_selected_frames, open(\"dump_dir/loaded_vidid_selected_frames_dict.pkl\", \"wb\"))\n",
    "pickle.dump(video_id_boundary_frames, open(\"dump_dir/chunk_1_video_id_boundary_frames_dict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_out(outp):\n",
    "    \n",
    "    weights = [1, 1, 1, 1, 0, 0]\n",
    "    ensemble_prob = F.softmax(outp[0], dim=1) * weights[0] / sum(weights)\n",
    "\n",
    "    for i, outp_ele in enumerate(outp[1]):\n",
    "        upped_logit = F.upsample(outp_ele, size=outp[0].shape[-1], mode='linear', align_corners=True)\n",
    "        ensemble_prob = ensemble_prob + F.softmax(upped_logit, dim=1) * weights[i + 1] / sum(weights)\n",
    "    \n",
    "    return ensemble_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/results/c2f-tcn-model/split2_c2ftcn_model.wt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration done\n",
      "11 iteration done\n",
      "21 iteration done\n",
      "31 iteration done\n",
      "41 iteration done\n",
      "51 iteration done\n",
      "61 iteration done\n",
      "71 iteration done\n",
      "81 iteration done\n",
      "91 iteration done\n",
      "101 iteration done\n",
      "111 iteration done\n",
      "121 iteration done\n",
      "131 iteration done\n",
      "141 iteration done\n",
      "151 iteration done\n",
      "Train Boundary avergage error = 107.269\n",
      "Train From boundary avergage accuracy = 87.407\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        prob = torch.softmax(predictions[-1], dim=1)\n",
    "        prob = prob.permute(0, 2, 1)\n",
    "        calculate_element_probb(prob, item_1, item[4], item_2)\n",
    "\n",
    "        if i%10==0:\n",
    "            print(f'{i+1} iteration done')\n",
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    idx = 4\n",
    "\n",
    "    cur_vid_feat = torch.softmax(predictions[-1], dim=1).permute(0, 2, 1)[idx]\n",
    "    cur_vidid = item[4][idx]\n",
    "\n",
    "    selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "    \n",
    "    bound_list = video_id_boundary_frames[cur_vidid]\n",
    "    \n",
    "    cumsum_feat = torch.cumsum(cur_vid_feat, dim=0)\n",
    "    prob_each_segment = prob_vals_per_segment(selected_frames, cur_vid_feat, item_2[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min prob 0 = 7.953912266787591e-36\n",
      "Min prob 1 = 2.7495868628582206e-249\n",
      "Min prob 2 = 8.185175464823537e-201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 442)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ymax = 1\n",
    "selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "\n",
    "plt.plot([0, item[1][idx].item()], [0, 0])\n",
    "\n",
    "for pivot in loaded_vidid_selected_frames[cur_vidid + \".txt\"]:\n",
    "    plt.plot([pivot, pivot], [0, ymax], '--')\n",
    "    \n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, ymax])\n",
    "    \n",
    "all_prob = []\n",
    "for i, segment in enumerate(prob_each_segment):\n",
    "    segment = segment.cpu().numpy()\n",
    "    print(f\"Min prob {i} = {np.min(segment).item()}\")\n",
    "    xs = np.arange(loaded_vidid_selected_frames[cur_vidid + \".txt\"][i], \n",
    "                   loaded_vidid_selected_frames[cur_vidid + \".txt\"][i+1])\n",
    "    plt.plot(xs, segment, '*')\n",
    "\n",
    "    \n",
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "\n",
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]], item_2[idx].unsqueeze(0))\n",
    "loss_arr = -loss_arr[0].detach().cpu().numpy()\n",
    "plt.plot(np.arange(selected_frames[0] - 1, selected_frames[-1] + 1), loss_arr/np.max(loss_arr), 'k+')\n",
    "\n",
    "plt.ylim([0, ymax])\n",
    "plt.xlim([0, item[1][idx].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1895, 48])\n"
     ]
    }
   ],
   "source": [
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "print(loss_prob.shape)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]], item_2[idx].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1387])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faf5b8ecb00>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "plt.plot(np.arange(selected_frames[0] - 1, selected_frames[-1] + 1), loss_arr[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3987, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([75, 345, 1305, 1415, 1440, 1519],\n",
       " [73, 282, 455, 1312, 1434, 1458],\n",
       " tensor(1520, device='cuda:0', dtype=torch.int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid], loaded_vidid_selected_frames[cur_vidid + \".txt\"], item_1[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_features_shortened = cur_vid_feat[:item[1][idx]]\n",
    "cur_features_shortened[:, item[2][idx][:item[1][idx]]].shape\n",
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47, 47, 47, 47, 47, 47, 47,  4,  4,  4,  4,  4,  4,  4,  4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[2][idx][video_id_boundary_frames[cur_vidid][1]-6:video_id_boundary_frames[cur_vidid][1]+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid][0]-6,video_id_boundary_frames[cur_vidid][0]+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0794, 13.3350],\n",
       "        [ 1.0831, 13.5102],\n",
       "        [ 1.1767, 13.7662],\n",
       "        [ 1.3750, 14.0177],\n",
       "        [ 1.7298, 14.1727],\n",
       "        [ 2.1706, 14.0367],\n",
       "        [ 2.7338, 13.4563],\n",
       "        [ 4.5600, 12.1745],\n",
       "        [ 7.8450, 10.3246],\n",
       "        [11.0151,  8.3563],\n",
       "        [13.4775,  6.6546],\n",
       "        [14.1836,  5.2898],\n",
       "        [11.2142,  4.2791],\n",
       "        [ 5.9829,  3.5694],\n",
       "        [ 2.3440,  2.9389],\n",
       "        [ 0.7406,  2.3515]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_vid_feat[video_id_boundary_frames[cur_vidid][1]-7:video_id_boundary_frames[cur_vidid][1]+9][:,[47,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frames_and_get_classification_value(model_output, count_list, video_ids_list, labels_all, p_criterion):\n",
    "    new_selected_frames = {}\n",
    "#     new_selected_frames_probs_values = {}\n",
    "#     new_selected_frames_labels = {}\n",
    "    \n",
    "    labels_arr = []\n",
    "    probs_arr = []\n",
    "    \n",
    "    for i, video_id in enumerate(video_ids_list):\n",
    "        current_boundary_frames = boundaries_dict[video_id]\n",
    "        current_video_logits = model_output[i].T\n",
    "        current_video_count = count_list[i]\n",
    "        current_selected_frames = loaded_vidid_selected_frames[video_id]\n",
    "        labels = labels_all[i]\n",
    "        cur_seg_start = 0\n",
    "        for seg_num, ele in enumerate(current_boundary_frames):\n",
    "            cur_seg_end = ele + 1\n",
    "            total_seg_len = cur_seg_end - cur_seg_start\n",
    "            per_frames_far_from_boundary = int(0.3 * total_seg_len)\n",
    "            new_frames_start = cur_seg_start + per_frames_far_from_boundary\n",
    "            new_frames_end = cur_seg_end - per_frames_far_from_boundary\n",
    "            \n",
    "            frames_added = list(range(new_frames_start, new_frames_end))\n",
    "            frames_added.append(current_selected_frames[seg_num])\n",
    "            frames_added = list(set(frames_added))\n",
    "            frames_added.sort()\n",
    "            new_selected_frames[video_id] = frames_added\n",
    "\n",
    "            \n",
    "            labels_seg = torch.stack([labels[current_selected_frames[seg_num]]] * len(frames_added))\n",
    "            frames_added = torch.tensor(np.array(frames_added), dtype=torch.long, device=current_video_logits.device)\n",
    "            prob_seg = current_video_logits[frames_added, :]\n",
    "            \n",
    "            labels_arr.append(labels_seg)\n",
    "            probs_arr.append(prob_seg)\n",
    "            \n",
    "            cur_seg_start = cur_seg_end\n",
    "            \n",
    "    labels_arr = torch.cat(labels_arr)\n",
    "    probs_arr = torch.cat(probs_arr)\n",
    "    loss = p_criterion(probs_arr, labels_arr)\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
