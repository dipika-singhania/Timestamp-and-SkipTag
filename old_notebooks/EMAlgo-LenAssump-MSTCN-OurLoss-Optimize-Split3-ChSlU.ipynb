{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='5'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 3, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split3-slup15/', 'project_name': 'breakfast-split-3', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split3.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split3.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split3_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=3,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split3-slup15/\",\n",
    "    project_name=\"breakfast-split-3\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1279\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 433\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = Breakfast(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = iter(trainloader).next()\n",
    "# print(item[0]) # -- data feature\n",
    "# print(item[1]) # -- valid count\n",
    "# item[2] # -- Actual labels\n",
    "# print(item[5]) # video names\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_frames_dict = pickle.load(open(\"data/breakfast_len_assum_annotations.pkl\", 'rb'))\n",
    "# loaded_vidid_selected_frames\n",
    "boundary_frames_dict = pickle.load(open(\"data/breakfast_boundary_annotations.pkl\", \"rb\"))\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"data/breakfast_meanvar_actions.pkl\", \"rb\"))\n",
    "def get_possion_prob(cur_len, cur_class):\n",
    "    mean_class, std_class = loaded_mean_var_actions[label_id_to_label_name[cur_class]]\n",
    "    mean_class = mean_class\n",
    "    prob = cur_len * torch.log(torch.tensor(mean_class, device=device) + 1e-5)\n",
    "    prob = prob - mean_class\n",
    "    factorials = torch.cumsum(torch.log(torch.arange(1, torch.max(cur_len)+1, 1).type(torch.float).to(device)), \n",
    "                              dim=0)[min(cur_len)-1:]\n",
    "    prob = prob - factorials\n",
    "    return prob\n",
    "\n",
    "# get_possion_prob(torch.arange(10, 21), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_video_each_segment_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels):\n",
    "    prob_each_segment = []\n",
    "    \n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    cur_boundary = 0\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[i]\n",
    "        label_next_ele = labels[i + 1]\n",
    "\n",
    "        indices = torch.arange(cur_ele, next_ele).to(cumsum_feat.device)\n",
    "        strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "        end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "        left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "        right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "\n",
    "        cur_boundary_len = indices - cur_boundary\n",
    "        len_prob = get_possion_prob(cur_boundary_len, label_cur_ele)\n",
    "\n",
    "        prob = torch.softmax((left_sum + right_sum + len_prob), dim=0)\n",
    "#         prob = torch.softmax((left_sum + right_sum), dim=0)\n",
    "\n",
    "        cur_boundary = round(np.sum(np.arange(cur_ele, next_ele, 1) * prob.detach().cpu().numpy()).item())\n",
    "        prob_each_segment.append(prob)\n",
    "    \n",
    "    return prob_each_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_element_probb(data_feat, data_count, video_ids): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "        prob_video = prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels)\n",
    "        prob_video_each_segment_dict[cur_vidid] = prob_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_loss(data_feat, data_count, video_ids): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "#     global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    loss_arr = []\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "\n",
    "        prob_each_video = prob_video_each_segment_dict[cur_vidid]\n",
    "        \n",
    "        log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "        cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "        \n",
    "        \n",
    "        current_vid_prob_arr = []\n",
    "        # Start segment log probability\n",
    "        start_ele_idx = selected_frames_indices[0]\n",
    "        if start_ele_idx > 0:\n",
    "            start_ele_label_idx = selected_frames_labels[0]\n",
    "            first_segment_prob = (cumsum_feat[start_ele_idx - 1, :])[start_ele_label_idx]\n",
    "            current_vid_prob_arr.append(first_segment_prob.unsqueeze(0))\n",
    "        \n",
    "        for i, cur_ele in enumerate(selected_frames_indices[:-1]):\n",
    "            next_ele = selected_frames_indices[i + 1]\n",
    "            label_cur_ele = selected_frames_labels[i]\n",
    "            label_next_ele = selected_frames_labels[i + 1]\n",
    "\n",
    "            indices = torch.arange(cur_ele, next_ele)\n",
    "            strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "            end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "            left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "            right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "            current_vid_prob_arr.append((left_sum + right_sum)  * (prob_each_video[i]))\n",
    "        \n",
    "        # End segment log probability\n",
    "        end_index = cur_vid_count.item() - 1\n",
    "        last_ele_label_idx = selected_frames_labels[-1]\n",
    "        last_segment_sum_prob = (cumsum_feat[end_index, :] - cumsum_feat[selected_frames_indices[-1] - 1, \\\n",
    "                                                                         :])[last_ele_label_idx]\n",
    "        current_vid_prob_arr.append(last_segment_sum_prob.unsqueeze(0))\n",
    "            \n",
    "        loss_arr.append(torch.cat(current_vid_prob_arr))\n",
    "    return -torch.mean(torch.cat(loss_arr)), loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_file_list = set(open(config.train_split_file).read().split(\"\\n\")[0:-1])\n",
    "\n",
    "def get_estimated_boundaries():\n",
    "    estimated_boundary_dict = {}\n",
    "    for video_id in train_split_file_list:\n",
    "        ele = video_id.split(\".txt\")[0]\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        \n",
    "        selected_frames_indices_and_labels = selected_frames_dict[video_id]\n",
    "        selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "        \n",
    "        boundary_list = []\n",
    "        for i, segment in enumerate(estimated_boundary_probs):\n",
    "            estimated_boundary = np.sum(np.arange(selected_frames_indices[i], selected_frames_indices[i + 1], 1) \\\n",
    "                                        * segment.detach().cpu().numpy())\n",
    "            estimated_boundary = round(estimated_boundary.item())\n",
    "            \n",
    "            if (estimated_boundary < selected_frames_indices[i]) or (estimated_boundary > selected_frames_indices[i + 1]):\n",
    "                print(\"Estimated value wrong\")\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "            boundary_list.append(estimated_boundary)\n",
    "\n",
    "        estimated_boundary_dict[ele] = boundary_list\n",
    "    return estimated_boundary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_err():\n",
    "    err_list = []\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    estimated_boundar_dict = get_estimated_boundaries()\n",
    "    for video_id in train_split_file_list:\n",
    "        ele = video_id.split(\".txt\")[0]\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        estimated_boundary_list = estimated_boundar_dict[ele]\n",
    "        \n",
    "        estimated = np.array(estimated_boundary_list) #.detach().cpu().numpy()\n",
    "        actual = np.array(boundary_frames_dict[video_id][:-1])\n",
    "        if len(actual) != len(estimated):\n",
    "            print(ele)\n",
    "            continue\n",
    "        \n",
    "        mse_err = (actual - estimated)**2\n",
    "        err_list.append(mse_err)\n",
    "        \n",
    "        estimated_labels = []\n",
    "        actual_labels = []\n",
    "        start_v1 = 0\n",
    "        start_v2 = 0\n",
    "        for i, v1 in enumerate(estimated):\n",
    "            estimated_labels.extend([i] * (v1 - start_v1))\n",
    "            start_v1 = v1\n",
    "            v2 = actual[i]\n",
    "            actual_labels.extend([i] * (v2 - start_v2))\n",
    "            start_v2 = v2\n",
    "            \n",
    "        last_ele = boundary_frames_dict[video_id][-1]\n",
    "        estimated_labels.extend([i+1] * (last_ele - start_v1))\n",
    "        actual_labels.extend([i+1] * (last_ele - start_v2))\n",
    "        \n",
    "        correct += np.sum(np.array(actual_labels) == np.array(estimated_labels))\n",
    "        total += len(actual_labels)\n",
    "        \n",
    "    print(f\"Train Boundary avergage error = {np.sqrt(np.mean(np.concatenate(err_list))):.3f}\")\n",
    "    print(f\"Train From boundary avergage accuracy = {correct * 100.0 / total:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_file=torch.load(\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split1/ms-tcn-best-model.wt\")\n",
    "# model.load_state_dict(loaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels_dir = \"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/length_segmentation_output/\"\n",
    "def get_single_random(output_p, video_ids):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((output_p.shape[0], output_p.shape[2]), dtype=torch.long, \n",
    "                                        device=output_p.device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        pseudo_l = open(pseudo_labels_dir + cur_vidid + \".txt\").read().split(\"\\n\")[0:-1]\n",
    "        pseudo_l = [label_name_to_label_id_dict[ele] for ele in pseudo_l]\n",
    "        abc = torch.tensor(pseudo_l).to(torch.long).to(boundary_target_tensor.device)\n",
    "        frame_idx_tensor = torch.arange(0, len(pseudo_l), 1).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = abc\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weakly_labels = pickle.load(open(\"data/breakfast_weaklysupervised_labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_probs = pickle.load(open('data/breakfast_lengthmodel_multinomial_prior.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def change_selected_frames(model):\n",
    "    global selected_frames_dict\n",
    "    new_selected_frame_dict = {}\n",
    "    with torch.no_grad():\n",
    "        for train_idx, item in enumerate(trainloader):\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "            if train_idx % 10 == 0:\n",
    "                print(f\"Completed {train_idx} videos selected frames calculation\")\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "            \n",
    "            for idx, video_id in enumerate(item[4]):\n",
    "                start = 0\n",
    "                new_index_label_pair_list = []\n",
    "                weakly_labels_video = [label_name_to_label_id_dict[wl] for wl in weakly_labels[video_id + \".txt\"]]\n",
    "                cur_video_predictions = predictions[-1][idx][:, :item_1[idx]]\n",
    "                cur_preds_for_weakly_labels = torch.softmax(cur_video_predictions[weakly_labels_video], dim=0)\n",
    "                prior_probs_cur_vid = prior_probs[video_id]\n",
    "                weakly_labels_masked = []\n",
    "                for i, prob_class in enumerate(cur_preds_for_weakly_labels):\n",
    "                    prob_class_masked = prob_class * torch.tensor(prior_probs_cur_vid[i], \n",
    "                                                                  dtype=prob_class.dtype, device=prob_class.device)\n",
    "                    weakly_labels_masked.append(prob_class_masked)\n",
    "                    \n",
    "                weakly_labels_masked = torch.stack(weakly_labels_masked)\n",
    "                weakly_labels_masked = weakly_labels_masked / torch.sum(weakly_labels_masked, dim=0)\n",
    "\n",
    "                for i in range(len(weakly_labels_video)):\n",
    "                    cur_l = weakly_labels_video[i]\n",
    "                    prob_class = weakly_labels_masked[i]\n",
    "                    expected_value_of_class = torch.argmax(prob_class)\n",
    "                    new_index_label_pair_list.append((int(expected_value_of_class.item()),\n",
    "                                                      weakly_labels_video[i])) \n",
    "                \n",
    "                back_list = copy.deepcopy(new_index_label_pair_list)\n",
    "                error_list = []\n",
    "                if new_index_label_pair_list[0][0] > new_index_label_pair_list[1][0]:\n",
    "                    error_list.append(1)\n",
    "                else:\n",
    "                    error_list.append(0)\n",
    "                for i in range(1, len(new_index_label_pair_list) - 1, 1):\n",
    "                    err = 0\n",
    "                    prev_ele = new_index_label_pair_list[i - 1]\n",
    "                    cur_ele = new_index_label_pair_list[i]\n",
    "                    next_ele = new_index_label_pair_list[i + 1]\n",
    "                    if not (prev_ele[0] < cur_ele[0]):\n",
    "                        err += 1\n",
    "                    if not (cur_ele[0] < next_ele[0]):\n",
    "                        err += 1\n",
    "                    error_list.append(err)\n",
    "\n",
    "                if new_index_label_pair_list[-1][0] < new_index_label_pair_list[-2][0]:\n",
    "                    error_list.append(1)\n",
    "                else:\n",
    "                    error_list.append(0)\n",
    "                    \n",
    "                if error_list[0] == 1 and error_list[1] == 1:\n",
    "                    new_index = new_index_label_pair_list[1][0] // 2\n",
    "                    new_index_label_pair_list[0] = (new_index, new_index_label_pair_list[0][1])\n",
    "                    error_list[0] = 0\n",
    "                    error_list[1] = 0\n",
    "                    \n",
    "                if error_list[-1] == 1 and error_list[-2] == 1:\n",
    "                    new_index = (new_index_label_pair_list[-2][0] + weakly_labels_masked.shape[1]) // 2\n",
    "                    new_index_label_pair_list[-1] = (new_index, new_index_label_pair_list[-1][1])\n",
    "                    error_list[-1] = 0\n",
    "                    error_list[-2] = 0\n",
    "                    \n",
    "                start_flag = False\n",
    "                start_index = -1\n",
    "                end_index = -1\n",
    "                for i in range(1, len(error_list) - 1):\n",
    "                    if error_list[i] == 1 and error_list[i + 1] == 2:\n",
    "                        start_flag = True\n",
    "                        start_index = i\n",
    "                        \n",
    "                    if (start_flag is True) and (error_list[i] == 2 or error_list[i + 1] == 1):\n",
    "                        start_flag = False\n",
    "                        end_index = i + 1\n",
    "                        \n",
    "                        num_div = end_index - start_index - 1\n",
    "                        increm = (new_index_label_pair_list[end_index][0] - \\\n",
    "                                  new_index_label_pair_list[start_index][0]) // num_div\n",
    "                        value = list(range(new_index_label_pair_list[start_index][0], \n",
    "                                           new_index_label_pair_list[end_index][0], increm))\n",
    "                        count = 0\n",
    "                        for ch_i in range(start_index + 1, end_index):\n",
    "                            old_ele = new_index_label_pair_list[ch_i]\n",
    "                            new_ele = (value[count], old_ele[1])\n",
    "                            new_index_label_pair_list[ch_i] = new_ele\n",
    "                            count += 1\n",
    "                    \n",
    "                final_list = new_index_label_pair_list\n",
    "                is_valid_list = True\n",
    "                for i in range(1, len(final_list) - 1, 1):\n",
    "                    cur_ele = final_list[i]\n",
    "                    \n",
    "                    if not (final_list[i - 1][0] < cur_ele[0] and cur_ele[0] < final_list[i + 1][0]):\n",
    "                        is_valid_list  = False\n",
    "\n",
    "                if is_valid_list == False:\n",
    "                    print(f\"Could not find expected solution for video {video_id}\")\n",
    "                    print(final_list)\n",
    "                    print(back_list)\n",
    "                    print(error_list)\n",
    "                    new_selected_frame_dict[video_id + \".txt\"] = selected_frames_dict[video_id + \".txt\"]\n",
    "                else:\n",
    "                \n",
    "                    label_name_final_list = []\n",
    "                    for ele in final_list:\n",
    "                        label_name_final_list.append((ele[0], label_id_to_label_name[ele[1]]))\n",
    "                    new_selected_frame_dict[video_id + \".txt\"] = label_name_final_list\n",
    "                \n",
    "        return new_selected_frame_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_selected_frame_acc(selected_frame_dict):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    for video_id in selected_frame_dict.keys():\n",
    "        ground_labels = open(config.ground_truth_files_dir + video_id).read().split(\"\\n\")[0:-1]\n",
    "        ground_labels = np.array(ground_labels)\n",
    "\n",
    "        selected_frames_index = [ele[0] for ele in selected_frame_dict[video_id]]\n",
    "        selected_frames_labels = np.array([ele[1] for ele in selected_frame_dict[video_id]])\n",
    "\n",
    "        ground_selected_labels = ground_labels[selected_frames_index]\n",
    "\n",
    "        correct += np.sum(ground_selected_labels == selected_frames_labels)\n",
    "        total += len(ground_selected_labels)\n",
    "\n",
    "    print(\"Total correct pivots labels selected = \", correct * 100.0 / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# selected_frames_dict = change_selected_frames(model)\n",
    "# get_new_selected_frame_acc(selected_frames_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Expection Boundaries\n",
    "# print(\"Calculating Expectation\")\n",
    "# correct = 0.0\n",
    "# total = 0.0\n",
    "# model.eval()\n",
    "# for i, item in enumerate(trainloader):\n",
    "#     with torch.no_grad():\n",
    "#         item_0 = item[0].to(device)\n",
    "#         item_1 = item[1].to(device)\n",
    "#         item_2 = item[2].to(device)\n",
    "#         src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "#         src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "#         middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "#         prob = torch.softmax(predictions[-1], dim=1)\n",
    "#         prob = prob.permute(0, 2, 1)\n",
    "#         calculate_element_probb(prob, item_1, item[4])\n",
    "\n",
    "#         if i % 10 == 0:\n",
    "#             print(f\"Completed iter {i}\")\n",
    "\n",
    "# get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-lenassum-mstcn-split3-slup15/'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Training:: Epoch 25, Iteration 0, Current loss 2.7276387214660645 Accuracy 57.904980978501285\n",
      "Training:: Epoch 25, Iteration 10, Current loss 2.8379733562469482 Accuracy 61.90614346848481\n",
      "Training:: Epoch 25, Iteration 20, Current loss 2.712575674057007 Accuracy 65.9049518688752\n",
      "Training:: Epoch 25, Iteration 30, Current loss 2.7919278144836426 Accuracy 71.48133897652943\n",
      "Training:: Epoch 25, Iteration 40, Current loss 2.3483405113220215 Accuracy 66.65755670948347\n",
      "Training:: Epoch 25, Iteration 50, Current loss 2.795650005340576 Accuracy 64.61070391370488\n",
      "Training:: Epoch 25, Iteration 60, Current loss 2.397219181060791 Accuracy 69.9423076923077\n",
      "Training:: Epoch 25, Iteration 70, Current loss 2.63720440864563 Accuracy 72.45338930732188\n",
      "Training:: Epoch 25, Iteration 80, Current loss 2.610546112060547 Accuracy 60.014771730600565\n",
      "Training:: Epoch 25, Iteration 90, Current loss 3.098721742630005 Accuracy 62.31452399003574\n",
      "Training:: Epoch 25, Iteration 100, Current loss 3.625441312789917 Accuracy 56.039881344759394\n",
      "Training:: Epoch 25, Iteration 110, Current loss 3.208087205886841 Accuracy 62.174807197943444\n",
      "Training:: Epoch 25, Iteration 120, Current loss 2.8630781173706055 Accuracy 60.57194325602342\n",
      "Training:: Epoch 25, Iteration 130, Current loss 2.933288335800171 Accuracy 69.42559495364618\n",
      "Training:: Epoch 25, Iteration 140, Current loss 2.7767717838287354 Accuracy 63.660508083140876\n",
      "Training:: Epoch 25, Iteration 150, Current loss 2.4875378608703613 Accuracy 65.5124874065433\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 25, Probability Accuracy 53.210640565621844\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  62.18468211391394\n",
      "Calculating Expectation\n",
      "Epoch 25 iter 0\n",
      "Epoch 25 iter 10\n",
      "Epoch 25 iter 20\n",
      "Epoch 25 iter 30\n",
      "Epoch 25 iter 40\n",
      "Epoch 25 iter 50\n",
      "Epoch 25 iter 60\n",
      "Epoch 25 iter 70\n",
      "Epoch 25 iter 80\n",
      "Epoch 25 iter 90\n",
      "Epoch 25 iter 100\n",
      "Epoch 25 iter 110\n",
      "Epoch 25 iter 120\n",
      "Epoch 25 iter 130\n",
      "Epoch 25 iter 140\n",
      "Epoch 25 iter 150\n",
      "Train Boundary avergage error = 310.491\n",
      "Train From boundary avergage accuracy = 59.558\n",
      "Starting Training\n",
      "Training:: Epoch 26, Iteration 0, Current loss 2.119548283027017 Accuracy 60.607809194075784\n",
      "Training:: Epoch 26, Iteration 10, Current loss 1.7153859315960616 Accuracy 67.2406779661017\n",
      "Training:: Epoch 26, Iteration 20, Current loss 1.221111829709376 Accuracy 64.94890832904507\n",
      "Training:: Epoch 26, Iteration 30, Current loss 1.1971452445719724 Accuracy 71.90360545488511\n",
      "Training:: Epoch 26, Iteration 40, Current loss 1.6835785824269425 Accuracy 63.61556064073226\n",
      "Training:: Epoch 26, Iteration 50, Current loss 1.2099101697262138 Accuracy 57.51558531516971\n",
      "Training:: Epoch 26, Iteration 60, Current loss 1.3491363700286432 Accuracy 76.74261830928947\n",
      "Training:: Epoch 26, Iteration 70, Current loss 1.6139063427056464 Accuracy 61.22709842351939\n",
      "Training:: Epoch 26, Iteration 80, Current loss 1.656584633919846 Accuracy 63.87015177065767\n",
      "Training:: Epoch 26, Iteration 90, Current loss 1.5505351015231446 Accuracy 60.76644033113199\n",
      "Training:: Epoch 26, Iteration 100, Current loss 2.30677979816363 Accuracy 60.472020187026864\n",
      "Training:: Epoch 26, Iteration 110, Current loss 1.7739857599327942 Accuracy 64.49222419371674\n",
      "Training:: Epoch 26, Iteration 120, Current loss 1.1719752358528588 Accuracy 60.82681017612524\n",
      "Training:: Epoch 26, Iteration 130, Current loss 2.1273475026915305 Accuracy 51.760039662865644\n",
      "Training:: Epoch 26, Iteration 140, Current loss 1.670927157677942 Accuracy 62.10364576058109\n",
      "Training:: Epoch 26, Iteration 150, Current loss 1.7971693802839088 Accuracy 54.439644828413726\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 26, Probability Accuracy 44.816044553322804\n",
      "Starting Training\n",
      "Training:: Epoch 27, Iteration 0, Current loss 6.001794480927759 Accuracy 44.359771902540174\n",
      "Training:: Epoch 27, Iteration 10, Current loss 3.4549042753047754 Accuracy 46.83518290176737\n",
      "Training:: Epoch 27, Iteration 20, Current loss 2.9269825036794472 Accuracy 66.42134314627415\n",
      "Training:: Epoch 27, Iteration 30, Current loss 1.8501115267629111 Accuracy 60.29098651525905\n",
      "Training:: Epoch 27, Iteration 40, Current loss 2.3084479600853047 Accuracy 63.3348815606131\n",
      "Training:: Epoch 27, Iteration 50, Current loss 3.0522405081778112 Accuracy 62.4972440655545\n",
      "Training:: Epoch 27, Iteration 60, Current loss 2.3668621957540954 Accuracy 50.64679415073116\n",
      "Training:: Epoch 27, Iteration 70, Current loss 2.611330376433365 Accuracy 49.29898924029997\n",
      "Training:: Epoch 27, Iteration 80, Current loss 1.6814241142942847 Accuracy 63.59928372463192\n",
      "Training:: Epoch 27, Iteration 90, Current loss 3.874781815427405 Accuracy 57.607444839145444\n",
      "Training:: Epoch 27, Iteration 100, Current loss 3.8420715317624787 Accuracy 59.24421144604631\n",
      "Training:: Epoch 27, Iteration 110, Current loss 2.5914270466849434 Accuracy 72.77280315677645\n",
      "Training:: Epoch 27, Iteration 120, Current loss 2.7535221980303253 Accuracy 60.54064085116912\n",
      "Training:: Epoch 27, Iteration 130, Current loss 5.104127263400205 Accuracy 49.8352393874782\n",
      "Training:: Epoch 27, Iteration 140, Current loss 2.806209033929652 Accuracy 53.70404926292219\n",
      "Training:: Epoch 27, Iteration 150, Current loss 3.8639142569807845 Accuracy 54.595487066593286\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 27, Probability Accuracy 53.544232454059966\n",
      "Starting Training\n",
      "Training:: Epoch 28, Iteration 0, Current loss 2.3917926045959907 Accuracy 67.02223061311182\n",
      "Training:: Epoch 28, Iteration 10, Current loss 3.2260524288379218 Accuracy 48.78872946558536\n",
      "Training:: Epoch 28, Iteration 20, Current loss 3.884546191959264 Accuracy 44.234548335974644\n",
      "Training:: Epoch 28, Iteration 30, Current loss 1.465384566097871 Accuracy 69.64391107613613\n",
      "Training:: Epoch 28, Iteration 40, Current loss 3.6667757479238974 Accuracy 52.057754640997935\n",
      "Training:: Epoch 28, Iteration 50, Current loss 1.9277107587924074 Accuracy 66.86192468619247\n",
      "Training:: Epoch 28, Iteration 60, Current loss 1.8200203809532975 Accuracy 63.20289937142534\n",
      "Training:: Epoch 28, Iteration 70, Current loss 1.1891940703298838 Accuracy 68.75683323686411\n",
      "Training:: Epoch 28, Iteration 80, Current loss 1.5805676792929373 Accuracy 61.607199442296725\n",
      "Training:: Epoch 28, Iteration 90, Current loss 1.6966270659417233 Accuracy 58.37243763892319\n",
      "Training:: Epoch 28, Iteration 100, Current loss 1.1728944575792164 Accuracy 63.78117795011528\n",
      "Training:: Epoch 28, Iteration 110, Current loss 1.7895863147594873 Accuracy 60.17489421720733\n",
      "Training:: Epoch 28, Iteration 120, Current loss 1.733920796187991 Accuracy 74.58695281894056\n",
      "Training:: Epoch 28, Iteration 130, Current loss 1.3493674431357046 Accuracy 63.20398610901404\n",
      "Training:: Epoch 28, Iteration 140, Current loss 1.4896249751285344 Accuracy 66.63571649644074\n",
      "Training:: Epoch 28, Iteration 150, Current loss 2.828217173140007 Accuracy 52.50354532562452\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 28, Probability Accuracy 55.928259328909995\n",
      "Starting Training\n",
      "Training:: Epoch 29, Iteration 0, Current loss 1.49150685426405 Accuracy 65.21604938271605\n",
      "Training:: Epoch 29, Iteration 10, Current loss 1.211472997116004 Accuracy 66.32403635224068\n",
      "Training:: Epoch 29, Iteration 20, Current loss 1.1932060246288227 Accuracy 60.66818526955201\n",
      "Training:: Epoch 29, Iteration 30, Current loss 1.368633884967335 Accuracy 62.35533174308684\n",
      "Training:: Epoch 29, Iteration 40, Current loss 2.1307628190480683 Accuracy 56.43802121992752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 29, Iteration 50, Current loss 1.6752144459838676 Accuracy 51.739088544175736\n",
      "Training:: Epoch 29, Iteration 60, Current loss 1.3960604235229552 Accuracy 63.01514399205561\n",
      "Training:: Epoch 29, Iteration 70, Current loss 1.2236683938589252 Accuracy 78.1052431430337\n",
      "Training:: Epoch 29, Iteration 80, Current loss 2.263130386763507 Accuracy 62.807047264103\n",
      "Training:: Epoch 29, Iteration 90, Current loss 3.6965656447613826 Accuracy 48.739081431389124\n",
      "Training:: Epoch 29, Iteration 100, Current loss 2.4007375398595987 Accuracy 65.92146928435719\n",
      "Training:: Epoch 29, Iteration 110, Current loss 3.8039548462742734 Accuracy 58.87376567921004\n",
      "Training:: Epoch 29, Iteration 120, Current loss 4.298412075476217 Accuracy 49.33730544747082\n",
      "Training:: Epoch 29, Iteration 130, Current loss 2.3951938162264144 Accuracy 57.635926471728844\n",
      "Training:: Epoch 29, Iteration 140, Current loss 1.9745883809545313 Accuracy 57.57618576609674\n",
      "Training:: Epoch 29, Iteration 150, Current loss 1.8600398883873193 Accuracy 65.25819214771228\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 29, Probability Accuracy 55.79712166784783\n",
      "Starting Training\n",
      "Training:: Epoch 30, Iteration 0, Current loss 1.4878234163903938 Accuracy 62.699594046008116\n",
      "Training:: Epoch 30, Iteration 10, Current loss 2.111087887079321 Accuracy 59.43361226761202\n",
      "Training:: Epoch 30, Iteration 20, Current loss 1.4744028007476238 Accuracy 62.416777629826896\n",
      "Training:: Epoch 30, Iteration 30, Current loss 2.319123219309919 Accuracy 64.5335584634867\n",
      "Training:: Epoch 30, Iteration 40, Current loss 2.119525237036292 Accuracy 67.19128742617187\n",
      "Training:: Epoch 30, Iteration 50, Current loss 1.2258675905783212 Accuracy 69.67233774417139\n",
      "Training:: Epoch 30, Iteration 60, Current loss 1.7078581296028421 Accuracy 60.76295739886254\n",
      "Training:: Epoch 30, Iteration 70, Current loss 1.77868046010946 Accuracy 66.81061946902655\n",
      "Training:: Epoch 30, Iteration 80, Current loss 1.7256323753574236 Accuracy 58.8396431832549\n",
      "Training:: Epoch 30, Iteration 90, Current loss 1.344680808891984 Accuracy 74.34788772327758\n",
      "Training:: Epoch 30, Iteration 100, Current loss 1.7236513911549252 Accuracy 53.01958008964378\n",
      "Training:: Epoch 30, Iteration 110, Current loss 1.5978702071152766 Accuracy 63.87741505662891\n",
      "Training:: Epoch 30, Iteration 120, Current loss 1.5301967863455468 Accuracy 56.061442698659704\n",
      "Training:: Epoch 30, Iteration 130, Current loss 1.396945784026923 Accuracy 60.035728906918756\n",
      "Training:: Epoch 30, Iteration 140, Current loss 1.890483582116953 Accuracy 54.510982328110465\n",
      "Training:: Epoch 30, Iteration 150, Current loss 1.3045489361279836 Accuracy 59.50087830880126\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 30, Probability Accuracy 54.426481995078156\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.96781189361945\n",
      "Calculating Expectation\n",
      "Epoch 30 iter 0\n",
      "Epoch 30 iter 10\n",
      "Epoch 30 iter 20\n",
      "Epoch 30 iter 30\n",
      "Epoch 30 iter 40\n",
      "Epoch 30 iter 50\n",
      "Epoch 30 iter 60\n",
      "Epoch 30 iter 70\n",
      "Epoch 30 iter 80\n",
      "Epoch 30 iter 90\n",
      "Epoch 30 iter 100\n",
      "Epoch 30 iter 110\n",
      "Epoch 30 iter 120\n",
      "Epoch 30 iter 130\n",
      "Epoch 30 iter 140\n",
      "Epoch 30 iter 150\n",
      "Train Boundary avergage error = 308.382\n",
      "Train From boundary avergage accuracy = 59.662\n",
      "Starting Training\n",
      "Training:: Epoch 31, Iteration 0, Current loss 1.8244746741808284 Accuracy 57.362083450014005\n",
      "Training:: Epoch 31, Iteration 10, Current loss 1.2948068548152873 Accuracy 57.73450123309805\n",
      "Training:: Epoch 31, Iteration 20, Current loss 1.7632865530839499 Accuracy 53.87166126152388\n",
      "Training:: Epoch 31, Iteration 30, Current loss 1.1548937485511988 Accuracy 67.26266496381439\n",
      "Training:: Epoch 31, Iteration 40, Current loss 1.293999832251379 Accuracy 62.51968503937008\n",
      "Training:: Epoch 31, Iteration 50, Current loss 1.0985217701288394 Accuracy 64.77594710882569\n",
      "Training:: Epoch 31, Iteration 60, Current loss 1.0026245470742483 Accuracy 49.71703452178834\n",
      "Training:: Epoch 31, Iteration 70, Current loss 1.2480643526301296 Accuracy 64.60096735187425\n",
      "Training:: Epoch 31, Iteration 80, Current loss 1.1245882788411796 Accuracy 65.96875332128813\n",
      "Training:: Epoch 31, Iteration 90, Current loss 0.9327323375774318 Accuracy 71.63351809585915\n",
      "Training:: Epoch 31, Iteration 100, Current loss 1.0433518866049771 Accuracy 55.464809031948114\n",
      "Training:: Epoch 31, Iteration 110, Current loss 1.1204060989316114 Accuracy 58.10216600618859\n",
      "Training:: Epoch 31, Iteration 120, Current loss 1.1195854047271048 Accuracy 68.16265342452918\n",
      "Training:: Epoch 31, Iteration 130, Current loss 0.8615059110628305 Accuracy 59.24828735419367\n",
      "Training:: Epoch 31, Iteration 140, Current loss 1.6275205810493496 Accuracy 65.83695412033286\n",
      "Training:: Epoch 31, Iteration 150, Current loss 1.3212338518353384 Accuracy 56.6282887131826\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 31, Probability Accuracy 52.81879007371611\n",
      "Starting Training\n",
      "Training:: Epoch 32, Iteration 0, Current loss 2.1878323168109146 Accuracy 57.0979570455736\n",
      "Training:: Epoch 32, Iteration 10, Current loss 1.3127990753240029 Accuracy 64.18969127879484\n",
      "Training:: Epoch 32, Iteration 20, Current loss 1.4549406593585184 Accuracy 60.26991831419439\n",
      "Training:: Epoch 32, Iteration 30, Current loss 0.9263366888226929 Accuracy 58.607222255602956\n",
      "Training:: Epoch 32, Iteration 40, Current loss 1.3468236338849517 Accuracy 65.37701063431838\n",
      "Training:: Epoch 32, Iteration 50, Current loss 1.0017806213860572 Accuracy 70.44812703149145\n",
      "Training:: Epoch 32, Iteration 60, Current loss 0.9030098711229266 Accuracy 72.03934277105009\n",
      "Training:: Epoch 32, Iteration 70, Current loss 1.1552641405532569 Accuracy 66.16164817749603\n",
      "Training:: Epoch 32, Iteration 80, Current loss 1.29866667065069 Accuracy 65.91165317208159\n",
      "Training:: Epoch 32, Iteration 90, Current loss 1.0762953771588073 Accuracy 55.71050561395981\n",
      "Training:: Epoch 32, Iteration 100, Current loss 0.9612358340566058 Accuracy 60.56988399594549\n",
      "Training:: Epoch 32, Iteration 110, Current loss 1.1240215124506001 Accuracy 66.11931304609823\n",
      "Training:: Epoch 32, Iteration 120, Current loss 0.9387596343674873 Accuracy 67.70276833414279\n",
      "Training:: Epoch 32, Iteration 130, Current loss 1.4364063804616838 Accuracy 57.166679901532596\n",
      "Training:: Epoch 32, Iteration 140, Current loss 1.2196182547791032 Accuracy 62.068062827225134\n",
      "Training:: Epoch 32, Iteration 150, Current loss 0.9675368685836507 Accuracy 66.12287400208261\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 32, Probability Accuracy 52.70684873410305\n",
      "Starting Training\n",
      "Training:: Epoch 33, Iteration 0, Current loss 1.3902288342023537 Accuracy 50.45769361166271\n",
      "Training:: Epoch 33, Iteration 10, Current loss 1.2127669250484043 Accuracy 62.57083977331273\n",
      "Training:: Epoch 33, Iteration 20, Current loss 1.2452834200914202 Accuracy 46.31022565562106\n",
      "Training:: Epoch 33, Iteration 30, Current loss 1.0930699954818737 Accuracy 59.55933299459559\n",
      "Training:: Epoch 33, Iteration 40, Current loss 1.0340548495023394 Accuracy 64.09623689080814\n",
      "Training:: Epoch 33, Iteration 50, Current loss 1.4065810450324132 Accuracy 60.52879607123369\n",
      "Training:: Epoch 33, Iteration 60, Current loss 1.233609730518861 Accuracy 70.28266191853996\n",
      "Training:: Epoch 33, Iteration 70, Current loss 0.8715247984243384 Accuracy 60.096256684491976\n",
      "Training:: Epoch 33, Iteration 80, Current loss 1.4312973290962672 Accuracy 59.19302158846491\n",
      "Training:: Epoch 33, Iteration 90, Current loss 1.510199426907145 Accuracy 67.51959602050046\n",
      "Training:: Epoch 33, Iteration 100, Current loss 2.1180746219119633 Accuracy 52.568012687568626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 33, Iteration 110, Current loss 1.5318749316398779 Accuracy 67.62254741124745\n",
      "Training:: Epoch 33, Iteration 120, Current loss 1.060779263046441 Accuracy 68.4144638644133\n",
      "Training:: Epoch 33, Iteration 130, Current loss 1.712548487400298 Accuracy 63.95708834329325\n",
      "Training:: Epoch 33, Iteration 140, Current loss 1.5035815371653445 Accuracy 60.44659587757651\n",
      "Training:: Epoch 33, Iteration 150, Current loss 1.2160427265871507 Accuracy 62.98930104426933\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 33, Probability Accuracy 51.699488284105556\n",
      "Starting Training\n",
      "Training:: Epoch 34, Iteration 0, Current loss 1.1631290786557573 Accuracy 64.87228554788251\n",
      "Training:: Epoch 34, Iteration 10, Current loss 1.018452370933895 Accuracy 63.15066925981009\n",
      "Training:: Epoch 34, Iteration 20, Current loss 1.437101244311072 Accuracy 57.482609513066365\n",
      "Training:: Epoch 34, Iteration 30, Current loss 1.1217977833236066 Accuracy 60.357541899441344\n",
      "Training:: Epoch 34, Iteration 40, Current loss 1.006251311352546 Accuracy 65.50874599655087\n",
      "Training:: Epoch 34, Iteration 50, Current loss 1.1638257260396296 Accuracy 53.63860167405219\n",
      "Training:: Epoch 34, Iteration 60, Current loss 0.7599107762221711 Accuracy 62.98950343157045\n",
      "Training:: Epoch 34, Iteration 70, Current loss 1.4316937454090475 Accuracy 59.49773005692873\n",
      "Training:: Epoch 34, Iteration 80, Current loss 0.876201950790908 Accuracy 63.06446893592119\n",
      "Training:: Epoch 34, Iteration 90, Current loss 1.0269889469430948 Accuracy 61.67914819909318\n",
      "Training:: Epoch 34, Iteration 100, Current loss 0.9674356559130197 Accuracy 61.116502083452254\n",
      "Training:: Epoch 34, Iteration 110, Current loss 1.0544159477240478 Accuracy 59.98025666337611\n",
      "Training:: Epoch 34, Iteration 120, Current loss 1.28216768159189 Accuracy 63.79517589550445\n",
      "Training:: Epoch 34, Iteration 130, Current loss 0.7513882404956228 Accuracy 70.87553241836252\n",
      "Training:: Epoch 34, Iteration 140, Current loss 1.079731138542997 Accuracy 58.729559748427675\n",
      "Training:: Epoch 34, Iteration 150, Current loss 1.179327989162852 Accuracy 60.79273827534039\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 34, Probability Accuracy 52.0029464121294\n",
      "Starting Training\n",
      "Training:: Epoch 35, Iteration 0, Current loss 0.9698812063604726 Accuracy 68.2832593276051\n",
      "Training:: Epoch 35, Iteration 10, Current loss 0.9686629107264147 Accuracy 61.67531504818384\n",
      "Training:: Epoch 35, Iteration 20, Current loss 0.6504880301977974 Accuracy 64.51310185519382\n",
      "Training:: Epoch 35, Iteration 30, Current loss 1.1731954753080447 Accuracy 63.22213181448332\n",
      "Training:: Epoch 35, Iteration 40, Current loss 0.9546596789680993 Accuracy 64.47865233807725\n",
      "Training:: Epoch 35, Iteration 50, Current loss 0.7856954539892683 Accuracy 68.3669854764435\n",
      "Training:: Epoch 35, Iteration 60, Current loss 1.2492698878130934 Accuracy 55.547117271058795\n",
      "Training:: Epoch 35, Iteration 70, Current loss 1.0346938513295996 Accuracy 63.52146225268582\n",
      "Training:: Epoch 35, Iteration 80, Current loss 1.5331171919959545 Accuracy 59.124426638796955\n",
      "Training:: Epoch 35, Iteration 90, Current loss 1.0510759765057487 Accuracy 66.97728200244865\n",
      "Training:: Epoch 35, Iteration 100, Current loss 0.7723340570977129 Accuracy 68.28901154039137\n",
      "Training:: Epoch 35, Iteration 110, Current loss 1.0108551658299558 Accuracy 70.6109739074412\n",
      "Training:: Epoch 35, Iteration 120, Current loss 1.5480172829947243 Accuracy 65.0953206239168\n",
      "Training:: Epoch 35, Iteration 130, Current loss 0.852021257379328 Accuracy 67.43572841133816\n",
      "Training:: Epoch 35, Iteration 140, Current loss 1.017755270676461 Accuracy 68.11672921192968\n",
      "Training:: Epoch 35, Iteration 150, Current loss 1.4086537355255797 Accuracy 60.811439200186\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 35, Probability Accuracy 54.96141204569171\n",
      "Calculating Expectation\n",
      "Epoch 35 iter 0\n",
      "Epoch 35 iter 10\n",
      "Epoch 35 iter 20\n",
      "Epoch 35 iter 30\n",
      "Epoch 35 iter 40\n",
      "Epoch 35 iter 50\n",
      "Epoch 35 iter 60\n",
      "Epoch 35 iter 70\n",
      "Epoch 35 iter 80\n",
      "Epoch 35 iter 90\n",
      "Epoch 35 iter 100\n",
      "Epoch 35 iter 110\n",
      "Epoch 35 iter 120\n",
      "Epoch 35 iter 130\n",
      "Epoch 35 iter 140\n",
      "Epoch 35 iter 150\n",
      "Train Boundary avergage error = 308.896\n",
      "Train From boundary avergage accuracy = 59.753\n",
      "Starting Training\n",
      "Training:: Epoch 36, Iteration 0, Current loss 0.7611038588399196 Accuracy 51.96918778084054\n",
      "Training:: Epoch 36, Iteration 10, Current loss 0.9993241180570072 Accuracy 55.07908822998737\n",
      "Training:: Epoch 36, Iteration 20, Current loss 1.1560534291921476 Accuracy 58.80233017377567\n",
      "Training:: Epoch 36, Iteration 30, Current loss 0.7114290854277935 Accuracy 74.79081089304731\n",
      "Training:: Epoch 36, Iteration 40, Current loss 0.992512244877378 Accuracy 61.16663823980897\n",
      "Training:: Epoch 36, Iteration 50, Current loss 1.2990252814196819 Accuracy 57.89352385342245\n",
      "Training:: Epoch 36, Iteration 60, Current loss 0.8394955202166856 Accuracy 57.01512605042017\n",
      "Training:: Epoch 36, Iteration 70, Current loss 0.8306206637310692 Accuracy 69.67825988444545\n",
      "Training:: Epoch 36, Iteration 80, Current loss 1.1744112524345678 Accuracy 69.24243189973215\n",
      "Training:: Epoch 36, Iteration 90, Current loss 0.9612969623193028 Accuracy 57.18022670869944\n",
      "Training:: Epoch 36, Iteration 100, Current loss 1.2767244376236235 Accuracy 59.92379397155882\n",
      "Training:: Epoch 36, Iteration 110, Current loss 0.9460904207596271 Accuracy 64.36101549053356\n",
      "Training:: Epoch 36, Iteration 120, Current loss 1.2881419197774115 Accuracy 59.25034199726402\n",
      "Training:: Epoch 36, Iteration 130, Current loss 1.370522606483249 Accuracy 67.60852713178295\n",
      "Training:: Epoch 36, Iteration 140, Current loss 0.8843840234058712 Accuracy 64.22978653259705\n",
      "Training:: Epoch 36, Iteration 150, Current loss 1.1798633322882468 Accuracy 71.4693125779811\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 36, Probability Accuracy 56.14700810821368\n",
      "Starting Training\n",
      "Training:: Epoch 37, Iteration 0, Current loss 0.8604776811273267 Accuracy 71.23400542846065\n",
      "Training:: Epoch 37, Iteration 10, Current loss 0.8399087839615491 Accuracy 54.184160996090924\n",
      "Training:: Epoch 37, Iteration 20, Current loss 1.1138168346584627 Accuracy 69.73117300807088\n",
      "Training:: Epoch 37, Iteration 30, Current loss 0.8259023691256646 Accuracy 64.29595127194554\n",
      "Training:: Epoch 37, Iteration 40, Current loss 1.6489452345818398 Accuracy 66.04825859321647\n",
      "Training:: Epoch 37, Iteration 50, Current loss 1.9613871542885326 Accuracy 66.56692599241971\n",
      "Training:: Epoch 37, Iteration 60, Current loss 1.3910462343269772 Accuracy 62.563075690828995\n",
      "Training:: Epoch 37, Iteration 70, Current loss 1.3670583068201614 Accuracy 56.23054711816102\n",
      "Training:: Epoch 37, Iteration 80, Current loss 1.7007855510538958 Accuracy 59.66488036832968\n",
      "Training:: Epoch 37, Iteration 90, Current loss 1.443166584333698 Accuracy 53.53858195812406\n",
      "Training:: Epoch 37, Iteration 100, Current loss 1.4535388382375674 Accuracy 64.556687621938\n",
      "Training:: Epoch 37, Iteration 110, Current loss 1.5106885384011681 Accuracy 63.9942778952606\n",
      "Training:: Epoch 37, Iteration 120, Current loss 1.1699772674912894 Accuracy 64.17582417582418\n",
      "Training:: Epoch 37, Iteration 130, Current loss 1.5894914005128498 Accuracy 65.86338418862691\n",
      "Training:: Epoch 37, Iteration 140, Current loss 2.20147252822841 Accuracy 51.257200948830906\n",
      "Training:: Epoch 37, Iteration 150, Current loss 5.049152320310372 Accuracy 62.76589476165223\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 37, Probability Accuracy 49.65418719761608\n",
      "Starting Training\n",
      "Training:: Epoch 38, Iteration 0, Current loss 2.3008914779927196 Accuracy 59.88108108108108\n",
      "Training:: Epoch 38, Iteration 10, Current loss 2.8742830320715655 Accuracy 67.94485135717363\n",
      "Training:: Epoch 38, Iteration 20, Current loss 3.4658026826105397 Accuracy 57.85178168039059\n",
      "Training:: Epoch 38, Iteration 30, Current loss 2.159834193254542 Accuracy 58.41883345045678\n",
      "Training:: Epoch 38, Iteration 40, Current loss 4.911844486133628 Accuracy 56.04503943545039\n",
      "Training:: Epoch 38, Iteration 50, Current loss 2.4999576078072967 Accuracy 64.69306404464523\n",
      "Training:: Epoch 38, Iteration 60, Current loss 3.005038101459875 Accuracy 59.187185597034684\n",
      "Training:: Epoch 38, Iteration 70, Current loss 3.923373129867046 Accuracy 51.92889561270802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 38, Iteration 80, Current loss 1.7824268928186613 Accuracy 56.24481460208054\n",
      "Training:: Epoch 38, Iteration 90, Current loss 1.3260594259963479 Accuracy 62.97751029458347\n",
      "Training:: Epoch 38, Iteration 100, Current loss 1.9898370537160865 Accuracy 67.77653003930376\n",
      "Training:: Epoch 38, Iteration 110, Current loss 1.2524703875290615 Accuracy 66.49127752200194\n",
      "Training:: Epoch 38, Iteration 120, Current loss 6.407019674007659 Accuracy 54.453072572140734\n",
      "Training:: Epoch 38, Iteration 130, Current loss 2.342814437882912 Accuracy 59.30386355725722\n",
      "Training:: Epoch 38, Iteration 140, Current loss 1.829513898404319 Accuracy 47.01657007591217\n",
      "Training:: Epoch 38, Iteration 150, Current loss 4.7851447930011695 Accuracy 36.08687749909124\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 38, Probability Accuracy 55.80783589377292\n",
      "Starting Training\n",
      "Training:: Epoch 39, Iteration 0, Current loss 1.569847381484327 Accuracy 61.38189608998393\n",
      "Training:: Epoch 39, Iteration 10, Current loss 2.296893276466423 Accuracy 55.94162943245556\n",
      "Training:: Epoch 39, Iteration 20, Current loss 1.6406028853177759 Accuracy 64.0644824240615\n",
      "Training:: Epoch 39, Iteration 30, Current loss 1.4582840300863311 Accuracy 62.14672096274236\n",
      "Training:: Epoch 39, Iteration 40, Current loss 1.817802770192869 Accuracy 68.94224589110274\n",
      "Training:: Epoch 39, Iteration 50, Current loss 1.7602505068724137 Accuracy 69.67661247096659\n",
      "Training:: Epoch 39, Iteration 60, Current loss 1.3658594076207686 Accuracy 59.66467838142834\n",
      "Training:: Epoch 39, Iteration 70, Current loss 1.4056681348901823 Accuracy 70.27244126112859\n",
      "Training:: Epoch 39, Iteration 80, Current loss 1.1561512973550585 Accuracy 66.04359148146827\n",
      "Training:: Epoch 39, Iteration 90, Current loss 1.2550905960465968 Accuracy 53.803533016100644\n",
      "Training:: Epoch 39, Iteration 100, Current loss 1.0615081654131506 Accuracy 66.89818468823994\n",
      "Training:: Epoch 39, Iteration 110, Current loss 1.3689547922961003 Accuracy 49.91519799424821\n",
      "Training:: Epoch 39, Iteration 120, Current loss 1.9278685735786625 Accuracy 68.97900274686903\n",
      "Training:: Epoch 39, Iteration 130, Current loss 1.8630316281053867 Accuracy 66.63630261770064\n",
      "Training:: Epoch 39, Iteration 140, Current loss 0.9997118021652844 Accuracy 58.67243477085305\n",
      "Training:: Epoch 39, Iteration 150, Current loss 1.1659266755254067 Accuracy 64.74157985233134\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 39, Probability Accuracy 56.81776329373162\n",
      "Starting Training\n",
      "Training:: Epoch 40, Iteration 0, Current loss 0.967901525061378 Accuracy 52.17083681739242\n",
      "Training:: Epoch 40, Iteration 10, Current loss 0.919736351086979 Accuracy 60.20838899278653\n",
      "Training:: Epoch 40, Iteration 20, Current loss 1.045751574992847 Accuracy 60.681466184821886\n",
      "Training:: Epoch 40, Iteration 30, Current loss 1.4708280169709262 Accuracy 66.82094301417413\n",
      "Training:: Epoch 40, Iteration 40, Current loss 2.031024175654373 Accuracy 50.793340819215935\n",
      "Training:: Epoch 40, Iteration 50, Current loss 1.2462059174411342 Accuracy 62.5371044525343\n",
      "Training:: Epoch 40, Iteration 60, Current loss 0.9705396677553582 Accuracy 59.981451425921634\n",
      "Training:: Epoch 40, Iteration 70, Current loss 1.0929291617915515 Accuracy 53.481679428542066\n",
      "Training:: Epoch 40, Iteration 80, Current loss 1.0401746559174685 Accuracy 67.3431226970247\n",
      "Training:: Epoch 40, Iteration 90, Current loss 0.8846547193048426 Accuracy 62.256410256410255\n",
      "Training:: Epoch 40, Iteration 100, Current loss 0.870525783091425 Accuracy 59.84987184181618\n",
      "Training:: Epoch 40, Iteration 110, Current loss 0.8063941575019089 Accuracy 74.51190157796202\n",
      "Training:: Epoch 40, Iteration 120, Current loss 0.8478730694678336 Accuracy 65.9254533855828\n",
      "Training:: Epoch 40, Iteration 130, Current loss 1.0061869114167528 Accuracy 57.07800941492939\n",
      "Training:: Epoch 40, Iteration 140, Current loss 0.8737637923210917 Accuracy 57.51182592242195\n",
      "Training:: Epoch 40, Iteration 150, Current loss 0.7890947603632199 Accuracy 66.70310015898251\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 40, Probability Accuracy 55.92055847902635\n",
      "Calculating Expectation\n",
      "Epoch 40 iter 0\n",
      "Epoch 40 iter 10\n",
      "Epoch 40 iter 20\n",
      "Epoch 40 iter 30\n",
      "Epoch 40 iter 40\n",
      "Epoch 40 iter 50\n",
      "Epoch 40 iter 60\n",
      "Epoch 40 iter 70\n",
      "Epoch 40 iter 80\n",
      "Epoch 40 iter 90\n",
      "Epoch 40 iter 100\n",
      "Epoch 40 iter 110\n",
      "Epoch 40 iter 120\n",
      "Epoch 40 iter 130\n",
      "Epoch 40 iter 140\n",
      "Epoch 40 iter 150\n",
      "Train Boundary avergage error = 309.880\n",
      "Train From boundary avergage accuracy = 59.560\n",
      "Starting Training\n",
      "Training:: Epoch 41, Iteration 0, Current loss 0.7016122185958082 Accuracy 72.64755270850178\n",
      "Training:: Epoch 41, Iteration 10, Current loss 0.8171691111863099 Accuracy 66.76287986058163\n",
      "Training:: Epoch 41, Iteration 20, Current loss 0.7953088370655227 Accuracy 70.48314216197429\n",
      "Training:: Epoch 41, Iteration 30, Current loss 1.2600735860292631 Accuracy 63.50546780072904\n",
      "Training:: Epoch 41, Iteration 40, Current loss 0.7635258836647766 Accuracy 59.091967403958094\n",
      "Training:: Epoch 41, Iteration 50, Current loss 1.3255109248116135 Accuracy 59.23278116826504\n",
      "Training:: Epoch 41, Iteration 60, Current loss 0.9408935760557398 Accuracy 69.00041674108472\n",
      "Training:: Epoch 41, Iteration 70, Current loss 0.795710447013527 Accuracy 58.612207246451085\n",
      "Training:: Epoch 41, Iteration 80, Current loss 0.7319819710087176 Accuracy 75.21695925803246\n",
      "Training:: Epoch 41, Iteration 90, Current loss 2.4460379825945555 Accuracy 53.45227734261677\n",
      "Training:: Epoch 41, Iteration 100, Current loss 0.8447576794529412 Accuracy 67.25872135812767\n",
      "Training:: Epoch 41, Iteration 110, Current loss 0.7573852542974493 Accuracy 65.66914975597226\n",
      "Training:: Epoch 41, Iteration 120, Current loss 1.2436879839001347 Accuracy 58.01905861969391\n",
      "Training:: Epoch 41, Iteration 130, Current loss 0.8285137918791665 Accuracy 57.85839989170164\n",
      "Training:: Epoch 41, Iteration 140, Current loss 1.55909193437149 Accuracy 55.14003903159449\n",
      "Training:: Epoch 41, Iteration 150, Current loss 0.8608955241838423 Accuracy 55.90978531800273\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 41, Probability Accuracy 55.02179117304033\n",
      "Starting Training\n",
      "Training:: Epoch 42, Iteration 0, Current loss 0.7351893535279499 Accuracy 61.96488172979248\n",
      "Training:: Epoch 42, Iteration 10, Current loss 1.1347911384284262 Accuracy 52.21544605753144\n",
      "Training:: Epoch 42, Iteration 20, Current loss 0.7458126576407089 Accuracy 65.22064754003918\n",
      "Training:: Epoch 42, Iteration 30, Current loss 0.7867335049919721 Accuracy 63.6099182712287\n",
      "Training:: Epoch 42, Iteration 40, Current loss 0.7288517935586316 Accuracy 67.58833619210978\n",
      "Training:: Epoch 42, Iteration 50, Current loss 1.0081305897911579 Accuracy 71.05390966488586\n",
      "Training:: Epoch 42, Iteration 60, Current loss 0.8661193133982044 Accuracy 73.69793364187471\n",
      "Training:: Epoch 42, Iteration 70, Current loss 0.9324897331704382 Accuracy 63.41463414634146\n",
      "Training:: Epoch 42, Iteration 80, Current loss 1.1771651026943117 Accuracy 68.35359298767882\n",
      "Training:: Epoch 42, Iteration 90, Current loss 1.0564595311906326 Accuracy 65.9733837539088\n",
      "Training:: Epoch 42, Iteration 100, Current loss 1.0742035741619547 Accuracy 56.3571606063116\n",
      "Training:: Epoch 42, Iteration 110, Current loss 1.4450965247540335 Accuracy 60.010845333494004\n",
      "Training:: Epoch 42, Iteration 120, Current loss 0.7764522017660584 Accuracy 68.0581348405329\n",
      "Training:: Epoch 42, Iteration 130, Current loss 0.6411525929919024 Accuracy 67.73471145564169\n",
      "Training:: Epoch 42, Iteration 140, Current loss 0.9758837756252368 Accuracy 67.54083620560468\n",
      "Training:: Epoch 42, Iteration 150, Current loss 0.9831457603936612 Accuracy 62.59646715829189\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 42, Probability Accuracy 54.09378295880045\n",
      "Starting Training\n",
      "Training:: Epoch 43, Iteration 0, Current loss 0.6215113992920566 Accuracy 69.21447978264344\n",
      "Training:: Epoch 43, Iteration 10, Current loss 1.093687033271476 Accuracy 57.51356852103121\n",
      "Training:: Epoch 43, Iteration 20, Current loss 0.7730807775516353 Accuracy 63.385720353708926\n",
      "Training:: Epoch 43, Iteration 30, Current loss 0.8921464070448801 Accuracy 66.14250435793143\n",
      "Training:: Epoch 43, Iteration 40, Current loss 0.7146910722800235 Accuracy 56.79048171793384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 43, Iteration 50, Current loss 1.5997474717583444 Accuracy 43.94595530919799\n",
      "Training:: Epoch 43, Iteration 60, Current loss 0.9514318993983009 Accuracy 55.367618302698475\n",
      "Training:: Epoch 43, Iteration 70, Current loss 0.8459121334384524 Accuracy 60.591914853888525\n",
      "Training:: Epoch 43, Iteration 80, Current loss 0.9301911352927155 Accuracy 60.03300330033003\n",
      "Training:: Epoch 43, Iteration 90, Current loss 0.9324342614478442 Accuracy 65.41053921568627\n",
      "Training:: Epoch 43, Iteration 100, Current loss 1.037024350984988 Accuracy 60.02994011976048\n",
      "Training:: Epoch 43, Iteration 110, Current loss 0.6238125846306628 Accuracy 71.32293986636971\n",
      "Training:: Epoch 43, Iteration 120, Current loss 0.8665306215811645 Accuracy 65.63625882692031\n",
      "Training:: Epoch 43, Iteration 130, Current loss 0.5138080234606532 Accuracy 78.9054054054054\n",
      "Training:: Epoch 43, Iteration 140, Current loss 1.0402594696238268 Accuracy 63.35884736605133\n",
      "Training:: Epoch 43, Iteration 150, Current loss 0.7533926735525 Accuracy 63.89496717724289\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 43, Probability Accuracy 55.95671899152349\n",
      "Starting Training\n",
      "Training:: Epoch 44, Iteration 0, Current loss 0.6350416838251118 Accuracy 68.06787703734268\n",
      "Training:: Epoch 44, Iteration 10, Current loss 0.9067267369178584 Accuracy 63.05641890112206\n",
      "Training:: Epoch 44, Iteration 20, Current loss 0.5866324947365165 Accuracy 57.25097541484511\n",
      "Training:: Epoch 44, Iteration 30, Current loss 0.9411061514451722 Accuracy 62.42491657397108\n",
      "Training:: Epoch 44, Iteration 40, Current loss 1.104779119955269 Accuracy 62.69103145300743\n",
      "Training:: Epoch 44, Iteration 50, Current loss 0.958576897176107 Accuracy 61.72254927054006\n",
      "Training:: Epoch 44, Iteration 60, Current loss 0.8702941728319308 Accuracy 62.57204911870353\n",
      "Training:: Epoch 44, Iteration 70, Current loss 0.6348108328373305 Accuracy 67.92247477918707\n",
      "Training:: Epoch 44, Iteration 80, Current loss 0.845944704561242 Accuracy 65.60886110356076\n",
      "Training:: Epoch 44, Iteration 90, Current loss 0.8973852957161059 Accuracy 68.12959855427907\n",
      "Training:: Epoch 44, Iteration 100, Current loss 0.5621244416416767 Accuracy 50.094406419636535\n",
      "Training:: Epoch 44, Iteration 110, Current loss 0.6516377431051152 Accuracy 70.32585284513306\n",
      "Training:: Epoch 44, Iteration 120, Current loss 0.7296699856124781 Accuracy 69.39755180414433\n",
      "Training:: Epoch 44, Iteration 130, Current loss 0.9362976246448071 Accuracy 65.08090901052259\n",
      "Training:: Epoch 44, Iteration 140, Current loss 0.6628635684666917 Accuracy 63.295378432685865\n",
      "Training:: Epoch 44, Iteration 150, Current loss 0.6380739740088955 Accuracy 66.41063799145505\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 44, Probability Accuracy 56.22926211349267\n",
      "Starting Training\n",
      "Training:: Epoch 45, Iteration 0, Current loss 0.5852722989754644 Accuracy 74.79387514723204\n",
      "Training:: Epoch 45, Iteration 10, Current loss 0.8745477882222827 Accuracy 64.5106671181849\n",
      "Training:: Epoch 45, Iteration 20, Current loss 0.6613255416583984 Accuracy 68.44599303135888\n",
      "Training:: Epoch 45, Iteration 30, Current loss 0.8304438986752548 Accuracy 64.29746440524136\n",
      "Training:: Epoch 45, Iteration 40, Current loss 0.8709782906867152 Accuracy 52.84783895796329\n",
      "Training:: Epoch 45, Iteration 50, Current loss 0.7581293673642375 Accuracy 52.98321076730956\n",
      "Training:: Epoch 45, Iteration 60, Current loss 0.7369204497605488 Accuracy 61.33868403119558\n",
      "Training:: Epoch 45, Iteration 70, Current loss 0.987607342865451 Accuracy 56.01184275453698\n",
      "Training:: Epoch 45, Iteration 80, Current loss 0.9391505652666334 Accuracy 65.73583127135619\n",
      "Training:: Epoch 45, Iteration 90, Current loss 0.9500737836840656 Accuracy 58.09413307773798\n",
      "Training:: Epoch 45, Iteration 100, Current loss 0.6608703010087968 Accuracy 68.93791910015142\n",
      "Training:: Epoch 45, Iteration 110, Current loss 0.5703291161969116 Accuracy 67.47624740451771\n",
      "Training:: Epoch 45, Iteration 120, Current loss 0.6501039407336094 Accuracy 60.47714860592124\n",
      "Training:: Epoch 45, Iteration 130, Current loss 0.5034506818136926 Accuracy 74.87039252549421\n",
      "Training:: Epoch 45, Iteration 140, Current loss 0.7563025322051068 Accuracy 71.25373134328358\n",
      "Training:: Epoch 45, Iteration 150, Current loss 1.0716257802109186 Accuracy 50.49792531120332\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 45, Probability Accuracy 55.171009090351056\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.38568656546057\n",
      "Calculating Expectation\n",
      "Epoch 45 iter 0\n",
      "Epoch 45 iter 10\n",
      "Epoch 45 iter 20\n",
      "Epoch 45 iter 30\n",
      "Epoch 45 iter 40\n",
      "Epoch 45 iter 50\n",
      "Epoch 45 iter 60\n",
      "Epoch 45 iter 70\n",
      "Epoch 45 iter 80\n",
      "Epoch 45 iter 90\n",
      "Epoch 45 iter 100\n",
      "Epoch 45 iter 110\n",
      "Epoch 45 iter 120\n",
      "Epoch 45 iter 130\n",
      "Epoch 45 iter 140\n",
      "Epoch 45 iter 150\n",
      "Train Boundary avergage error = 311.181\n",
      "Train From boundary avergage accuracy = 59.364\n",
      "Starting Training\n",
      "Training:: Epoch 46, Iteration 0, Current loss 0.5753036458318692 Accuracy 62.64446377532\n",
      "Training:: Epoch 46, Iteration 10, Current loss 0.5923519701729353 Accuracy 69.7425624413946\n",
      "Training:: Epoch 46, Iteration 20, Current loss 0.9138823783393718 Accuracy 60.78842676311031\n",
      "Training:: Epoch 46, Iteration 30, Current loss 0.7756020406344059 Accuracy 61.46450472923812\n",
      "Training:: Epoch 46, Iteration 40, Current loss 0.6607307718287829 Accuracy 55.16957674376086\n",
      "Training:: Epoch 46, Iteration 50, Current loss 0.8667535304132334 Accuracy 69.38610007298678\n",
      "Training:: Epoch 46, Iteration 60, Current loss 0.8003004357533896 Accuracy 62.4806754667618\n",
      "Training:: Epoch 46, Iteration 70, Current loss 0.7321814727260113 Accuracy 59.12849577255412\n",
      "Training:: Epoch 46, Iteration 80, Current loss 0.6107060915905413 Accuracy 64.39795359035264\n",
      "Training:: Epoch 46, Iteration 90, Current loss 0.7497476272267249 Accuracy 64.1939141939142\n",
      "Training:: Epoch 46, Iteration 100, Current loss 0.9414889329622202 Accuracy 59.675193716166014\n",
      "Training:: Epoch 46, Iteration 110, Current loss 0.7218073900238943 Accuracy 65.15475846109344\n",
      "Training:: Epoch 46, Iteration 120, Current loss 0.5023171312447716 Accuracy 57.412049442475585\n",
      "Training:: Epoch 46, Iteration 130, Current loss 0.9558206059412089 Accuracy 57.895364554345235\n",
      "Training:: Epoch 46, Iteration 140, Current loss 0.6918765429680898 Accuracy 59.85028203911645\n",
      "Training:: Epoch 46, Iteration 150, Current loss 0.8023287491705275 Accuracy 46.974427594409754\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 46, Probability Accuracy 56.00303569734544\n",
      "Starting Training\n",
      "Training:: Epoch 47, Iteration 0, Current loss 0.5326176143148618 Accuracy 54.6282070978645\n",
      "Training:: Epoch 47, Iteration 10, Current loss 0.7269175153908364 Accuracy 69.63393494442745\n",
      "Training:: Epoch 47, Iteration 20, Current loss 1.0569591357682995 Accuracy 59.14279889919478\n",
      "Training:: Epoch 47, Iteration 30, Current loss 0.7861472899025235 Accuracy 68.08571428571429\n",
      "Training:: Epoch 47, Iteration 40, Current loss 0.8674741815322425 Accuracy 56.80666394827285\n",
      "Training:: Epoch 47, Iteration 50, Current loss 0.6417548898478292 Accuracy 51.00147181160811\n",
      "Training:: Epoch 47, Iteration 60, Current loss 0.9647472206558885 Accuracy 65.24598003467034\n",
      "Training:: Epoch 47, Iteration 70, Current loss 1.263459785269963 Accuracy 57.60244428468727\n",
      "Training:: Epoch 47, Iteration 80, Current loss 0.9631851171325543 Accuracy 52.10266535044423\n",
      "Training:: Epoch 47, Iteration 90, Current loss 0.8675728519712577 Accuracy 61.50564030627155\n",
      "Training:: Epoch 47, Iteration 100, Current loss 0.8049293341356603 Accuracy 57.28867031641459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 47, Iteration 110, Current loss 0.7840939488479695 Accuracy 61.34808853118712\n",
      "Training:: Epoch 47, Iteration 120, Current loss 0.7323309311296196 Accuracy 67.83103566697739\n",
      "Training:: Epoch 47, Iteration 130, Current loss 0.7285881435852488 Accuracy 65.52141527001862\n",
      "Training:: Epoch 47, Iteration 140, Current loss 0.7575194636758096 Accuracy 67.7389404696887\n",
      "Training:: Epoch 47, Iteration 150, Current loss 0.8975698117368982 Accuracy 60.67242442936459\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 47, Probability Accuracy 55.71888549729075\n",
      "Starting Training\n",
      "Training:: Epoch 48, Iteration 0, Current loss 0.6986942731406132 Accuracy 62.275784753363226\n",
      "Training:: Epoch 48, Iteration 10, Current loss 0.688708204249694 Accuracy 72.002772002772\n",
      "Training:: Epoch 48, Iteration 20, Current loss 0.627750459665618 Accuracy 71.13161205295633\n",
      "Training:: Epoch 48, Iteration 30, Current loss 0.588544809916312 Accuracy 68.57808270913326\n",
      "Training:: Epoch 48, Iteration 40, Current loss 0.6324908678766716 Accuracy 66.6779388764425\n",
      "Training:: Epoch 48, Iteration 50, Current loss 0.7728401680676742 Accuracy 59.76200969590128\n",
      "Training:: Epoch 48, Iteration 60, Current loss 0.7399521912324781 Accuracy 56.94315485401837\n",
      "Training:: Epoch 48, Iteration 70, Current loss 0.9315666542793245 Accuracy 63.77313669207166\n",
      "Training:: Epoch 48, Iteration 80, Current loss 0.7368257936385605 Accuracy 63.14437403665011\n",
      "Training:: Epoch 48, Iteration 90, Current loss 0.6631026293394469 Accuracy 67.19133496958702\n",
      "Training:: Epoch 48, Iteration 100, Current loss 0.7577942525209981 Accuracy 63.171265260038105\n",
      "Training:: Epoch 48, Iteration 110, Current loss 0.8994581688761483 Accuracy 65.58663028649386\n",
      "Training:: Epoch 48, Iteration 120, Current loss 0.7252722921992153 Accuracy 61.054880791722894\n",
      "Training:: Epoch 48, Iteration 130, Current loss 0.6166301140789227 Accuracy 63.6295774063783\n",
      "Training:: Epoch 48, Iteration 140, Current loss 0.6297929491107539 Accuracy 62.86499934529265\n",
      "Training:: Epoch 48, Iteration 150, Current loss 0.6223206688632936 Accuracy 68.3676703645008\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 48, Probability Accuracy 55.36765977868427\n",
      "Starting Training\n",
      "Training:: Epoch 49, Iteration 0, Current loss 0.6189330722934083 Accuracy 60.94167739380136\n",
      "Training:: Epoch 49, Iteration 10, Current loss 0.628841604984069 Accuracy 64.86513141673653\n",
      "Training:: Epoch 49, Iteration 20, Current loss 0.5065466395499644 Accuracy 57.142857142857146\n",
      "Training:: Epoch 49, Iteration 30, Current loss 0.6030447078537367 Accuracy 55.7428991739278\n",
      "Training:: Epoch 49, Iteration 40, Current loss 0.604071326929613 Accuracy 57.683084301789336\n",
      "Training:: Epoch 49, Iteration 50, Current loss 0.5463400420363632 Accuracy 67.95563843360486\n",
      "Training:: Epoch 49, Iteration 60, Current loss 0.529839126035359 Accuracy 64.22576328913757\n",
      "Training:: Epoch 49, Iteration 70, Current loss 0.5787395085444544 Accuracy 71.1406181976491\n",
      "Training:: Epoch 49, Iteration 80, Current loss 0.7135985870612024 Accuracy 56.36309256766861\n",
      "Training:: Epoch 49, Iteration 90, Current loss 0.4949702895618151 Accuracy 53.87274931525302\n",
      "Training:: Epoch 49, Iteration 100, Current loss 0.7640958190033861 Accuracy 65.01628664495114\n",
      "Training:: Epoch 49, Iteration 110, Current loss 0.9164316126763523 Accuracy 53.20829750644884\n",
      "Training:: Epoch 49, Iteration 120, Current loss 0.9371477405274126 Accuracy 56.30118890356671\n",
      "Training:: Epoch 49, Iteration 130, Current loss 0.5846666721256711 Accuracy 74.75426469655653\n",
      "Training:: Epoch 49, Iteration 140, Current loss 0.7973129783693568 Accuracy 70.74352941176471\n",
      "Training:: Epoch 49, Iteration 150, Current loss 0.7207384497318281 Accuracy 63.740779246497354\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 49, Probability Accuracy 55.91453172694349\n",
      "Starting Training\n",
      "Training:: Epoch 50, Iteration 0, Current loss 0.8800489417753201 Accuracy 63.76791134326251\n",
      "Training:: Epoch 50, Iteration 10, Current loss 0.9110403906424324 Accuracy 75.71500250878073\n",
      "Training:: Epoch 50, Iteration 20, Current loss 1.9727923809480479 Accuracy 62.458824186254255\n",
      "Training:: Epoch 50, Iteration 30, Current loss 2.1749324982310014 Accuracy 69.49266585923833\n",
      "Training:: Epoch 50, Iteration 40, Current loss 0.94490139498095 Accuracy 70.88491517652453\n",
      "Training:: Epoch 50, Iteration 50, Current loss 1.3254951207998427 Accuracy 59.9768875192604\n",
      "Training:: Epoch 50, Iteration 60, Current loss 10.156255655331297 Accuracy 30.595599393019725\n",
      "Training:: Epoch 50, Iteration 70, Current loss 0.8507163147531586 Accuracy 75.79690161408062\n",
      "Training:: Epoch 50, Iteration 80, Current loss 2.2245371678434562 Accuracy 55.484378512025174\n",
      "Training:: Epoch 50, Iteration 90, Current loss 3.2560127140313924 Accuracy 55.34732124668975\n",
      "Training:: Epoch 50, Iteration 100, Current loss 4.019944755998958 Accuracy 60.91518823020338\n",
      "Training:: Epoch 50, Iteration 110, Current loss 1.8962346232391052 Accuracy 61.29468055164649\n",
      "Training:: Epoch 50, Iteration 120, Current loss 2.7562332047191305 Accuracy 56.098342275967006\n",
      "Training:: Epoch 50, Iteration 130, Current loss 3.3582719164932833 Accuracy 53.94177560349667\n",
      "Training:: Epoch 50, Iteration 140, Current loss 2.428726441448188 Accuracy 59.817711263643524\n",
      "Training:: Epoch 50, Iteration 150, Current loss 1.5221910603543307 Accuracy 69.28171440878742\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 50, Probability Accuracy 55.02078671435985\n",
      "Calculating Expectation\n",
      "Epoch 50 iter 0\n",
      "Epoch 50 iter 10\n",
      "Epoch 50 iter 20\n",
      "Epoch 50 iter 30\n",
      "Epoch 50 iter 40\n",
      "Epoch 50 iter 50\n",
      "Epoch 50 iter 60\n",
      "Epoch 50 iter 70\n",
      "Epoch 50 iter 80\n",
      "Epoch 50 iter 90\n",
      "Epoch 50 iter 100\n",
      "Epoch 50 iter 110\n",
      "Epoch 50 iter 120\n",
      "Epoch 50 iter 130\n",
      "Epoch 50 iter 140\n",
      "Epoch 50 iter 150\n",
      "Train Boundary avergage error = 309.658\n",
      "Train From boundary avergage accuracy = 59.652\n",
      "Starting Training\n",
      "Training:: Epoch 51, Iteration 0, Current loss 1.0195629710112277 Accuracy 58.29959514170041\n",
      "Training:: Epoch 51, Iteration 10, Current loss 0.8906682718963377 Accuracy 59.83766233766234\n",
      "Training:: Epoch 51, Iteration 20, Current loss 1.6965641048352083 Accuracy 65.16751326979053\n",
      "Training:: Epoch 51, Iteration 30, Current loss 1.1059088789723779 Accuracy 62.10873146622735\n",
      "Training:: Epoch 51, Iteration 40, Current loss 1.0492014634535012 Accuracy 61.0821155184412\n",
      "Training:: Epoch 51, Iteration 50, Current loss 0.6752383274980327 Accuracy 69.23076923076923\n",
      "Training:: Epoch 51, Iteration 60, Current loss 1.6657316234007395 Accuracy 62.11772665764547\n",
      "Training:: Epoch 51, Iteration 70, Current loss 1.0237942688543704 Accuracy 74.53637215110834\n",
      "Training:: Epoch 51, Iteration 80, Current loss 1.353654750242145 Accuracy 66.21719065474474\n",
      "Training:: Epoch 51, Iteration 90, Current loss 0.7968880147172395 Accuracy 61.3518710249963\n",
      "Training:: Epoch 51, Iteration 100, Current loss 0.7746904684735505 Accuracy 56.21949415766898\n",
      "Training:: Epoch 51, Iteration 110, Current loss 0.8144437475012349 Accuracy 72.56402344955261\n",
      "Training:: Epoch 51, Iteration 120, Current loss 1.4920181596139936 Accuracy 60.2603157020216\n",
      "Training:: Epoch 51, Iteration 130, Current loss 0.7200510996768822 Accuracy 59.94552175886893\n",
      "Training:: Epoch 51, Iteration 140, Current loss 0.6978517351889253 Accuracy 65.02514532035791\n",
      "Training:: Epoch 51, Iteration 150, Current loss 0.7389549101463455 Accuracy 58.093525179856115\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 51, Probability Accuracy 55.18708042923868\n",
      "Starting Training\n",
      "Training:: Epoch 52, Iteration 0, Current loss 0.7327378219821912 Accuracy 68.97921760391198\n",
      "Training:: Epoch 52, Iteration 10, Current loss 0.5924676941971676 Accuracy 67.42419009463286\n",
      "Training:: Epoch 52, Iteration 20, Current loss 1.549977093773458 Accuracy 66.70599339310996\n",
      "Training:: Epoch 52, Iteration 30, Current loss 1.092293241888218 Accuracy 72.53094725511302\n",
      "Training:: Epoch 52, Iteration 40, Current loss 0.9724537673482301 Accuracy 48.784604996623905\n",
      "Training:: Epoch 52, Iteration 50, Current loss 0.7210529768453118 Accuracy 66.60716562539845\n",
      "Training:: Epoch 52, Iteration 60, Current loss 0.8547953593243871 Accuracy 60.43615949330646\n",
      "Training:: Epoch 52, Iteration 70, Current loss 0.6819704401602737 Accuracy 68.88476821192053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 52, Iteration 80, Current loss 0.9826910496239855 Accuracy 62.549684358194995\n",
      "Training:: Epoch 52, Iteration 90, Current loss 0.714737879187501 Accuracy 53.34930522280786\n",
      "Training:: Epoch 52, Iteration 100, Current loss 0.763611737322816 Accuracy 57.22916841486951\n",
      "Training:: Epoch 52, Iteration 110, Current loss 0.7546113126402917 Accuracy 61.45182578090629\n",
      "Training:: Epoch 52, Iteration 120, Current loss 0.6942867850093002 Accuracy 54.97318097014925\n",
      "Training:: Epoch 52, Iteration 130, Current loss 0.9175285827157666 Accuracy 67.91255289139633\n",
      "Training:: Epoch 52, Iteration 140, Current loss 0.5660430994530691 Accuracy 71.87682428488033\n",
      "Training:: Epoch 52, Iteration 150, Current loss 0.8377363450868764 Accuracy 60.64720709000732\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 52, Probability Accuracy 55.495114424584685\n",
      "Starting Training\n",
      "Training:: Epoch 53, Iteration 0, Current loss 0.7374775845924366 Accuracy 65.22796352583586\n",
      "Training:: Epoch 53, Iteration 10, Current loss 0.6444679445739848 Accuracy 65.07442790491002\n",
      "Training:: Epoch 53, Iteration 20, Current loss 0.5417925711413506 Accuracy 65.82459485224022\n",
      "Training:: Epoch 53, Iteration 30, Current loss 0.4910703161001876 Accuracy 76.09262383070082\n",
      "Training:: Epoch 53, Iteration 40, Current loss 0.6399607474537234 Accuracy 60.9652592965547\n",
      "Training:: Epoch 53, Iteration 50, Current loss 0.5962581418055783 Accuracy 59.077920650620946\n",
      "Training:: Epoch 53, Iteration 60, Current loss 0.7046197378217642 Accuracy 65.5823878421984\n",
      "Training:: Epoch 53, Iteration 70, Current loss 0.8618156727212354 Accuracy 53.961722488038276\n",
      "Training:: Epoch 53, Iteration 80, Current loss 0.5310752508967923 Accuracy 61.72652166582364\n",
      "Training:: Epoch 53, Iteration 90, Current loss 0.5368464362329189 Accuracy 55.32004418029769\n",
      "Training:: Epoch 53, Iteration 100, Current loss 0.6023280544183671 Accuracy 70.96199260348438\n",
      "Training:: Epoch 53, Iteration 110, Current loss 0.6024249528960701 Accuracy 61.97235945219186\n",
      "Training:: Epoch 53, Iteration 120, Current loss 0.6178358401404076 Accuracy 69.31696569090337\n",
      "Training:: Epoch 53, Iteration 130, Current loss 0.6098287334135187 Accuracy 67.32841747022121\n",
      "Training:: Epoch 53, Iteration 140, Current loss 0.5213406767945228 Accuracy 60.573313616198384\n",
      "Training:: Epoch 53, Iteration 150, Current loss 0.7523416407662983 Accuracy 70.06936713196883\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 53, Probability Accuracy 55.522011595917434\n",
      "Starting Training\n",
      "Training:: Epoch 54, Iteration 0, Current loss 0.5737015522617207 Accuracy 64.1039701688967\n",
      "Training:: Epoch 54, Iteration 10, Current loss 0.7173842758739107 Accuracy 61.09967811724975\n",
      "Training:: Epoch 54, Iteration 20, Current loss 0.48120664685695147 Accuracy 60.28811252268603\n",
      "Training:: Epoch 54, Iteration 30, Current loss 0.7685441845276363 Accuracy 65.99016470220904\n",
      "Training:: Epoch 54, Iteration 40, Current loss 0.8082882020858253 Accuracy 60.94296188933413\n",
      "Training:: Epoch 54, Iteration 50, Current loss 0.6164367124914745 Accuracy 55.9802752441422\n",
      "Training:: Epoch 54, Iteration 60, Current loss 0.603281154503245 Accuracy 65.36028390680451\n",
      "Training:: Epoch 54, Iteration 70, Current loss 0.7252553578566577 Accuracy 71.25026899074672\n",
      "Training:: Epoch 54, Iteration 80, Current loss 0.7983063902456006 Accuracy 66.29506147113982\n",
      "Training:: Epoch 54, Iteration 90, Current loss 0.8892295937275123 Accuracy 65.83680090274349\n",
      "Training:: Epoch 54, Iteration 100, Current loss 0.6929706182876291 Accuracy 64.63818583319178\n",
      "Training:: Epoch 54, Iteration 110, Current loss 0.5946988131606381 Accuracy 66.93636862314865\n",
      "Training:: Epoch 54, Iteration 120, Current loss 0.5899740279935219 Accuracy 52.79610976033345\n",
      "Training:: Epoch 54, Iteration 130, Current loss 0.5217894982176712 Accuracy 68.513195714659\n",
      "Training:: Epoch 54, Iteration 140, Current loss 0.6538298409497156 Accuracy 71.65704718685289\n",
      "Training:: Epoch 54, Iteration 150, Current loss 0.6143302555877364 Accuracy 67.38901956859016\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 54, Probability Accuracy 55.14902260590063\n",
      "Starting Training\n",
      "Training:: Epoch 55, Iteration 0, Current loss 0.6255750215341827 Accuracy 69.13767840668584\n",
      "Training:: Epoch 55, Iteration 10, Current loss 1.0065304563582915 Accuracy 60.683400126555576\n",
      "Training:: Epoch 55, Iteration 20, Current loss 0.8436293203099394 Accuracy 64.63098325866541\n",
      "Training:: Epoch 55, Iteration 30, Current loss 0.646791579127031 Accuracy 52.972748075722905\n",
      "Training:: Epoch 55, Iteration 40, Current loss 0.5684547947038905 Accuracy 65.31850353892821\n",
      "Training:: Epoch 55, Iteration 50, Current loss 0.625321516985618 Accuracy 67.02737110120943\n",
      "Training:: Epoch 55, Iteration 60, Current loss 0.6271830928540859 Accuracy 58.429304344706345\n",
      "Training:: Epoch 55, Iteration 70, Current loss 1.050702140861378 Accuracy 54.51617735170761\n",
      "Training:: Epoch 55, Iteration 80, Current loss 1.0104871348379936 Accuracy 64.34858563461668\n",
      "Training:: Epoch 55, Iteration 90, Current loss 1.430421256983483 Accuracy 54.900422450211224\n",
      "Training:: Epoch 55, Iteration 100, Current loss 0.9179405007761134 Accuracy 58.064404671411786\n",
      "Training:: Epoch 55, Iteration 110, Current loss 0.6672430584196741 Accuracy 73.21780496092423\n",
      "Training:: Epoch 55, Iteration 120, Current loss 0.8600340280904963 Accuracy 65.36709484138383\n",
      "Training:: Epoch 55, Iteration 130, Current loss 1.128154113793598 Accuracy 66.42895732036737\n",
      "Training:: Epoch 55, Iteration 140, Current loss 0.6191976665010991 Accuracy 58.25605132691747\n",
      "Training:: Epoch 55, Iteration 150, Current loss 0.6334629877783117 Accuracy 64.83448197943736\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 55, Probability Accuracy 55.6725687914688\n",
      "Calculating Expectation\n",
      "Epoch 55 iter 0\n",
      "Epoch 55 iter 10\n",
      "Epoch 55 iter 20\n",
      "Epoch 55 iter 30\n",
      "Epoch 55 iter 40\n",
      "Epoch 55 iter 50\n",
      "Epoch 55 iter 60\n",
      "Epoch 55 iter 70\n",
      "Epoch 55 iter 80\n",
      "Epoch 55 iter 90\n",
      "Epoch 55 iter 100\n",
      "Epoch 55 iter 110\n",
      "Epoch 55 iter 120\n",
      "Epoch 55 iter 130\n",
      "Epoch 55 iter 140\n",
      "Epoch 55 iter 150\n",
      "Train Boundary avergage error = 309.299\n",
      "Train From boundary avergage accuracy = 59.502\n",
      "Starting Training\n",
      "Training:: Epoch 56, Iteration 0, Current loss 0.5191800666952593 Accuracy 71.12313511241858\n",
      "Training:: Epoch 56, Iteration 10, Current loss 0.7135848982358105 Accuracy 57.1515587795559\n",
      "Training:: Epoch 56, Iteration 20, Current loss 0.5631945050848033 Accuracy 64.77972383286509\n",
      "Training:: Epoch 56, Iteration 30, Current loss 0.5644761016203237 Accuracy 60.06137251255347\n",
      "Training:: Epoch 56, Iteration 40, Current loss 0.42190145482246216 Accuracy 70.64330292846856\n",
      "Training:: Epoch 56, Iteration 50, Current loss 0.6221584938035039 Accuracy 62.82566741717594\n",
      "Training:: Epoch 56, Iteration 60, Current loss 0.7148296517817164 Accuracy 59.32968459064492\n",
      "Training:: Epoch 56, Iteration 70, Current loss 0.7230399337952204 Accuracy 57.35756250853942\n",
      "Training:: Epoch 56, Iteration 80, Current loss 0.6816840401886218 Accuracy 60.78983909172588\n",
      "Training:: Epoch 56, Iteration 90, Current loss 0.7137434514168253 Accuracy 61.192540385455\n",
      "Training:: Epoch 56, Iteration 100, Current loss 0.6620774252562196 Accuracy 52.049883086515976\n",
      "Training:: Epoch 56, Iteration 110, Current loss 0.7697678582178824 Accuracy 63.900831183720264\n",
      "Training:: Epoch 56, Iteration 120, Current loss 0.7413263572943761 Accuracy 56.785976697806234\n",
      "Training:: Epoch 56, Iteration 130, Current loss 0.9496038075007049 Accuracy 64.3023132988275\n",
      "Training:: Epoch 56, Iteration 140, Current loss 0.7959871459776531 Accuracy 58.13008130081301\n",
      "Training:: Epoch 56, Iteration 150, Current loss 1.0793948955093842 Accuracy 56.72447013487476\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 56, Probability Accuracy 55.69444366939916\n",
      "Starting Training\n",
      "Training:: Epoch 57, Iteration 0, Current loss 0.6389538118761786 Accuracy 59.910155186496056\n",
      "Training:: Epoch 57, Iteration 10, Current loss 0.7516790864637305 Accuracy 61.06992295391772\n",
      "Training:: Epoch 57, Iteration 20, Current loss 0.5780438367839427 Accuracy 58.674082982561636\n",
      "Training:: Epoch 57, Iteration 30, Current loss 0.5393265496401222 Accuracy 58.701193372726216\n",
      "Training:: Epoch 57, Iteration 40, Current loss 0.809627334803058 Accuracy 62.24690915606522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 57, Iteration 50, Current loss 0.6576755578569279 Accuracy 65.3539059128183\n",
      "Training:: Epoch 57, Iteration 60, Current loss 0.5005670048910424 Accuracy 62.83318623124448\n",
      "Training:: Epoch 57, Iteration 70, Current loss 0.6568862505403621 Accuracy 67.7310451540301\n",
      "Training:: Epoch 57, Iteration 80, Current loss 0.502225081195971 Accuracy 67.92246635223744\n",
      "Training:: Epoch 57, Iteration 90, Current loss 0.7502294928936583 Accuracy 60.06648659879493\n",
      "Training:: Epoch 57, Iteration 100, Current loss 0.5801523565293573 Accuracy 72.57961424220777\n",
      "Training:: Epoch 57, Iteration 110, Current loss 0.5701876301238982 Accuracy 61.52043440983138\n",
      "Training:: Epoch 57, Iteration 120, Current loss 0.7962254421517976 Accuracy 66.42088827203331\n",
      "Training:: Epoch 57, Iteration 130, Current loss 0.942822644588587 Accuracy 58.3956574185766\n",
      "Training:: Epoch 57, Iteration 140, Current loss 0.9151606153711502 Accuracy 66.91862674718128\n",
      "Training:: Epoch 57, Iteration 150, Current loss 1.115383912099258 Accuracy 75.5437228138593\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 57, Probability Accuracy 54.48295489422492\n",
      "Starting Training\n",
      "Training:: Epoch 58, Iteration 0, Current loss 0.5676052959867612 Accuracy 59.39869511549991\n",
      "Training:: Epoch 58, Iteration 10, Current loss 0.5344567681704431 Accuracy 68.539283564118\n",
      "Training:: Epoch 58, Iteration 20, Current loss 0.6264920385070311 Accuracy 63.16283435007039\n",
      "Training:: Epoch 58, Iteration 30, Current loss 1.0198923961499382 Accuracy 60.17035410081963\n",
      "Training:: Epoch 58, Iteration 40, Current loss 1.9513868444757367 Accuracy 56.193307800846604\n",
      "Training:: Epoch 58, Iteration 50, Current loss 0.6447447140413444 Accuracy 73.96440129449839\n",
      "Training:: Epoch 58, Iteration 60, Current loss 0.9104386081911127 Accuracy 64.48230668414155\n",
      "Training:: Epoch 58, Iteration 70, Current loss 0.5614040114385924 Accuracy 66.20822565809645\n",
      "Training:: Epoch 58, Iteration 80, Current loss 0.6803715164489537 Accuracy 59.37632135306554\n",
      "Training:: Epoch 58, Iteration 90, Current loss 0.6995751702068486 Accuracy 54.935812306330234\n",
      "Training:: Epoch 58, Iteration 100, Current loss 0.6566304501806932 Accuracy 68.47219722872053\n",
      "Training:: Epoch 58, Iteration 110, Current loss 0.5744151153055953 Accuracy 56.6432474629196\n",
      "Training:: Epoch 58, Iteration 120, Current loss 0.650803227619259 Accuracy 64.96438854371874\n",
      "Training:: Epoch 58, Iteration 130, Current loss 0.5719954668700686 Accuracy 55.838385950240436\n",
      "Training:: Epoch 58, Iteration 140, Current loss 0.8941406926537813 Accuracy 62.492787074437395\n",
      "Training:: Epoch 58, Iteration 150, Current loss 0.6543108985644006 Accuracy 57.3038773669973\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 58, Probability Accuracy 56.493323139937836\n",
      "Starting Training\n",
      "Training:: Epoch 59, Iteration 0, Current loss 0.6878552645723284 Accuracy 67.6754939050021\n",
      "Training:: Epoch 59, Iteration 10, Current loss 0.5257493387172931 Accuracy 68.84415905161768\n",
      "Training:: Epoch 59, Iteration 20, Current loss 0.5140968665570058 Accuracy 61.330213903743314\n",
      "Training:: Epoch 59, Iteration 30, Current loss 0.5726613551306878 Accuracy 63.88967668746455\n",
      "Training:: Epoch 59, Iteration 40, Current loss 0.8084453228691264 Accuracy 61.572473671517\n",
      "Training:: Epoch 59, Iteration 50, Current loss 0.6530970259580186 Accuracy 68.15583034170987\n",
      "Training:: Epoch 59, Iteration 60, Current loss 0.86895279151685 Accuracy 55.30571992110453\n",
      "Training:: Epoch 59, Iteration 70, Current loss 0.6756832924533136 Accuracy 57.20653789004458\n",
      "Training:: Epoch 59, Iteration 80, Current loss 0.6692319983680979 Accuracy 65.34008399073747\n",
      "Training:: Epoch 59, Iteration 90, Current loss 0.7520928059301653 Accuracy 62.96443210366257\n",
      "Training:: Epoch 59, Iteration 100, Current loss 0.682431245270571 Accuracy 66.44812957963748\n",
      "Training:: Epoch 59, Iteration 110, Current loss 0.5526760735632303 Accuracy 56.28026006363259\n",
      "Training:: Epoch 59, Iteration 120, Current loss 0.40952992013383854 Accuracy 70.66230418401744\n",
      "Training:: Epoch 59, Iteration 130, Current loss 0.6416927258733401 Accuracy 61.34652913298021\n",
      "Training:: Epoch 59, Iteration 140, Current loss 0.7982871884705416 Accuracy 64.09324377716318\n",
      "Training:: Epoch 59, Iteration 150, Current loss 0.6786069267791687 Accuracy 60.40330537740503\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 59, Probability Accuracy 54.69043141500327\n",
      "Starting Training\n",
      "Training:: Epoch 60, Iteration 0, Current loss 0.5371673906257621 Accuracy 61.197047821251644\n",
      "Training:: Epoch 60, Iteration 10, Current loss 0.46074422036728896 Accuracy 70.11557918836084\n",
      "Training:: Epoch 60, Iteration 20, Current loss 0.4214706991242941 Accuracy 70.32101479140907\n",
      "Training:: Epoch 60, Iteration 30, Current loss 0.6439254297110969 Accuracy 65.12884152127893\n",
      "Training:: Epoch 60, Iteration 40, Current loss 0.4742820931663819 Accuracy 56.51965484180249\n",
      "Training:: Epoch 60, Iteration 50, Current loss 0.5879162337287814 Accuracy 64.21470030458019\n",
      "Training:: Epoch 60, Iteration 60, Current loss 1.000333492542331 Accuracy 67.74193548387096\n",
      "Training:: Epoch 60, Iteration 70, Current loss 1.2618291613100898 Accuracy 62.88792598664949\n",
      "Training:: Epoch 60, Iteration 80, Current loss 0.46500782151603726 Accuracy 70.43422733077905\n",
      "Training:: Epoch 60, Iteration 90, Current loss 0.7352684282603014 Accuracy 60.73899806255189\n",
      "Training:: Epoch 60, Iteration 100, Current loss 0.9365299551308206 Accuracy 63.743855453700014\n",
      "Training:: Epoch 60, Iteration 110, Current loss 0.6137327226793216 Accuracy 64.15774847750251\n",
      "Training:: Epoch 60, Iteration 120, Current loss 0.7649847314376144 Accuracy 53.157518873699246\n",
      "Training:: Epoch 60, Iteration 130, Current loss 1.0683096923949684 Accuracy 68.2757966616085\n",
      "Training:: Epoch 60, Iteration 140, Current loss 0.5341646313567332 Accuracy 64.91242633020669\n",
      "Training:: Epoch 60, Iteration 150, Current loss 0.6920945569812056 Accuracy 62.53891793455912\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 60, Probability Accuracy 54.60750777060396\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.625385229996574\n",
      "Calculating Expectation\n",
      "Epoch 60 iter 0\n",
      "Epoch 60 iter 10\n",
      "Epoch 60 iter 20\n",
      "Epoch 60 iter 30\n",
      "Epoch 60 iter 40\n",
      "Epoch 60 iter 50\n",
      "Epoch 60 iter 60\n",
      "Epoch 60 iter 70\n",
      "Epoch 60 iter 80\n",
      "Epoch 60 iter 90\n",
      "Epoch 60 iter 100\n",
      "Epoch 60 iter 110\n",
      "Epoch 60 iter 120\n",
      "Epoch 60 iter 130\n",
      "Epoch 60 iter 140\n",
      "Epoch 60 iter 150\n",
      "Train Boundary avergage error = 309.894\n",
      "Train From boundary avergage accuracy = 59.388\n",
      "Starting Training\n",
      "Training:: Epoch 61, Iteration 0, Current loss 0.48256019633189934 Accuracy 65.60081763761133\n",
      "Training:: Epoch 61, Iteration 10, Current loss 0.7365025805519797 Accuracy 61.03129408076903\n",
      "Training:: Epoch 61, Iteration 20, Current loss 0.48304208826631084 Accuracy 53.19980459208598\n",
      "Training:: Epoch 61, Iteration 30, Current loss 0.44298813023927563 Accuracy 73.98735130251468\n",
      "Training:: Epoch 61, Iteration 40, Current loss 0.4918023218190134 Accuracy 65.71773059146628\n",
      "Training:: Epoch 61, Iteration 50, Current loss 0.5521649477684875 Accuracy 70.74511217226777\n",
      "Training:: Epoch 61, Iteration 60, Current loss 0.5501344101052933 Accuracy 55.48037889039242\n",
      "Training:: Epoch 61, Iteration 70, Current loss 0.40177127064815665 Accuracy 54.76735015772871\n",
      "Training:: Epoch 61, Iteration 80, Current loss 0.44684947583670254 Accuracy 63.57711803041274\n",
      "Training:: Epoch 61, Iteration 90, Current loss 0.5098012278375 Accuracy 56.11393119007332\n",
      "Training:: Epoch 61, Iteration 100, Current loss 0.45848274117492527 Accuracy 60.5603225472966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 61, Iteration 110, Current loss 0.5430805960979912 Accuracy 70.1642740861329\n",
      "Training:: Epoch 61, Iteration 120, Current loss 0.5601208412872463 Accuracy 70.1796768835875\n",
      "Training:: Epoch 61, Iteration 130, Current loss 0.55903926731807 Accuracy 48.60587002096436\n",
      "Training:: Epoch 61, Iteration 140, Current loss 0.42725612348132513 Accuracy 71.91599059822579\n",
      "Training:: Epoch 61, Iteration 150, Current loss 0.592352836558039 Accuracy 65.08372093023256\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 61, Probability Accuracy 55.700582028002074\n",
      "Starting Training\n",
      "Training:: Epoch 62, Iteration 0, Current loss 0.5570877573790556 Accuracy 61.11848900693522\n",
      "Training:: Epoch 62, Iteration 10, Current loss 0.49148179704514405 Accuracy 72.10871484424266\n",
      "Training:: Epoch 62, Iteration 20, Current loss 0.4528456842234413 Accuracy 62.80336581045173\n",
      "Training:: Epoch 62, Iteration 30, Current loss 0.6580876633444178 Accuracy 67.44450050454087\n",
      "Training:: Epoch 62, Iteration 40, Current loss 0.49125870464190163 Accuracy 69.6312517660356\n",
      "Training:: Epoch 62, Iteration 50, Current loss 0.5291722301928589 Accuracy 66.7346560356017\n",
      "Training:: Epoch 62, Iteration 60, Current loss 0.7784275687131216 Accuracy 71.8073378936062\n",
      "Training:: Epoch 62, Iteration 70, Current loss 0.42137687217285597 Accuracy 69.38676967648479\n",
      "Training:: Epoch 62, Iteration 80, Current loss 0.5666093778179571 Accuracy 66.73192012976118\n",
      "Training:: Epoch 62, Iteration 90, Current loss 0.6340878692353161 Accuracy 60.21524771524771\n",
      "Training:: Epoch 62, Iteration 100, Current loss 0.5431305033588664 Accuracy 63.39058742700103\n",
      "Training:: Epoch 62, Iteration 110, Current loss 0.5096813877588081 Accuracy 56.609848484848484\n",
      "Training:: Epoch 62, Iteration 120, Current loss 0.6023221875098874 Accuracy 65.11995637949836\n",
      "Training:: Epoch 62, Iteration 130, Current loss 0.5126353291955265 Accuracy 67.88148784284257\n",
      "Training:: Epoch 62, Iteration 140, Current loss 0.6740995176241227 Accuracy 59.54174010575228\n",
      "Training:: Epoch 62, Iteration 150, Current loss 0.8966053448613687 Accuracy 67.98396334478808\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 62, Probability Accuracy 54.94500588724393\n",
      "Starting Training\n",
      "Training:: Epoch 63, Iteration 0, Current loss 0.7046459262894071 Accuracy 54.93443329434218\n",
      "Training:: Epoch 63, Iteration 10, Current loss 0.5650080197540958 Accuracy 65.61244979919678\n",
      "Training:: Epoch 63, Iteration 20, Current loss 0.6147885502575843 Accuracy 67.41542770954536\n",
      "Training:: Epoch 63, Iteration 30, Current loss 0.5009503663901678 Accuracy 62.850312801993795\n",
      "Training:: Epoch 63, Iteration 40, Current loss 0.43407033345225643 Accuracy 65.78854935019318\n",
      "Training:: Epoch 63, Iteration 50, Current loss 0.4273277906826848 Accuracy 59.95488593803201\n",
      "Training:: Epoch 63, Iteration 60, Current loss 0.6911895467642912 Accuracy 65.90314136125654\n",
      "Training:: Epoch 63, Iteration 70, Current loss 0.6853035178075297 Accuracy 54.823755794629584\n",
      "Training:: Epoch 63, Iteration 80, Current loss 0.46886570741082334 Accuracy 64.11283859592884\n",
      "Training:: Epoch 63, Iteration 90, Current loss 0.5137369289017434 Accuracy 63.91098484848485\n",
      "Training:: Epoch 63, Iteration 100, Current loss 0.4335030705592745 Accuracy 59.96404494382023\n",
      "Training:: Epoch 63, Iteration 110, Current loss 0.4578963264006581 Accuracy 71.89248946313826\n",
      "Training:: Epoch 63, Iteration 120, Current loss 0.5639717928163013 Accuracy 74.75408336002197\n",
      "Training:: Epoch 63, Iteration 130, Current loss 0.5810709903194938 Accuracy 54.58767855577951\n",
      "Training:: Epoch 63, Iteration 140, Current loss 0.4711358507485033 Accuracy 64.80012284383477\n",
      "Training:: Epoch 63, Iteration 150, Current loss 0.5295178437123845 Accuracy 60.81613253666485\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 63, Probability Accuracy 55.981830458535384\n",
      "Starting Training\n",
      "Training:: Epoch 64, Iteration 0, Current loss 1.0521965954574823 Accuracy 57.54305872587674\n",
      "Training:: Epoch 64, Iteration 10, Current loss 1.1383319228902595 Accuracy 65.6851232950953\n",
      "Training:: Epoch 64, Iteration 20, Current loss 1.6309007407892921 Accuracy 67.42576061213336\n",
      "Training:: Epoch 64, Iteration 30, Current loss 3.6160454940337097 Accuracy 54.41644745950436\n",
      "Training:: Epoch 64, Iteration 40, Current loss 4.857098306843237 Accuracy 39.401377781297015\n",
      "Training:: Epoch 64, Iteration 50, Current loss 3.010379245162217 Accuracy 64.15784867531228\n",
      "Training:: Epoch 64, Iteration 60, Current loss 2.7679616840638337 Accuracy 56.689777253282195\n",
      "Training:: Epoch 64, Iteration 70, Current loss 3.264686108871667 Accuracy 58.7853739739395\n",
      "Training:: Epoch 64, Iteration 80, Current loss 4.106127130757485 Accuracy 52.37514579577987\n",
      "Training:: Epoch 64, Iteration 90, Current loss 1.8849328532756362 Accuracy 50.05200884150305\n",
      "Training:: Epoch 64, Iteration 100, Current loss 2.263178895406718 Accuracy 52.48774156331122\n",
      "Training:: Epoch 64, Iteration 110, Current loss 2.2094122677186534 Accuracy 62.09367185997307\n",
      "Training:: Epoch 64, Iteration 120, Current loss 3.0564796085909314 Accuracy 56.54648956356736\n",
      "Training:: Epoch 64, Iteration 130, Current loss 3.6653558890763294 Accuracy 55.39827255278311\n",
      "Training:: Epoch 64, Iteration 140, Current loss 3.825244670351555 Accuracy 49.70539712467594\n",
      "Training:: Epoch 64, Iteration 150, Current loss 2.6014946359856266 Accuracy 62.91027576889454\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 64, Probability Accuracy 53.55360740174441\n",
      "Starting Training\n",
      "Training:: Epoch 65, Iteration 0, Current loss 2.351338664468388 Accuracy 60.81339103869654\n",
      "Training:: Epoch 65, Iteration 10, Current loss 3.866362316163512 Accuracy 62.982268121590025\n",
      "Training:: Epoch 65, Iteration 20, Current loss 3.063016212779448 Accuracy 59.2450148405167\n",
      "Training:: Epoch 65, Iteration 30, Current loss 1.535817244693676 Accuracy 61.54170176916597\n",
      "Training:: Epoch 65, Iteration 40, Current loss 1.0553685447844072 Accuracy 56.31868131868132\n",
      "Training:: Epoch 65, Iteration 50, Current loss 1.165234780545596 Accuracy 56.699157442590455\n",
      "Training:: Epoch 65, Iteration 60, Current loss 1.668210496957091 Accuracy 65.82592516022328\n",
      "Training:: Epoch 65, Iteration 70, Current loss 2.1979139121201094 Accuracy 51.517908842749605\n",
      "Training:: Epoch 65, Iteration 80, Current loss 1.2982408732986457 Accuracy 58.74700718276137\n",
      "Training:: Epoch 65, Iteration 90, Current loss 0.9669136175058857 Accuracy 66.99282452707111\n",
      "Training:: Epoch 65, Iteration 100, Current loss 1.4024742619148762 Accuracy 69.01076309106301\n",
      "Training:: Epoch 65, Iteration 110, Current loss 1.3728985692322824 Accuracy 67.8935339491477\n",
      "Training:: Epoch 65, Iteration 120, Current loss 0.8146344936339024 Accuracy 76.48814749780509\n",
      "Training:: Epoch 65, Iteration 130, Current loss 1.2152683901403978 Accuracy 57.130060910068075\n",
      "Training:: Epoch 65, Iteration 140, Current loss 1.242705093649942 Accuracy 63.53476183135502\n",
      "Training:: Epoch 65, Iteration 150, Current loss 1.6296477799982558 Accuracy 53.81204294383071\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 65, Probability Accuracy 55.31420025557893\n",
      "Calculating Expectation\n",
      "Epoch 65 iter 0\n",
      "Epoch 65 iter 10\n",
      "Epoch 65 iter 20\n",
      "Epoch 65 iter 30\n",
      "Epoch 65 iter 40\n",
      "Epoch 65 iter 50\n",
      "Epoch 65 iter 60\n",
      "Epoch 65 iter 70\n",
      "Epoch 65 iter 80\n",
      "Epoch 65 iter 90\n",
      "Epoch 65 iter 100\n",
      "Epoch 65 iter 110\n",
      "Epoch 65 iter 120\n",
      "Epoch 65 iter 130\n",
      "Epoch 65 iter 140\n",
      "Epoch 65 iter 150\n",
      "Train Boundary avergage error = 309.406\n",
      "Train From boundary avergage accuracy = 59.109\n",
      "Starting Training\n",
      "Training:: Epoch 66, Iteration 0, Current loss 0.8235995858604349 Accuracy 59.67243510506798\n",
      "Training:: Epoch 66, Iteration 10, Current loss 0.6620195192801016 Accuracy 62.569867097255\n",
      "Training:: Epoch 66, Iteration 20, Current loss 0.6127649411521726 Accuracy 61.42771445710858\n",
      "Training:: Epoch 66, Iteration 30, Current loss 0.5259271665166483 Accuracy 67.90957515915292\n",
      "Training:: Epoch 66, Iteration 40, Current loss 0.5513507382887554 Accuracy 53.778593432522776\n",
      "Training:: Epoch 66, Iteration 50, Current loss 0.4656070560598644 Accuracy 64.41756441756442\n",
      "Training:: Epoch 66, Iteration 60, Current loss 0.7693038050909385 Accuracy 66.67810275323784\n",
      "Training:: Epoch 66, Iteration 70, Current loss 0.612243590621509 Accuracy 62.32475146571501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 66, Iteration 80, Current loss 0.3945887745254318 Accuracy 71.37373554913295\n",
      "Training:: Epoch 66, Iteration 90, Current loss 0.5958340079173803 Accuracy 66.1977412324153\n",
      "Training:: Epoch 66, Iteration 100, Current loss 0.4761093666394274 Accuracy 65.60852254385021\n",
      "Training:: Epoch 66, Iteration 110, Current loss 0.539497626743511 Accuracy 55.2591941759759\n",
      "Training:: Epoch 66, Iteration 120, Current loss 0.5355589232193062 Accuracy 57.78658249949634\n",
      "Training:: Epoch 66, Iteration 130, Current loss 0.5517980317096558 Accuracy 67.84128483703354\n",
      "Training:: Epoch 66, Iteration 140, Current loss 1.00276132661814 Accuracy 60.02141982864137\n",
      "Training:: Epoch 66, Iteration 150, Current loss 0.5227219071918431 Accuracy 66.69371956548882\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 66, Probability Accuracy 55.41419969754633\n",
      "Starting Training\n",
      "Training:: Epoch 67, Iteration 0, Current loss 0.5524532361100932 Accuracy 62.48925809223718\n",
      "Training:: Epoch 67, Iteration 10, Current loss 0.544937652592551 Accuracy 46.36748699801619\n",
      "Training:: Epoch 67, Iteration 20, Current loss 0.4774030817050666 Accuracy 63.27920865994774\n",
      "Training:: Epoch 67, Iteration 30, Current loss 0.48032422107730777 Accuracy 56.53281263265133\n",
      "Training:: Epoch 67, Iteration 40, Current loss 0.47778222711547536 Accuracy 60.186001410437235\n",
      "Training:: Epoch 67, Iteration 50, Current loss 0.4933099999464175 Accuracy 66.35719689154804\n",
      "Training:: Epoch 67, Iteration 60, Current loss 0.4704991917111858 Accuracy 67.60465000249464\n",
      "Training:: Epoch 67, Iteration 70, Current loss 0.6011528898521291 Accuracy 63.588190764572296\n",
      "Training:: Epoch 67, Iteration 80, Current loss 0.5016098471908012 Accuracy 61.37090946629503\n",
      "Training:: Epoch 67, Iteration 90, Current loss 0.6067047821352853 Accuracy 68.61920777279522\n",
      "Training:: Epoch 67, Iteration 100, Current loss 0.6821146560479471 Accuracy 56.76381633214188\n",
      "Training:: Epoch 67, Iteration 110, Current loss 0.6351134261890805 Accuracy 69.32936123042816\n",
      "Training:: Epoch 67, Iteration 120, Current loss 0.41839776785287464 Accuracy 59.627063959005504\n",
      "Training:: Epoch 67, Iteration 130, Current loss 0.4369487407508965 Accuracy 63.647222132549956\n",
      "Training:: Epoch 67, Iteration 140, Current loss 0.6441575298273748 Accuracy 62.563320442289886\n",
      "Training:: Epoch 67, Iteration 150, Current loss 0.4615728377600645 Accuracy 69.42306671620402\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 67, Probability Accuracy 55.425025529991466\n",
      "Starting Training\n",
      "Training:: Epoch 68, Iteration 0, Current loss 0.5482227426206299 Accuracy 52.65323617659666\n",
      "Training:: Epoch 68, Iteration 10, Current loss 0.45181422613231814 Accuracy 63.996721555770804\n",
      "Training:: Epoch 68, Iteration 20, Current loss 0.3600360174387053 Accuracy 61.66090934553263\n",
      "Training:: Epoch 68, Iteration 30, Current loss 0.3466220259203323 Accuracy 60.480178671133444\n",
      "Training:: Epoch 68, Iteration 40, Current loss 0.5339252673504842 Accuracy 53.634564193570405\n",
      "Training:: Epoch 68, Iteration 50, Current loss 0.5732414845857419 Accuracy 51.833492214807755\n",
      "Training:: Epoch 68, Iteration 60, Current loss 0.48779560576978886 Accuracy 67.29301233118026\n",
      "Training:: Epoch 68, Iteration 70, Current loss 0.4173233594551246 Accuracy 67.02527448235207\n",
      "Training:: Epoch 68, Iteration 80, Current loss 0.4531039805969278 Accuracy 62.183610391780135\n",
      "Training:: Epoch 68, Iteration 90, Current loss 0.6299453835454228 Accuracy 62.98460571787622\n",
      "Training:: Epoch 68, Iteration 100, Current loss 0.46073278895057307 Accuracy 55.854442488712024\n",
      "Training:: Epoch 68, Iteration 110, Current loss 0.5678881166609471 Accuracy 53.81323762854579\n",
      "Training:: Epoch 68, Iteration 120, Current loss 0.4113812999698463 Accuracy 72.87581699346406\n",
      "Training:: Epoch 68, Iteration 130, Current loss 0.4992087911104569 Accuracy 67.50375617085211\n",
      "Training:: Epoch 68, Iteration 140, Current loss 0.4424504346813023 Accuracy 66.21697582911749\n",
      "Training:: Epoch 68, Iteration 150, Current loss 0.5359710627017991 Accuracy 67.2901181917875\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 68, Probability Accuracy 55.293664655889195\n",
      "Starting Training\n",
      "Training:: Epoch 69, Iteration 0, Current loss 0.5601685799469814 Accuracy 60.67836841776501\n",
      "Training:: Epoch 69, Iteration 10, Current loss 0.4020051103817142 Accuracy 67.00922661465756\n",
      "Training:: Epoch 69, Iteration 20, Current loss 0.5584193614526016 Accuracy 63.91019228631766\n",
      "Training:: Epoch 69, Iteration 30, Current loss 0.5345699444759897 Accuracy 69.2588624853915\n",
      "Training:: Epoch 69, Iteration 40, Current loss 0.42405771209999193 Accuracy 63.306739313744565\n",
      "Training:: Epoch 69, Iteration 50, Current loss 0.6050317177228577 Accuracy 62.38789237668161\n",
      "Training:: Epoch 69, Iteration 60, Current loss 0.40211451520733 Accuracy 65.79307201458523\n",
      "Training:: Epoch 69, Iteration 70, Current loss 0.5193874581787393 Accuracy 64.21686746987952\n",
      "Training:: Epoch 69, Iteration 80, Current loss 0.5478847791881716 Accuracy 61.99498746867168\n",
      "Training:: Epoch 69, Iteration 90, Current loss 0.5140206534638377 Accuracy 68.15027686269012\n",
      "Training:: Epoch 69, Iteration 100, Current loss 0.4608841609341121 Accuracy 63.49884321053568\n",
      "Training:: Epoch 69, Iteration 110, Current loss 0.3982659155130431 Accuracy 57.020019402063674\n",
      "Training:: Epoch 69, Iteration 120, Current loss 0.38670268077958975 Accuracy 65.63400184792651\n",
      "Training:: Epoch 69, Iteration 130, Current loss 0.44597196551342405 Accuracy 61.73160736355949\n",
      "Training:: Epoch 69, Iteration 140, Current loss 0.48210132332578415 Accuracy 59.941857276068234\n",
      "Training:: Epoch 69, Iteration 150, Current loss 0.42835834605432727 Accuracy 71.37943806550611\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 69, Probability Accuracy 56.02691949263676\n",
      "Starting Training\n",
      "Training:: Epoch 70, Iteration 0, Current loss 0.43956684040663485 Accuracy 62.82531451070777\n",
      "Training:: Epoch 70, Iteration 10, Current loss 0.5563828922564131 Accuracy 57.820395738203956\n",
      "Training:: Epoch 70, Iteration 20, Current loss 0.4009299030710955 Accuracy 56.034440100945126\n",
      "Training:: Epoch 70, Iteration 30, Current loss 0.5255963096153216 Accuracy 63.81659388646288\n",
      "Training:: Epoch 70, Iteration 40, Current loss 0.5371387957775933 Accuracy 56.85502912010074\n",
      "Training:: Epoch 70, Iteration 50, Current loss 0.4886188965359126 Accuracy 70.34966276180333\n",
      "Training:: Epoch 70, Iteration 60, Current loss 0.3533322220302368 Accuracy 65.23061037173015\n",
      "Training:: Epoch 70, Iteration 70, Current loss 0.6006152450056274 Accuracy 58.44005936349145\n",
      "Training:: Epoch 70, Iteration 80, Current loss 0.5258144560372624 Accuracy 55.64992082913488\n",
      "Training:: Epoch 70, Iteration 90, Current loss 0.6218686884752872 Accuracy 52.02333211811885\n",
      "Training:: Epoch 70, Iteration 100, Current loss 1.302820798433053 Accuracy 65.94986866123503\n",
      "Training:: Epoch 70, Iteration 110, Current loss 1.221011764575683 Accuracy 66.68621987583712\n",
      "Training:: Epoch 70, Iteration 120, Current loss 1.350113802771201 Accuracy 66.8069687431374\n",
      "Training:: Epoch 70, Iteration 130, Current loss 0.9351984687461858 Accuracy 53.930076865856684\n",
      "Training:: Epoch 70, Iteration 140, Current loss 1.0618498695803198 Accuracy 52.998052309404564\n",
      "Training:: Epoch 70, Iteration 150, Current loss 0.7479049468305138 Accuracy 72.73914936855857\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 70, Probability Accuracy 50.25619276678144\n",
      "Calculating Expectation\n",
      "Epoch 70 iter 0\n",
      "Epoch 70 iter 10\n",
      "Epoch 70 iter 20\n",
      "Epoch 70 iter 30\n",
      "Epoch 70 iter 40\n",
      "Epoch 70 iter 50\n",
      "Epoch 70 iter 60\n",
      "Epoch 70 iter 70\n",
      "Epoch 70 iter 80\n",
      "Epoch 70 iter 90\n",
      "Epoch 70 iter 100\n",
      "Epoch 70 iter 110\n",
      "Epoch 70 iter 120\n",
      "Epoch 70 iter 130\n",
      "Epoch 70 iter 140\n",
      "Epoch 70 iter 150\n",
      "Train Boundary avergage error = 306.381\n",
      "Train From boundary avergage accuracy = 58.834\n",
      "Starting Training\n",
      "Training:: Epoch 71, Iteration 0, Current loss 0.6046039482250256 Accuracy 57.065948855989234\n",
      "Training:: Epoch 71, Iteration 10, Current loss 0.8608170738370093 Accuracy 68.82455059640478\n",
      "Training:: Epoch 71, Iteration 20, Current loss 1.9954315097596906 Accuracy 63.81498745069918\n",
      "Training:: Epoch 71, Iteration 30, Current loss 1.352980935291865 Accuracy 67.42690274646066\n",
      "Training:: Epoch 71, Iteration 40, Current loss 0.7695439813711376 Accuracy 61.83748066919724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 71, Iteration 50, Current loss 0.7761691473948567 Accuracy 62.7985884907709\n",
      "Training:: Epoch 71, Iteration 60, Current loss 0.7054935553007703 Accuracy 68.47947612202523\n",
      "Training:: Epoch 71, Iteration 70, Current loss 0.9208656306353427 Accuracy 61.23340165760627\n",
      "Training:: Epoch 71, Iteration 80, Current loss 0.6442981109658024 Accuracy 75.55133432171979\n",
      "Training:: Epoch 71, Iteration 90, Current loss 1.2859175542898318 Accuracy 61.72093023255814\n",
      "Training:: Epoch 71, Iteration 100, Current loss 1.0866239582805894 Accuracy 59.12301559549619\n",
      "Training:: Epoch 71, Iteration 110, Current loss 1.1251024314740252 Accuracy 57.18936115118559\n",
      "Training:: Epoch 71, Iteration 120, Current loss 1.6586596375727083 Accuracy 60.124364047484455\n",
      "Training:: Epoch 71, Iteration 130, Current loss 0.6490999367335599 Accuracy 65.57173074530297\n",
      "Training:: Epoch 71, Iteration 140, Current loss 1.3556717043664277 Accuracy 51.64053576990967\n",
      "Training:: Epoch 71, Iteration 150, Current loss 1.1190008727209957 Accuracy 56.12351481916699\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 71, Probability Accuracy 55.3379724443502\n",
      "Starting Training\n",
      "Training:: Epoch 72, Iteration 0, Current loss 0.7739212637262909 Accuracy 57.00187685415027\n",
      "Training:: Epoch 72, Iteration 10, Current loss 1.2628215329099257 Accuracy 64.6839392295171\n",
      "Training:: Epoch 72, Iteration 20, Current loss 0.46769518927780834 Accuracy 60.26203691751646\n",
      "Training:: Epoch 72, Iteration 30, Current loss 0.8348829736870094 Accuracy 57.26761110032991\n",
      "Training:: Epoch 72, Iteration 40, Current loss 0.7303224488898384 Accuracy 61.96118839086382\n",
      "Training:: Epoch 72, Iteration 50, Current loss 0.5572526051324792 Accuracy 62.01688555347092\n",
      "Training:: Epoch 72, Iteration 60, Current loss 0.553392990496864 Accuracy 60.753003222970996\n",
      "Training:: Epoch 72, Iteration 70, Current loss 0.8689373230698264 Accuracy 62.48355003421593\n",
      "Training:: Epoch 72, Iteration 80, Current loss 0.6069617257923648 Accuracy 65.725905841755\n",
      "Training:: Epoch 72, Iteration 90, Current loss 0.7498826053743587 Accuracy 63.80931434541156\n",
      "Training:: Epoch 72, Iteration 100, Current loss 0.5126389215833389 Accuracy 67.61615394353716\n",
      "Training:: Epoch 72, Iteration 110, Current loss 0.6021337052180957 Accuracy 64.92097192734136\n",
      "Training:: Epoch 72, Iteration 120, Current loss 0.8153818915029531 Accuracy 63.94187839922071\n",
      "Training:: Epoch 72, Iteration 130, Current loss 0.708944614944291 Accuracy 60.66198717172939\n",
      "Training:: Epoch 72, Iteration 140, Current loss 0.8071878584626548 Accuracy 60.828996949578325\n",
      "Training:: Epoch 72, Iteration 150, Current loss 0.6477293553030883 Accuracy 69.78271854471956\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 72, Probability Accuracy 55.21766061573317\n",
      "Starting Training\n",
      "Training:: Epoch 73, Iteration 0, Current loss 0.9313773586368617 Accuracy 69.01590958174357\n",
      "Training:: Epoch 73, Iteration 10, Current loss 0.5816412562088893 Accuracy 60.75563680682511\n",
      "Training:: Epoch 73, Iteration 20, Current loss 0.6166769155436574 Accuracy 63.975155279503106\n",
      "Training:: Epoch 73, Iteration 30, Current loss 0.7668389127065492 Accuracy 63.88623119074541\n",
      "Training:: Epoch 73, Iteration 40, Current loss 0.5699706502433775 Accuracy 68.12297734627832\n",
      "Training:: Epoch 73, Iteration 50, Current loss 0.5454415782590889 Accuracy 62.46317030053035\n",
      "Training:: Epoch 73, Iteration 60, Current loss 0.5551039365052369 Accuracy 70.73189552066052\n",
      "Training:: Epoch 73, Iteration 70, Current loss 0.5035246509695562 Accuracy 47.40010469377072\n",
      "Training:: Epoch 73, Iteration 80, Current loss 0.414814988759421 Accuracy 60.834829443447035\n",
      "Training:: Epoch 73, Iteration 90, Current loss 0.6740880825027715 Accuracy 51.64810439869502\n",
      "Training:: Epoch 73, Iteration 100, Current loss 0.6198054947452667 Accuracy 66.33559354407411\n",
      "Training:: Epoch 73, Iteration 110, Current loss 0.5975729533711205 Accuracy 68.60278472507372\n",
      "Training:: Epoch 73, Iteration 120, Current loss 0.8012126127404733 Accuracy 62.94823743922204\n",
      "Training:: Epoch 73, Iteration 130, Current loss 0.5383754460582817 Accuracy 57.52101367457032\n",
      "Training:: Epoch 73, Iteration 140, Current loss 0.5201501531259315 Accuracy 58.32010743498962\n",
      "Training:: Epoch 73, Iteration 150, Current loss 0.6117804248399087 Accuracy 65.78138252756574\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 73, Probability Accuracy 55.498127800626115\n",
      "Starting Training\n",
      "Training:: Epoch 74, Iteration 0, Current loss 0.5089536121710424 Accuracy 65.24402490459931\n",
      "Training:: Epoch 74, Iteration 10, Current loss 0.6940438269342241 Accuracy 61.35723142824935\n",
      "Training:: Epoch 74, Iteration 20, Current loss 0.7593300343332545 Accuracy 60.4276978785912\n",
      "Training:: Epoch 74, Iteration 30, Current loss 0.48036050874210595 Accuracy 66.73578199052133\n",
      "Training:: Epoch 74, Iteration 40, Current loss 0.6447335583723632 Accuracy 61.95047143019425\n",
      "Training:: Epoch 74, Iteration 50, Current loss 0.49359644317382306 Accuracy 60.480143594345975\n",
      "Training:: Epoch 74, Iteration 60, Current loss 0.48605238209092533 Accuracy 63.25537885874649\n",
      "Training:: Epoch 74, Iteration 70, Current loss 0.43295423349039613 Accuracy 69.71625563511004\n",
      "Training:: Epoch 74, Iteration 80, Current loss 0.9031062907203212 Accuracy 54.56208789311976\n",
      "Training:: Epoch 74, Iteration 90, Current loss 0.7641860840241579 Accuracy 59.220223472541406\n",
      "Training:: Epoch 74, Iteration 100, Current loss 0.6148358479002484 Accuracy 73.37615123606399\n",
      "Training:: Epoch 74, Iteration 110, Current loss 0.4793532563648459 Accuracy 62.01471707688404\n",
      "Training:: Epoch 74, Iteration 120, Current loss 0.6367520906927668 Accuracy 63.77304820439884\n",
      "Training:: Epoch 74, Iteration 130, Current loss 0.5749242694513872 Accuracy 60.3928819043217\n",
      "Training:: Epoch 74, Iteration 140, Current loss 1.0088592096885822 Accuracy 66.3350930814115\n",
      "Training:: Epoch 74, Iteration 150, Current loss 0.4379197875739943 Accuracy 64.82154561163081\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 74, Probability Accuracy 55.66151974598356\n",
      "Starting Training\n",
      "Training:: Epoch 75, Iteration 0, Current loss 0.6952359883926142 Accuracy 58.60413332405539\n",
      "Training:: Epoch 75, Iteration 10, Current loss 1.1793490941591593 Accuracy 53.04278288684526\n",
      "Training:: Epoch 75, Iteration 20, Current loss 0.6253668508341339 Accuracy 73.76353908390969\n",
      "Training:: Epoch 75, Iteration 30, Current loss 0.8176998738673938 Accuracy 67.5776270840769\n",
      "Training:: Epoch 75, Iteration 40, Current loss 0.7677749956949509 Accuracy 64.25333086602517\n",
      "Training:: Epoch 75, Iteration 50, Current loss 0.69468594788204 Accuracy 59.58801498127341\n",
      "Training:: Epoch 75, Iteration 60, Current loss 0.545779047823318 Accuracy 62.55401114061117\n",
      "Training:: Epoch 75, Iteration 70, Current loss 0.9168464485263516 Accuracy 61.41727805266451\n",
      "Training:: Epoch 75, Iteration 80, Current loss 0.5265006465954628 Accuracy 70.46099290780141\n",
      "Training:: Epoch 75, Iteration 90, Current loss 0.43313631175677836 Accuracy 71.6661285114627\n",
      "Training:: Epoch 75, Iteration 100, Current loss 0.5345121813897755 Accuracy 60.26143790849673\n",
      "Training:: Epoch 75, Iteration 110, Current loss 0.474414815976591 Accuracy 38.93830060972199\n",
      "Training:: Epoch 75, Iteration 120, Current loss 0.8205485591530324 Accuracy 62.589019647456944\n",
      "Training:: Epoch 75, Iteration 130, Current loss 0.8281847630724072 Accuracy 63.17717076148329\n",
      "Training:: Epoch 75, Iteration 140, Current loss 0.6814202802582445 Accuracy 42.943762316204335\n",
      "Training:: Epoch 75, Iteration 150, Current loss 0.4083033918720598 Accuracy 69.72086619101265\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 75, Probability Accuracy 55.47312794013426\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.24871590001141\n",
      "Calculating Expectation\n",
      "Epoch 75 iter 0\n",
      "Epoch 75 iter 10\n",
      "Epoch 75 iter 20\n",
      "Epoch 75 iter 30\n",
      "Epoch 75 iter 40\n",
      "Epoch 75 iter 50\n",
      "Epoch 75 iter 60\n",
      "Epoch 75 iter 70\n",
      "Epoch 75 iter 80\n",
      "Epoch 75 iter 90\n",
      "Epoch 75 iter 100\n",
      "Epoch 75 iter 110\n",
      "Epoch 75 iter 120\n",
      "Epoch 75 iter 130\n",
      "Epoch 75 iter 140\n",
      "Epoch 75 iter 150\n",
      "Train Boundary avergage error = 304.691\n",
      "Train From boundary avergage accuracy = 58.872\n",
      "Starting Training\n",
      "Training:: Epoch 76, Iteration 0, Current loss 0.39058130620770337 Accuracy 66.11953268320943\n",
      "Training:: Epoch 76, Iteration 10, Current loss 0.4736694550237509 Accuracy 53.892925997330565\n",
      "Training:: Epoch 76, Iteration 20, Current loss 0.677358020283291 Accuracy 58.80610828320222\n",
      "Training:: Epoch 76, Iteration 30, Current loss 0.47143113031422246 Accuracy 64.31269578035747\n",
      "Training:: Epoch 76, Iteration 40, Current loss 0.7190328756578258 Accuracy 64.95668154371226\n",
      "Training:: Epoch 76, Iteration 50, Current loss 0.5595158284139332 Accuracy 60.18299158565477\n",
      "Training:: Epoch 76, Iteration 60, Current loss 0.6464934151784211 Accuracy 61.043041156142\n",
      "Training:: Epoch 76, Iteration 70, Current loss 0.7038518379610407 Accuracy 55.932203389830505\n",
      "Training:: Epoch 76, Iteration 80, Current loss 0.5680368006908187 Accuracy 59.97493072964771\n",
      "Training:: Epoch 76, Iteration 90, Current loss 0.7166214851109618 Accuracy 55.86972522080471\n",
      "Training:: Epoch 76, Iteration 100, Current loss 0.7403979664903388 Accuracy 53.70551934944345\n",
      "Training:: Epoch 76, Iteration 110, Current loss 0.6818035941967666 Accuracy 64.142717833993\n",
      "Training:: Epoch 76, Iteration 120, Current loss 0.6824262145227384 Accuracy 59.35209448938514\n",
      "Training:: Epoch 76, Iteration 130, Current loss 0.9502908345914529 Accuracy 58.07402809032358\n",
      "Training:: Epoch 76, Iteration 140, Current loss 0.8676636659700849 Accuracy 58.56330663568079\n",
      "Training:: Epoch 76, Iteration 150, Current loss 0.7496275864893576 Accuracy 52.391586226768474\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 76, Probability Accuracy 55.23138821769968\n",
      "Starting Training\n",
      "Training:: Epoch 77, Iteration 0, Current loss 0.5225650976446854 Accuracy 55.400590450982385\n",
      "Training:: Epoch 77, Iteration 10, Current loss 0.906318941084225 Accuracy 43.086680761099366\n",
      "Training:: Epoch 77, Iteration 20, Current loss 0.4429648588603131 Accuracy 61.129588196166175\n",
      "Training:: Epoch 77, Iteration 30, Current loss 0.48190844608240774 Accuracy 64.88716572223879\n",
      "Training:: Epoch 77, Iteration 40, Current loss 0.544488334315081 Accuracy 60.54594875947024\n",
      "Training:: Epoch 77, Iteration 50, Current loss 0.7160853943681826 Accuracy 56.942628903413215\n",
      "Training:: Epoch 77, Iteration 60, Current loss 0.5842050999493487 Accuracy 58.60276847733746\n",
      "Training:: Epoch 77, Iteration 70, Current loss 0.5108680021109357 Accuracy 58.24844300680732\n",
      "Training:: Epoch 77, Iteration 80, Current loss 0.6324958495603246 Accuracy 67.45607925083198\n",
      "Training:: Epoch 77, Iteration 90, Current loss 0.5167635755676337 Accuracy 57.00015192950471\n",
      "Training:: Epoch 77, Iteration 100, Current loss 0.5389283216150702 Accuracy 62.18536422737123\n",
      "Training:: Epoch 77, Iteration 110, Current loss 0.5151685439769457 Accuracy 60.62610429030943\n",
      "Training:: Epoch 77, Iteration 120, Current loss 0.428921293741261 Accuracy 61.93447737909516\n",
      "Training:: Epoch 77, Iteration 130, Current loss 0.4400324528694412 Accuracy 65.4419306184012\n",
      "Training:: Epoch 77, Iteration 140, Current loss 0.5274049410865181 Accuracy 76.24293624065301\n",
      "Training:: Epoch 77, Iteration 150, Current loss 0.5357227128146671 Accuracy 62.928463268021844\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 77, Probability Accuracy 54.876702696971556\n",
      "Starting Training\n",
      "Training:: Epoch 78, Iteration 0, Current loss 0.4745957548162181 Accuracy 54.057034819599814\n",
      "Training:: Epoch 78, Iteration 10, Current loss 0.4953798024323083 Accuracy 71.9106463878327\n",
      "Training:: Epoch 78, Iteration 20, Current loss 0.4391177396568344 Accuracy 68.33899660203878\n",
      "Training:: Epoch 78, Iteration 30, Current loss 0.4404736322018875 Accuracy 66.00430383224212\n",
      "Training:: Epoch 78, Iteration 40, Current loss 0.4920386266061056 Accuracy 52.55801079485168\n",
      "Training:: Epoch 78, Iteration 50, Current loss 0.7858587881145757 Accuracy 72.74483404554235\n",
      "Training:: Epoch 78, Iteration 60, Current loss 0.5957439015713324 Accuracy 41.23265306122449\n",
      "Training:: Epoch 78, Iteration 70, Current loss 0.3888036679535738 Accuracy 62.60881092307012\n",
      "Training:: Epoch 78, Iteration 80, Current loss 0.4261088177086919 Accuracy 59.23581487087748\n",
      "Training:: Epoch 78, Iteration 90, Current loss 0.38007021483342573 Accuracy 58.82316040398971\n",
      "Training:: Epoch 78, Iteration 100, Current loss 0.49275815654080135 Accuracy 58.82104551980407\n",
      "Training:: Epoch 78, Iteration 110, Current loss 0.46116891298035917 Accuracy 59.2086669806877\n",
      "Training:: Epoch 78, Iteration 120, Current loss 0.5583226507436911 Accuracy 60.28769586437195\n",
      "Training:: Epoch 78, Iteration 130, Current loss 0.4507721723333804 Accuracy 59.190845197332855\n",
      "Training:: Epoch 78, Iteration 140, Current loss 0.4536113217923618 Accuracy 66.35064849562183\n",
      "Training:: Epoch 78, Iteration 150, Current loss 0.5324911719978778 Accuracy 61.058610390246294\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 78, Probability Accuracy 55.339311722590836\n",
      "Starting Training\n",
      "Training:: Epoch 79, Iteration 0, Current loss 0.3168566038799382 Accuracy 64.59435129965118\n",
      "Training:: Epoch 79, Iteration 10, Current loss 0.4871360286634032 Accuracy 66.31830293802125\n",
      "Training:: Epoch 79, Iteration 20, Current loss 0.5671389871246696 Accuracy 65.40016168148748\n",
      "Training:: Epoch 79, Iteration 30, Current loss 0.5280067682818352 Accuracy 59.44225817422144\n",
      "Training:: Epoch 79, Iteration 40, Current loss 0.35308738159883046 Accuracy 69.22424036666101\n",
      "Training:: Epoch 79, Iteration 50, Current loss 0.38381123628971164 Accuracy 69.21529175050301\n",
      "Training:: Epoch 79, Iteration 60, Current loss 0.5598918008869933 Accuracy 63.04070820199853\n",
      "Training:: Epoch 79, Iteration 70, Current loss 0.43023927992825567 Accuracy 64.75155279503106\n",
      "Training:: Epoch 79, Iteration 80, Current loss 0.3748004790443067 Accuracy 67.56704858221852\n",
      "Training:: Epoch 79, Iteration 90, Current loss 0.4473772531828674 Accuracy 63.69481690582608\n",
      "Training:: Epoch 79, Iteration 100, Current loss 0.4557040980937681 Accuracy 64.29364278506559\n",
      "Training:: Epoch 79, Iteration 110, Current loss 0.6422535060090545 Accuracy 53.78844204123015\n",
      "Training:: Epoch 79, Iteration 120, Current loss 0.6294570715033908 Accuracy 61.116957833438576\n",
      "Training:: Epoch 79, Iteration 130, Current loss 0.675078598927815 Accuracy 43.252995946006145\n",
      "Training:: Epoch 79, Iteration 140, Current loss 0.6576150598697763 Accuracy 65.57163431863384\n",
      "Training:: Epoch 79, Iteration 150, Current loss 0.40259788249934414 Accuracy 58.682391215941436\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 79, Probability Accuracy 54.18351460092298\n",
      "Starting Training\n",
      "Training:: Epoch 80, Iteration 0, Current loss 0.4371698547509716 Accuracy 58.47234952642835\n",
      "Training:: Epoch 80, Iteration 10, Current loss 0.45149662317065153 Accuracy 57.666934835076425\n",
      "Training:: Epoch 80, Iteration 20, Current loss 0.5081685087740264 Accuracy 63.22294776119403\n",
      "Training:: Epoch 80, Iteration 30, Current loss 0.38728242033532717 Accuracy 57.99222267703643\n",
      "Training:: Epoch 80, Iteration 40, Current loss 0.489117765695284 Accuracy 61.29219348103468\n",
      "Training:: Epoch 80, Iteration 50, Current loss 0.43729837104643077 Accuracy 60.185526801243874\n",
      "Training:: Epoch 80, Iteration 60, Current loss 0.7599913577509262 Accuracy 65.38950183884988\n",
      "Training:: Epoch 80, Iteration 70, Current loss 0.5323273142036017 Accuracy 67.50777325998565\n",
      "Training:: Epoch 80, Iteration 80, Current loss 0.34158491783376527 Accuracy 65.48853016142736\n",
      "Training:: Epoch 80, Iteration 90, Current loss 0.37291516974111627 Accuracy 61.95876934645028\n",
      "Training:: Epoch 80, Iteration 100, Current loss 0.3975764751298598 Accuracy 58.22219710669078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 80, Iteration 110, Current loss 0.49471415946251895 Accuracy 62.45095583938559\n",
      "Training:: Epoch 80, Iteration 120, Current loss 0.4000596791800924 Accuracy 56.58690507494084\n",
      "Training:: Epoch 80, Iteration 130, Current loss 0.5647342202065171 Accuracy 67.45858365192062\n",
      "Training:: Epoch 80, Iteration 140, Current loss 0.5292725804664172 Accuracy 60.0558059669457\n",
      "Training:: Epoch 80, Iteration 150, Current loss 0.33119133143247803 Accuracy 62.28971962616822\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 80, Probability Accuracy 54.149363005786796\n",
      "Calculating Expectation\n",
      "Epoch 80 iter 0\n",
      "Epoch 80 iter 10\n",
      "Epoch 80 iter 20\n",
      "Epoch 80 iter 30\n",
      "Epoch 80 iter 40\n",
      "Epoch 80 iter 50\n",
      "Epoch 80 iter 60\n",
      "Epoch 80 iter 70\n",
      "Epoch 80 iter 80\n",
      "Epoch 80 iter 90\n",
      "Epoch 80 iter 100\n",
      "Epoch 80 iter 110\n",
      "Epoch 80 iter 120\n",
      "Epoch 80 iter 130\n",
      "Epoch 80 iter 140\n",
      "Epoch 80 iter 150\n",
      "Train Boundary avergage error = 305.058\n",
      "Train From boundary avergage accuracy = 58.729\n",
      "Starting Training\n",
      "Training:: Epoch 81, Iteration 0, Current loss 0.36597931423393776 Accuracy 59.1482878699942\n",
      "Training:: Epoch 81, Iteration 10, Current loss 0.4631211040220353 Accuracy 65.7616043262731\n",
      "Training:: Epoch 81, Iteration 20, Current loss 0.3712911571696361 Accuracy 57.83154229453083\n",
      "Training:: Epoch 81, Iteration 30, Current loss 0.4043822917527676 Accuracy 60.34585843719818\n",
      "Training:: Epoch 81, Iteration 40, Current loss 0.3727471539868359 Accuracy 58.013264339333865\n",
      "Training:: Epoch 81, Iteration 50, Current loss 0.33892439660305435 Accuracy 60.11191677175284\n",
      "Training:: Epoch 81, Iteration 60, Current loss 0.3673568229316543 Accuracy 59.75580173041158\n",
      "Training:: Epoch 81, Iteration 70, Current loss 0.4665522105440619 Accuracy 64.07070791294922\n",
      "Training:: Epoch 81, Iteration 80, Current loss 0.38311100895334543 Accuracy 62.767775003285585\n",
      "Training:: Epoch 81, Iteration 90, Current loss 0.42601885006354634 Accuracy 69.02629297890783\n",
      "Training:: Epoch 81, Iteration 100, Current loss 0.8410130908322649 Accuracy 72.13913627961688\n",
      "Training:: Epoch 81, Iteration 110, Current loss 0.6380055425439977 Accuracy 69.26386233269598\n",
      "Training:: Epoch 81, Iteration 120, Current loss 0.526896268711464 Accuracy 70.55179368967008\n",
      "Training:: Epoch 81, Iteration 130, Current loss 0.5819557615298135 Accuracy 59.14675510665561\n",
      "Training:: Epoch 81, Iteration 140, Current loss 0.5666302542212078 Accuracy 56.16983195784031\n",
      "Training:: Epoch 81, Iteration 150, Current loss 0.7788995630998488 Accuracy 57.69357858795021\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 81, Probability Accuracy 54.79623439601342\n",
      "Starting Training\n",
      "Training:: Epoch 82, Iteration 0, Current loss 0.6291378888165583 Accuracy 60.66969035220337\n",
      "Training:: Epoch 82, Iteration 10, Current loss 0.8078256184474127 Accuracy 53.101736972704714\n",
      "Training:: Epoch 82, Iteration 20, Current loss 0.8863944237835842 Accuracy 50.44045189867118\n",
      "Training:: Epoch 82, Iteration 30, Current loss 0.4458781245753267 Accuracy 62.33028539761707\n",
      "Training:: Epoch 82, Iteration 40, Current loss 0.511847355005844 Accuracy 54.5585274662065\n",
      "Training:: Epoch 82, Iteration 50, Current loss 0.47420632935711193 Accuracy 73.04316285817919\n",
      "Training:: Epoch 82, Iteration 60, Current loss 0.5476823468584702 Accuracy 51.96418656302055\n",
      "Training:: Epoch 82, Iteration 70, Current loss 0.5819161207738833 Accuracy 62.281083906944325\n",
      "Training:: Epoch 82, Iteration 80, Current loss 0.37322564174425144 Accuracy 67.55086661642804\n",
      "Training:: Epoch 82, Iteration 90, Current loss 0.5121017191325826 Accuracy 49.00779588944011\n",
      "Training:: Epoch 82, Iteration 100, Current loss 0.4798513833101712 Accuracy 68.95705521472392\n",
      "Training:: Epoch 82, Iteration 110, Current loss 0.4839052509126779 Accuracy 57.484220018034264\n",
      "Training:: Epoch 82, Iteration 120, Current loss 2.3145233992185847 Accuracy 64.17547428470348\n",
      "Training:: Epoch 82, Iteration 130, Current loss 0.5844480220608008 Accuracy 66.02340783653658\n",
      "Training:: Epoch 82, Iteration 140, Current loss 0.9349017909365831 Accuracy 47.17182060208888\n",
      "Training:: Epoch 82, Iteration 150, Current loss 0.47242202452364174 Accuracy 62.865163610843055\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 82, Probability Accuracy 53.92313658963957\n",
      "Starting Training\n",
      "Training:: Epoch 83, Iteration 0, Current loss 0.6644256231027444 Accuracy 45.166774611398964\n",
      "Training:: Epoch 83, Iteration 10, Current loss 0.6318214435771483 Accuracy 65.72939441704378\n",
      "Training:: Epoch 83, Iteration 20, Current loss 2.57499332249353 Accuracy 59.68798650752465\n",
      "Training:: Epoch 83, Iteration 30, Current loss 0.787182625826826 Accuracy 57.82007759456838\n",
      "Training:: Epoch 83, Iteration 40, Current loss 0.7102059681519857 Accuracy 65.12404841448053\n",
      "Training:: Epoch 83, Iteration 50, Current loss 0.7241537393567795 Accuracy 68.79711938786993\n",
      "Training:: Epoch 83, Iteration 60, Current loss 0.5174278006712097 Accuracy 65.71120868196505\n",
      "Training:: Epoch 83, Iteration 70, Current loss 0.4485371252915764 Accuracy 49.042397660818715\n",
      "Training:: Epoch 83, Iteration 80, Current loss 0.5024419545780632 Accuracy 55.487475220760494\n",
      "Training:: Epoch 83, Iteration 90, Current loss 0.5826182994137947 Accuracy 55.31707748816215\n",
      "Training:: Epoch 83, Iteration 100, Current loss 0.43762303614645187 Accuracy 67.51735954549554\n",
      "Training:: Epoch 83, Iteration 110, Current loss 0.45694250734599656 Accuracy 63.766724281416046\n",
      "Training:: Epoch 83, Iteration 120, Current loss 0.4265539902368853 Accuracy 61.40310257003936\n",
      "Training:: Epoch 83, Iteration 130, Current loss 0.4157771479560452 Accuracy 74.59132906894101\n",
      "Training:: Epoch 83, Iteration 140, Current loss 0.589664716764733 Accuracy 58.45282441189978\n",
      "Training:: Epoch 83, Iteration 150, Current loss 0.5061940328510519 Accuracy 60.70899992952287\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 83, Probability Accuracy 52.63854554383067\n",
      "Starting Training\n",
      "Training:: Epoch 84, Iteration 0, Current loss 0.7685697731589086 Accuracy 69.34989267095983\n",
      "Training:: Epoch 84, Iteration 10, Current loss 0.5666677849316933 Accuracy 60.596849958552085\n",
      "Training:: Epoch 84, Iteration 20, Current loss 0.5685238617814508 Accuracy 65.68403760153326\n",
      "Training:: Epoch 84, Iteration 30, Current loss 0.6977783957122085 Accuracy 61.911570611526614\n",
      "Training:: Epoch 84, Iteration 40, Current loss 0.4918400565654457 Accuracy 52.89220816287698\n",
      "Training:: Epoch 84, Iteration 50, Current loss 0.4585792706515598 Accuracy 66.09138266990098\n",
      "Training:: Epoch 84, Iteration 60, Current loss 0.40181299688271044 Accuracy 55.79399141630901\n",
      "Training:: Epoch 84, Iteration 70, Current loss 0.5704682637181648 Accuracy 58.3618738027515\n",
      "Training:: Epoch 84, Iteration 80, Current loss 0.453291490434041 Accuracy 70.74107546317217\n",
      "Training:: Epoch 84, Iteration 90, Current loss 0.8218367291784809 Accuracy 63.56536245071277\n",
      "Training:: Epoch 84, Iteration 100, Current loss 0.5974312061880753 Accuracy 61.584811821529335\n",
      "Training:: Epoch 84, Iteration 110, Current loss 0.3685790696216502 Accuracy 61.560058022553925\n",
      "Training:: Epoch 84, Iteration 120, Current loss 0.6633275972918514 Accuracy 57.98827244023455\n",
      "Training:: Epoch 84, Iteration 130, Current loss 0.41615041033925587 Accuracy 63.11823392061134\n",
      "Training:: Epoch 84, Iteration 140, Current loss 0.42250384713068506 Accuracy 68.83292239051309\n",
      "Training:: Epoch 84, Iteration 150, Current loss 0.43862955291790373 Accuracy 57.22852721176167\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 84, Probability Accuracy 52.337207939687836\n",
      "Starting Training\n",
      "Training:: Epoch 85, Iteration 0, Current loss 0.5258082415804308 Accuracy 53.14292841107508\n",
      "Training:: Epoch 85, Iteration 10, Current loss 12.313730054434139 Accuracy 29.311248558549114\n",
      "Training:: Epoch 85, Iteration 20, Current loss 3.749176365820428 Accuracy 65.17322450428071\n",
      "Training:: Epoch 85, Iteration 30, Current loss 5.843893553536489 Accuracy 42.51545555893382\n",
      "Training:: Epoch 85, Iteration 40, Current loss 1.8601127086785745 Accuracy 57.3353233028115\n",
      "Training:: Epoch 85, Iteration 50, Current loss 7.071793300944229 Accuracy 53.0232355377305\n",
      "Training:: Epoch 85, Iteration 60, Current loss 1.9626557413360337 Accuracy 54.22882386836545\n",
      "Training:: Epoch 85, Iteration 70, Current loss 1.2966016411967203 Accuracy 58.04795374108968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 85, Iteration 80, Current loss 3.4847808215684513 Accuracy 53.55662332768042\n",
      "Training:: Epoch 85, Iteration 90, Current loss 1.2209736007803846 Accuracy 60.3089321692411\n",
      "Training:: Epoch 85, Iteration 100, Current loss 0.8427936160324293 Accuracy 58.51517431652872\n",
      "Training:: Epoch 85, Iteration 110, Current loss 0.8004137989751547 Accuracy 58.96804215424622\n",
      "Training:: Epoch 85, Iteration 120, Current loss 0.8147678901099625 Accuracy 54.57434928270767\n",
      "Training:: Epoch 85, Iteration 130, Current loss 0.6883111223706627 Accuracy 68.32294302820813\n",
      "Training:: Epoch 85, Iteration 140, Current loss 0.7737460209410089 Accuracy 55.67426027755957\n",
      "Training:: Epoch 85, Iteration 150, Current loss 0.7999574576456367 Accuracy 64.56408196062675\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 85, Probability Accuracy 53.49702289607759\n",
      "Calculating Expectation\n",
      "Epoch 85 iter 0\n",
      "Epoch 85 iter 10\n",
      "Epoch 85 iter 20\n",
      "Epoch 85 iter 30\n",
      "Epoch 85 iter 40\n",
      "Epoch 85 iter 50\n",
      "Epoch 85 iter 60\n",
      "Epoch 85 iter 70\n",
      "Epoch 85 iter 80\n",
      "Epoch 85 iter 90\n",
      "Epoch 85 iter 100\n",
      "Epoch 85 iter 110\n",
      "Epoch 85 iter 120\n",
      "Epoch 85 iter 130\n",
      "Epoch 85 iter 140\n",
      "Epoch 85 iter 150\n",
      "Train Boundary avergage error = 306.831\n",
      "Train From boundary avergage accuracy = 58.489\n",
      "Starting Training\n",
      "Training:: Epoch 86, Iteration 0, Current loss 0.43187379531272846 Accuracy 66.5518453427065\n",
      "Training:: Epoch 86, Iteration 10, Current loss 0.4891490954953078 Accuracy 62.51285214887929\n",
      "Training:: Epoch 86, Iteration 20, Current loss 0.5415449532532601 Accuracy 61.51343311332156\n",
      "Training:: Epoch 86, Iteration 30, Current loss 0.5723424665703073 Accuracy 56.30899872212375\n",
      "Training:: Epoch 86, Iteration 40, Current loss 0.4853925641895226 Accuracy 58.15456674473068\n",
      "Training:: Epoch 86, Iteration 50, Current loss 1.2040468457586655 Accuracy 60.85549382383084\n",
      "Training:: Epoch 86, Iteration 60, Current loss 0.6715519873156731 Accuracy 66.0331529381685\n",
      "Training:: Epoch 86, Iteration 70, Current loss 0.6307338668754408 Accuracy 64.34985034918523\n",
      "Training:: Epoch 86, Iteration 80, Current loss 0.5174045357626692 Accuracy 63.73654147500379\n",
      "Training:: Epoch 86, Iteration 90, Current loss 0.713098885342895 Accuracy 57.147571277719116\n",
      "Training:: Epoch 86, Iteration 100, Current loss 0.598078609486239 Accuracy 63.50608165067641\n",
      "Training:: Epoch 86, Iteration 110, Current loss 0.5853127281679796 Accuracy 66.38060825052695\n",
      "Training:: Epoch 86, Iteration 120, Current loss 0.5586080376355436 Accuracy 52.112426035502956\n",
      "Training:: Epoch 86, Iteration 130, Current loss 0.6055942245778451 Accuracy 59.01318365748597\n",
      "Training:: Epoch 86, Iteration 140, Current loss 0.7462807186366263 Accuracy 53.34728033472803\n",
      "Training:: Epoch 86, Iteration 150, Current loss 0.5890606644781001 Accuracy 63.69884217695499\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 86, Probability Accuracy 52.63642501994966\n",
      "Starting Training\n",
      "Training:: Epoch 87, Iteration 0, Current loss 0.776702958578582 Accuracy 56.96093387278636\n",
      "Training:: Epoch 87, Iteration 10, Current loss 0.8560124514066476 Accuracy 58.26378312519037\n",
      "Training:: Epoch 87, Iteration 20, Current loss 0.5685325140524725 Accuracy 66.09848484848484\n",
      "Training:: Epoch 87, Iteration 30, Current loss 0.5978348679778557 Accuracy 72.29976379643547\n",
      "Training:: Epoch 87, Iteration 40, Current loss 1.0739661001716732 Accuracy 63.684689095614466\n",
      "Training:: Epoch 87, Iteration 50, Current loss 0.5034603901444287 Accuracy 69.79400501782649\n",
      "Training:: Epoch 87, Iteration 60, Current loss 0.5719231954148868 Accuracy 66.65425016762273\n",
      "Training:: Epoch 87, Iteration 70, Current loss 0.37387432189719483 Accuracy 60.71543408360129\n",
      "Training:: Epoch 87, Iteration 80, Current loss 0.406874638133139 Accuracy 57.16516023007395\n",
      "Training:: Epoch 87, Iteration 90, Current loss 0.7501887124901002 Accuracy 64.62953629032258\n",
      "Training:: Epoch 87, Iteration 100, Current loss 0.4945106772225435 Accuracy 57.83395203582582\n",
      "Training:: Epoch 87, Iteration 110, Current loss 0.5824554206528967 Accuracy 58.60045792787636\n",
      "Training:: Epoch 87, Iteration 120, Current loss 0.5380515774846193 Accuracy 68.3240039512677\n",
      "Training:: Epoch 87, Iteration 130, Current loss 0.6417510923959805 Accuracy 69.51405867970661\n",
      "Training:: Epoch 87, Iteration 140, Current loss 0.4366859964653965 Accuracy 53.23010219882317\n",
      "Training:: Epoch 87, Iteration 150, Current loss 0.426429332320874 Accuracy 66.75240544917595\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 87, Probability Accuracy 53.47514801814722\n",
      "Starting Training\n",
      "Training:: Epoch 88, Iteration 0, Current loss 0.47598078406265143 Accuracy 56.283152311189696\n",
      "Training:: Epoch 88, Iteration 10, Current loss 0.43371043420105077 Accuracy 54.314322628276116\n",
      "Training:: Epoch 88, Iteration 20, Current loss 0.5448539432184732 Accuracy 61.54242971369616\n",
      "Training:: Epoch 88, Iteration 30, Current loss 0.4084851420661395 Accuracy 57.565905717718564\n",
      "Training:: Epoch 88, Iteration 40, Current loss 0.3916949421536376 Accuracy 68.17174760723148\n",
      "Training:: Epoch 88, Iteration 50, Current loss 0.33112402281662 Accuracy 71.7431877566256\n",
      "Training:: Epoch 88, Iteration 60, Current loss 0.5599695930615021 Accuracy 64.23178679744467\n",
      "Training:: Epoch 88, Iteration 70, Current loss 0.49216094988575665 Accuracy 61.242857865196946\n",
      "Training:: Epoch 88, Iteration 80, Current loss 0.5407891117908784 Accuracy 56.85180143388692\n",
      "Training:: Epoch 88, Iteration 90, Current loss 0.4513085871907876 Accuracy 46.05830308529946\n",
      "Training:: Epoch 88, Iteration 100, Current loss 0.43666802196918747 Accuracy 55.512233161126815\n",
      "Training:: Epoch 88, Iteration 110, Current loss 0.5499946044444992 Accuracy 58.708868693199626\n",
      "Training:: Epoch 88, Iteration 120, Current loss 0.3594687403338299 Accuracy 61.26410571244811\n",
      "Training:: Epoch 88, Iteration 130, Current loss 0.5027265833016733 Accuracy 61.65818984006373\n",
      "Training:: Epoch 88, Iteration 140, Current loss 0.4465784871946506 Accuracy 65.60700044306601\n",
      "Training:: Epoch 88, Iteration 150, Current loss 0.49516441767254793 Accuracy 58.19013613032805\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 88, Probability Accuracy 54.48072276382386\n",
      "Starting Training\n",
      "Training:: Epoch 89, Iteration 0, Current loss 0.38314306184250113 Accuracy 68.16848527513787\n",
      "Training:: Epoch 89, Iteration 10, Current loss 0.3411184703020816 Accuracy 60.452488687782804\n",
      "Training:: Epoch 89, Iteration 20, Current loss 0.4182309902251318 Accuracy 57.213431107680435\n",
      "Training:: Epoch 89, Iteration 30, Current loss 0.42669690016242956 Accuracy 50.895736295234684\n",
      "Training:: Epoch 89, Iteration 40, Current loss 0.4721227669046105 Accuracy 59.96201657458563\n",
      "Training:: Epoch 89, Iteration 50, Current loss 0.36672653123509363 Accuracy 59.247120516902335\n",
      "Training:: Epoch 89, Iteration 60, Current loss 0.4376806680293188 Accuracy 55.59279118260351\n",
      "Training:: Epoch 89, Iteration 70, Current loss 0.44700306073890894 Accuracy 53.77814452434281\n",
      "Training:: Epoch 89, Iteration 80, Current loss 0.35780303454423784 Accuracy 62.91970802919708\n",
      "Training:: Epoch 89, Iteration 90, Current loss 0.5057985454051019 Accuracy 57.097112571081546\n",
      "Training:: Epoch 89, Iteration 100, Current loss 0.6587684311129112 Accuracy 66.93168741500156\n",
      "Training:: Epoch 89, Iteration 110, Current loss 0.50718331061649 Accuracy 61.99281395145036\n",
      "Training:: Epoch 89, Iteration 120, Current loss 0.36750457261576 Accuracy 62.14230471771075\n",
      "Training:: Epoch 89, Iteration 130, Current loss 0.4409075720064406 Accuracy 60.16437912466092\n",
      "Training:: Epoch 89, Iteration 140, Current loss 0.4274362676286936 Accuracy 61.97995748557546\n",
      "Training:: Epoch 89, Iteration 150, Current loss 0.5418901793667256 Accuracy 64.4901610017889\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 89, Probability Accuracy 54.38507597613852\n",
      "Starting Training\n",
      "Training:: Epoch 90, Iteration 0, Current loss 0.3144054804586383 Accuracy 57.034577347866886\n",
      "Training:: Epoch 90, Iteration 10, Current loss 0.27667613929722246 Accuracy 64.18391001974757\n",
      "Training:: Epoch 90, Iteration 20, Current loss 0.40304307257373884 Accuracy 63.33837619768028\n",
      "Training:: Epoch 90, Iteration 30, Current loss 0.3994296426587198 Accuracy 65.6960604807749\n",
      "Training:: Epoch 90, Iteration 40, Current loss 0.36673642040778964 Accuracy 58.19907305230633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 90, Iteration 50, Current loss 0.41523700308973555 Accuracy 66.18208397628523\n",
      "Training:: Epoch 90, Iteration 60, Current loss 0.4820597878186631 Accuracy 48.823635597809734\n",
      "Training:: Epoch 90, Iteration 70, Current loss 0.3157662682301914 Accuracy 63.66664143516766\n",
      "Training:: Epoch 90, Iteration 80, Current loss 0.4246005505394063 Accuracy 66.02370569160237\n",
      "Training:: Epoch 90, Iteration 90, Current loss 0.4384343264190441 Accuracy 62.303664921465966\n",
      "Training:: Epoch 90, Iteration 100, Current loss 0.42327709585128087 Accuracy 72.32824427480917\n",
      "Training:: Epoch 90, Iteration 110, Current loss 0.48845295404458 Accuracy 67.66687461010605\n",
      "Training:: Epoch 90, Iteration 120, Current loss 0.48627076717037354 Accuracy 65.26478035891225\n",
      "Training:: Epoch 90, Iteration 130, Current loss 0.37079718816951196 Accuracy 64.67882092349633\n",
      "Training:: Epoch 90, Iteration 140, Current loss 0.35476305856173135 Accuracy 69.59524135101873\n",
      "Training:: Epoch 90, Iteration 150, Current loss 0.4726823141296648 Accuracy 42.88851913477537\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 90, Probability Accuracy 54.163202214273355\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.08891679032074\n",
      "Calculating Expectation\n",
      "Epoch 90 iter 0\n",
      "Epoch 90 iter 10\n",
      "Epoch 90 iter 20\n",
      "Epoch 90 iter 30\n",
      "Epoch 90 iter 40\n",
      "Epoch 90 iter 50\n",
      "Epoch 90 iter 60\n",
      "Epoch 90 iter 70\n",
      "Epoch 90 iter 80\n",
      "Epoch 90 iter 90\n",
      "Epoch 90 iter 100\n",
      "Epoch 90 iter 110\n",
      "Epoch 90 iter 120\n",
      "Epoch 90 iter 130\n",
      "Epoch 90 iter 140\n",
      "Epoch 90 iter 150\n",
      "Train Boundary avergage error = 306.565\n",
      "Train From boundary avergage accuracy = 58.519\n",
      "Starting Training\n",
      "Training:: Epoch 91, Iteration 0, Current loss 0.26386628048409366 Accuracy 78.16085360256999\n",
      "Training:: Epoch 91, Iteration 10, Current loss 0.3293856649701024 Accuracy 68.18661043753295\n",
      "Training:: Epoch 91, Iteration 20, Current loss 0.36646677462218513 Accuracy 57.78234308266205\n",
      "Training:: Epoch 91, Iteration 30, Current loss 0.3363561315110862 Accuracy 60.59960594280846\n",
      "Training:: Epoch 91, Iteration 40, Current loss 0.3827504246786071 Accuracy 59.379776365537765\n",
      "Training:: Epoch 91, Iteration 50, Current loss 0.3198706365447448 Accuracy 63.081258806951624\n",
      "Training:: Epoch 91, Iteration 60, Current loss 0.3341357799201622 Accuracy 67.31044057000531\n",
      "Training:: Epoch 91, Iteration 70, Current loss 0.3237020862489335 Accuracy 59.626923547899914\n",
      "Training:: Epoch 91, Iteration 80, Current loss 0.4133127069863241 Accuracy 56.172568315613745\n",
      "Training:: Epoch 91, Iteration 90, Current loss 0.3193249722544162 Accuracy 70.36304472659988\n",
      "Training:: Epoch 91, Iteration 100, Current loss 0.46193652951995545 Accuracy 54.562804834947336\n",
      "Training:: Epoch 91, Iteration 110, Current loss 0.3534516678224901 Accuracy 52.52788723014596\n",
      "Training:: Epoch 91, Iteration 120, Current loss 0.3784865944308886 Accuracy 65.70348791433746\n",
      "Training:: Epoch 91, Iteration 130, Current loss 0.3748198875911144 Accuracy 63.538278460928204\n",
      "Training:: Epoch 91, Iteration 140, Current loss 0.3023237025886669 Accuracy 64.96598639455782\n",
      "Training:: Epoch 91, Iteration 150, Current loss 0.36517532473929226 Accuracy 69.28082385559894\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 91, Probability Accuracy 53.84646291036322\n",
      "Starting Training\n",
      "Training:: Epoch 92, Iteration 0, Current loss 0.3744368094340605 Accuracy 60.62187200511128\n",
      "Training:: Epoch 92, Iteration 10, Current loss 0.3746922266472949 Accuracy 55.52429847387299\n",
      "Training:: Epoch 92, Iteration 20, Current loss 0.3648834647367642 Accuracy 60.339441899208666\n",
      "Training:: Epoch 92, Iteration 30, Current loss 0.3220628283200211 Accuracy 60.776812792941826\n",
      "Training:: Epoch 92, Iteration 40, Current loss 0.5426308705723133 Accuracy 56.656883671291354\n",
      "Training:: Epoch 92, Iteration 50, Current loss 0.45543269229075756 Accuracy 61.42484198955757\n",
      "Training:: Epoch 92, Iteration 60, Current loss 0.3954042166932119 Accuracy 66.00607742105959\n",
      "Training:: Epoch 92, Iteration 70, Current loss 0.4470662156273971 Accuracy 59.60940967598757\n",
      "Training:: Epoch 92, Iteration 80, Current loss 0.3824506802801968 Accuracy 59.63656623666052\n",
      "Training:: Epoch 92, Iteration 90, Current loss 0.3056896412107981 Accuracy 64.87269566477129\n",
      "Training:: Epoch 92, Iteration 100, Current loss 0.4003991435720598 Accuracy 62.485593545908564\n",
      "Training:: Epoch 92, Iteration 110, Current loss 0.35477502039611597 Accuracy 59.413672159354114\n",
      "Training:: Epoch 92, Iteration 120, Current loss 0.4178740259268918 Accuracy 54.62396971250542\n",
      "Training:: Epoch 92, Iteration 130, Current loss 0.46375740643673413 Accuracy 61.64528501520963\n",
      "Training:: Epoch 92, Iteration 140, Current loss 0.35650641983923304 Accuracy 60.4145511020847\n",
      "Training:: Epoch 92, Iteration 150, Current loss 0.6419248699745472 Accuracy 66.5918591859186\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 92, Probability Accuracy 54.634962974536975\n",
      "Starting Training\n",
      "Training:: Epoch 93, Iteration 0, Current loss 0.2995757992772052 Accuracy 61.34298118668596\n",
      "Training:: Epoch 93, Iteration 10, Current loss 0.3277793665351014 Accuracy 73.59283423642596\n",
      "Training:: Epoch 93, Iteration 20, Current loss 0.2767657374168771 Accuracy 65.07119574541088\n",
      "Training:: Epoch 93, Iteration 30, Current loss 0.3409954001181677 Accuracy 56.7241602904941\n",
      "Training:: Epoch 93, Iteration 40, Current loss 0.32514068085686615 Accuracy 54.1197462331483\n",
      "Training:: Epoch 93, Iteration 50, Current loss 0.39053170967035417 Accuracy 61.385751034559895\n",
      "Training:: Epoch 93, Iteration 60, Current loss 0.31895807936402604 Accuracy 59.22150139017609\n",
      "Training:: Epoch 93, Iteration 70, Current loss 0.4048982815345699 Accuracy 65.82237896761782\n",
      "Training:: Epoch 93, Iteration 80, Current loss 0.45752591750377297 Accuracy 68.21968528232027\n",
      "Training:: Epoch 93, Iteration 90, Current loss 0.41636482254005197 Accuracy 48.74528456618009\n",
      "Training:: Epoch 93, Iteration 100, Current loss 0.33043267076729993 Accuracy 64.63620981387479\n",
      "Training:: Epoch 93, Iteration 110, Current loss 0.37718006123172676 Accuracy 59.93748850891708\n",
      "Training:: Epoch 93, Iteration 120, Current loss 0.40189896897291094 Accuracy 56.38998267443692\n",
      "Training:: Epoch 93, Iteration 130, Current loss 0.32636454260896713 Accuracy 63.17491425771681\n",
      "Training:: Epoch 93, Iteration 140, Current loss 0.3624707223227739 Accuracy 59.731232622798885\n",
      "Training:: Epoch 93, Iteration 150, Current loss 0.367227591320122 Accuracy 66.54013015184381\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 93, Probability Accuracy 54.23384914146684\n",
      "Starting Training\n",
      "Training:: Epoch 94, Iteration 0, Current loss 0.27552146756984125 Accuracy 73.37457044673539\n",
      "Training:: Epoch 94, Iteration 10, Current loss 0.39514610327023153 Accuracy 70.8252772972423\n",
      "Training:: Epoch 94, Iteration 20, Current loss 0.2815063817488314 Accuracy 62.100561218646206\n",
      "Training:: Epoch 94, Iteration 30, Current loss 0.41952037558591304 Accuracy 56.48087838466549\n",
      "Training:: Epoch 94, Iteration 40, Current loss 0.3566742581521577 Accuracy 54.533308762554135\n",
      "Training:: Epoch 94, Iteration 50, Current loss 0.2421171274798595 Accuracy 74.35196809689093\n",
      "Training:: Epoch 94, Iteration 60, Current loss 0.2764612542822183 Accuracy 63.96861654583375\n",
      "Training:: Epoch 94, Iteration 70, Current loss 0.32965997399995445 Accuracy 69.54034457526774\n",
      "Training:: Epoch 94, Iteration 80, Current loss 0.25762402198715667 Accuracy 63.10844962092078\n",
      "Training:: Epoch 94, Iteration 90, Current loss 0.3027964856411158 Accuracy 67.7463768115942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 94, Iteration 100, Current loss 0.36998465338011216 Accuracy 57.32586545909551\n",
      "Training:: Epoch 94, Iteration 110, Current loss 0.3329548064905862 Accuracy 62.887288561380004\n",
      "Training:: Epoch 94, Iteration 120, Current loss 0.36847567388517444 Accuracy 69.29284948360517\n",
      "Training:: Epoch 94, Iteration 130, Current loss 0.3037362473655181 Accuracy 60.07109004739336\n",
      "Training:: Epoch 94, Iteration 140, Current loss 0.33878519439569865 Accuracy 52.95190335080921\n",
      "Training:: Epoch 94, Iteration 150, Current loss 0.439228774393417 Accuracy 60.749418708638885\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 94, Probability Accuracy 54.31297816418435\n",
      "Starting Training\n",
      "Training:: Epoch 95, Iteration 0, Current loss 0.30123913807235814 Accuracy 65.55633968478006\n",
      "Training:: Epoch 95, Iteration 10, Current loss 0.4682315292269865 Accuracy 57.30531706582317\n",
      "Training:: Epoch 95, Iteration 20, Current loss 0.312815106085995 Accuracy 64.44660312063627\n",
      "Training:: Epoch 95, Iteration 30, Current loss 0.5580962789826197 Accuracy 56.43242143801485\n",
      "Training:: Epoch 95, Iteration 40, Current loss 0.30067673726252026 Accuracy 56.078382426360456\n",
      "Training:: Epoch 95, Iteration 50, Current loss 0.4111764312303382 Accuracy 55.907908572693565\n",
      "Training:: Epoch 95, Iteration 60, Current loss 0.3437397479930124 Accuracy 61.81832914674662\n",
      "Training:: Epoch 95, Iteration 70, Current loss 0.2775489880373674 Accuracy 63.13250819075355\n",
      "Training:: Epoch 95, Iteration 80, Current loss 0.3049261881036187 Accuracy 72.64829452396212\n",
      "Training:: Epoch 95, Iteration 90, Current loss 0.23387397491655457 Accuracy 72.66738531560667\n",
      "Training:: Epoch 95, Iteration 100, Current loss 0.5331674937212697 Accuracy 66.98473282442748\n",
      "Training:: Epoch 95, Iteration 110, Current loss 0.2790955451087976 Accuracy 53.62234660471011\n",
      "Training:: Epoch 95, Iteration 120, Current loss 0.42376371846821764 Accuracy 62.487472439366606\n",
      "Training:: Epoch 95, Iteration 130, Current loss 0.34585210456850857 Accuracy 64.8754827540285\n",
      "Training:: Epoch 95, Iteration 140, Current loss 0.4951591781476301 Accuracy 51.787399098437994\n",
      "Training:: Epoch 95, Iteration 150, Current loss 0.4001141955485475 Accuracy 59.11970656885629\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 95, Probability Accuracy 54.04266717261623\n",
      "Calculating Expectation\n",
      "Epoch 95 iter 0\n",
      "Epoch 95 iter 10\n",
      "Epoch 95 iter 20\n",
      "Epoch 95 iter 30\n",
      "Epoch 95 iter 40\n",
      "Epoch 95 iter 50\n",
      "Epoch 95 iter 60\n",
      "Epoch 95 iter 70\n",
      "Epoch 95 iter 80\n",
      "Epoch 95 iter 90\n",
      "Epoch 95 iter 100\n",
      "Epoch 95 iter 110\n",
      "Epoch 95 iter 120\n",
      "Epoch 95 iter 130\n",
      "Epoch 95 iter 140\n",
      "Epoch 95 iter 150\n",
      "Train Boundary avergage error = 306.808\n",
      "Train From boundary avergage accuracy = 58.401\n",
      "Starting Training\n",
      "Training:: Epoch 96, Iteration 0, Current loss 0.28833728103577383 Accuracy 65.48241030999651\n",
      "Training:: Epoch 96, Iteration 10, Current loss 0.310173092673629 Accuracy 66.98384984722829\n",
      "Training:: Epoch 96, Iteration 20, Current loss 0.3026148100533833 Accuracy 64.30215941568753\n",
      "Training:: Epoch 96, Iteration 30, Current loss 0.29369261073609143 Accuracy 50.82093876762604\n",
      "Training:: Epoch 96, Iteration 40, Current loss 0.2764322181938513 Accuracy 56.50333368610435\n",
      "Training:: Epoch 96, Iteration 50, Current loss 0.29263120041716306 Accuracy 50.39076842381327\n",
      "Training:: Epoch 96, Iteration 60, Current loss 0.30403623254639284 Accuracy 65.2682131206959\n",
      "Training:: Epoch 96, Iteration 70, Current loss 0.2937181951035542 Accuracy 60.72239031770045\n",
      "Training:: Epoch 96, Iteration 80, Current loss 0.2501323936435158 Accuracy 74.78187811025657\n",
      "Training:: Epoch 96, Iteration 90, Current loss 0.4564963366840229 Accuracy 56.94056269796907\n",
      "Training:: Epoch 96, Iteration 100, Current loss 0.4736682551759642 Accuracy 66.88803869198007\n",
      "Training:: Epoch 96, Iteration 110, Current loss 0.3905691974203615 Accuracy 49.75745385707525\n",
      "Training:: Epoch 96, Iteration 120, Current loss 0.4750642618004795 Accuracy 62.84106492646711\n",
      "Training:: Epoch 96, Iteration 130, Current loss 0.33878132722330667 Accuracy 63.29329378009045\n",
      "Training:: Epoch 96, Iteration 140, Current loss 0.25860390383768034 Accuracy 72.92120332284861\n",
      "Training:: Epoch 96, Iteration 150, Current loss 0.4757629135013485 Accuracy 60.720178588760554\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 96, Probability Accuracy 53.243564489037446\n",
      "Starting Training\n",
      "Training:: Epoch 97, Iteration 0, Current loss 0.3906319741476542 Accuracy 59.794957051814905\n",
      "Training:: Epoch 97, Iteration 10, Current loss 0.36474006280025717 Accuracy 63.631717289719624\n",
      "Training:: Epoch 97, Iteration 20, Current loss 0.3970222233002899 Accuracy 58.30674324611785\n",
      "Training:: Epoch 97, Iteration 30, Current loss 0.376085720665359 Accuracy 56.342008412197686\n",
      "Training:: Epoch 97, Iteration 40, Current loss 0.35172946831669355 Accuracy 60.1769415980738\n",
      "Training:: Epoch 97, Iteration 50, Current loss 0.4296156416394008 Accuracy 64.61957243393971\n",
      "Training:: Epoch 97, Iteration 60, Current loss 0.33638967659518926 Accuracy 68.73986861189319\n",
      "Training:: Epoch 97, Iteration 70, Current loss 0.27050079380378383 Accuracy 59.173259947253754\n",
      "Training:: Epoch 97, Iteration 80, Current loss 0.4426342677533063 Accuracy 70.19364117314706\n",
      "Training:: Epoch 97, Iteration 90, Current loss 0.3945977830392385 Accuracy 61.34724857685009\n",
      "Training:: Epoch 97, Iteration 100, Current loss 0.2552065575943425 Accuracy 59.76392096484475\n",
      "Training:: Epoch 97, Iteration 110, Current loss 0.39336372305843287 Accuracy 60.46073929082286\n",
      "Training:: Epoch 97, Iteration 120, Current loss 0.3898518903247852 Accuracy 64.92771841609051\n",
      "Training:: Epoch 97, Iteration 130, Current loss 0.3655038849678926 Accuracy 56.85746492985972\n",
      "Training:: Epoch 97, Iteration 140, Current loss 0.7423295616864543 Accuracy 59.193548387096776\n",
      "Training:: Epoch 97, Iteration 150, Current loss 0.8036739950496868 Accuracy 60.236588149839164\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 97, Probability Accuracy 51.246589025730884\n",
      "Starting Training\n",
      "Training:: Epoch 98, Iteration 0, Current loss 0.4465457766334674 Accuracy 66.61740904932799\n",
      "Training:: Epoch 98, Iteration 10, Current loss 0.4036260752074434 Accuracy 59.951326356777805\n",
      "Training:: Epoch 98, Iteration 20, Current loss 0.34055195283183276 Accuracy 64.31787322232545\n",
      "Training:: Epoch 98, Iteration 30, Current loss 0.34329032681351734 Accuracy 69.03938665063139\n",
      "Training:: Epoch 98, Iteration 40, Current loss 0.47603638549946 Accuracy 68.42135118271031\n",
      "Training:: Epoch 98, Iteration 50, Current loss 0.4923182639754925 Accuracy 57.93258426966292\n",
      "Training:: Epoch 98, Iteration 60, Current loss 0.6208900534862875 Accuracy 50.67293589854197\n",
      "Training:: Epoch 98, Iteration 70, Current loss 0.48315519125551926 Accuracy 65.43758329631275\n",
      "Training:: Epoch 98, Iteration 80, Current loss 0.4363174271943651 Accuracy 71.7301473230327\n",
      "Training:: Epoch 98, Iteration 90, Current loss 0.5358081530185772 Accuracy 62.19180098623684\n",
      "Training:: Epoch 98, Iteration 100, Current loss 0.37757177729475716 Accuracy 58.021913519859126\n",
      "Training:: Epoch 98, Iteration 110, Current loss 0.6175579394513296 Accuracy 61.60530031497773\n",
      "Training:: Epoch 98, Iteration 120, Current loss 0.6256571775077705 Accuracy 59.073860357761106\n",
      "Training:: Epoch 98, Iteration 130, Current loss 2.1391253704735975 Accuracy 66.21208124505408\n",
      "Training:: Epoch 98, Iteration 140, Current loss 1.0223044293340193 Accuracy 67.59668294195149\n",
      "Training:: Epoch 98, Iteration 150, Current loss 0.7447250186100067 Accuracy 68.47072108404582\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 98, Probability Accuracy 54.12492117789521\n",
      "Starting Training\n",
      "Training:: Epoch 99, Iteration 0, Current loss 0.6515311458827406 Accuracy 65.53298800436205\n",
      "Training:: Epoch 99, Iteration 10, Current loss 0.6286297758532925 Accuracy 61.455024405361435\n",
      "Training:: Epoch 99, Iteration 20, Current loss 0.4426715131378067 Accuracy 67.96988126267014\n",
      "Training:: Epoch 99, Iteration 30, Current loss 0.6813627172022929 Accuracy 55.718558034270934\n",
      "Training:: Epoch 99, Iteration 40, Current loss 0.4357844352493886 Accuracy 58.384398145681246\n",
      "Training:: Epoch 99, Iteration 50, Current loss 0.37964505070805105 Accuracy 72.36520091576537\n",
      "Training:: Epoch 99, Iteration 60, Current loss 0.4491848323968593 Accuracy 60.382032727035664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 99, Iteration 70, Current loss 0.46772544408003225 Accuracy 50.37564829625321\n",
      "Training:: Epoch 99, Iteration 80, Current loss 0.3882541022530779 Accuracy 71.70373600814072\n",
      "Training:: Epoch 99, Iteration 90, Current loss 0.39748748236427234 Accuracy 58.64426856189092\n",
      "Training:: Epoch 99, Iteration 100, Current loss 0.3896212225836907 Accuracy 59.85936867664913\n",
      "Training:: Epoch 99, Iteration 110, Current loss 0.3415387343439896 Accuracy 64.1394905974768\n",
      "Training:: Epoch 99, Iteration 120, Current loss 0.4205602180632798 Accuracy 40.07365375220773\n",
      "Training:: Epoch 99, Iteration 130, Current loss 0.3286949172702342 Accuracy 72.02333598514983\n",
      "Training:: Epoch 99, Iteration 140, Current loss 0.3543442626779455 Accuracy 69.69883220651506\n",
      "Training:: Epoch 99, Iteration 150, Current loss 0.48164238054912173 Accuracy 66.1301671064204\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 99, Probability Accuracy 53.220461939386496\n",
      "Starting Training\n",
      "Training:: Epoch 100, Iteration 0, Current loss 0.29449927615873017 Accuracy 59.4208790712382\n",
      "Training:: Epoch 100, Iteration 10, Current loss 0.32408997981708343 Accuracy 53.087928679272416\n",
      "Training:: Epoch 100, Iteration 20, Current loss 0.32553021861896186 Accuracy 51.96002617333888\n",
      "Training:: Epoch 100, Iteration 30, Current loss 0.425950422521639 Accuracy 56.43603133159269\n",
      "Training:: Epoch 100, Iteration 40, Current loss 0.3097478176603366 Accuracy 65.12611749680715\n",
      "Training:: Epoch 100, Iteration 50, Current loss 0.3013740910395135 Accuracy 59.29131599081867\n",
      "Training:: Epoch 100, Iteration 60, Current loss 0.4026056386333903 Accuracy 64.88882429879378\n",
      "Training:: Epoch 100, Iteration 70, Current loss 0.32022591618653024 Accuracy 64.8630683328902\n",
      "Training:: Epoch 100, Iteration 80, Current loss 0.29112293962847174 Accuracy 56.20212644335201\n",
      "Training:: Epoch 100, Iteration 90, Current loss 0.2671651848469562 Accuracy 63.136444520980426\n",
      "Training:: Epoch 100, Iteration 100, Current loss 0.3174380794445769 Accuracy 65.45636438533514\n",
      "Training:: Epoch 100, Iteration 110, Current loss 0.34494249349847395 Accuracy 59.01626939084374\n",
      "Training:: Epoch 100, Iteration 120, Current loss 0.2707075860756042 Accuracy 68.7313926563017\n",
      "Training:: Epoch 100, Iteration 130, Current loss 0.25378441408315594 Accuracy 68.72436638973603\n",
      "Training:: Epoch 100, Iteration 140, Current loss 0.3425384587171617 Accuracy 58.92310262264046\n",
      "Training:: Epoch 100, Iteration 150, Current loss 0.2676976303775184 Accuracy 71.10025334781035\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 100, Probability Accuracy 54.4223525538362\n",
      "Calculating Expectation\n",
      "Epoch 100 iter 0\n",
      "Epoch 100 iter 10\n",
      "Epoch 100 iter 20\n",
      "Epoch 100 iter 30\n",
      "Epoch 100 iter 40\n",
      "Epoch 100 iter 50\n",
      "Epoch 100 iter 60\n",
      "Epoch 100 iter 70\n",
      "Epoch 100 iter 80\n",
      "Epoch 100 iter 90\n",
      "Epoch 100 iter 100\n",
      "Epoch 100 iter 110\n",
      "Epoch 100 iter 120\n",
      "Epoch 100 iter 130\n",
      "Epoch 100 iter 140\n",
      "Epoch 100 iter 150\n",
      "Train Boundary avergage error = 306.067\n",
      "Train From boundary avergage accuracy = 58.480\n",
      "Starting Training\n",
      "Training:: Epoch 101, Iteration 0, Current loss 0.23468991538147466 Accuracy 56.19542263569431\n",
      "Training:: Epoch 101, Iteration 10, Current loss 0.2221784666881542 Accuracy 55.46734031035727\n",
      "Training:: Epoch 101, Iteration 20, Current loss 0.33970910696881257 Accuracy 48.34433696709146\n",
      "Training:: Epoch 101, Iteration 30, Current loss 0.21327208227771666 Accuracy 72.8302887895096\n",
      "Training:: Epoch 101, Iteration 40, Current loss 0.2728282470989319 Accuracy 51.34597074352982\n",
      "Training:: Epoch 101, Iteration 50, Current loss 0.27912066622154985 Accuracy 60.741413474240424\n",
      "Training:: Epoch 101, Iteration 60, Current loss 0.24658168366180883 Accuracy 57.80126849894292\n",
      "Training:: Epoch 101, Iteration 70, Current loss 0.26628878184927063 Accuracy 65.84648622696993\n",
      "Training:: Epoch 101, Iteration 80, Current loss 0.29369903243516193 Accuracy 53.394972551285754\n",
      "Training:: Epoch 101, Iteration 90, Current loss 0.2880111503420858 Accuracy 55.59142264237953\n",
      "Training:: Epoch 101, Iteration 100, Current loss 0.22843407568407922 Accuracy 62.44859063095596\n",
      "Training:: Epoch 101, Iteration 110, Current loss 0.19763941061004858 Accuracy 78.31699572000552\n",
      "Training:: Epoch 101, Iteration 120, Current loss 0.3107799809917511 Accuracy 70.01694915254237\n",
      "Training:: Epoch 101, Iteration 130, Current loss 0.23520802667679952 Accuracy 66.02384807890475\n",
      "Training:: Epoch 101, Iteration 140, Current loss 0.42443135930108283 Accuracy 50.32661761672282\n",
      "Training:: Epoch 101, Iteration 150, Current loss 0.3795374629150581 Accuracy 59.998619928236266\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 101, Probability Accuracy 54.15706385567045\n",
      "Starting Training\n",
      "Training:: Epoch 102, Iteration 0, Current loss 0.206691151808535 Accuracy 58.234240104251505\n",
      "Training:: Epoch 102, Iteration 10, Current loss 0.2218629002545931 Accuracy 48.48049557839924\n",
      "Training:: Epoch 102, Iteration 20, Current loss 0.29747984945376255 Accuracy 60.48277116101464\n",
      "Training:: Epoch 102, Iteration 30, Current loss 0.36448692861696597 Accuracy 56.02620893318568\n",
      "Training:: Epoch 102, Iteration 40, Current loss 0.27167329022270015 Accuracy 64.09768851387486\n",
      "Training:: Epoch 102, Iteration 50, Current loss 0.2631873700377542 Accuracy 65.31332744924978\n",
      "Training:: Epoch 102, Iteration 60, Current loss 0.38157580719493656 Accuracy 53.6136901511014\n",
      "Training:: Epoch 102, Iteration 70, Current loss 0.2885337824709428 Accuracy 54.1191381495564\n",
      "Training:: Epoch 102, Iteration 80, Current loss 0.3402803858461837 Accuracy 59.6650067904029\n",
      "Training:: Epoch 102, Iteration 90, Current loss 0.34004081003981806 Accuracy 67.97080641301747\n",
      "Training:: Epoch 102, Iteration 100, Current loss 0.35134345090928565 Accuracy 63.22202166064982\n",
      "Training:: Epoch 102, Iteration 110, Current loss 0.3358553590777862 Accuracy 62.049840449779666\n",
      "Training:: Epoch 102, Iteration 120, Current loss 0.34997983081446427 Accuracy 49.739463096101844\n",
      "Training:: Epoch 102, Iteration 130, Current loss 0.4800142092063612 Accuracy 58.881811748053785\n",
      "Training:: Epoch 102, Iteration 140, Current loss 0.22608091688124987 Accuracy 55.604149144939726\n",
      "Training:: Epoch 102, Iteration 150, Current loss 0.2992276677195864 Accuracy 60.65104063034741\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 102, Probability Accuracy 54.96911289557536\n",
      "Starting Training\n",
      "Training:: Epoch 103, Iteration 0, Current loss 0.24946024371449 Accuracy 63.03526851436984\n",
      "Training:: Epoch 103, Iteration 10, Current loss 0.222835060775432 Accuracy 68.64980711530218\n",
      "Training:: Epoch 103, Iteration 20, Current loss 0.2298002483098115 Accuracy 72.46879907430366\n",
      "Training:: Epoch 103, Iteration 30, Current loss 0.30395231597979516 Accuracy 67.37884741322856\n",
      "Training:: Epoch 103, Iteration 40, Current loss 0.30651447462901293 Accuracy 58.834862850479134\n",
      "Training:: Epoch 103, Iteration 50, Current loss 0.4279369694521475 Accuracy 65.43957986163713\n",
      "Training:: Epoch 103, Iteration 60, Current loss 0.3079551340574743 Accuracy 65.31923714759536\n",
      "Training:: Epoch 103, Iteration 70, Current loss 0.37572911053657404 Accuracy 51.917978683114214\n",
      "Training:: Epoch 103, Iteration 80, Current loss 0.29024809553162306 Accuracy 58.867924528301884\n",
      "Training:: Epoch 103, Iteration 90, Current loss 0.3496420791859978 Accuracy 62.208258527827645\n",
      "Training:: Epoch 103, Iteration 100, Current loss 0.2711030027566563 Accuracy 58.00761303500139\n",
      "Training:: Epoch 103, Iteration 110, Current loss 0.3598527426819546 Accuracy 68.3381088825215\n",
      "Training:: Epoch 103, Iteration 120, Current loss 0.2873067795665716 Accuracy 55.17485702717749\n",
      "Training:: Epoch 103, Iteration 130, Current loss 0.32087761066592746 Accuracy 67.29848925588814\n",
      "Training:: Epoch 103, Iteration 140, Current loss 0.3614471470196767 Accuracy 53.91089664459657\n",
      "Training:: Epoch 103, Iteration 150, Current loss 0.2900514496264774 Accuracy 63.703495980557115\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 103, Probability Accuracy 54.01164056004152\n",
      "Starting Training\n",
      "Training:: Epoch 104, Iteration 0, Current loss 0.3645598509518747 Accuracy 57.970677216662786\n",
      "Training:: Epoch 104, Iteration 10, Current loss 0.4636554618468563 Accuracy 64.3584174438908\n",
      "Training:: Epoch 104, Iteration 20, Current loss 0.3763293244228863 Accuracy 46.58357334392691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 104, Iteration 30, Current loss 0.33495600091885136 Accuracy 61.38975966562173\n",
      "Training:: Epoch 104, Iteration 40, Current loss 0.29302217945043196 Accuracy 55.67481325694394\n",
      "Training:: Epoch 104, Iteration 50, Current loss 0.31301728728948847 Accuracy 54.24549054113506\n",
      "Training:: Epoch 104, Iteration 60, Current loss 0.25619908529695645 Accuracy 69.6195212212328\n",
      "Training:: Epoch 104, Iteration 70, Current loss 0.27356176711627833 Accuracy 72.51851390876844\n",
      "Training:: Epoch 104, Iteration 80, Current loss 0.3882024653592545 Accuracy 59.33405801247211\n",
      "Training:: Epoch 104, Iteration 90, Current loss 1.060870263347085 Accuracy 74.19817470664928\n",
      "Training:: Epoch 104, Iteration 100, Current loss 2.0459035178331995 Accuracy 59.25270837939421\n",
      "Training:: Epoch 104, Iteration 110, Current loss 4.071030163789215 Accuracy 64.43074691805656\n",
      "Training:: Epoch 104, Iteration 120, Current loss 13.279714534695694 Accuracy 29.805151915455745\n",
      "Training:: Epoch 104, Iteration 130, Current loss 2.15825161630917 Accuracy 55.2022948664316\n",
      "Training:: Epoch 104, Iteration 140, Current loss 4.037017910672535 Accuracy 46.987690079652424\n",
      "Training:: Epoch 104, Iteration 150, Current loss 3.0080370729086265 Accuracy 50.082268067333246\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 104, Probability Accuracy 47.487346610789004\n",
      "Starting Training\n",
      "Training:: Epoch 105, Iteration 0, Current loss 2.6001430085377124 Accuracy 58.339317187805996\n",
      "Training:: Epoch 105, Iteration 10, Current loss 1.3630774635832226 Accuracy 54.88640120920127\n",
      "Training:: Epoch 105, Iteration 20, Current loss 0.7324193975931003 Accuracy 53.26575131528295\n",
      "Training:: Epoch 105, Iteration 30, Current loss 3.3434023258556156 Accuracy 44.27958526993207\n",
      "Training:: Epoch 105, Iteration 40, Current loss 1.092641375142063 Accuracy 63.24436284893847\n",
      "Training:: Epoch 105, Iteration 50, Current loss 1.0694178483257983 Accuracy 61.35528547201809\n",
      "Training:: Epoch 105, Iteration 60, Current loss 0.9771524863602866 Accuracy 70.41077376067963\n",
      "Training:: Epoch 105, Iteration 70, Current loss 2.42660721665848 Accuracy 53.82113821138211\n",
      "Training:: Epoch 105, Iteration 80, Current loss 1.0536537143894038 Accuracy 63.31831216714461\n",
      "Training:: Epoch 105, Iteration 90, Current loss 1.0061796214055738 Accuracy 53.69300506621634\n",
      "Training:: Epoch 105, Iteration 100, Current loss 0.7478212332311731 Accuracy 64.3303153293787\n",
      "Training:: Epoch 105, Iteration 110, Current loss 0.7473491463225036 Accuracy 64.70263883418669\n",
      "Training:: Epoch 105, Iteration 120, Current loss 0.7363159930084118 Accuracy 60.9439498682051\n",
      "Training:: Epoch 105, Iteration 130, Current loss 2.2839218939842834 Accuracy 62.47533632286996\n",
      "Training:: Epoch 105, Iteration 140, Current loss 1.4966978341809327 Accuracy 52.94757450511203\n",
      "Training:: Epoch 105, Iteration 150, Current loss 3.2494014741490806 Accuracy 51.86304682347769\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 105, Probability Accuracy 52.47347950067243\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  62.31023855724232\n",
      "Calculating Expectation\n",
      "Epoch 105 iter 0\n",
      "Epoch 105 iter 10\n",
      "Epoch 105 iter 20\n",
      "Epoch 105 iter 30\n",
      "Epoch 105 iter 40\n",
      "Epoch 105 iter 50\n",
      "Epoch 105 iter 60\n",
      "Epoch 105 iter 70\n",
      "Epoch 105 iter 80\n",
      "Epoch 105 iter 90\n",
      "Epoch 105 iter 100\n",
      "Epoch 105 iter 110\n",
      "Epoch 105 iter 120\n",
      "Epoch 105 iter 130\n",
      "Epoch 105 iter 140\n",
      "Epoch 105 iter 150\n",
      "Train Boundary avergage error = 306.463\n",
      "Train From boundary avergage accuracy = 58.798\n",
      "Starting Training\n",
      "Training:: Epoch 106, Iteration 0, Current loss 1.0056547043936228 Accuracy 58.59260806013781\n",
      "Training:: Epoch 106, Iteration 10, Current loss 1.0818728281143035 Accuracy 58.954393770856505\n",
      "Training:: Epoch 106, Iteration 20, Current loss 2.452934428472033 Accuracy 66.9595283981408\n",
      "Training:: Epoch 106, Iteration 30, Current loss 1.6621207437216545 Accuracy 48.23778928326367\n",
      "Training:: Epoch 106, Iteration 40, Current loss 0.7356142417442135 Accuracy 69.82535909889428\n",
      "Training:: Epoch 106, Iteration 50, Current loss 0.5674142818403444 Accuracy 78.05203856429318\n",
      "Training:: Epoch 106, Iteration 60, Current loss 1.0448537396397233 Accuracy 64.04356496395152\n",
      "Training:: Epoch 106, Iteration 70, Current loss 0.6743930652631775 Accuracy 65.51901714117561\n",
      "Training:: Epoch 106, Iteration 80, Current loss 0.6313998845591079 Accuracy 57.576620713227754\n",
      "Training:: Epoch 106, Iteration 90, Current loss 0.8107258440491756 Accuracy 66.24274406332454\n",
      "Training:: Epoch 106, Iteration 100, Current loss 0.9730746069237172 Accuracy 61.1971682904605\n",
      "Training:: Epoch 106, Iteration 110, Current loss 0.527357749656596 Accuracy 58.197003193318594\n",
      "Training:: Epoch 106, Iteration 120, Current loss 0.8168928485191305 Accuracy 62.76143513007992\n",
      "Training:: Epoch 106, Iteration 130, Current loss 0.6901479927564766 Accuracy 52.544378698224854\n",
      "Training:: Epoch 106, Iteration 140, Current loss 1.1420745928812042 Accuracy 51.38725605454973\n",
      "Training:: Epoch 106, Iteration 150, Current loss 0.5892774095320035 Accuracy 58.40481839751779\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 106, Probability Accuracy 55.696229373720016\n",
      "Starting Training\n",
      "Training:: Epoch 107, Iteration 0, Current loss 0.5754072135486448 Accuracy 60.29887748777632\n",
      "Training:: Epoch 107, Iteration 10, Current loss 0.5564153009541182 Accuracy 49.44337451265912\n",
      "Training:: Epoch 107, Iteration 20, Current loss 0.755619913132572 Accuracy 58.27521764893569\n",
      "Training:: Epoch 107, Iteration 30, Current loss 0.5821580557027969 Accuracy 63.72444308819042\n",
      "Training:: Epoch 107, Iteration 40, Current loss 0.5367016595262185 Accuracy 70.06266616027345\n",
      "Training:: Epoch 107, Iteration 50, Current loss 1.067713496761262 Accuracy 64.6406784704657\n",
      "Training:: Epoch 107, Iteration 60, Current loss 0.476024536086052 Accuracy 76.51662049861496\n",
      "Training:: Epoch 107, Iteration 70, Current loss 0.6868208419240556 Accuracy 68.9821965693846\n",
      "Training:: Epoch 107, Iteration 80, Current loss 0.4891189460918778 Accuracy 58.61403036019043\n",
      "Training:: Epoch 107, Iteration 90, Current loss 0.6017799056241753 Accuracy 64.9098774333093\n",
      "Training:: Epoch 107, Iteration 100, Current loss 0.5133783084620798 Accuracy 65.58607949466659\n",
      "Training:: Epoch 107, Iteration 110, Current loss 0.5318547901266467 Accuracy 54.91408631123283\n",
      "Training:: Epoch 107, Iteration 120, Current loss 0.6725245245604703 Accuracy 68.17214471506266\n",
      "Training:: Epoch 107, Iteration 130, Current loss 0.6264053920974444 Accuracy 65.17797179314977\n",
      "Training:: Epoch 107, Iteration 140, Current loss 0.5667827076344033 Accuracy 60.68515497553018\n",
      "Training:: Epoch 107, Iteration 150, Current loss 0.8666845342705092 Accuracy 70.6001786729473\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 107, Probability Accuracy 54.56219552346248\n",
      "Starting Training\n",
      "Training:: Epoch 108, Iteration 0, Current loss 0.42187503352970057 Accuracy 68.94341115947765\n",
      "Training:: Epoch 108, Iteration 10, Current loss 0.5497838760141462 Accuracy 63.332386094534435\n",
      "Training:: Epoch 108, Iteration 20, Current loss 1.9712375018319537 Accuracy 61.283709194133415\n",
      "Training:: Epoch 108, Iteration 30, Current loss 0.45974642665662735 Accuracy 59.284125063429485\n",
      "Training:: Epoch 108, Iteration 40, Current loss 0.5671009781258121 Accuracy 61.960467930617185\n",
      "Training:: Epoch 108, Iteration 50, Current loss 0.3905971677507981 Accuracy 52.80876883930319\n",
      "Training:: Epoch 108, Iteration 60, Current loss 0.44642631472441785 Accuracy 58.09961115247787\n",
      "Training:: Epoch 108, Iteration 70, Current loss 0.435840854642524 Accuracy 61.21072796934866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 108, Iteration 80, Current loss 0.6757537930328269 Accuracy 62.36054634553227\n",
      "Training:: Epoch 108, Iteration 90, Current loss 0.47934385538297797 Accuracy 64.80548016026884\n",
      "Training:: Epoch 108, Iteration 100, Current loss 0.4972861948688721 Accuracy 57.756364501546514\n",
      "Training:: Epoch 108, Iteration 110, Current loss 0.5996740951431029 Accuracy 58.84288064077809\n",
      "Training:: Epoch 108, Iteration 120, Current loss 0.459939634102091 Accuracy 48.57633235048189\n",
      "Training:: Epoch 108, Iteration 130, Current loss 0.43242202078144637 Accuracy 58.28168044077135\n",
      "Training:: Epoch 108, Iteration 140, Current loss 0.39772107615538055 Accuracy 64.6285018270402\n",
      "Training:: Epoch 108, Iteration 150, Current loss 0.37215343266516165 Accuracy 56.34766168047601\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 108, Probability Accuracy 55.24187923058465\n",
      "Starting Training\n",
      "Training:: Epoch 109, Iteration 0, Current loss 0.46509442447286903 Accuracy 62.51657225503194\n",
      "Training:: Epoch 109, Iteration 10, Current loss 0.36060261300644303 Accuracy 66.30964400158027\n",
      "Training:: Epoch 109, Iteration 20, Current loss 0.44216255741129945 Accuracy 67.8822994773915\n",
      "Training:: Epoch 109, Iteration 30, Current loss 0.3523528155506004 Accuracy 59.64490263459336\n",
      "Training:: Epoch 109, Iteration 40, Current loss 0.3635550168821691 Accuracy 69.01776177855136\n",
      "Training:: Epoch 109, Iteration 50, Current loss 0.39485972353680554 Accuracy 57.503531073446325\n",
      "Training:: Epoch 109, Iteration 60, Current loss 0.4427877415440542 Accuracy 69.42844483828091\n",
      "Training:: Epoch 109, Iteration 70, Current loss 0.4725889682499213 Accuracy 53.598506280411904\n",
      "Training:: Epoch 109, Iteration 80, Current loss 0.3832147979636496 Accuracy 66.46160856687173\n",
      "Training:: Epoch 109, Iteration 90, Current loss 0.5563415887439541 Accuracy 63.30049261083744\n",
      "Training:: Epoch 109, Iteration 100, Current loss 0.6178502728038602 Accuracy 61.847418006658636\n",
      "Training:: Epoch 109, Iteration 110, Current loss 0.44596909639329124 Accuracy 64.28677784395474\n",
      "Training:: Epoch 109, Iteration 120, Current loss 0.4807721627847477 Accuracy 50.96493977522053\n",
      "Training:: Epoch 109, Iteration 130, Current loss 0.4342093302664818 Accuracy 62.62973327193511\n",
      "Training:: Epoch 109, Iteration 140, Current loss 0.2766115555284872 Accuracy 59.75011861458169\n",
      "Training:: Epoch 109, Iteration 150, Current loss 0.47329597458612604 Accuracy 59.52238359035784\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 109, Probability Accuracy 55.1592904057455\n",
      "Starting Training\n",
      "Training:: Epoch 110, Iteration 0, Current loss 0.46059788693162595 Accuracy 61.71008350990901\n",
      "Training:: Epoch 110, Iteration 10, Current loss 0.40594696412656006 Accuracy 57.50354312109601\n",
      "Training:: Epoch 110, Iteration 20, Current loss 0.4159260830656642 Accuracy 65.48117154811716\n",
      "Training:: Epoch 110, Iteration 30, Current loss 0.5033491327205416 Accuracy 56.71558739653614\n",
      "Training:: Epoch 110, Iteration 40, Current loss 0.3520621475693718 Accuracy 57.21649484536083\n",
      "Training:: Epoch 110, Iteration 50, Current loss 0.34561754303173176 Accuracy 66.94012178619757\n",
      "Training:: Epoch 110, Iteration 60, Current loss 0.4495469525359058 Accuracy 71.42699906444335\n",
      "Training:: Epoch 110, Iteration 70, Current loss 0.30788873654345367 Accuracy 53.43950680708965\n",
      "Training:: Epoch 110, Iteration 80, Current loss 0.36456366917399685 Accuracy 46.81492397347444\n",
      "Training:: Epoch 110, Iteration 90, Current loss 0.44282697088169365 Accuracy 58.161362905818066\n",
      "Training:: Epoch 110, Iteration 100, Current loss 0.43705322454949935 Accuracy 70.08026008330793\n",
      "Training:: Epoch 110, Iteration 110, Current loss 0.45636381024275696 Accuracy 64.70949185043145\n",
      "Training:: Epoch 110, Iteration 120, Current loss 0.4933681906176161 Accuracy 62.55378657487091\n",
      "Training:: Epoch 110, Iteration 130, Current loss 0.4439987122056758 Accuracy 53.753737999055666\n",
      "Training:: Epoch 110, Iteration 140, Current loss 0.47554590107264666 Accuracy 66.6941618550087\n",
      "Training:: Epoch 110, Iteration 150, Current loss 0.39990853388983766 Accuracy 50.22001982160555\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 110, Probability Accuracy 55.078933711307414\n",
      "Calculating Expectation\n",
      "Epoch 110 iter 0\n",
      "Epoch 110 iter 10\n",
      "Epoch 110 iter 20\n",
      "Epoch 110 iter 30\n",
      "Epoch 110 iter 40\n",
      "Epoch 110 iter 50\n",
      "Epoch 110 iter 60\n",
      "Epoch 110 iter 70\n",
      "Epoch 110 iter 80\n",
      "Epoch 110 iter 90\n",
      "Epoch 110 iter 100\n",
      "Epoch 110 iter 110\n",
      "Epoch 110 iter 120\n",
      "Epoch 110 iter 130\n",
      "Epoch 110 iter 140\n",
      "Epoch 110 iter 150\n",
      "Train Boundary avergage error = 306.909\n",
      "Train From boundary avergage accuracy = 58.687\n",
      "Starting Training\n",
      "Training:: Epoch 111, Iteration 0, Current loss 0.4274684115509762 Accuracy 55.029093931837075\n",
      "Training:: Epoch 111, Iteration 10, Current loss 0.29557857409401445 Accuracy 65.34586971121558\n",
      "Training:: Epoch 111, Iteration 20, Current loss 0.4804709511317405 Accuracy 66.14957968628131\n",
      "Training:: Epoch 111, Iteration 30, Current loss 0.3858375690127113 Accuracy 56.202437666274825\n",
      "Training:: Epoch 111, Iteration 40, Current loss 0.35170611223508896 Accuracy 59.236031927023944\n",
      "Training:: Epoch 111, Iteration 50, Current loss 0.3914427663935275 Accuracy 68.32162921348315\n",
      "Training:: Epoch 111, Iteration 60, Current loss 0.3181324241179489 Accuracy 70.13356418501112\n",
      "Training:: Epoch 111, Iteration 70, Current loss 0.43421330235054784 Accuracy 62.90235011246413\n",
      "Training:: Epoch 111, Iteration 80, Current loss 0.2780492601945199 Accuracy 71.75642195853436\n",
      "Training:: Epoch 111, Iteration 90, Current loss 0.3407653891575768 Accuracy 48.27880998518181\n",
      "Training:: Epoch 111, Iteration 100, Current loss 0.3711484249694947 Accuracy 63.09632528810611\n",
      "Training:: Epoch 111, Iteration 110, Current loss 0.36323483735630885 Accuracy 75.93235312677479\n",
      "Training:: Epoch 111, Iteration 120, Current loss 0.2839508405599925 Accuracy 65.61849457653118\n",
      "Training:: Epoch 111, Iteration 130, Current loss 0.2836744873112486 Accuracy 65.27464705184482\n",
      "Training:: Epoch 111, Iteration 140, Current loss 0.3422146330412319 Accuracy 67.77465062111801\n",
      "Training:: Epoch 111, Iteration 150, Current loss 0.3754290799510505 Accuracy 62.666666666666664\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 111, Probability Accuracy 54.92815330271594\n",
      "Starting Training\n",
      "Training:: Epoch 112, Iteration 0, Current loss 0.23767423777189478 Accuracy 68.64290405397337\n",
      "Training:: Epoch 112, Iteration 10, Current loss 0.42063227952788595 Accuracy 67.05851157857522\n",
      "Training:: Epoch 112, Iteration 20, Current loss 0.2663789752737314 Accuracy 66.95713965143241\n",
      "Training:: Epoch 112, Iteration 30, Current loss 0.3832693682857526 Accuracy 62.278284828655075\n",
      "Training:: Epoch 112, Iteration 40, Current loss 0.28579885044649717 Accuracy 60.65587044534413\n",
      "Training:: Epoch 112, Iteration 50, Current loss 0.395124848530071 Accuracy 64.48253239298016\n",
      "Training:: Epoch 112, Iteration 60, Current loss 0.2933199662402616 Accuracy 59.121818535068975\n",
      "Training:: Epoch 112, Iteration 70, Current loss 0.24877253929748244 Accuracy 66.26646867397555\n",
      "Training:: Epoch 112, Iteration 80, Current loss 0.31447343434199565 Accuracy 69.51426450312864\n",
      "Training:: Epoch 112, Iteration 90, Current loss 0.3785831078920457 Accuracy 58.280922431865825\n",
      "Training:: Epoch 112, Iteration 100, Current loss 0.40895727477704014 Accuracy 53.35542667771334\n",
      "Training:: Epoch 112, Iteration 110, Current loss 0.5072263470793719 Accuracy 65.31179970635964\n",
      "Training:: Epoch 112, Iteration 120, Current loss 0.5965925595459283 Accuracy 62.34321971373764\n",
      "Training:: Epoch 112, Iteration 130, Current loss 0.29961784423247184 Accuracy 77.72910460837568\n",
      "Training:: Epoch 112, Iteration 140, Current loss 0.3481142537490859 Accuracy 61.53404524055575\n",
      "Training:: Epoch 112, Iteration 150, Current loss 0.28191325903911546 Accuracy 68.1794287716839\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 112, Probability Accuracy 54.950028180646314\n",
      "Starting Training\n",
      "Training:: Epoch 113, Iteration 0, Current loss 0.38722730069749745 Accuracy 60.87052707261766\n",
      "Training:: Epoch 113, Iteration 10, Current loss 0.2701817571388276 Accuracy 63.898368077845724\n",
      "Training:: Epoch 113, Iteration 20, Current loss 0.32059351350526205 Accuracy 54.23970809867534\n",
      "Training:: Epoch 113, Iteration 30, Current loss 0.4536366780668304 Accuracy 62.721281819356506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 113, Iteration 40, Current loss 0.38428991676995355 Accuracy 65.60765449066977\n",
      "Training:: Epoch 113, Iteration 50, Current loss 0.3293260871586173 Accuracy 64.03675344563553\n",
      "Training:: Epoch 113, Iteration 60, Current loss 0.27778556071452015 Accuracy 61.38013216336258\n",
      "Training:: Epoch 113, Iteration 70, Current loss 0.2951844424709124 Accuracy 63.46018322762509\n",
      "Training:: Epoch 113, Iteration 80, Current loss 0.2935606846503869 Accuracy 67.47356908494349\n",
      "Training:: Epoch 113, Iteration 90, Current loss 0.286006009940665 Accuracy 61.85396358285819\n",
      "Training:: Epoch 113, Iteration 100, Current loss 0.33410872832613836 Accuracy 58.658653603353365\n",
      "Training:: Epoch 113, Iteration 110, Current loss 0.4662871979792185 Accuracy 61.78174194236168\n",
      "Training:: Epoch 113, Iteration 120, Current loss 0.3387655807576525 Accuracy 72.31408954646552\n",
      "Training:: Epoch 113, Iteration 130, Current loss 0.3533561155135173 Accuracy 68.64490603363006\n",
      "Training:: Epoch 113, Iteration 140, Current loss 0.34082366752841714 Accuracy 70.2870651806822\n",
      "Training:: Epoch 113, Iteration 150, Current loss 0.5204496206568822 Accuracy 66.74345894355767\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 113, Probability Accuracy 54.6995831496476\n",
      "Starting Training\n",
      "Training:: Epoch 114, Iteration 0, Current loss 0.32278831040814476 Accuracy 52.421984163949695\n",
      "Training:: Epoch 114, Iteration 10, Current loss 0.1981888960856006 Accuracy 60.06502766527865\n",
      "Training:: Epoch 114, Iteration 20, Current loss 0.2663383270305001 Accuracy 69.98505869797225\n",
      "Training:: Epoch 114, Iteration 30, Current loss 0.2955986423825415 Accuracy 64.92851135407906\n",
      "Training:: Epoch 114, Iteration 40, Current loss 0.4222624046822897 Accuracy 63.88484177399615\n",
      "Training:: Epoch 114, Iteration 50, Current loss 0.38041024693091 Accuracy 62.17085858315011\n",
      "Training:: Epoch 114, Iteration 60, Current loss 0.2770065285072946 Accuracy 63.94325731729215\n",
      "Training:: Epoch 114, Iteration 70, Current loss 0.30296834383093807 Accuracy 64.3995552260934\n",
      "Training:: Epoch 114, Iteration 80, Current loss 0.3183805606391497 Accuracy 59.79276280468163\n",
      "Training:: Epoch 114, Iteration 90, Current loss 0.37493641567075653 Accuracy 52.10558019823668\n",
      "Training:: Epoch 114, Iteration 100, Current loss 0.29486686688266955 Accuracy 61.92017259978425\n",
      "Training:: Epoch 114, Iteration 110, Current loss 0.38555000916758625 Accuracy 65.40388768898488\n",
      "Training:: Epoch 114, Iteration 120, Current loss 0.31177406462121865 Accuracy 70.31414716424204\n",
      "Training:: Epoch 114, Iteration 130, Current loss 0.3083557545101595 Accuracy 64.2411720510894\n",
      "Training:: Epoch 114, Iteration 140, Current loss 0.3043689947805992 Accuracy 68.32979273123959\n",
      "Training:: Epoch 114, Iteration 150, Current loss 0.2587677113113328 Accuracy 55.43839829285132\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 114, Probability Accuracy 55.20661157024794\n",
      "Starting Training\n",
      "Training:: Epoch 115, Iteration 0, Current loss 0.3919604022272345 Accuracy 57.903560593964556\n",
      "Training:: Epoch 115, Iteration 10, Current loss 0.29473327189544474 Accuracy 67.41146070831434\n",
      "Training:: Epoch 115, Iteration 20, Current loss 0.37556102539369796 Accuracy 58.884909854285006\n",
      "Training:: Epoch 115, Iteration 30, Current loss 0.6258378173855582 Accuracy 62.78828853388583\n",
      "Training:: Epoch 115, Iteration 40, Current loss 0.321141275852843 Accuracy 61.60763287879428\n",
      "Training:: Epoch 115, Iteration 50, Current loss 0.2554535536775874 Accuracy 63.847109739898016\n",
      "Training:: Epoch 115, Iteration 60, Current loss 0.3106630423989459 Accuracy 62.90956749672346\n",
      "Training:: Epoch 115, Iteration 70, Current loss 0.2840213627180245 Accuracy 68.2492795389049\n",
      "Training:: Epoch 115, Iteration 80, Current loss 0.2982422467833915 Accuracy 58.46912227851568\n",
      "Training:: Epoch 115, Iteration 90, Current loss 0.30635574165615503 Accuracy 62.243978371292805\n",
      "Training:: Epoch 115, Iteration 100, Current loss 0.5112649194915537 Accuracy 56.43496685120634\n",
      "Training:: Epoch 115, Iteration 110, Current loss 0.3956038804323813 Accuracy 50.83881928222552\n",
      "Training:: Epoch 115, Iteration 120, Current loss 0.2933520515692396 Accuracy 66.1998575836696\n",
      "Training:: Epoch 115, Iteration 130, Current loss 0.4837802674087393 Accuracy 43.31297016206392\n",
      "Training:: Epoch 115, Iteration 140, Current loss 0.3877473298465962 Accuracy 60.5456774984672\n",
      "Training:: Epoch 115, Iteration 150, Current loss 0.4186076129480183 Accuracy 65.56646355224554\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 115, Probability Accuracy 55.161410929626506\n",
      "Calculating Expectation\n",
      "Epoch 115 iter 0\n",
      "Epoch 115 iter 10\n",
      "Epoch 115 iter 20\n",
      "Epoch 115 iter 30\n",
      "Epoch 115 iter 40\n",
      "Epoch 115 iter 50\n",
      "Epoch 115 iter 60\n",
      "Epoch 115 iter 70\n",
      "Epoch 115 iter 80\n",
      "Epoch 115 iter 90\n",
      "Epoch 115 iter 100\n",
      "Epoch 115 iter 110\n",
      "Epoch 115 iter 120\n",
      "Epoch 115 iter 130\n",
      "Epoch 115 iter 140\n",
      "Epoch 115 iter 150\n",
      "Train Boundary avergage error = 306.916\n",
      "Train From boundary avergage accuracy = 58.582\n",
      "Starting Training\n",
      "Training:: Epoch 116, Iteration 0, Current loss 0.2925944696852837 Accuracy 51.86795688388045\n",
      "Training:: Epoch 116, Iteration 10, Current loss 0.40968009045359377 Accuracy 61.184769675335716\n",
      "Training:: Epoch 116, Iteration 20, Current loss 0.22773184148117243 Accuracy 44.71307489231624\n",
      "Training:: Epoch 116, Iteration 30, Current loss 0.23281232815942074 Accuracy 60.70645117965707\n",
      "Training:: Epoch 116, Iteration 40, Current loss 0.2253265334548973 Accuracy 67.31556585554269\n",
      "Training:: Epoch 116, Iteration 50, Current loss 0.2632883411628469 Accuracy 67.53729210721838\n",
      "Training:: Epoch 116, Iteration 60, Current loss 0.2901533338801905 Accuracy 62.706704490417216\n",
      "Training:: Epoch 116, Iteration 70, Current loss 0.2640264288504657 Accuracy 66.61123525437822\n",
      "Training:: Epoch 116, Iteration 80, Current loss 0.26339662192584334 Accuracy 62.754253206676324\n",
      "Training:: Epoch 116, Iteration 90, Current loss 0.2921995034590704 Accuracy 62.89211649322453\n",
      "Training:: Epoch 116, Iteration 100, Current loss 0.29256714290902436 Accuracy 60.27131782945737\n",
      "Training:: Epoch 116, Iteration 110, Current loss 0.2550948613872675 Accuracy 78.28659506762132\n",
      "Training:: Epoch 116, Iteration 120, Current loss 0.3048364386185859 Accuracy 68.32722306088706\n",
      "Training:: Epoch 116, Iteration 130, Current loss 0.3534703601549761 Accuracy 57.78838057816447\n",
      "Training:: Epoch 116, Iteration 140, Current loss 0.27569882216517394 Accuracy 61.21771937813049\n",
      "Training:: Epoch 116, Iteration 150, Current loss 0.2940927388575022 Accuracy 64.56955153063552\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 116, Probability Accuracy 55.21464723969174\n",
      "Starting Training\n",
      "Training:: Epoch 117, Iteration 0, Current loss 0.3235814575533192 Accuracy 55.41933686263583\n",
      "Training:: Epoch 117, Iteration 10, Current loss 0.34463096393345244 Accuracy 51.720029784065524\n",
      "Training:: Epoch 117, Iteration 20, Current loss 0.2982838796565441 Accuracy 59.90450204638472\n",
      "Training:: Epoch 117, Iteration 30, Current loss 0.3877986125514805 Accuracy 68.86216233234683\n",
      "Training:: Epoch 117, Iteration 40, Current loss 0.2732798609797429 Accuracy 62.63596038160053\n",
      "Training:: Epoch 117, Iteration 50, Current loss 0.2933154618796517 Accuracy 61.63097305292945\n",
      "Training:: Epoch 117, Iteration 60, Current loss 0.21857653250044465 Accuracy 51.203106858309646\n",
      "Training:: Epoch 117, Iteration 70, Current loss 0.3216293627621544 Accuracy 56.99918896999189\n",
      "Training:: Epoch 117, Iteration 80, Current loss 0.26696101268803296 Accuracy 63.47509515141486\n",
      "Training:: Epoch 117, Iteration 90, Current loss 0.3217967660464939 Accuracy 64.28869202709744\n",
      "Training:: Epoch 117, Iteration 100, Current loss 0.36999575251731937 Accuracy 66.37460499856363\n",
      "Training:: Epoch 117, Iteration 110, Current loss 0.41572325265691756 Accuracy 54.355522024258605\n",
      "Training:: Epoch 117, Iteration 120, Current loss 1.1304114005539474 Accuracy 63.240846167675436\n",
      "Training:: Epoch 117, Iteration 130, Current loss 0.6793353220285503 Accuracy 67.71455981108406\n",
      "Training:: Epoch 117, Iteration 140, Current loss 0.4941063985662579 Accuracy 68.54215351429085\n",
      "Training:: Epoch 117, Iteration 150, Current loss 0.5382154253056515 Accuracy 67.57710888145671\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 117, Probability Accuracy 53.2818455254156\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 118, Iteration 0, Current loss 0.5719302885820957 Accuracy 61.528253125654814\n",
      "Training:: Epoch 118, Iteration 10, Current loss 0.5189005886724765 Accuracy 64.7339158061954\n",
      "Training:: Epoch 118, Iteration 20, Current loss 0.3566272133232748 Accuracy 59.628603672925\n",
      "Training:: Epoch 118, Iteration 30, Current loss 0.49635894863892566 Accuracy 60.732932715988575\n",
      "Training:: Epoch 118, Iteration 40, Current loss 0.47965990225081284 Accuracy 65.99496221662469\n",
      "Training:: Epoch 118, Iteration 50, Current loss 0.3868139280501264 Accuracy 68.11438885441932\n",
      "Training:: Epoch 118, Iteration 60, Current loss 0.46457511709299015 Accuracy 63.04679552390641\n",
      "Training:: Epoch 118, Iteration 70, Current loss 0.3618693318140962 Accuracy 53.2715095311695\n",
      "Training:: Epoch 118, Iteration 80, Current loss 0.3606697312561307 Accuracy 58.12390734265734\n",
      "Training:: Epoch 118, Iteration 90, Current loss 0.5638482077312369 Accuracy 61.44701086956522\n",
      "Training:: Epoch 118, Iteration 100, Current loss 0.39575086787998354 Accuracy 65.90351003900044\n",
      "Training:: Epoch 118, Iteration 110, Current loss 0.3978569091497387 Accuracy 69.19185978120221\n",
      "Training:: Epoch 118, Iteration 120, Current loss 0.3361945976387198 Accuracy 55.20355218519258\n",
      "Training:: Epoch 118, Iteration 130, Current loss 0.2831328353034934 Accuracy 68.9016275975023\n",
      "Training:: Epoch 118, Iteration 140, Current loss 0.33975957010266156 Accuracy 63.569937369519835\n",
      "Training:: Epoch 118, Iteration 150, Current loss 0.4727313513781794 Accuracy 57.41080924296626\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 118, Probability Accuracy 53.719231477502916\n",
      "Starting Training\n",
      "Training:: Epoch 119, Iteration 0, Current loss 0.36393076893360227 Accuracy 61.84098474878068\n",
      "Training:: Epoch 119, Iteration 10, Current loss 0.2693399286581307 Accuracy 65.29923879848671\n",
      "Training:: Epoch 119, Iteration 20, Current loss 0.2819812397601399 Accuracy 67.36069502696225\n",
      "Training:: Epoch 119, Iteration 30, Current loss 0.27645192393603013 Accuracy 62.92263610315186\n",
      "Training:: Epoch 119, Iteration 40, Current loss 0.6055968839266005 Accuracy 61.19452786119453\n",
      "Training:: Epoch 119, Iteration 50, Current loss 0.4349972435395043 Accuracy 43.94085813683804\n",
      "Training:: Epoch 119, Iteration 60, Current loss 0.261421951836321 Accuracy 62.34867825084411\n",
      "Training:: Epoch 119, Iteration 70, Current loss 0.3236123857481504 Accuracy 65.53974207470586\n",
      "Training:: Epoch 119, Iteration 80, Current loss 0.43888083640555864 Accuracy 65.86106798082766\n",
      "Training:: Epoch 119, Iteration 90, Current loss 0.34984229966298697 Accuracy 68.69651741293532\n",
      "Training:: Epoch 119, Iteration 100, Current loss 0.3735830462079983 Accuracy 54.937216294287566\n",
      "Training:: Epoch 119, Iteration 110, Current loss 0.3044611816496565 Accuracy 67.1994291830182\n",
      "Training:: Epoch 119, Iteration 120, Current loss 0.3365437761003622 Accuracy 63.174542924021004\n",
      "Training:: Epoch 119, Iteration 130, Current loss 0.34390421496290285 Accuracy 64.01098901098901\n",
      "Training:: Epoch 119, Iteration 140, Current loss 0.4458478614719838 Accuracy 57.25985844287159\n",
      "Training:: Epoch 119, Iteration 150, Current loss 0.6071092439285612 Accuracy 56.36969662730919\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 119, Probability Accuracy 53.538428915017214\n",
      "Starting Training\n",
      "Training:: Epoch 120, Iteration 0, Current loss 0.26955886716567856 Accuracy 62.68642308991747\n",
      "Training:: Epoch 120, Iteration 10, Current loss 0.4068229698361549 Accuracy 58.893508893508894\n",
      "Training:: Epoch 120, Iteration 20, Current loss 0.2806991015827794 Accuracy 63.93385982230997\n",
      "Training:: Epoch 120, Iteration 30, Current loss 0.34575376169375666 Accuracy 68.6411149825784\n",
      "Training:: Epoch 120, Iteration 40, Current loss 0.2623519699049679 Accuracy 51.49515536251253\n",
      "Training:: Epoch 120, Iteration 50, Current loss 0.33113709820242077 Accuracy 64.6029756389994\n",
      "Training:: Epoch 120, Iteration 60, Current loss 0.36399794032960736 Accuracy 59.73447039441806\n",
      "Training:: Epoch 120, Iteration 70, Current loss 0.3167509665726645 Accuracy 60.740244835501144\n",
      "Training:: Epoch 120, Iteration 80, Current loss 0.32430717016580096 Accuracy 68.37761674718196\n",
      "Training:: Epoch 120, Iteration 90, Current loss 0.30965292644925313 Accuracy 54.504287503613064\n",
      "Training:: Epoch 120, Iteration 100, Current loss 0.7175891977989631 Accuracy 59.968425800631486\n",
      "Training:: Epoch 120, Iteration 110, Current loss 0.35931377817667276 Accuracy 70.86640487927146\n",
      "Training:: Epoch 120, Iteration 120, Current loss 0.26724451730625315 Accuracy 72.03329107644822\n",
      "Training:: Epoch 120, Iteration 130, Current loss 0.3316714777725907 Accuracy 59.013852562239656\n",
      "Training:: Epoch 120, Iteration 140, Current loss 0.21556505567997963 Accuracy 51.8232007669675\n",
      "Training:: Epoch 120, Iteration 150, Current loss 0.32096353120175825 Accuracy 58.03895359938896\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 120, Probability Accuracy 54.56219552346248\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.2829585663737\n",
      "Calculating Expectation\n",
      "Epoch 120 iter 0\n",
      "Epoch 120 iter 10\n",
      "Epoch 120 iter 20\n",
      "Epoch 120 iter 30\n",
      "Epoch 120 iter 40\n",
      "Epoch 120 iter 50\n",
      "Epoch 120 iter 60\n",
      "Epoch 120 iter 70\n",
      "Epoch 120 iter 80\n",
      "Epoch 120 iter 90\n",
      "Epoch 120 iter 100\n",
      "Epoch 120 iter 110\n",
      "Epoch 120 iter 120\n",
      "Epoch 120 iter 130\n",
      "Epoch 120 iter 140\n",
      "Epoch 120 iter 150\n",
      "Train Boundary avergage error = 306.811\n",
      "Train From boundary avergage accuracy = 58.658\n",
      "Starting Training\n",
      "Training:: Epoch 121, Iteration 0, Current loss 0.3675624985876235 Accuracy 57.29325391328439\n",
      "Training:: Epoch 121, Iteration 10, Current loss 0.27179051637648177 Accuracy 50.415163968799796\n",
      "Training:: Epoch 121, Iteration 20, Current loss 0.21142775473104786 Accuracy 69.88451086956522\n",
      "Training:: Epoch 121, Iteration 30, Current loss 0.18903396262831954 Accuracy 59.4619523443505\n",
      "Training:: Epoch 121, Iteration 40, Current loss 0.3207387334529687 Accuracy 63.926767676767675\n",
      "Training:: Epoch 121, Iteration 50, Current loss 0.31316026896586685 Accuracy 69.01904955596231\n",
      "Training:: Epoch 121, Iteration 60, Current loss 0.2909871461628977 Accuracy 61.96675578286644\n",
      "Training:: Epoch 121, Iteration 70, Current loss 0.2531908575780458 Accuracy 60.78116639914393\n",
      "Training:: Epoch 121, Iteration 80, Current loss 0.25316793069460924 Accuracy 68.57578397212544\n",
      "Training:: Epoch 121, Iteration 90, Current loss 0.24398391514553924 Accuracy 65.13941737882853\n",
      "Training:: Epoch 121, Iteration 100, Current loss 0.25649580359145985 Accuracy 55.87446094873023\n",
      "Training:: Epoch 121, Iteration 110, Current loss 0.3188906481596091 Accuracy 60.58572949946752\n",
      "Training:: Epoch 121, Iteration 120, Current loss 0.3232570476703767 Accuracy 51.04865173348552\n",
      "Training:: Epoch 121, Iteration 130, Current loss 0.2730378429590456 Accuracy 56.169242462629846\n",
      "Training:: Epoch 121, Iteration 140, Current loss 0.2831301860007086 Accuracy 65.69358619220115\n",
      "Training:: Epoch 121, Iteration 150, Current loss 0.3167512264151864 Accuracy 69.49821361915427\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 121, Probability Accuracy 54.47134781613942\n",
      "Starting Training\n",
      "Training:: Epoch 122, Iteration 0, Current loss 0.5542879555594497 Accuracy 56.25633232016211\n",
      "Training:: Epoch 122, Iteration 10, Current loss 0.34228781576702916 Accuracy 67.28725117567481\n",
      "Training:: Epoch 122, Iteration 20, Current loss 0.23582814098208604 Accuracy 54.203220433092724\n",
      "Training:: Epoch 122, Iteration 30, Current loss 0.25983896214801777 Accuracy 66.3247339814744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 122, Iteration 40, Current loss 0.30235882028182715 Accuracy 53.815692328344184\n",
      "Training:: Epoch 122, Iteration 50, Current loss 0.2351502254694143 Accuracy 61.2727767201523\n",
      "Training:: Epoch 122, Iteration 60, Current loss 0.31714125313388314 Accuracy 61.64296597257491\n",
      "Training:: Epoch 122, Iteration 70, Current loss 0.32811909486450574 Accuracy 65.12029775355576\n",
      "Training:: Epoch 122, Iteration 80, Current loss 0.2709947145287627 Accuracy 62.10466195473692\n",
      "Training:: Epoch 122, Iteration 90, Current loss 0.36213573062297044 Accuracy 53.10911496413899\n",
      "Training:: Epoch 122, Iteration 100, Current loss 0.26709563226526645 Accuracy 62.86644951140065\n",
      "Training:: Epoch 122, Iteration 110, Current loss 0.3135303510384071 Accuracy 55.28609848836131\n",
      "Training:: Epoch 122, Iteration 120, Current loss 0.25700524339355896 Accuracy 47.50135795763172\n",
      "Training:: Epoch 122, Iteration 130, Current loss 0.31655534557641574 Accuracy 55.82742521182777\n",
      "Training:: Epoch 122, Iteration 140, Current loss 0.2755254815685697 Accuracy 68.87699640438164\n",
      "Training:: Epoch 122, Iteration 150, Current loss 0.34953974350619577 Accuracy 64.08921933085502\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 122, Probability Accuracy 54.82681458250791\n",
      "Starting Training\n",
      "Training:: Epoch 123, Iteration 0, Current loss 0.24561064863084106 Accuracy 54.57729351104193\n",
      "Training:: Epoch 123, Iteration 10, Current loss 0.300825455959427 Accuracy 63.72296601441813\n",
      "Training:: Epoch 123, Iteration 20, Current loss 0.2945111449746036 Accuracy 61.59016538427523\n",
      "Training:: Epoch 123, Iteration 30, Current loss 0.28608687149054024 Accuracy 64.19840316540663\n",
      "Training:: Epoch 123, Iteration 40, Current loss 0.28437888120507676 Accuracy 61.61805173362686\n",
      "Training:: Epoch 123, Iteration 50, Current loss 0.30746217538438414 Accuracy 63.52183650615901\n",
      "Training:: Epoch 123, Iteration 60, Current loss 0.26354090503209887 Accuracy 63.508691147691955\n",
      "Training:: Epoch 123, Iteration 70, Current loss 0.28724793744622434 Accuracy 68.52729775194985\n",
      "Training:: Epoch 123, Iteration 80, Current loss 0.25081285899372546 Accuracy 57.853970876794385\n",
      "Training:: Epoch 123, Iteration 90, Current loss 0.19686748565311557 Accuracy 70.08715750951028\n",
      "Training:: Epoch 123, Iteration 100, Current loss 0.2608153381137074 Accuracy 72.14571301643714\n",
      "Training:: Epoch 123, Iteration 110, Current loss 0.2903279711340579 Accuracy 64.2886335770401\n",
      "Training:: Epoch 123, Iteration 120, Current loss 0.2692406433006069 Accuracy 69.88859587750929\n",
      "Training:: Epoch 123, Iteration 130, Current loss 0.31576890454919626 Accuracy 60.03993154592128\n",
      "Training:: Epoch 123, Iteration 140, Current loss 0.8249549848749268 Accuracy 71.2181036006836\n",
      "Training:: Epoch 123, Iteration 150, Current loss 0.9284941924359127 Accuracy 55.171697590695096\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 123, Probability Accuracy 51.3204725420059\n",
      "Starting Training\n",
      "Training:: Epoch 124, Iteration 0, Current loss 1.4869866670725063 Accuracy 55.072832517015456\n",
      "Training:: Epoch 124, Iteration 10, Current loss 0.4142912231378182 Accuracy 68.8426709125286\n",
      "Training:: Epoch 124, Iteration 20, Current loss 0.7904820153388648 Accuracy 48.39334107626791\n",
      "Training:: Epoch 124, Iteration 30, Current loss 1.6338746393068337 Accuracy 66.70317634173055\n",
      "Training:: Epoch 124, Iteration 40, Current loss 1.8353260770041375 Accuracy 57.741670627889896\n",
      "Training:: Epoch 124, Iteration 50, Current loss 1.9981376263358779 Accuracy 54.24670971961089\n",
      "Training:: Epoch 124, Iteration 60, Current loss 2.522184285210956 Accuracy 69.36196132176032\n",
      "Training:: Epoch 124, Iteration 70, Current loss 1.5691608834829904 Accuracy 61.4738358137302\n",
      "Training:: Epoch 124, Iteration 80, Current loss 0.8010677085816197 Accuracy 69.9721189591078\n",
      "Training:: Epoch 124, Iteration 90, Current loss 1.3246082223029012 Accuracy 52.906843671320665\n",
      "Training:: Epoch 124, Iteration 100, Current loss 0.8443695932742896 Accuracy 61.20516159583284\n",
      "Training:: Epoch 124, Iteration 110, Current loss 1.1637463246380737 Accuracy 64.61608566871725\n",
      "Training:: Epoch 124, Iteration 120, Current loss 0.9362179666777404 Accuracy 65.00645994832041\n",
      "Training:: Epoch 124, Iteration 130, Current loss 1.0774521006479847 Accuracy 55.80815081785417\n",
      "Training:: Epoch 124, Iteration 140, Current loss 1.0069899563684548 Accuracy 65.39026318762002\n",
      "Training:: Epoch 124, Iteration 150, Current loss 2.070233523287429 Accuracy 63.61996825854855\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 124, Probability Accuracy 50.04090378959939\n",
      "Starting Training\n",
      "Training:: Epoch 125, Iteration 0, Current loss 1.5398453746452927 Accuracy 54.69007131102578\n",
      "Training:: Epoch 125, Iteration 10, Current loss 0.8700428173492898 Accuracy 60.40816326530612\n",
      "Training:: Epoch 125, Iteration 20, Current loss 0.8885927356429278 Accuracy 61.323167266527754\n",
      "Training:: Epoch 125, Iteration 30, Current loss 1.0917856821690672 Accuracy 61.10672504126893\n",
      "Training:: Epoch 125, Iteration 40, Current loss 1.2954557990683262 Accuracy 63.90113928702683\n",
      "Training:: Epoch 125, Iteration 50, Current loss 2.79679373356442 Accuracy 50.81229692576856\n",
      "Training:: Epoch 125, Iteration 60, Current loss 1.552908143859943 Accuracy 62.82116975331235\n",
      "Training:: Epoch 125, Iteration 70, Current loss 1.0045935141588767 Accuracy 57.11524003866395\n",
      "Training:: Epoch 125, Iteration 80, Current loss 0.7997560730650659 Accuracy 67.18545867651235\n",
      "Training:: Epoch 125, Iteration 90, Current loss 1.0855320650132718 Accuracy 66.39805909366606\n",
      "Training:: Epoch 125, Iteration 100, Current loss 1.4292074022934502 Accuracy 64.49264812927646\n",
      "Training:: Epoch 125, Iteration 110, Current loss 1.4089101197611489 Accuracy 68.18738859180036\n",
      "Training:: Epoch 125, Iteration 120, Current loss 0.7357029189474398 Accuracy 58.3641899119559\n",
      "Training:: Epoch 125, Iteration 130, Current loss 1.2771125093471434 Accuracy 63.21997654687177\n",
      "Training:: Epoch 125, Iteration 140, Current loss 0.6320876811840722 Accuracy 59.77793869176925\n",
      "Training:: Epoch 125, Iteration 150, Current loss 0.580995137844877 Accuracy 63.615638892055166\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 125, Probability Accuracy 53.46052756402029\n",
      "Calculating Expectation\n",
      "Epoch 125 iter 0\n",
      "Epoch 125 iter 10\n",
      "Epoch 125 iter 20\n",
      "Epoch 125 iter 30\n",
      "Epoch 125 iter 40\n",
      "Epoch 125 iter 50\n",
      "Epoch 125 iter 60\n",
      "Epoch 125 iter 70\n",
      "Epoch 125 iter 80\n",
      "Epoch 125 iter 90\n",
      "Epoch 125 iter 100\n",
      "Epoch 125 iter 110\n",
      "Epoch 125 iter 120\n",
      "Epoch 125 iter 130\n",
      "Epoch 125 iter 140\n",
      "Epoch 125 iter 150\n",
      "Train Boundary avergage error = 307.393\n",
      "Train From boundary avergage accuracy = 58.616\n",
      "Starting Training\n",
      "Training:: Epoch 126, Iteration 0, Current loss 0.5082613981330231 Accuracy 58.12220566318927\n",
      "Training:: Epoch 126, Iteration 10, Current loss 0.3205009389400103 Accuracy 62.86972938955318\n",
      "Training:: Epoch 126, Iteration 20, Current loss 0.4222678465412432 Accuracy 62.15236887399221\n",
      "Training:: Epoch 126, Iteration 30, Current loss 0.46393351087221224 Accuracy 62.804284323271666\n",
      "Training:: Epoch 126, Iteration 40, Current loss 0.5384329824122767 Accuracy 71.65638565227324\n",
      "Training:: Epoch 126, Iteration 50, Current loss 0.42884661230385146 Accuracy 57.284978888310484\n",
      "Training:: Epoch 126, Iteration 60, Current loss 0.4559144294966267 Accuracy 65.52156862745097\n",
      "Training:: Epoch 126, Iteration 70, Current loss 0.8224225814098325 Accuracy 65.04570987994272\n",
      "Training:: Epoch 126, Iteration 80, Current loss 0.5378355028763675 Accuracy 64.71388101983003\n",
      "Training:: Epoch 126, Iteration 90, Current loss 0.769910590184721 Accuracy 54.92945088523412\n",
      "Training:: Epoch 126, Iteration 100, Current loss 0.6692777989674064 Accuracy 64.21694480102695\n",
      "Training:: Epoch 126, Iteration 110, Current loss 0.7132833473739342 Accuracy 61.268847544308265\n",
      "Training:: Epoch 126, Iteration 120, Current loss 0.5682293105348017 Accuracy 65.09232370828995\n",
      "Training:: Epoch 126, Iteration 130, Current loss 0.6117662258599562 Accuracy 65.68210794730132\n",
      "Training:: Epoch 126, Iteration 140, Current loss 0.4811750425109138 Accuracy 74.02300396852088\n",
      "Training:: Epoch 126, Iteration 150, Current loss 0.47197108950177 Accuracy 52.83265001863585\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 126, Probability Accuracy 54.883175875134626\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 127, Iteration 0, Current loss 0.4009952520768787 Accuracy 68.49121053070066\n",
      "Training:: Epoch 127, Iteration 10, Current loss 0.38620118472054615 Accuracy 62.702893436838394\n",
      "Training:: Epoch 127, Iteration 20, Current loss 0.4796443461753419 Accuracy 63.28505181198832\n",
      "Training:: Epoch 127, Iteration 30, Current loss 0.39330000862475295 Accuracy 58.39171337069656\n",
      "Training:: Epoch 127, Iteration 40, Current loss 0.3307875445497412 Accuracy 71.15690582619895\n",
      "Training:: Epoch 127, Iteration 50, Current loss 0.359563291224822 Accuracy 62.45674740484429\n",
      "Training:: Epoch 127, Iteration 60, Current loss 0.41700443025636863 Accuracy 60.2187833511206\n",
      "Training:: Epoch 127, Iteration 70, Current loss 0.2993212900879423 Accuracy 58.84866376631448\n",
      "Training:: Epoch 127, Iteration 80, Current loss 0.48811579556630197 Accuracy 63.41326489694442\n",
      "Training:: Epoch 127, Iteration 90, Current loss 0.7267430819776762 Accuracy 61.690966597238294\n",
      "Training:: Epoch 127, Iteration 100, Current loss 0.8225688668625185 Accuracy 65.61111111111111\n",
      "Training:: Epoch 127, Iteration 110, Current loss 0.8853516552947408 Accuracy 69.84941820670774\n",
      "Training:: Epoch 127, Iteration 120, Current loss 0.41730108406714095 Accuracy 53.98044105696752\n",
      "Training:: Epoch 127, Iteration 130, Current loss 0.4251606968475946 Accuracy 53.54747060216242\n",
      "Training:: Epoch 127, Iteration 140, Current loss 0.49256163484684734 Accuracy 60.669210449075436\n",
      "Training:: Epoch 127, Iteration 150, Current loss 0.3730329646049912 Accuracy 61.950592269326684\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 127, Probability Accuracy 55.22804002209809\n",
      "Starting Training\n",
      "Training:: Epoch 128, Iteration 0, Current loss 0.3234805077436374 Accuracy 65.3305367824128\n",
      "Training:: Epoch 128, Iteration 10, Current loss 0.3686551237524421 Accuracy 58.16335740072202\n",
      "Training:: Epoch 128, Iteration 20, Current loss 0.3180417584413735 Accuracy 69.52500847334528\n",
      "Training:: Epoch 128, Iteration 30, Current loss 0.303227000570496 Accuracy 50.15214696269582\n",
      "Training:: Epoch 128, Iteration 40, Current loss 0.3792839027329397 Accuracy 63.72826786864134\n",
      "Training:: Epoch 128, Iteration 50, Current loss 0.2601790325996002 Accuracy 64.70410262616483\n",
      "Training:: Epoch 128, Iteration 60, Current loss 0.35505420590023534 Accuracy 57.06749919259339\n",
      "Training:: Epoch 128, Iteration 70, Current loss 0.3634418691446731 Accuracy 64.72414616670648\n",
      "Training:: Epoch 128, Iteration 80, Current loss 0.3795761746703057 Accuracy 60.81037966606402\n",
      "Training:: Epoch 128, Iteration 90, Current loss 0.29489250638856324 Accuracy 65.64159070419713\n",
      "Training:: Epoch 128, Iteration 100, Current loss 0.3012558225134389 Accuracy 65.75567994731644\n",
      "Training:: Epoch 128, Iteration 110, Current loss 0.27931328444936027 Accuracy 66.21294363256784\n",
      "Training:: Epoch 128, Iteration 120, Current loss 0.31420446216192954 Accuracy 56.98352344740177\n",
      "Training:: Epoch 128, Iteration 130, Current loss 0.4312762989555639 Accuracy 57.21109682160573\n",
      "Training:: Epoch 128, Iteration 140, Current loss 0.283012110606135 Accuracy 59.06239683063718\n",
      "Training:: Epoch 128, Iteration 150, Current loss 0.28192588352707304 Accuracy 67.95305351104038\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 128, Probability Accuracy 55.64422073537536\n",
      "Starting Training\n",
      "Training:: Epoch 129, Iteration 0, Current loss 0.2084724059508381 Accuracy 70.2828964443291\n",
      "Training:: Epoch 129, Iteration 10, Current loss 0.2467786966950271 Accuracy 69.0409450395435\n",
      "Training:: Epoch 129, Iteration 20, Current loss 0.3006280396582154 Accuracy 69.86012934275831\n",
      "Training:: Epoch 129, Iteration 30, Current loss 0.46937703318567336 Accuracy 62.044374009508715\n",
      "Training:: Epoch 129, Iteration 40, Current loss 0.2803822436788962 Accuracy 68.58970630997383\n",
      "Training:: Epoch 129, Iteration 50, Current loss 0.32496214599067386 Accuracy 73.2627027027027\n",
      "Training:: Epoch 129, Iteration 60, Current loss 0.2848100466492343 Accuracy 63.75411291586149\n",
      "Training:: Epoch 129, Iteration 70, Current loss 0.3270919984542193 Accuracy 64.73908064779977\n",
      "Training:: Epoch 129, Iteration 80, Current loss 0.3381758588646183 Accuracy 66.1101713613297\n",
      "Training:: Epoch 129, Iteration 90, Current loss 0.30186910646486814 Accuracy 66.61679964539007\n",
      "Training:: Epoch 129, Iteration 100, Current loss 0.2872927631159963 Accuracy 65.85526826616973\n",
      "Training:: Epoch 129, Iteration 110, Current loss 0.2657098476483721 Accuracy 66.49837029462516\n",
      "Training:: Epoch 129, Iteration 120, Current loss 0.3025414995488004 Accuracy 65.94515636411924\n",
      "Training:: Epoch 129, Iteration 130, Current loss 0.27234085171182676 Accuracy 68.51457000710732\n",
      "Training:: Epoch 129, Iteration 140, Current loss 0.2445687403486448 Accuracy 68.04370853542956\n",
      "Training:: Epoch 129, Iteration 150, Current loss 0.2975929584610128 Accuracy 52.62158609610048\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 129, Probability Accuracy 55.2611871585538\n",
      "Starting Training\n",
      "Training:: Epoch 130, Iteration 0, Current loss 0.2381514979183204 Accuracy 68.03006638032019\n",
      "Training:: Epoch 130, Iteration 10, Current loss 0.38012602695908965 Accuracy 56.715130606209954\n",
      "Training:: Epoch 130, Iteration 20, Current loss 0.28837678086942536 Accuracy 51.06564748201439\n",
      "Training:: Epoch 130, Iteration 30, Current loss 0.3997966528793813 Accuracy 62.63238344797467\n",
      "Training:: Epoch 130, Iteration 40, Current loss 0.25308172575519855 Accuracy 61.86893515154106\n",
      "Training:: Epoch 130, Iteration 50, Current loss 0.24970589477897 Accuracy 54.97106785902157\n",
      "Training:: Epoch 130, Iteration 60, Current loss 0.3040226129891495 Accuracy 59.45028842891076\n",
      "Training:: Epoch 130, Iteration 70, Current loss 0.3153053775328976 Accuracy 70.33944257672704\n",
      "Training:: Epoch 130, Iteration 80, Current loss 0.36875112519846653 Accuracy 61.40020195220465\n",
      "Training:: Epoch 130, Iteration 90, Current loss 0.2913466115632906 Accuracy 57.86520477265398\n",
      "Training:: Epoch 130, Iteration 100, Current loss 0.2621942306673834 Accuracy 72.89814949730439\n",
      "Training:: Epoch 130, Iteration 110, Current loss 0.21063029934079766 Accuracy 69.9588092117581\n",
      "Training:: Epoch 130, Iteration 120, Current loss 0.35795756100197024 Accuracy 60.011518525628716\n",
      "Training:: Epoch 130, Iteration 130, Current loss 0.22057109405193653 Accuracy 53.23090101183147\n",
      "Training:: Epoch 130, Iteration 140, Current loss 0.3607086384995762 Accuracy 71.5580166121319\n",
      "Training:: Epoch 130, Iteration 150, Current loss 0.2419361181288648 Accuracy 65.01592673700975\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 130, Probability Accuracy 55.16966981211042\n",
      "Calculating Expectation\n",
      "Epoch 130 iter 0\n",
      "Epoch 130 iter 10\n",
      "Epoch 130 iter 20\n",
      "Epoch 130 iter 30\n",
      "Epoch 130 iter 40\n",
      "Epoch 130 iter 50\n",
      "Epoch 130 iter 60\n",
      "Epoch 130 iter 70\n",
      "Epoch 130 iter 80\n",
      "Epoch 130 iter 90\n",
      "Epoch 130 iter 100\n",
      "Epoch 130 iter 110\n",
      "Epoch 130 iter 120\n",
      "Epoch 130 iter 130\n",
      "Epoch 130 iter 140\n",
      "Epoch 130 iter 150\n",
      "Train Boundary avergage error = 307.330\n",
      "Train From boundary avergage accuracy = 58.676\n",
      "Starting Training\n",
      "Training:: Epoch 131, Iteration 0, Current loss 0.20701533233943425 Accuracy 62.53337675024422\n",
      "Training:: Epoch 131, Iteration 10, Current loss 0.20851333829629798 Accuracy 66.0754171593746\n",
      "Training:: Epoch 131, Iteration 20, Current loss 0.2360319741321526 Accuracy 69.60034013605443\n",
      "Training:: Epoch 131, Iteration 30, Current loss 0.2770345092169314 Accuracy 68.36872717435412\n",
      "Training:: Epoch 131, Iteration 40, Current loss 0.23545024569784262 Accuracy 66.00525240735337\n",
      "Training:: Epoch 131, Iteration 50, Current loss 0.23015405950579693 Accuracy 54.36950376884422\n",
      "Training:: Epoch 131, Iteration 60, Current loss 0.24998867150372683 Accuracy 60.648791330925256\n",
      "Training:: Epoch 131, Iteration 70, Current loss 0.2219442063686027 Accuracy 52.17033419305274\n",
      "Training:: Epoch 131, Iteration 80, Current loss 0.2325335337235298 Accuracy 69.10173614023316\n",
      "Training:: Epoch 131, Iteration 90, Current loss 0.3229663784447792 Accuracy 68.10782556750299\n",
      "Training:: Epoch 131, Iteration 100, Current loss 0.20525263592366144 Accuracy 64.27555696002528\n",
      "Training:: Epoch 131, Iteration 110, Current loss 0.23535028655798423 Accuracy 54.63543844974209\n",
      "Training:: Epoch 131, Iteration 120, Current loss 0.2662022177697601 Accuracy 58.93674959772249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 131, Iteration 130, Current loss 0.29947361552982416 Accuracy 59.09319537256593\n",
      "Training:: Epoch 131, Iteration 140, Current loss 0.22075919533446423 Accuracy 63.86174778559036\n",
      "Training:: Epoch 131, Iteration 150, Current loss 0.39155327427273995 Accuracy 48.05640528239946\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 131, Probability Accuracy 55.07804085914699\n",
      "Starting Training\n",
      "Training:: Epoch 132, Iteration 0, Current loss 0.335734210923587 Accuracy 60.363036303630366\n",
      "Training:: Epoch 132, Iteration 10, Current loss 0.32012685447506706 Accuracy 54.710144927536234\n",
      "Training:: Epoch 132, Iteration 20, Current loss 0.24421259217418012 Accuracy 51.14991013461468\n",
      "Training:: Epoch 132, Iteration 30, Current loss 0.26205417163319206 Accuracy 70.05760243451799\n",
      "Training:: Epoch 132, Iteration 40, Current loss 0.2072792966792624 Accuracy 56.75912043978011\n",
      "Training:: Epoch 132, Iteration 50, Current loss 0.33201070834349755 Accuracy 61.51180594729632\n",
      "Training:: Epoch 132, Iteration 60, Current loss 0.2560816640008456 Accuracy 61.27977874159281\n",
      "Training:: Epoch 132, Iteration 70, Current loss 0.3108349451168924 Accuracy 60.46256604525969\n",
      "Training:: Epoch 132, Iteration 80, Current loss 0.24837508447892828 Accuracy 64.18347090168217\n",
      "Training:: Epoch 132, Iteration 90, Current loss 0.2599627437132409 Accuracy 54.035362432309\n",
      "Training:: Epoch 132, Iteration 100, Current loss 0.22893419494098916 Accuracy 63.36583153837434\n",
      "Training:: Epoch 132, Iteration 110, Current loss 0.27848363445352925 Accuracy 63.16775244299674\n",
      "Training:: Epoch 132, Iteration 120, Current loss 0.24862508820380658 Accuracy 66.68172577366163\n",
      "Training:: Epoch 132, Iteration 130, Current loss 0.23537577231072454 Accuracy 68.07792773182412\n",
      "Training:: Epoch 132, Iteration 140, Current loss 0.31658088498640946 Accuracy 56.66721608702819\n",
      "Training:: Epoch 132, Iteration 150, Current loss 0.31462977503500006 Accuracy 61.41707920792079\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 132, Probability Accuracy 55.591207638350234\n",
      "Starting Training\n",
      "Training:: Epoch 133, Iteration 0, Current loss 0.2864273110950475 Accuracy 54.994502905607035\n",
      "Training:: Epoch 133, Iteration 10, Current loss 0.23135652178485214 Accuracy 62.97585078989491\n",
      "Training:: Epoch 133, Iteration 20, Current loss 0.18041933716581757 Accuracy 60.27876256616969\n",
      "Training:: Epoch 133, Iteration 30, Current loss 0.2812694277139569 Accuracy 67.32397567767234\n",
      "Training:: Epoch 133, Iteration 40, Current loss 0.2683984888833274 Accuracy 64.36856134284274\n",
      "Training:: Epoch 133, Iteration 50, Current loss 0.2727320402586696 Accuracy 55.032679738562095\n",
      "Training:: Epoch 133, Iteration 60, Current loss 0.23161355644139953 Accuracy 58.97346062888675\n",
      "Training:: Epoch 133, Iteration 70, Current loss 0.2900918135685553 Accuracy 43.866413959871906\n",
      "Training:: Epoch 133, Iteration 80, Current loss 0.2662811896267101 Accuracy 65.97635616668065\n",
      "Training:: Epoch 133, Iteration 90, Current loss 0.21771768542313485 Accuracy 57.40450267577044\n",
      "Training:: Epoch 133, Iteration 100, Current loss 0.17891011110027005 Accuracy 63.7521713954835\n",
      "Training:: Epoch 133, Iteration 110, Current loss 0.3147773939649079 Accuracy 55.13347763347763\n",
      "Training:: Epoch 133, Iteration 120, Current loss 0.27696156624437357 Accuracy 58.53775434621585\n",
      "Training:: Epoch 133, Iteration 130, Current loss 0.28813736024010433 Accuracy 65.39531355360755\n",
      "Training:: Epoch 133, Iteration 140, Current loss 0.20404192020613876 Accuracy 71.52944065819365\n",
      "Training:: Epoch 133, Iteration 150, Current loss 0.27605198024801625 Accuracy 54.94276795005203\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 133, Probability Accuracy 54.80270757417648\n",
      "Starting Training\n",
      "Training:: Epoch 134, Iteration 0, Current loss 0.20214735949737622 Accuracy 70.64382008315485\n",
      "Training:: Epoch 134, Iteration 10, Current loss 0.25082859975645333 Accuracy 66.50251636993343\n",
      "Training:: Epoch 134, Iteration 20, Current loss 0.3170322098347901 Accuracy 63.51238186385931\n",
      "Training:: Epoch 134, Iteration 30, Current loss 0.33251595921453303 Accuracy 66.7952353942144\n",
      "Training:: Epoch 134, Iteration 40, Current loss 0.26549248501579786 Accuracy 71.69968615143193\n",
      "Training:: Epoch 134, Iteration 50, Current loss 0.26738125789467454 Accuracy 59.58169329320059\n",
      "Training:: Epoch 134, Iteration 60, Current loss 0.24271778040415248 Accuracy 66.31413660924584\n",
      "Training:: Epoch 134, Iteration 70, Current loss 0.33459685292478264 Accuracy 58.44041735310269\n",
      "Training:: Epoch 134, Iteration 80, Current loss 0.27747680619736437 Accuracy 73.25158946412353\n",
      "Training:: Epoch 134, Iteration 90, Current loss 0.2572352336460308 Accuracy 60.283687943262414\n",
      "Training:: Epoch 134, Iteration 100, Current loss 0.24581435130994111 Accuracy 50.28812368236121\n",
      "Training:: Epoch 134, Iteration 110, Current loss 0.224612029250888 Accuracy 58.43342631069619\n",
      "Training:: Epoch 134, Iteration 120, Current loss 0.21988050223282524 Accuracy 51.16783048398748\n",
      "Training:: Epoch 134, Iteration 130, Current loss 0.21936310358342304 Accuracy 60.156116460600536\n",
      "Training:: Epoch 134, Iteration 140, Current loss 0.2271295550278117 Accuracy 71.29781366161717\n",
      "Training:: Epoch 134, Iteration 150, Current loss 0.24292803543025882 Accuracy 59.95954307472632\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 134, Probability Accuracy 55.02603222080234\n",
      "Starting Training\n",
      "Training:: Epoch 135, Iteration 0, Current loss 0.2729135138067722 Accuracy 55.12769915994813\n",
      "Training:: Epoch 135, Iteration 10, Current loss 0.25219617904802316 Accuracy 54.9636803874092\n",
      "Training:: Epoch 135, Iteration 20, Current loss 0.31997409640384095 Accuracy 64.38594456685608\n",
      "Training:: Epoch 135, Iteration 30, Current loss 0.2260911885155721 Accuracy 61.06926058655745\n",
      "Training:: Epoch 135, Iteration 40, Current loss 0.1829200062920793 Accuracy 64.9353647276085\n",
      "Training:: Epoch 135, Iteration 50, Current loss 0.2833288593987619 Accuracy 49.27881948296905\n",
      "Training:: Epoch 135, Iteration 60, Current loss 0.2492839245615714 Accuracy 57.40552448737502\n",
      "Training:: Epoch 135, Iteration 70, Current loss 0.2832099893942811 Accuracy 55.99970875200233\n",
      "Training:: Epoch 135, Iteration 80, Current loss 0.3110368694713345 Accuracy 61.79027186979841\n",
      "Training:: Epoch 135, Iteration 90, Current loss 0.26048994899596584 Accuracy 58.11540955262589\n",
      "Training:: Epoch 135, Iteration 100, Current loss 0.30661237235155003 Accuracy 70.69576865495233\n",
      "Training:: Epoch 135, Iteration 110, Current loss 0.32764084724503256 Accuracy 59.614814814814814\n",
      "Training:: Epoch 135, Iteration 120, Current loss 0.24326238046385396 Accuracy 53.35523613963039\n",
      "Training:: Epoch 135, Iteration 130, Current loss 0.2537429038975203 Accuracy 60.7320540156361\n",
      "Training:: Epoch 135, Iteration 140, Current loss 0.27541360349140676 Accuracy 59.091374194208534\n",
      "Training:: Epoch 135, Iteration 150, Current loss 0.22655306430368816 Accuracy 71.38426548123643\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 135, Probability Accuracy 54.776368435444\n",
      "Completed 0 videos selected frames calculation\n",
      "Completed 10 videos selected frames calculation\n",
      "Completed 20 videos selected frames calculation\n",
      "Completed 30 videos selected frames calculation\n",
      "Completed 40 videos selected frames calculation\n",
      "Completed 50 videos selected frames calculation\n",
      "Completed 60 videos selected frames calculation\n",
      "Completed 70 videos selected frames calculation\n",
      "Completed 80 videos selected frames calculation\n",
      "Completed 90 videos selected frames calculation\n",
      "Completed 100 videos selected frames calculation\n",
      "Completed 110 videos selected frames calculation\n",
      "Completed 120 videos selected frames calculation\n",
      "Completed 130 videos selected frames calculation\n",
      "Completed 140 videos selected frames calculation\n",
      "Completed 150 videos selected frames calculation\n",
      "Total correct pivots labels selected =  61.41992923182285\n",
      "Calculating Expectation\n",
      "Epoch 135 iter 0\n",
      "Epoch 135 iter 10\n",
      "Epoch 135 iter 20\n",
      "Epoch 135 iter 30\n",
      "Epoch 135 iter 40\n",
      "Epoch 135 iter 50\n",
      "Epoch 135 iter 60\n",
      "Epoch 135 iter 70\n",
      "Epoch 135 iter 80\n",
      "Epoch 135 iter 90\n",
      "Epoch 135 iter 100\n",
      "Epoch 135 iter 110\n",
      "Epoch 135 iter 120\n",
      "Epoch 135 iter 130\n",
      "Epoch 135 iter 140\n",
      "Epoch 135 iter 150\n",
      "Train Boundary avergage error = 307.851\n",
      "Train From boundary avergage accuracy = 58.572\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 136, Iteration 0, Current loss 0.2260278811798236 Accuracy 54.885930745195395\n",
      "Training:: Epoch 136, Iteration 10, Current loss 0.22567000064117218 Accuracy 48.272632100942204\n",
      "Training:: Epoch 136, Iteration 20, Current loss 0.2609790666381134 Accuracy 66.14111154907371\n",
      "Training:: Epoch 136, Iteration 30, Current loss 0.20423807085458265 Accuracy 69.29483019684187\n",
      "Training:: Epoch 136, Iteration 40, Current loss 0.235026838291079 Accuracy 72.40982749607946\n",
      "Training:: Epoch 136, Iteration 50, Current loss 0.29869474837074245 Accuracy 52.18758422423861\n",
      "Training:: Epoch 136, Iteration 60, Current loss 0.28251375767886355 Accuracy 66.88666363222576\n",
      "Training:: Epoch 136, Iteration 70, Current loss 0.2126526950944047 Accuracy 56.98240602480036\n",
      "Training:: Epoch 137, Iteration 0, Current loss 0.2962972855465565 Accuracy 57.486121468224376\n",
      "Training:: Epoch 137, Iteration 10, Current loss 0.19632743251294552 Accuracy 61.41904134409488\n",
      "Training:: Epoch 137, Iteration 20, Current loss 0.30464741673828055 Accuracy 44.365288317588146\n",
      "Training:: Epoch 137, Iteration 30, Current loss 0.2396687733796847 Accuracy 65.43767398700896\n",
      "Training:: Epoch 137, Iteration 40, Current loss 0.2625336518709377 Accuracy 63.96356756281075\n",
      "Training:: Epoch 137, Iteration 50, Current loss 0.33694565683653255 Accuracy 58.757463747512084\n",
      "Training:: Epoch 137, Iteration 60, Current loss 0.23774570793325617 Accuracy 68.41409691629956\n",
      "Training:: Epoch 137, Iteration 70, Current loss 0.30802208386338276 Accuracy 64.11871908357199\n",
      "Training:: Epoch 137, Iteration 80, Current loss 0.4809415299452988 Accuracy 57.692606098223294\n",
      "Training:: Epoch 137, Iteration 90, Current loss 0.3484168380465693 Accuracy 68.9620326259564\n",
      "Training:: Epoch 137, Iteration 100, Current loss 0.2735373282657585 Accuracy 59.374728237238024\n",
      "Training:: Epoch 137, Iteration 110, Current loss 0.32843045048917985 Accuracy 67.02530871744712\n",
      "Training:: Epoch 137, Iteration 120, Current loss 0.26773255533459805 Accuracy 55.125255623721884\n",
      "Training:: Epoch 137, Iteration 130, Current loss 0.2766968205822431 Accuracy 63.72364548656342\n",
      "Training:: Epoch 137, Iteration 140, Current loss 0.23092031988529357 Accuracy 58.83654416922994\n",
      "Training:: Epoch 137, Iteration 150, Current loss 0.34591508007069016 Accuracy 60.795273075694666\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 137, Probability Accuracy 54.953599589288004\n",
      "Starting Training\n",
      "Training:: Epoch 138, Iteration 0, Current loss 0.335941314330728 Accuracy 65.96696856686201\n",
      "Training:: Epoch 138, Iteration 10, Current loss 0.31803864757952593 Accuracy 66.31968641114983\n",
      "Training:: Epoch 138, Iteration 20, Current loss 0.262799350827161 Accuracy 64.16969696969697\n",
      "Training:: Epoch 138, Iteration 30, Current loss 0.272057283968817 Accuracy 61.73849525200877\n",
      "Training:: Epoch 138, Iteration 40, Current loss 0.2697191370998337 Accuracy 49.08727586951825\n",
      "Training:: Epoch 138, Iteration 50, Current loss 0.23774275895955907 Accuracy 66.87834640767028\n",
      "Training:: Epoch 138, Iteration 60, Current loss 0.22498939658673242 Accuracy 64.47554424653661\n",
      "Training:: Epoch 138, Iteration 70, Current loss 0.2500855535546223 Accuracy 66.43710870802504\n",
      "Training:: Epoch 138, Iteration 80, Current loss 0.2716914448213187 Accuracy 59.57428978463086\n",
      "Training:: Epoch 138, Iteration 90, Current loss 0.21036882126663273 Accuracy 61.891891891891895\n",
      "Training:: Epoch 138, Iteration 100, Current loss 0.309909292036112 Accuracy 61.85693560986497\n",
      "Training:: Epoch 138, Iteration 110, Current loss 0.2321995327347131 Accuracy 47.12611213105494\n",
      "Training:: Epoch 138, Iteration 120, Current loss 0.27604558669806156 Accuracy 62.1643502901093\n",
      "Training:: Epoch 138, Iteration 130, Current loss 0.316977518383965 Accuracy 63.316466003606116\n",
      "Training:: Epoch 138, Iteration 140, Current loss 0.2176022264732283 Accuracy 66.8244170096022\n",
      "Training:: Epoch 138, Iteration 150, Current loss 0.27778911755668334 Accuracy 59.743911407189515\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 138, Probability Accuracy 54.78273000708701\n",
      "Starting Training\n",
      "Training:: Epoch 139, Iteration 0, Current loss 0.31811634114801135 Accuracy 77.10349050826699\n",
      "Training:: Epoch 139, Iteration 10, Current loss 0.21628877589960202 Accuracy 69.899474525931\n",
      "Training:: Epoch 139, Iteration 20, Current loss 0.23066889898524448 Accuracy 69.79160446647161\n",
      "Training:: Epoch 139, Iteration 30, Current loss 0.251702267050956 Accuracy 67.20542806707856\n",
      "Training:: Epoch 139, Iteration 40, Current loss 0.2653226046066424 Accuracy 69.12621359223301\n",
      "Training:: Epoch 139, Iteration 50, Current loss 0.29387224091676517 Accuracy 57.94816991717873\n",
      "Training:: Epoch 139, Iteration 60, Current loss 0.2501603878481912 Accuracy 60.01383444777496\n",
      "Training:: Epoch 139, Iteration 70, Current loss 0.46659241566300447 Accuracy 54.04660486093711\n",
      "Training:: Epoch 139, Iteration 80, Current loss 0.31132771402181 Accuracy 66.19987822910325\n",
      "Training:: Epoch 139, Iteration 90, Current loss 0.2898084760168134 Accuracy 58.32007876997652\n",
      "Training:: Epoch 139, Iteration 100, Current loss 0.302210094907271 Accuracy 62.298190764184305\n",
      "Training:: Epoch 139, Iteration 110, Current loss 0.2253238770115374 Accuracy 63.97373002057287\n",
      "Training:: Epoch 139, Iteration 120, Current loss 0.21296890329233084 Accuracy 77.44722207224233\n",
      "Training:: Epoch 139, Iteration 130, Current loss 1.6471157539794987 Accuracy 56.06485812285625\n",
      "Training:: Epoch 139, Iteration 140, Current loss 0.9199008713146004 Accuracy 67.4975969240628\n",
      "Training:: Epoch 139, Iteration 150, Current loss 1.3465326977435788 Accuracy 51.891653172383336\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 139, Probability Accuracy 53.48329529411108\n",
      "Starting Training\n",
      "Training:: Epoch 140, Iteration 0, Current loss 0.6813065323565071 Accuracy 71.25523012552301\n",
      "Training:: Epoch 140, Iteration 10, Current loss 0.7777601572548248 Accuracy 58.9328743545611\n",
      "Training:: Epoch 140, Iteration 20, Current loss 0.727806157164248 Accuracy 56.004765687053215\n",
      "Training:: Epoch 140, Iteration 30, Current loss 0.7721049680275904 Accuracy 58.6972492041466\n",
      "Training:: Epoch 140, Iteration 40, Current loss 0.5263725116286065 Accuracy 66.21316842488177\n",
      "Training:: Epoch 140, Iteration 50, Current loss 0.568266893060422 Accuracy 57.44323703507377\n",
      "Training:: Epoch 140, Iteration 60, Current loss 0.5145252589624758 Accuracy 55.34033309196234\n",
      "Training:: Epoch 140, Iteration 70, Current loss 0.4709216389246058 Accuracy 64.48090555682597\n",
      "Training:: Epoch 140, Iteration 80, Current loss 0.5396642094325352 Accuracy 64.4570728553442\n",
      "Training:: Epoch 140, Iteration 90, Current loss 0.5365705004632917 Accuracy 60.535065336735485\n",
      "Training:: Epoch 140, Iteration 100, Current loss 1.2430775232899445 Accuracy 59.04651162790697\n",
      "Training:: Epoch 140, Iteration 110, Current loss 0.8492280780492627 Accuracy 68.85157582832001\n",
      "Training:: Epoch 140, Iteration 120, Current loss 0.8627072099253152 Accuracy 57.25604670558799\n",
      "Training:: Epoch 140, Iteration 130, Current loss 0.9452420915679401 Accuracy 64.76291578202407\n",
      "Training:: Epoch 140, Iteration 140, Current loss 0.5102641905368598 Accuracy 65.75519305245864\n",
      "Training:: Epoch 140, Iteration 150, Current loss 0.42899566940407513 Accuracy 65.06647502694933\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 140, Probability Accuracy 53.87001188609439\n",
      "Calculating Expectation\n",
      "Epoch 140 iter 0\n",
      "Epoch 140 iter 10\n",
      "Epoch 140 iter 20\n",
      "Epoch 140 iter 30\n",
      "Epoch 140 iter 40\n",
      "Epoch 140 iter 50\n",
      "Epoch 140 iter 60\n",
      "Epoch 140 iter 70\n",
      "Epoch 140 iter 80\n",
      "Epoch 140 iter 90\n",
      "Epoch 140 iter 100\n",
      "Epoch 140 iter 110\n",
      "Epoch 140 iter 120\n",
      "Epoch 140 iter 130\n",
      "Epoch 140 iter 140\n",
      "Epoch 140 iter 150\n",
      "Train Boundary avergage error = 308.159\n",
      "Train From boundary avergage accuracy = 58.554\n",
      "Starting Training\n",
      "Training:: Epoch 141, Iteration 0, Current loss 0.4844951678075643 Accuracy 57.88569540799472\n",
      "Training:: Epoch 141, Iteration 10, Current loss 0.4785572062208757 Accuracy 48.09556197925523\n",
      "Training:: Epoch 141, Iteration 20, Current loss 0.5185286394846074 Accuracy 56.226150611323106\n",
      "Training:: Epoch 141, Iteration 30, Current loss 0.4487060401522724 Accuracy 56.24429775130145\n",
      "Training:: Epoch 141, Iteration 40, Current loss 0.5392420642929512 Accuracy 61.29418017539197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 141, Iteration 50, Current loss 2.0829215281434035 Accuracy 66.95532224691547\n",
      "Training:: Epoch 141, Iteration 60, Current loss 3.591808827126159 Accuracy 42.28772891979238\n",
      "Training:: Epoch 141, Iteration 70, Current loss 1.2358263946511752 Accuracy 55.55398829254531\n",
      "Training:: Epoch 141, Iteration 80, Current loss 3.0973087561979504 Accuracy 46.35841429685838\n",
      "Training:: Epoch 141, Iteration 90, Current loss 9.501530909521492 Accuracy 49.33282500953107\n",
      "Training:: Epoch 141, Iteration 100, Current loss 1.6030675984763179 Accuracy 63.45017976373909\n",
      "Training:: Epoch 141, Iteration 110, Current loss 1.2973583034268041 Accuracy 54.44737659112077\n",
      "Training:: Epoch 141, Iteration 120, Current loss 0.9975716718235277 Accuracy 66.56010582593838\n",
      "Training:: Epoch 141, Iteration 130, Current loss 0.9127437663957121 Accuracy 56.734214390602055\n",
      "Training:: Epoch 141, Iteration 140, Current loss 0.9465817576395905 Accuracy 65.16704379076268\n",
      "Training:: Epoch 141, Iteration 150, Current loss 0.8834029401925301 Accuracy 69.03297931805479\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 141, Probability Accuracy 54.20985373965547\n",
      "Starting Training\n",
      "Training:: Epoch 142, Iteration 0, Current loss 0.6522539321350861 Accuracy 57.86939313984169\n",
      "Training:: Epoch 142, Iteration 10, Current loss 0.5325961683797675 Accuracy 59.842812055201435\n",
      "Training:: Epoch 142, Iteration 20, Current loss 0.48961083936409816 Accuracy 61.627978572747985\n",
      "Training:: Epoch 142, Iteration 30, Current loss 0.5397114685075775 Accuracy 46.422671241580886\n",
      "Training:: Epoch 142, Iteration 40, Current loss 0.37107248018472644 Accuracy 61.81112718663685\n",
      "Training:: Epoch 142, Iteration 50, Current loss 0.5481855898246513 Accuracy 59.631544925662574\n",
      "Training:: Epoch 142, Iteration 60, Current loss 0.46552540601239734 Accuracy 61.99202674897119\n",
      "Training:: Epoch 142, Iteration 70, Current loss 0.4712949251469562 Accuracy 61.08156596399051\n",
      "Training:: Epoch 142, Iteration 80, Current loss 0.4808210487238927 Accuracy 56.95629761154705\n",
      "Training:: Epoch 142, Iteration 90, Current loss 0.3891269053265025 Accuracy 56.741047568145376\n",
      "Training:: Epoch 142, Iteration 100, Current loss 0.4043314799707259 Accuracy 61.49513156835922\n",
      "Training:: Epoch 142, Iteration 110, Current loss 0.3903767303712664 Accuracy 62.59516897628307\n",
      "Training:: Epoch 142, Iteration 120, Current loss 0.34960214574583187 Accuracy 52.430007886435334\n",
      "Training:: Epoch 142, Iteration 130, Current loss 0.4880639755886481 Accuracy 56.38962286812395\n",
      "Training:: Epoch 142, Iteration 140, Current loss 0.5326085890528037 Accuracy 61.959840843897474\n",
      "Training:: Epoch 142, Iteration 150, Current loss 0.6186741814388244 Accuracy 70.2394526795895\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 142, Probability Accuracy 53.06901189167471\n",
      "Starting Training\n",
      "Training:: Epoch 143, Iteration 0, Current loss 0.36469298662578115 Accuracy 57.61731658955717\n",
      "Training:: Epoch 143, Iteration 10, Current loss 0.3595993454955878 Accuracy 71.3147605083089\n",
      "Training:: Epoch 143, Iteration 20, Current loss 0.3169511363392546 Accuracy 70.41704379307944\n",
      "Training:: Epoch 143, Iteration 30, Current loss 0.3225079372276708 Accuracy 67.21962285552247\n",
      "Training:: Epoch 143, Iteration 40, Current loss 0.348371558762363 Accuracy 63.73780569290392\n",
      "Training:: Epoch 143, Iteration 50, Current loss 0.4133231749082625 Accuracy 59.62241413938542\n",
      "Training:: Epoch 143, Iteration 60, Current loss 0.40777286122214745 Accuracy 61.645932069510266\n",
      "Training:: Epoch 143, Iteration 70, Current loss 0.29335917765896946 Accuracy 61.64107001225755\n",
      "Training:: Epoch 143, Iteration 80, Current loss 0.3693227827617122 Accuracy 58.962795941375425\n",
      "Training:: Epoch 143, Iteration 90, Current loss 0.3937124724483595 Accuracy 60.79478296311392\n",
      "Training:: Epoch 143, Iteration 100, Current loss 0.4687171546146753 Accuracy 70.69653662932922\n",
      "Training:: Epoch 143, Iteration 110, Current loss 0.3251085340636349 Accuracy 60.746507191833786\n",
      "Training:: Epoch 143, Iteration 120, Current loss 0.3337101108666073 Accuracy 66.14881907819307\n",
      "Training:: Epoch 143, Iteration 130, Current loss 0.3310769405285061 Accuracy 66.91499624825812\n",
      "Training:: Epoch 143, Iteration 140, Current loss 0.3259273090067003 Accuracy 57.854255004437434\n",
      "Training:: Epoch 143, Iteration 150, Current loss 0.35706254599303383 Accuracy 66.22323397595504\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 143, Probability Accuracy 54.90426950742462\n",
      "Starting Training\n",
      "Training:: Epoch 144, Iteration 0, Current loss 0.33017707227961207 Accuracy 71.55826183227235\n",
      "Training:: Epoch 144, Iteration 10, Current loss 0.28881297457786326 Accuracy 68.89078984887368\n",
      "Training:: Epoch 144, Iteration 20, Current loss 0.2954010986762867 Accuracy 60.92957414179545\n",
      "Training:: Epoch 144, Iteration 30, Current loss 0.381907488811966 Accuracy 64.12538033182157\n",
      "Training:: Epoch 144, Iteration 40, Current loss 0.21342828203131586 Accuracy 70.46489463094356\n",
      "Training:: Epoch 144, Iteration 50, Current loss 0.4475398256231151 Accuracy 74.8434290295105\n",
      "Training:: Epoch 144, Iteration 60, Current loss 0.3037395271434429 Accuracy 68.11224489795919\n",
      "Training:: Epoch 144, Iteration 70, Current loss 0.282376374831768 Accuracy 65.46492358681643\n",
      "Training:: Epoch 144, Iteration 80, Current loss 0.2654977407021462 Accuracy 63.19104268719384\n",
      "Training:: Epoch 144, Iteration 90, Current loss 0.25809179351011796 Accuracy 71.43846886637222\n",
      "Training:: Epoch 144, Iteration 100, Current loss 0.26004793615727745 Accuracy 61.87161639597834\n",
      "Training:: Epoch 144, Iteration 110, Current loss 0.331203574746755 Accuracy 55.80728554641598\n",
      "Training:: Epoch 144, Iteration 120, Current loss 0.29075598759059423 Accuracy 62.97894829560469\n",
      "Training:: Epoch 144, Iteration 130, Current loss 0.29526439029046203 Accuracy 64.93310835241654\n",
      "Training:: Epoch 144, Iteration 140, Current loss 1.3085088967646152 Accuracy 57.39938357082235\n",
      "Training:: Epoch 144, Iteration 150, Current loss 0.25942523649022786 Accuracy 68.67282688690817\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 144, Probability Accuracy 54.338536057276464\n",
      "Starting Training\n",
      "Training:: Epoch 145, Iteration 0, Current loss 0.38005946104319405 Accuracy 70.32045036267186\n",
      "Training:: Epoch 145, Iteration 10, Current loss 0.7082534433624389 Accuracy 65.00106428267348\n",
      "Training:: Epoch 145, Iteration 20, Current loss 0.29241377067412716 Accuracy 52.1890764152706\n",
      "Training:: Epoch 145, Iteration 30, Current loss 0.2816039706149791 Accuracy 63.515597200806546\n",
      "Training:: Epoch 145, Iteration 40, Current loss 0.249308825970152 Accuracy 63.43801652892562\n",
      "Training:: Epoch 145, Iteration 50, Current loss 0.3242789002083703 Accuracy 66.39013984356482\n",
      "Training:: Epoch 145, Iteration 60, Current loss 0.31323711893022876 Accuracy 61.22170012815036\n",
      "Training:: Epoch 145, Iteration 70, Current loss 0.28600901023622066 Accuracy 69.5645592613149\n",
      "Training:: Epoch 145, Iteration 80, Current loss 0.2447362377011157 Accuracy 65.79962328459952\n",
      "Training:: Epoch 145, Iteration 90, Current loss 0.3363226632828042 Accuracy 62.18886566596998\n",
      "Training:: Epoch 145, Iteration 100, Current loss 0.2793555875948054 Accuracy 66.00950713034776\n",
      "Training:: Epoch 145, Iteration 110, Current loss 0.27880399583716364 Accuracy 65.58647957205984\n",
      "Training:: Epoch 145, Iteration 120, Current loss 0.3670998678095256 Accuracy 61.06418491730312\n",
      "Training:: Epoch 145, Iteration 130, Current loss 0.32848014367696066 Accuracy 46.57139195078185\n",
      "Training:: Epoch 145, Iteration 140, Current loss 0.3795638785087757 Accuracy 51.62767971660661\n",
      "Training:: Epoch 145, Iteration 150, Current loss 0.22504550578216764 Accuracy 73.43286634625217\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 145, Probability Accuracy 55.61832802272309\n",
      "Calculating Expectation\n",
      "Epoch 145 iter 0\n",
      "Epoch 145 iter 10\n",
      "Epoch 145 iter 20\n",
      "Epoch 145 iter 30\n",
      "Epoch 145 iter 40\n",
      "Epoch 145 iter 50\n",
      "Epoch 145 iter 60\n",
      "Epoch 145 iter 70\n",
      "Epoch 145 iter 80\n",
      "Epoch 145 iter 90\n",
      "Epoch 145 iter 100\n",
      "Epoch 145 iter 110\n",
      "Epoch 145 iter 120\n",
      "Epoch 145 iter 130\n",
      "Epoch 145 iter 140\n",
      "Epoch 145 iter 150\n",
      "Train Boundary avergage error = 307.622\n",
      "Train From boundary avergage accuracy = 58.639\n",
      "Starting Training\n",
      "Training:: Epoch 146, Iteration 0, Current loss 0.21278889707033488 Accuracy 64.26941428670216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 146, Iteration 10, Current loss 0.25454032381571956 Accuracy 61.18085523734798\n",
      "Training:: Epoch 146, Iteration 20, Current loss 0.26671494215577024 Accuracy 53.78755210579273\n",
      "Training:: Epoch 146, Iteration 30, Current loss 0.317440415609864 Accuracy 51.15486235404415\n",
      "Training:: Epoch 146, Iteration 40, Current loss 0.26750447944226813 Accuracy 61.665461557001684\n",
      "Training:: Epoch 146, Iteration 50, Current loss 0.1959851989480223 Accuracy 71.18959107806691\n",
      "Training:: Epoch 146, Iteration 60, Current loss 0.2865225800673914 Accuracy 65.41980406444823\n",
      "Training:: Epoch 146, Iteration 70, Current loss 0.192064406409917 Accuracy 62.66660970608339\n",
      "Training:: Epoch 146, Iteration 80, Current loss 0.21038378125065055 Accuracy 62.46817078225854\n",
      "Training:: Epoch 146, Iteration 90, Current loss 0.28177416144830075 Accuracy 58.4076792772445\n",
      "Training:: Epoch 146, Iteration 100, Current loss 0.3191194491443578 Accuracy 66.17717173643558\n",
      "Training:: Epoch 146, Iteration 110, Current loss 0.26892007646482186 Accuracy 67.38064516129032\n",
      "Training:: Epoch 146, Iteration 120, Current loss 0.2105143378464902 Accuracy 64.83672772784162\n",
      "Training:: Epoch 146, Iteration 130, Current loss 0.24046199903473064 Accuracy 74.20879477318012\n",
      "Training:: Epoch 146, Iteration 140, Current loss 0.27526404509933616 Accuracy 58.333333333333336\n",
      "Training:: Epoch 146, Iteration 150, Current loss 0.3174429876365549 Accuracy 59.07616361071932\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 146, Probability Accuracy 54.7592926378759\n",
      "Starting Training\n",
      "Training:: Epoch 147, Iteration 0, Current loss 0.191261084093378 Accuracy 56.03942100400369\n",
      "Training:: Epoch 147, Iteration 10, Current loss 0.23933156056027902 Accuracy 68.29325130499628\n",
      "Training:: Epoch 147, Iteration 20, Current loss 0.214956418709167 Accuracy 67.97900262467192\n",
      "Training:: Epoch 147, Iteration 30, Current loss 0.2801857885656157 Accuracy 61.24557474170941\n",
      "Training:: Epoch 147, Iteration 40, Current loss 0.1840476618409674 Accuracy 49.40185087653299\n",
      "Training:: Epoch 147, Iteration 50, Current loss 0.26558249568076736 Accuracy 56.59372225413903\n",
      "Training:: Epoch 147, Iteration 60, Current loss 0.2039709074388604 Accuracy 70.89605271658375\n",
      "Training:: Epoch 147, Iteration 70, Current loss 0.5164963402768974 Accuracy 62.08296127932462\n",
      "Training:: Epoch 147, Iteration 80, Current loss 0.15235328603946657 Accuracy 61.587935240629854\n",
      "Training:: Epoch 147, Iteration 90, Current loss 0.2468713094047232 Accuracy 61.506164016437374\n",
      "Training:: Epoch 147, Iteration 100, Current loss 0.22869611436406614 Accuracy 58.83616830796777\n",
      "Training:: Epoch 147, Iteration 110, Current loss 0.2063697936927225 Accuracy 46.73426194812226\n",
      "Training:: Epoch 147, Iteration 120, Current loss 0.163689103417233 Accuracy 71.5613588580281\n",
      "Training:: Epoch 147, Iteration 130, Current loss 0.2951990651709744 Accuracy 58.066204370011775\n",
      "Training:: Epoch 147, Iteration 140, Current loss 0.2809359574521311 Accuracy 71.99192176870748\n",
      "Training:: Epoch 147, Iteration 150, Current loss 0.23073646014004917 Accuracy 45.027156976226514\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 147, Probability Accuracy 55.118107599845985\n",
      "Starting Training\n",
      "Training:: Epoch 148, Iteration 0, Current loss 0.21150310636471686 Accuracy 69.52364691821752\n",
      "Training:: Epoch 148, Iteration 10, Current loss 0.23555836252086898 Accuracy 67.35883180387165\n",
      "Training:: Epoch 148, Iteration 20, Current loss 0.17971092939503597 Accuracy 60.47508150908244\n",
      "Training:: Epoch 148, Iteration 30, Current loss 0.24148221680896154 Accuracy 64.24365249311717\n",
      "Training:: Epoch 148, Iteration 40, Current loss 0.21756969589249966 Accuracy 66.83567450752223\n",
      "Training:: Epoch 148, Iteration 50, Current loss 0.256728752483771 Accuracy 69.6608253250424\n",
      "Training:: Epoch 148, Iteration 60, Current loss 0.23130761874852773 Accuracy 66.81894195864095\n",
      "Training:: Epoch 148, Iteration 70, Current loss 0.2785922811700401 Accuracy 49.41399891481281\n",
      "Training:: Epoch 148, Iteration 80, Current loss 0.20642432830240817 Accuracy 62.974459510973155\n",
      "Training:: Epoch 148, Iteration 90, Current loss 0.25946825114119937 Accuracy 62.929699597398574\n",
      "Training:: Epoch 148, Iteration 100, Current loss 0.18340292877271183 Accuracy 65.14027149321267\n",
      "Training:: Epoch 148, Iteration 110, Current loss 0.19691227396536032 Accuracy 65.75999075999076\n",
      "Training:: Epoch 148, Iteration 120, Current loss 0.21384520825966802 Accuracy 53.38659431212943\n",
      "Training:: Epoch 148, Iteration 130, Current loss 0.1883209401242759 Accuracy 51.46370906896031\n",
      "Training:: Epoch 148, Iteration 140, Current loss 0.304193812039579 Accuracy 59.857270294380015\n",
      "Training:: Epoch 148, Iteration 150, Current loss 0.24488285889944683 Accuracy 52.336059891861915\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 148, Probability Accuracy 54.44166048180535\n",
      "Starting Training\n",
      "Training:: Epoch 149, Iteration 0, Current loss 0.23659689451423316 Accuracy 58.047602621593654\n",
      "Training:: Epoch 149, Iteration 10, Current loss 0.3035583967914652 Accuracy 63.53813559322034\n",
      "Training:: Epoch 149, Iteration 20, Current loss 0.20655298517699724 Accuracy 65.43570194770385\n",
      "Training:: Epoch 149, Iteration 30, Current loss 0.18442317324772461 Accuracy 59.63711378873834\n",
      "Training:: Epoch 149, Iteration 40, Current loss 0.2837308998471419 Accuracy 54.40390953517445\n",
      "Training:: Epoch 149, Iteration 50, Current loss 0.20168171155200207 Accuracy 57.860956151400636\n",
      "Training:: Epoch 149, Iteration 60, Current loss 0.24989951978288594 Accuracy 60.772160406242996\n",
      "Training:: Epoch 149, Iteration 70, Current loss 0.2524422890789956 Accuracy 63.43372065449372\n",
      "Training:: Epoch 149, Iteration 80, Current loss 0.15088972997112385 Accuracy 47.79752221248905\n",
      "Training:: Epoch 149, Iteration 90, Current loss 0.1878085879721976 Accuracy 66.78092399403874\n",
      "Training:: Epoch 149, Iteration 100, Current loss 0.22925614136263328 Accuracy 64.27350427350427\n",
      "Training:: Epoch 149, Iteration 110, Current loss 0.23286565880953228 Accuracy 69.18853876814319\n",
      "Training:: Epoch 149, Iteration 120, Current loss 0.22974450001258817 Accuracy 73.14156609907974\n",
      "Training:: Epoch 149, Iteration 130, Current loss 0.2103717170726112 Accuracy 64.21761880868755\n",
      "Training:: Epoch 149, Iteration 140, Current loss 0.3397036887277392 Accuracy 60.46674445740957\n",
      "Training:: Epoch 149, Iteration 150, Current loss 0.27248345624696335 Accuracy 66.32402093712555\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 149, Probability Accuracy 55.14109854297688\n"
     ]
    }
   ],
   "source": [
    "initialize_epoch = 25\n",
    "expectation_cal_gap = 5\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(25, 150):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        psuedo_l = get_single_random(predictions[-1], item[4])\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, psuedo_l)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                            max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                es_loss, _ = get_estimated_loss(prob, item_1, item[4])\n",
    "                loss += es_loss\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(predictions[-1], dim=1)\n",
    "                correct = float(torch.sum((pred == item_2) * src_mask).item())\n",
    "                total = float(torch.sum(src_mask).item())\n",
    "                print(f\"Training:: Epoch {epoch}, Iteration {i}, Current loss {loss.item()}\" +\n",
    "                      f\" Accuracy {correct * 100.0 / total}\")\n",
    "\n",
    "    # Calculating Expectation Step\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-last-model.wt\")\n",
    "    print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")\n",
    "\n",
    "    if (epoch == initialize_epoch) or ((epoch > initialize_epoch) and ((epoch % (3 * expectation_cal_gap)) == 0)):\n",
    "        torch.save(model.state_dict(), config.output_dir + f\"ms-tcn-initial-{initialize_epoch}-epochs.wt\")\n",
    "        selected_frames_dict = change_selected_frames(model)\n",
    "        get_new_selected_frame_acc(selected_frames_dict)\n",
    "\n",
    "    if (epoch == initialize_epoch) or ((epoch > initialize_epoch) and (epoch % expectation_cal_gap == 0)):\n",
    "        print(\"Calculating Expectation\")\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, item in enumerate(trainloader):\n",
    "            with torch.no_grad():\n",
    "                item_0 = item[0].to(device)\n",
    "                item_1 = item[1].to(device)\n",
    "                item_2 = item[2].to(device)\n",
    "                src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "                src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "                middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "                prob = torch.softmax(predictions[-1], dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                calculate_element_probb(prob, item_1, item[4])\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Epoch {epoch} iter {i}\")\n",
    "                    \n",
    "        get_boundary_err()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:: Epoch 130, Probability Accuracy 51.43919338691232\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.61000906173455"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split1/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-emmax-best-model.wt\"))\n",
    "# model.load_state_dict(torch.load(config.output_dir + \"ms-tcn-initial-15-epochs.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Probability Accuracy 54.625639564561894\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Validation Data Accuracy\")\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "        pred = torch.argmax(predictions[-1], dim=1)\n",
    "        correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "        total += float(torch.sum(src_mask).item())\n",
    "\n",
    "print(f\"Validation:: Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration done\n",
      "11 iteration done\n",
      "21 iteration done\n",
      "31 iteration done\n",
      "41 iteration done\n",
      "51 iteration done\n",
      "61 iteration done\n",
      "71 iteration done\n",
      "81 iteration done\n",
      "91 iteration done\n",
      "101 iteration done\n",
      "111 iteration done\n",
      "121 iteration done\n",
      "131 iteration done\n",
      "141 iteration done\n",
      "151 iteration done\n",
      "161 iteration done\n",
      "171 iteration done\n",
      "181 iteration done\n",
      "Train Boundary avergage error = 307.224\n",
      "Train From boundary avergage accuracy = 57.704\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        prob = torch.softmax(predictions[-1], dim=1)\n",
    "        prob = prob.permute(0, 2, 1)\n",
    "        calculate_element_probb(prob, item_1, item[4])\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f'{i+1} iteration done')\n",
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    idx = 1\n",
    "\n",
    "    cur_vid_feat = torch.softmax(predictions[-1], dim=1).permute(0, 2, 1)[idx]\n",
    "    cur_vidid = item[4][idx]\n",
    "\n",
    "    selected_frames_indices_and_labels = selected_frames_dict[cur_vidid + \".txt\"]\n",
    "    selected_frames_indices = [ele[0] for ele in selected_frames_indices_and_labels]\n",
    "    selected_frames_labels = [label_name_to_label_id_dict[ele[1]] for ele in selected_frames_indices_and_labels]\n",
    "    \n",
    "    cumsum_feat = torch.cumsum(cur_vid_feat, dim=0)\n",
    "    prob_each_segment = prob_vals_per_segment(selected_frames_indices, cur_vid_feat, selected_frames_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 228, 481, 735, 1578, 2388, 2567, 2745]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_frames_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[88, 229, 578, 1128, 2241, 2479, 2720, 2810]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_frames_dict[cur_vidid + \".txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min prob 0 = 0.0\n",
      "Min prob 1 = 0.0\n",
      "Min prob 2 = 0.0\n",
      "Min prob 3 = 0.0\n",
      "Min prob 4 = 0.0\n",
      "Min prob 5 = 7.224189870987231e-126\n",
      "Min prob 6 = 4.631831900603335e-244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 2811)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ymax = 1\n",
    "\n",
    "plt.plot([0, item[1][idx].item()], [0, 0])\n",
    "\n",
    "for pivot in selected_frames_indices:\n",
    "    plt.plot([pivot, pivot], [0, ymax], '--')\n",
    "    \n",
    "for pivot in boundary_frames_dict[cur_vidid + \".txt\"]:\n",
    "    plt.plot([pivot, pivot], [0, ymax])\n",
    "    \n",
    "all_prob = []\n",
    "for i, segment in enumerate(prob_each_segment):\n",
    "    segment = segment.cpu().numpy()\n",
    "    print(f\"Min prob {i} = {np.min(segment).item()}\")\n",
    "    xs = np.arange(selected_frames_indices[i], \n",
    "                   selected_frames_indices[i+1])\n",
    "    plt.plot(xs, segment, '*')\n",
    "\n",
    "    \n",
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "\n",
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]])\n",
    "loss_arr = -loss_arr[0].detach().cpu().numpy()\n",
    "plt.plot(np.arange(selected_frames_indices[0] - 1, selected_frames_indices[-1] + 1), loss_arr/np.max(loss_arr), 'k+')\n",
    "\n",
    "plt.ylim([0, ymax])\n",
    "plt.xlim([0, item[1][idx].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1895, 48])\n"
     ]
    }
   ],
   "source": [
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "print(loss_prob.shape)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]], item_2[idx].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1387])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faf5b8ecb00>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "plt.plot(np.arange(selected_frames[0] - 1, selected_frames[-1] + 1), loss_arr[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3987, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([75, 345, 1305, 1415, 1440, 1519],\n",
       " [73, 282, 455, 1312, 1434, 1458],\n",
       " tensor(1520, device='cuda:0', dtype=torch.int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid], loaded_vidid_selected_frames[cur_vidid + \".txt\"], item_1[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_features_shortened = cur_vid_feat[:item[1][idx]]\n",
    "cur_features_shortened[:, item[2][idx][:item[1][idx]]].shape\n",
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47, 47, 47, 47, 47, 47, 47,  4,  4,  4,  4,  4,  4,  4,  4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[2][idx][video_id_boundary_frames[cur_vidid][1]-6:video_id_boundary_frames[cur_vidid][1]+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid][0]-6,video_id_boundary_frames[cur_vidid][0]+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0794, 13.3350],\n",
       "        [ 1.0831, 13.5102],\n",
       "        [ 1.1767, 13.7662],\n",
       "        [ 1.3750, 14.0177],\n",
       "        [ 1.7298, 14.1727],\n",
       "        [ 2.1706, 14.0367],\n",
       "        [ 2.7338, 13.4563],\n",
       "        [ 4.5600, 12.1745],\n",
       "        [ 7.8450, 10.3246],\n",
       "        [11.0151,  8.3563],\n",
       "        [13.4775,  6.6546],\n",
       "        [14.1836,  5.2898],\n",
       "        [11.2142,  4.2791],\n",
       "        [ 5.9829,  3.5694],\n",
       "        [ 2.3440,  2.9389],\n",
       "        [ 0.7406,  2.3515]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_vid_feat[video_id_boundary_frames[cur_vidid][1]-7:video_id_boundary_frames[cur_vidid][1]+9][:,[47,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frames_and_get_classification_value(model_output, count_list, video_ids_list, labels_all, p_criterion):\n",
    "    new_selected_frames = {}\n",
    "#     new_selected_frames_probs_values = {}\n",
    "#     new_selected_frames_labels = {}\n",
    "    \n",
    "    labels_arr = []\n",
    "    probs_arr = []\n",
    "    \n",
    "    for i, video_id in enumerate(video_ids_list):\n",
    "        current_boundary_frames = boundaries_dict[video_id]\n",
    "        current_video_logits = model_output[i].T\n",
    "        current_video_count = count_list[i]\n",
    "        current_selected_frames = loaded_vidid_selected_frames[video_id]\n",
    "        labels = labels_all[i]\n",
    "        cur_seg_start = 0\n",
    "        for seg_num, ele in enumerate(current_boundary_frames):\n",
    "            cur_seg_end = ele + 1\n",
    "            total_seg_len = cur_seg_end - cur_seg_start\n",
    "            per_frames_far_from_boundary = int(0.3 * total_seg_len)\n",
    "            new_frames_start = cur_seg_start + per_frames_far_from_boundary\n",
    "            new_frames_end = cur_seg_end - per_frames_far_from_boundary\n",
    "            \n",
    "            frames_added = list(range(new_frames_start, new_frames_end))\n",
    "            frames_added.append(current_selected_frames[seg_num])\n",
    "            frames_added = list(set(frames_added))\n",
    "            frames_added.sort()\n",
    "            new_selected_frames[video_id] = frames_added\n",
    "\n",
    "            \n",
    "            labels_seg = torch.stack([labels[current_selected_frames[seg_num]]] * len(frames_added))\n",
    "            frames_added = torch.tensor(np.array(frames_added), dtype=torch.long, device=current_video_logits.device)\n",
    "            prob_seg = current_video_logits[frames_added, :]\n",
    "            \n",
    "            labels_arr.append(labels_seg)\n",
    "            probs_arr.append(prob_seg)\n",
    "            \n",
    "            cur_seg_start = cur_seg_end\n",
    "            \n",
    "    labels_arr = torch.cat(labels_arr)\n",
    "    probs_arr = torch.cat(probs_arr)\n",
    "    loss = p_criterion(probs_arr, labels_arr)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mask_for_this_class(video_len, weakly_labels_video, old_index_label_pair_list, \n",
    "                             cur_ele_searched, cur_index_searched):\n",
    "    searched_label_index = np.where(cur_ele_searched == np.array(weakly_labels_video))[0]\n",
    "    if len(searched_label_index) <= 1:\n",
    "        mask = torch.ones(video_len)\n",
    "        return mask\n",
    "    else:\n",
    "        start = 0\n",
    "        for i, index in enumerate(searched_label_index[:-1]):\n",
    "            cur_index_frame_selected = old_index_label_pair_list[index][0]\n",
    "            next_index = searched_label_index[i + 1]\n",
    "            next_index_frame_selected = old_index_label_pair_list[next_index][0]\n",
    "            \n",
    "            mid_select = (cur_index_frame_selected + next_index_frame_selected) // 2\n",
    "            \n",
    "            if index == cur_index_searched:\n",
    "                mask = torch.zeros(video_len)\n",
    "                mask[start: mid_select + 1] = 1\n",
    "                return mask\n",
    "            \n",
    "            start = mid_select\n",
    "        if searched_label_index[-1] == cur_index_searched:\n",
    "            mask = torch.zeros(video_len)\n",
    "            mask[start: video_len] = 1\n",
    "            return mask\n",
    "        else:\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "            return \"Error 1\"\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [2, 2, 2, 2, 3, 3, 4, 4, 3, 3, 2, 2, 2, 2]\n",
    "find_mask_for_this_class(12, [2, 3, 4, 3,  2], [3, 5, 7, 8, 10], 4, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
