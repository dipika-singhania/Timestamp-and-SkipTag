{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='5'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 3, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split3/', 'project_name': 'breakfast-split-3', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split3.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split3.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split3_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=3,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split3/\",\n",
    "    project_name=\"breakfast-split-3\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1279\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 433\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = Breakfast(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = iter(trainloader).next()\n",
    "# print(item[0]) # -- data feature\n",
    "# print(item[1]) # -- valid count\n",
    "# item[2] # -- Actual labels\n",
    "# print(item[5]) # video names\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vidid_selected_frames = np.load(\"/home/dipika16/ar/TimestampActionSeg/data/breakfast_annotation_all.npy\", allow_pickle=True).item()\n",
    "# loaded_vidid_selected_frames\n",
    "video_id_boundary_frames = pickle.load(open(\"dump_dir/chunk_1_video_id_boundary_frames_dict.pkl\", \"rb\"))\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mean_var_actions = pickle.load(open(\"dump_dir/mean_var_actions.pkl\", \"rb\"))\n",
    "def get_possion_prob(cur_len, cur_class):\n",
    "    mean_class, std_class = loaded_mean_var_actions[cur_class]\n",
    "    mean_class = mean_class * 10\n",
    "    prob = cur_len * torch.log(torch.tensor(mean_class, device=device) + 1e-5)\n",
    "    prob = prob - mean_class\n",
    "    factorials = torch.cumsum(torch.log(torch.arange(1, torch.max(cur_len)+1, 1).type(torch.float).to(device)), \n",
    "                              dim=0)[min(cur_len)-1:]\n",
    "    prob = prob - factorials\n",
    "    return prob\n",
    "\n",
    "# get_possion_prob(torch.arange(10, 21), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_video_each_segment_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, labels):\n",
    "    prob_each_segment = []\n",
    "    \n",
    "    log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "    cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "    cur_boundary = 0\n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "\n",
    "        next_ele = selected_frames[i + 1]\n",
    "        label_cur_ele = labels[cur_ele]\n",
    "        label_next_ele = labels[next_ele]\n",
    "\n",
    "        indices = torch.arange(cur_ele, next_ele).to(cumsum_feat.device)\n",
    "        strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "        end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "        left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "        right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "\n",
    "        cur_boundary_len = indices - cur_boundary\n",
    "        len_prob = get_possion_prob(cur_boundary_len, label_cur_ele.item())\n",
    "\n",
    "        prob = torch.softmax((left_sum + right_sum + len_prob), dim=0)\n",
    "#         prob = torch.softmax((left_sum + right_sum), dim=0)\n",
    "\n",
    "        cur_boundary = round(np.sum(np.arange(cur_ele, next_ele, 1) * prob.detach().cpu().numpy()).item())\n",
    "        prob_each_segment.append(prob)\n",
    "    \n",
    "    return prob_each_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_element_probb(data_feat, data_count, video_ids, labels_all): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        labels = labels_all[iter_num]\n",
    "        \n",
    "        selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "        prob_video = prob_vals_per_segment(selected_frames, cur_vid_feat, labels)\n",
    "        prob_video_each_segment_dict[cur_vidid] = prob_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_loss(data_feat, data_count, video_ids, labels_all): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    loss_arr = []\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        labels = labels_all[iter_num]\n",
    "        \n",
    "        selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "        prob_each_video = prob_video_each_segment_dict[cur_vidid]\n",
    "        \n",
    "        log_probs = torch.log(cur_vid_feat + 1e-8)\n",
    "        cumsum_feat = torch.cumsum(log_probs, dim=0)\n",
    "        \n",
    "        \n",
    "        current_vid_prob_arr = []\n",
    "        # Start segment log probability\n",
    "        start_ele_idx = selected_frames[0]\n",
    "        if start_ele_idx > 0:\n",
    "            start_ele_label_idx = labels[selected_frames[0]]\n",
    "            first_segment_prob = (cumsum_feat[start_ele_idx - 1, :])[start_ele_label_idx]\n",
    "            current_vid_prob_arr.append(first_segment_prob.unsqueeze(0))\n",
    "        \n",
    "        for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "            next_ele = selected_frames[i + 1]\n",
    "            label_cur_ele = labels[cur_ele]\n",
    "            label_next_ele = labels[next_ele]\n",
    "\n",
    "            indices = torch.arange(cur_ele, next_ele)\n",
    "            strt_index = cumsum_feat[cur_ele - 1, :][None, :] if cur_ele > 0 else 0\n",
    "            end_index = cumsum_feat[next_ele - 1, :][None, :]\n",
    "            left_sum = (cumsum_feat[indices, :] - strt_index)[:,label_cur_ele]\n",
    "            right_sum = (end_index - cumsum_feat[indices, :])[:,label_next_ele]\n",
    "            current_vid_prob_arr.append((left_sum + right_sum)  * (prob_each_video[i]))\n",
    "        \n",
    "        # End segment log probability\n",
    "        end_index = cur_vid_count.item() - 1\n",
    "        last_ele_label_idx = labels[selected_frames[-1]]\n",
    "        last_segment_sum_prob = (cumsum_feat[end_index, :] - cumsum_feat[selected_frames[-1] - 1, :])[last_ele_label_idx]\n",
    "        current_vid_prob_arr.append(last_segment_sum_prob.unsqueeze(0))\n",
    "            \n",
    "        loss_arr.append(torch.cat(current_vid_prob_arr))\n",
    "    return -torch.mean(torch.cat(loss_arr)), loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_file_list = set(open(config.train_split_file).read().split(\"\\n\")[0:-1])\n",
    "\n",
    "def get_estimated_boundaries():\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames, video_id_boundary_frames\n",
    "    estimated_boundary_dict = {}\n",
    "    for ele in video_id_boundary_frames.keys():\n",
    "        if (ele + \".txt\") not in train_split_file_list:\n",
    "            continue\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        selected_ele_list = loaded_vidid_selected_frames[ele + \".txt\"]\n",
    "        boundary_list = []\n",
    "        for i, segment in enumerate(estimated_boundary_probs):\n",
    "            estimated_boundary = np.sum(np.arange(selected_ele_list[i], selected_ele_list[i + 1], 1) \\\n",
    "                                        * segment.detach().cpu().numpy())\n",
    "            estimated_boundary = round(estimated_boundary.item())\n",
    "            \n",
    "            if (estimated_boundary < selected_ele_list[i]) or (estimated_boundary > selected_ele_list[i + 1]):\n",
    "                print(\"Estimated value wrong\")\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "            boundary_list.append(estimated_boundary)\n",
    "\n",
    "        estimated_boundary_dict[ele] = boundary_list\n",
    "    return estimated_boundary_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_boundary_err():\n",
    "    global prob_video_each_segment_dict, loaded_vidid_selected_frames\n",
    "    err_list = []\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    estimated_boundar_dict = get_estimated_boundaries()\n",
    "    for ele in video_id_boundary_frames.keys():\n",
    "        if (ele + \".txt\") not in train_split_file_list:\n",
    "            continue\n",
    "        estimated_boundary_probs = prob_video_each_segment_dict[ele]\n",
    "        estimated_boundary_list = estimated_boundar_dict[ele]\n",
    "        \n",
    "        estimated = np.array(estimated_boundary_list) #.detach().cpu().numpy()\n",
    "        actual = np.array(video_id_boundary_frames[ele][:-1])\n",
    "        if len(actual) != len(estimated):\n",
    "            print(ele)\n",
    "            continue\n",
    "        \n",
    "        mse_err = (actual - estimated)**2\n",
    "        err_list.append(mse_err)\n",
    "        \n",
    "        estimated_labels = []\n",
    "        actual_labels = []\n",
    "        start_v1 = 0\n",
    "        start_v2 = 0\n",
    "        for i, v1 in enumerate(estimated):\n",
    "            estimated_labels.extend([i] * (v1 - start_v1))\n",
    "            start_v1 = v1\n",
    "            v2 = actual[i]\n",
    "            actual_labels.extend([i] * (v2 - start_v2))\n",
    "            start_v2 = v2\n",
    "            \n",
    "        last_ele = video_id_boundary_frames[ele][-1]\n",
    "        estimated_labels.extend([i+1] * (last_ele - start_v1))\n",
    "        actual_labels.extend([i+1] * (last_ele - start_v2))\n",
    "        \n",
    "        correct += np.sum(np.array(actual_labels) == np.array(estimated_labels))\n",
    "        total += len(actual_labels)\n",
    "        \n",
    "    print(f\"Train Boundary avergage error = {np.sqrt(np.mean(np.concatenate(err_list))):.3f}\")\n",
    "    print(f\"Train From boundary avergage accuracy = {correct * 100.0 / total:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Boundary avergage error = 105.584\n",
      "Train From boundary avergage accuracy = 88.760\n"
     ]
    }
   ],
   "source": [
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_random(labels_all, video_ids):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((labels_all.shape[0], labels_all.shape[1]), dtype=torch.long, device=labels_all.device) * (-100)\n",
    "    for iter_num, labels in enumerate(labels_all):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        frame_idx_tensor = torch.from_numpy(np.array(loaded_vidid_selected_frames[cur_vidid + \".txt\"]))\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = labels[frame_idx_tensor]\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split3/'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Training:: Epoch 15, Iteration 0, Current loss 1.739311933517456 Accuracy 77.92345228996413\n",
      "Training:: Epoch 15, Iteration 10, Current loss 1.9804925918579102 Accuracy 70.96092925026399\n",
      "Training:: Epoch 15, Iteration 20, Current loss 2.067516803741455 Accuracy 63.32023575638507\n",
      "Training:: Epoch 15, Iteration 30, Current loss 1.3061540126800537 Accuracy 63.40113205199975\n",
      "Training:: Epoch 15, Iteration 40, Current loss 1.5165441036224365 Accuracy 77.19906951070458\n",
      "Training:: Epoch 15, Iteration 50, Current loss 1.469496488571167 Accuracy 67.29394053443734\n",
      "Training:: Epoch 15, Iteration 60, Current loss 1.8162904977798462 Accuracy 61.60199867434865\n",
      "Training:: Epoch 15, Iteration 70, Current loss 1.3940218687057495 Accuracy 79.98275968228558\n",
      "Training:: Epoch 15, Iteration 80, Current loss 1.8286348581314087 Accuracy 76.96798321627291\n",
      "Training:: Epoch 15, Iteration 90, Current loss 2.0181009769439697 Accuracy 60.75115965883585\n",
      "Training:: Epoch 15, Iteration 100, Current loss 1.5947242975234985 Accuracy 84.87227560346848\n",
      "Training:: Epoch 15, Iteration 110, Current loss 2.4608943462371826 Accuracy 80.10570402871959\n",
      "Training:: Epoch 15, Iteration 120, Current loss 1.973608374595642 Accuracy 63.62932187874093\n",
      "Training:: Epoch 15, Iteration 130, Current loss 1.6553181409835815 Accuracy 79.36174278616473\n",
      "Training:: Epoch 15, Iteration 140, Current loss 1.5579625368118286 Accuracy 72.75790565059616\n",
      "Training:: Epoch 15, Iteration 150, Current loss 4.509976387023926 Accuracy 67.05325156354363\n",
      "Calculating Expectation\n",
      "Epoch 15 iter 0\n",
      "Epoch 15 iter 10\n",
      "Epoch 15 iter 20\n",
      "Epoch 15 iter 30\n",
      "Epoch 15 iter 40\n",
      "Epoch 15 iter 50\n",
      "Epoch 15 iter 60\n",
      "Epoch 15 iter 70\n",
      "Epoch 15 iter 80\n",
      "Epoch 15 iter 90\n",
      "Epoch 15 iter 100\n",
      "Epoch 15 iter 110\n",
      "Epoch 15 iter 120\n",
      "Epoch 15 iter 130\n",
      "Epoch 15 iter 140\n",
      "Epoch 15 iter 150\n",
      "Train Boundary avergage error = 96.062\n",
      "Train From boundary avergage accuracy = 88.353\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 15, Probability Accuracy 59.128911110987104\n",
      "Starting Training\n",
      "Training:: Epoch 16, Iteration 0, Current loss 2.99570655514254 Accuracy 77.2298767222625\n",
      "Training:: Epoch 16, Iteration 10, Current loss 4.048378835886024 Accuracy 62.023092369477915\n",
      "Training:: Epoch 16, Iteration 20, Current loss 4.722547349513497 Accuracy 64.09963985594237\n",
      "Training:: Epoch 16, Iteration 30, Current loss 2.2879430121823514 Accuracy 82.16704288939052\n",
      "Training:: Epoch 16, Iteration 40, Current loss 3.037012672418292 Accuracy 77.14865363334563\n",
      "Training:: Epoch 16, Iteration 50, Current loss 5.797554104957432 Accuracy 51.49956604198142\n",
      "Training:: Epoch 16, Iteration 60, Current loss 3.4680404883540263 Accuracy 76.73065189843713\n",
      "Training:: Epoch 16, Iteration 70, Current loss 3.4017399477308503 Accuracy 72.54756150461672\n",
      "Training:: Epoch 16, Iteration 80, Current loss 3.85563545692887 Accuracy 56.9338862013361\n",
      "Training:: Epoch 16, Iteration 90, Current loss 3.5714553873943498 Accuracy 70.78545490722777\n",
      "Training:: Epoch 16, Iteration 100, Current loss 8.353954601726333 Accuracy 54.442923267488105\n",
      "Training:: Epoch 16, Iteration 110, Current loss 2.8460484300028344 Accuracy 72.75135389686838\n",
      "Training:: Epoch 16, Iteration 120, Current loss 3.3081625353163835 Accuracy 71.76848524447348\n",
      "Training:: Epoch 16, Iteration 130, Current loss 2.2209075640009592 Accuracy 70.39700145337719\n",
      "Training:: Epoch 16, Iteration 140, Current loss 2.6507227322160203 Accuracy 77.29394387001477\n",
      "Training:: Epoch 16, Iteration 150, Current loss 3.5786140546400196 Accuracy 74.35495538943815\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 16, Probability Accuracy 65.89126176751246\n",
      "Starting Training\n",
      "Training:: Epoch 17, Iteration 0, Current loss 4.1356069461232865 Accuracy 70.66232998225902\n",
      "Training:: Epoch 17, Iteration 10, Current loss 3.3981840853576415 Accuracy 68.72101033295063\n",
      "Training:: Epoch 17, Iteration 20, Current loss 4.067943712226412 Accuracy 58.74386789193671\n",
      "Training:: Epoch 17, Iteration 30, Current loss 2.9645612360867224 Accuracy 72.50078345346286\n",
      "Training:: Epoch 17, Iteration 40, Current loss 2.2750767163311276 Accuracy 78.7488986784141\n",
      "Training:: Epoch 17, Iteration 50, Current loss 2.3885719748923906 Accuracy 79.17632066728453\n",
      "Training:: Epoch 17, Iteration 60, Current loss 2.5308647294600686 Accuracy 78.51856618830041\n",
      "Training:: Epoch 17, Iteration 70, Current loss 2.2678824488631912 Accuracy 83.2768528068366\n",
      "Training:: Epoch 17, Iteration 80, Current loss 2.534428678641362 Accuracy 76.44881556683588\n",
      "Training:: Epoch 17, Iteration 90, Current loss 3.060993251136576 Accuracy 70.87919647771051\n",
      "Training:: Epoch 17, Iteration 100, Current loss 2.522522501575127 Accuracy 78.12186041014124\n",
      "Training:: Epoch 17, Iteration 110, Current loss 2.3936252098850934 Accuracy 71.7522912637686\n",
      "Training:: Epoch 17, Iteration 120, Current loss 3.100252823693796 Accuracy 79.21067980040179\n",
      "Training:: Epoch 17, Iteration 130, Current loss 1.9102997776051704 Accuracy 83.58599629185298\n",
      "Training:: Epoch 17, Iteration 140, Current loss 2.791843122610791 Accuracy 76.41702285820479\n",
      "Training:: Epoch 17, Iteration 150, Current loss 2.976181292578414 Accuracy 72.8788549505681\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 17, Probability Accuracy 66.58266415924018\n",
      "Starting Training\n",
      "Training:: Epoch 18, Iteration 0, Current loss 2.5248813623266337 Accuracy 80.89617486338798\n",
      "Training:: Epoch 18, Iteration 10, Current loss 2.011329198011282 Accuracy 84.22389165167706\n",
      "Training:: Epoch 18, Iteration 20, Current loss 1.0985618638400747 Accuracy 89.14117272147865\n",
      "Training:: Epoch 18, Iteration 30, Current loss 1.8975521304846872 Accuracy 80.23765228350237\n",
      "Training:: Epoch 18, Iteration 40, Current loss 1.6090082518829065 Accuracy 89.05683192261185\n",
      "Training:: Epoch 18, Iteration 50, Current loss 2.074411688896683 Accuracy 78.62581796549672\n",
      "Training:: Epoch 18, Iteration 60, Current loss 0.9122286617090575 Accuracy 90.56244041944709\n",
      "Training:: Epoch 18, Iteration 70, Current loss 1.7228580112636864 Accuracy 82.63032730458727\n",
      "Training:: Epoch 18, Iteration 80, Current loss 2.903983890337862 Accuracy 77.64754741359421\n",
      "Training:: Epoch 18, Iteration 90, Current loss 2.6249939858631026 Accuracy 76.60219729915312\n",
      "Training:: Epoch 18, Iteration 100, Current loss 4.225665416884386 Accuracy 70.1859013185482\n",
      "Training:: Epoch 18, Iteration 110, Current loss 1.4660564241152434 Accuracy 86.9508151423045\n",
      "Training:: Epoch 18, Iteration 120, Current loss 1.7846193985782328 Accuracy 87.06148424762004\n",
      "Training:: Epoch 18, Iteration 130, Current loss 1.88125179726751 Accuracy 82.37945020279405\n",
      "Training:: Epoch 18, Iteration 140, Current loss 3.467421483185558 Accuracy 61.47412176205201\n",
      "Training:: Epoch 18, Iteration 150, Current loss 3.1187573326128857 Accuracy 68.87253613666229\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 18, Probability Accuracy 67.29348608545712\n",
      "Starting Training\n",
      "Training:: Epoch 19, Iteration 0, Current loss 1.9656951191931364 Accuracy 86.23827125390959\n",
      "Training:: Epoch 19, Iteration 10, Current loss 1.8123610676665451 Accuracy 87.60876748540588\n",
      "Training:: Epoch 19, Iteration 20, Current loss 2.4296487838268854 Accuracy 83.76001393242773\n",
      "Training:: Epoch 19, Iteration 30, Current loss 1.4526895083259552 Accuracy 87.23769696064521\n",
      "Training:: Epoch 19, Iteration 40, Current loss 1.6379111178326093 Accuracy 83.58968074024143\n",
      "Training:: Epoch 19, Iteration 50, Current loss 2.0789915134253554 Accuracy 85.52299936988028\n",
      "Training:: Epoch 19, Iteration 60, Current loss 2.1544669870402706 Accuracy 82.64595607927156\n",
      "Training:: Epoch 19, Iteration 70, Current loss 1.912129069047817 Accuracy 81.99196631660456\n",
      "Training:: Epoch 19, Iteration 80, Current loss 2.0574077395836614 Accuracy 75.46835443037975\n",
      "Training:: Epoch 19, Iteration 90, Current loss 1.459961688378418 Accuracy 87.9237529962333\n",
      "Training:: Epoch 19, Iteration 100, Current loss 2.0960910440488982 Accuracy 85.5427974947808\n",
      "Training:: Epoch 19, Iteration 110, Current loss 2.2894827367833845 Accuracy 76.94924123495552\n",
      "Training:: Epoch 19, Iteration 120, Current loss 1.230343679626972 Accuracy 85.91991625228998\n",
      "Training:: Epoch 19, Iteration 130, Current loss 1.4425750707991674 Accuracy 80.70883521473166\n",
      "Training:: Epoch 19, Iteration 140, Current loss 2.286947358693409 Accuracy 75.54126473740622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 19, Iteration 150, Current loss 1.9172805700389697 Accuracy 86.24000830478563\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 19, Probability Accuracy 67.6677027471945\n",
      "Starting Training\n",
      "Training:: Epoch 20, Iteration 0, Current loss 1.6582796789482426 Accuracy 81.71366000547495\n",
      "Training:: Epoch 20, Iteration 10, Current loss 1.575872887458479 Accuracy 83.90268184929376\n",
      "Training:: Epoch 20, Iteration 20, Current loss 4.482389815483668 Accuracy 61.92864307207336\n",
      "Training:: Epoch 20, Iteration 30, Current loss 2.093778679542371 Accuracy 80.27357192016518\n",
      "Training:: Epoch 20, Iteration 40, Current loss 1.944051364883151 Accuracy 80.58397803843275\n",
      "Training:: Epoch 20, Iteration 50, Current loss 1.4229516875685326 Accuracy 89.6528544677582\n",
      "Training:: Epoch 20, Iteration 60, Current loss 2.2748619353117703 Accuracy 81.55169667038395\n",
      "Training:: Epoch 20, Iteration 70, Current loss 1.1038623798885925 Accuracy 89.04432231817857\n",
      "Training:: Epoch 20, Iteration 80, Current loss 1.6942141781980853 Accuracy 81.09183407252804\n",
      "Training:: Epoch 20, Iteration 90, Current loss 2.1396703659138954 Accuracy 75.7686932215234\n",
      "Training:: Epoch 20, Iteration 100, Current loss 1.5702435865879623 Accuracy 86.5356004250797\n",
      "Training:: Epoch 20, Iteration 110, Current loss 1.3853791682005536 Accuracy 88.05658176161774\n",
      "Training:: Epoch 20, Iteration 120, Current loss 1.8521129721483889 Accuracy 79.37981149723002\n",
      "Training:: Epoch 20, Iteration 130, Current loss 1.7197245983716036 Accuracy 85.21090534979425\n",
      "Training:: Epoch 20, Iteration 140, Current loss 2.9518850172757154 Accuracy 79.99060591827148\n",
      "Training:: Epoch 20, Iteration 150, Current loss 2.194170615919658 Accuracy 81.73880268861109\n",
      "Calculating Expectation\n",
      "Epoch 20 iter 0\n",
      "Epoch 20 iter 10\n",
      "Epoch 20 iter 20\n",
      "Epoch 20 iter 30\n",
      "Epoch 20 iter 40\n",
      "Epoch 20 iter 50\n",
      "Epoch 20 iter 60\n",
      "Epoch 20 iter 70\n",
      "Epoch 20 iter 80\n",
      "Epoch 20 iter 90\n",
      "Epoch 20 iter 100\n",
      "Epoch 20 iter 110\n",
      "Validation:: Epoch 20, Probability Accuracy 67.75776920887718\n",
      "Starting Training\n",
      "Training:: Epoch 21, Iteration 0, Current loss 1.3974809279873188 Accuracy 80.79333428286569\n",
      "Training:: Epoch 21, Iteration 10, Current loss 1.8165996803327815 Accuracy 87.53763440860214\n",
      "Training:: Epoch 21, Iteration 20, Current loss 2.016939043581578 Accuracy 84.22359147125316\n",
      "Training:: Epoch 21, Iteration 30, Current loss 5.291369221571368 Accuracy 57.35230076934243\n",
      "Training:: Epoch 21, Iteration 40, Current loss 5.301818579698486 Accuracy 55.271246350084525\n",
      "Training:: Epoch 21, Iteration 50, Current loss 2.682947552557082 Accuracy 74.07592963705189\n",
      "Training:: Epoch 21, Iteration 60, Current loss 2.0516274896335345 Accuracy 80.8224868457491\n",
      "Training:: Epoch 21, Iteration 70, Current loss 2.049270620351545 Accuracy 81.0767268577566\n",
      "Training:: Epoch 21, Iteration 80, Current loss 2.3719866928913103 Accuracy 84.00231730530497\n",
      "Training:: Epoch 21, Iteration 90, Current loss 1.9378559000771427 Accuracy 82.87849732015538\n",
      "Training:: Epoch 21, Iteration 100, Current loss 2.3119842998579117 Accuracy 77.18954740567814\n",
      "Training:: Epoch 21, Iteration 110, Current loss 2.2039498384196365 Accuracy 74.52730213620391\n",
      "Training:: Epoch 21, Iteration 120, Current loss 1.7218366580890478 Accuracy 86.74322506246396\n",
      "Training:: Epoch 21, Iteration 130, Current loss 1.5031967346636868 Accuracy 84.34528163862473\n",
      "Training:: Epoch 21, Iteration 140, Current loss 2.601439866738006 Accuracy 77.6416539050536\n",
      "Training:: Epoch 21, Iteration 150, Current loss 1.2740047339822287 Accuracy 85.12219083875722\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 21, Probability Accuracy 69.72293681396867\n",
      "Starting Training\n",
      "Training:: Epoch 22, Iteration 0, Current loss 1.47368988246257 Accuracy 83.27292621213158\n",
      "Training:: Epoch 22, Iteration 10, Current loss 1.1837673544270404 Accuracy 84.20183381741558\n",
      "Training:: Epoch 22, Iteration 20, Current loss 1.796298885877158 Accuracy 82.84835465286594\n",
      "Training:: Epoch 22, Iteration 30, Current loss 2.1100011661097544 Accuracy 79.71235840651649\n",
      "Training:: Epoch 22, Iteration 40, Current loss 2.84997670121418 Accuracy 84.17085427135679\n",
      "Training:: Epoch 22, Iteration 50, Current loss 1.376167077475539 Accuracy 84.8563794255177\n",
      "Training:: Epoch 22, Iteration 60, Current loss 2.0388727950939636 Accuracy 85.1664426346169\n",
      "Training:: Epoch 22, Iteration 70, Current loss 1.6025946131436555 Accuracy 82.55969153195907\n",
      "Training:: Epoch 22, Iteration 80, Current loss 1.5221829420471695 Accuracy 83.79629629629629\n",
      "Training:: Epoch 22, Iteration 90, Current loss 1.275903989186797 Accuracy 89.36987805356233\n",
      "Training:: Epoch 22, Iteration 100, Current loss 1.4380539928954963 Accuracy 86.53578874218208\n",
      "Training:: Epoch 22, Iteration 110, Current loss 2.199964967116447 Accuracy 77.10798816568047\n",
      "Training:: Epoch 22, Iteration 120, Current loss 2.6386681970225125 Accuracy 75.26588845654993\n",
      "Training:: Epoch 22, Iteration 130, Current loss 1.5676458265566495 Accuracy 82.50375611883875\n",
      "Training:: Epoch 22, Iteration 140, Current loss 1.3280916467908608 Accuracy 87.91044776119404\n",
      "Training:: Epoch 22, Iteration 150, Current loss 2.105692449843714 Accuracy 84.80023734177215\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 22, Probability Accuracy 66.8601179680917\n",
      "Starting Training\n",
      "Training:: Epoch 23, Iteration 0, Current loss 1.071731688421738 Accuracy 86.26877916218018\n",
      "Training:: Epoch 23, Iteration 10, Current loss 1.1679555632832817 Accuracy 86.57297663393159\n",
      "Training:: Epoch 23, Iteration 20, Current loss 1.1564263665250265 Accuracy 87.36154626892016\n",
      "Training:: Epoch 23, Iteration 30, Current loss 1.2119581290713621 Accuracy 88.83146519900664\n",
      "Training:: Epoch 23, Iteration 40, Current loss 1.406951264568644 Accuracy 87.15618465497829\n",
      "Training:: Epoch 23, Iteration 50, Current loss 1.834090959284301 Accuracy 86.66081614743308\n",
      "Training:: Epoch 23, Iteration 60, Current loss 2.0700778775095143 Accuracy 87.64548852108916\n",
      "Training:: Epoch 23, Iteration 70, Current loss 1.9516873344353396 Accuracy 76.19799020014949\n",
      "Training:: Epoch 23, Iteration 80, Current loss 1.9433157398643783 Accuracy 77.36938829089\n",
      "Training:: Epoch 23, Iteration 90, Current loss 2.981734009069682 Accuracy 71.54564825438453\n",
      "Training:: Epoch 23, Iteration 100, Current loss 4.092644742825942 Accuracy 68.35859798340078\n",
      "Training:: Epoch 23, Iteration 110, Current loss 1.2933095999632773 Accuracy 84.4458510760732\n",
      "Training:: Epoch 23, Iteration 120, Current loss 1.460809268010196 Accuracy 85.41676733510509\n",
      "Training:: Epoch 23, Iteration 130, Current loss 2.9314882541602443 Accuracy 73.53388429752066\n",
      "Training:: Epoch 23, Iteration 140, Current loss 1.7475426862290557 Accuracy 86.04393166185933\n",
      "Training:: Epoch 23, Iteration 150, Current loss 2.7770339163363347 Accuracy 75.10438897652408\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 23, Probability Accuracy 63.63390829292247\n",
      "Starting Training\n",
      "Training:: Epoch 24, Iteration 0, Current loss 1.0855647567686326 Accuracy 86.85927306616962\n",
      "Training:: Epoch 24, Iteration 10, Current loss 1.546766683694977 Accuracy 87.63956904995104\n",
      "Training:: Epoch 24, Iteration 20, Current loss 0.9469250117579738 Accuracy 85.48236756252913\n",
      "Training:: Epoch 24, Iteration 30, Current loss 1.6868599229312038 Accuracy 84.57001522070016\n",
      "Training:: Epoch 24, Iteration 40, Current loss 1.9249305837463409 Accuracy 81.45348837209302\n",
      "Training:: Epoch 24, Iteration 50, Current loss 1.3142296896502905 Accuracy 86.08320186000167\n",
      "Training:: Epoch 24, Iteration 60, Current loss 0.9962366265725335 Accuracy 90.43139798897178\n",
      "Training:: Epoch 24, Iteration 70, Current loss 2.8488747199493965 Accuracy 75.37813419957365\n",
      "Training:: Epoch 24, Iteration 80, Current loss 1.2317578288797468 Accuracy 85.75848936845446\n",
      "Training:: Epoch 24, Iteration 90, Current loss 1.7488142383469416 Accuracy 83.02182907690113\n",
      "Training:: Epoch 24, Iteration 100, Current loss 1.1575317075200378 Accuracy 87.57643135075041\n",
      "Training:: Epoch 24, Iteration 110, Current loss 1.1633872973799884 Accuracy 88.59644657129766\n",
      "Training:: Epoch 24, Iteration 120, Current loss 0.8247974241461907 Accuracy 83.36867954012725\n",
      "Training:: Epoch 24, Iteration 130, Current loss 1.6487756855607998 Accuracy 82.89379900213828\n",
      "Training:: Epoch 24, Iteration 140, Current loss 1.5716792453686779 Accuracy 84.88927831766767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 24, Iteration 150, Current loss 2.073645751890206 Accuracy 84.14868834194267\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 24, Probability Accuracy 68.9105529545036\n",
      "Starting Training\n",
      "Training:: Epoch 25, Iteration 0, Current loss 1.1966530653073228 Accuracy 85.35743148923665\n",
      "Training:: Epoch 25, Iteration 10, Current loss 1.4849858305949606 Accuracy 80.64786665268896\n",
      "Training:: Epoch 25, Iteration 20, Current loss 1.4104912013223676 Accuracy 84.14140642895319\n",
      "Training:: Epoch 25, Iteration 30, Current loss 1.0315230646762241 Accuracy 87.95499220497526\n",
      "Training:: Epoch 25, Iteration 40, Current loss 0.9374681979238408 Accuracy 87.88121561715538\n",
      "Training:: Epoch 25, Iteration 50, Current loss 1.1001319608365234 Accuracy 85.58354133575372\n",
      "Training:: Epoch 25, Iteration 60, Current loss 0.857439972648002 Accuracy 81.80738982044814\n",
      "Training:: Epoch 25, Iteration 70, Current loss 1.2159011606831849 Accuracy 88.47709868516111\n",
      "Training:: Epoch 25, Iteration 80, Current loss 1.059517684863718 Accuracy 87.54681647940075\n",
      "Training:: Epoch 25, Iteration 90, Current loss 3.2076043164540375 Accuracy 71.45183937096321\n",
      "Training:: Epoch 25, Iteration 100, Current loss 2.043744329813568 Accuracy 83.03063274188149\n",
      "Training:: Epoch 25, Iteration 110, Current loss 0.9070567591214573 Accuracy 90.71203119197921\n",
      "Training:: Epoch 25, Iteration 120, Current loss 0.9611628148777491 Accuracy 87.80565427252957\n",
      "Training:: Epoch 25, Iteration 130, Current loss 1.1122053086508377 Accuracy 86.75435268327642\n",
      "Training:: Epoch 25, Iteration 140, Current loss 0.888196843055919 Accuracy 89.21518278164247\n",
      "Training:: Epoch 25, Iteration 150, Current loss 1.1520184867144065 Accuracy 80.01211720643313\n",
      "Calculating Expectation\n",
      "Epoch 25 iter 0\n",
      "Epoch 25 iter 10\n",
      "Epoch 25 iter 20\n",
      "Epoch 25 iter 30\n",
      "Epoch 25 iter 40\n",
      "Epoch 25 iter 50\n",
      "Epoch 25 iter 60\n",
      "Epoch 25 iter 70\n",
      "Epoch 25 iter 80\n",
      "Epoch 25 iter 90\n",
      "Epoch 25 iter 100\n",
      "Epoch 25 iter 110\n",
      "Epoch 25 iter 120\n",
      "Epoch 25 iter 130\n",
      "Epoch 25 iter 140\n",
      "Epoch 25 iter 150\n",
      "Train Boundary avergage error = 97.325\n",
      "Train From boundary avergage accuracy = 87.864\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 25, Probability Accuracy 68.78198224340267\n",
      "Starting Training\n",
      "Training:: Epoch 26, Iteration 0, Current loss 0.9511583396417753 Accuracy 80.61713069693208\n",
      "Training:: Epoch 26, Iteration 10, Current loss 0.9136560338041737 Accuracy 83.83867441459064\n",
      "Training:: Epoch 26, Iteration 20, Current loss 0.6731457097259161 Accuracy 89.1985405133367\n",
      "Training:: Epoch 26, Iteration 30, Current loss 1.1585770960080959 Accuracy 82.70833333333333\n",
      "Training:: Epoch 26, Iteration 40, Current loss 2.115346977175774 Accuracy 82.0314832984941\n",
      "Training:: Epoch 26, Iteration 50, Current loss 1.149954097278744 Accuracy 90.36573965879879\n",
      "Training:: Epoch 26, Iteration 60, Current loss 1.0003318425122207 Accuracy 89.9677820664136\n",
      "Training:: Epoch 26, Iteration 70, Current loss 1.0223338726947193 Accuracy 89.06257226101836\n",
      "Training:: Epoch 26, Iteration 80, Current loss 0.5514716214343405 Accuracy 82.89381889214455\n",
      "Training:: Epoch 26, Iteration 90, Current loss 1.0051498752351498 Accuracy 80.01360775642117\n",
      "Training:: Epoch 26, Iteration 100, Current loss 1.3995942349599235 Accuracy 83.22444466780581\n",
      "Training:: Epoch 26, Iteration 110, Current loss 1.1946546538094474 Accuracy 83.09352517985612\n",
      "Training:: Epoch 26, Iteration 120, Current loss 1.0045636520935168 Accuracy 87.95502054350176\n",
      "Training:: Epoch 26, Iteration 130, Current loss 0.9395996666569263 Accuracy 87.94576190191745\n",
      "Training:: Epoch 26, Iteration 140, Current loss 1.2526204089949111 Accuracy 87.30934689088775\n",
      "Training:: Epoch 26, Iteration 150, Current loss 1.7151882585980869 Accuracy 86.59407794255308\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 26, Probability Accuracy 68.3008465354546\n",
      "Starting Training\n",
      "Training:: Epoch 27, Iteration 0, Current loss 1.1126788082012478 Accuracy 87.98112218143682\n",
      "Training:: Epoch 27, Iteration 10, Current loss 0.9976404931056109 Accuracy 84.8668407310705\n",
      "Training:: Epoch 27, Iteration 20, Current loss 1.0337427883356012 Accuracy 88.96435874963483\n",
      "Training:: Epoch 27, Iteration 30, Current loss 0.9279585597185918 Accuracy 84.69670095778645\n",
      "Training:: Epoch 27, Iteration 40, Current loss 0.7943776092126167 Accuracy 83.64968990791205\n",
      "Training:: Epoch 27, Iteration 50, Current loss 1.9268139062281842 Accuracy 82.85714285714286\n",
      "Training:: Epoch 27, Iteration 60, Current loss 1.2163159806617516 Accuracy 80.6198880757641\n",
      "Training:: Epoch 27, Iteration 70, Current loss 1.1571298510871497 Accuracy 89.41522378307742\n",
      "Training:: Epoch 27, Iteration 80, Current loss 0.8799458364352761 Accuracy 88.68087735557616\n",
      "Training:: Epoch 27, Iteration 90, Current loss 1.0477965278010744 Accuracy 86.31070718545868\n",
      "Training:: Epoch 27, Iteration 100, Current loss 1.7702404740246709 Accuracy 81.68726823238566\n",
      "Training:: Epoch 27, Iteration 110, Current loss 1.6250908164184703 Accuracy 85.89711099847948\n",
      "Training:: Epoch 27, Iteration 120, Current loss 1.3069195190973646 Accuracy 81.70844225741965\n",
      "Training:: Epoch 27, Iteration 130, Current loss 1.1394484342226556 Accuracy 89.728453364817\n",
      "Training:: Epoch 27, Iteration 140, Current loss 2.9770116380993352 Accuracy 81.13234455219623\n",
      "Training:: Epoch 27, Iteration 150, Current loss 1.3759309414790626 Accuracy 88.68048533872599\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 27, Probability Accuracy 64.85800860486269\n",
      "Starting Training\n",
      "Training:: Epoch 28, Iteration 0, Current loss 1.2532053557555431 Accuracy 90.52538042874598\n",
      "Training:: Epoch 28, Iteration 10, Current loss 2.0892309681450385 Accuracy 79.17262585812357\n",
      "Training:: Epoch 28, Iteration 20, Current loss 1.0735806343544887 Accuracy 89.72243502858153\n",
      "Training:: Epoch 28, Iteration 30, Current loss 1.919940494224107 Accuracy 77.63421474358974\n",
      "Training:: Epoch 28, Iteration 40, Current loss 0.661278414877714 Accuracy 92.33734939759036\n",
      "Training:: Epoch 28, Iteration 50, Current loss 1.6456066997965342 Accuracy 82.88102169217767\n",
      "Training:: Epoch 28, Iteration 60, Current loss 0.7986976181683856 Accuracy 85.84825954714431\n",
      "Training:: Epoch 28, Iteration 70, Current loss 1.3007635613508701 Accuracy 88.3616830796777\n",
      "Training:: Epoch 28, Iteration 80, Current loss 0.9620635611310598 Accuracy 89.50218340611353\n",
      "Training:: Epoch 28, Iteration 90, Current loss 0.8086550300733606 Accuracy 86.38831905393991\n",
      "Training:: Epoch 28, Iteration 100, Current loss 1.2995144848206739 Accuracy 80.9678952012489\n",
      "Training:: Epoch 28, Iteration 110, Current loss 0.7528859063391492 Accuracy 75.47070786590567\n",
      "Training:: Epoch 28, Iteration 120, Current loss 0.926773211518285 Accuracy 89.82415825756819\n",
      "Training:: Epoch 28, Iteration 130, Current loss 1.062178189243199 Accuracy 81.35231316725978\n",
      "Training:: Epoch 28, Iteration 140, Current loss 0.901014362297774 Accuracy 88.17407757805108\n",
      "Training:: Epoch 28, Iteration 150, Current loss 4.057558605112721 Accuracy 73.6816874400767\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 28, Probability Accuracy 64.9928292810866\n",
      "Starting Training\n",
      "Training:: Epoch 29, Iteration 0, Current loss 0.8572650814176185 Accuracy 87.06833210874358\n",
      "Training:: Epoch 29, Iteration 10, Current loss 2.3073369890604987 Accuracy 75.37532766701088\n",
      "Training:: Epoch 29, Iteration 20, Current loss 1.9939756373191981 Accuracy 74.87817295803332\n",
      "Training:: Epoch 29, Iteration 30, Current loss 3.712076857692892 Accuracy 74.12362857907412\n",
      "Training:: Epoch 29, Iteration 40, Current loss 1.981140368887063 Accuracy 81.8553369451573\n",
      "Training:: Epoch 29, Iteration 50, Current loss 1.2608597393073202 Accuracy 87.56739357849843\n",
      "Training:: Epoch 29, Iteration 60, Current loss 2.202599482469182 Accuracy 82.92125906066924\n",
      "Training:: Epoch 29, Iteration 70, Current loss 1.4743432620466816 Accuracy 89.31926243766671\n",
      "Training:: Epoch 29, Iteration 80, Current loss 1.5640824142099192 Accuracy 84.52723680496754\n",
      "Training:: Epoch 29, Iteration 90, Current loss 1.4565739969812528 Accuracy 81.7521877486078\n",
      "Training:: Epoch 29, Iteration 100, Current loss 0.9631254463670805 Accuracy 87.83501408194785\n",
      "Training:: Epoch 29, Iteration 110, Current loss 1.0383253856597927 Accuracy 88.48029163818637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 29, Iteration 120, Current loss 1.0894625555596031 Accuracy 85.41013211671894\n",
      "Training:: Epoch 29, Iteration 130, Current loss 0.9489696786533721 Accuracy 85.30281799782033\n",
      "Training:: Epoch 29, Iteration 140, Current loss 1.5056195625774311 Accuracy 83.8748984565394\n",
      "Training:: Epoch 29, Iteration 150, Current loss 1.1137738814331566 Accuracy 88.26563164610803\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 29, Probability Accuracy 67.65598406258894\n",
      "Starting Training\n",
      "Training:: Epoch 30, Iteration 0, Current loss 0.8532115660969799 Accuracy 85.93959731543625\n",
      "Training:: Epoch 30, Iteration 10, Current loss 1.1851605258269826 Accuracy 85.09999515761949\n",
      "Training:: Epoch 30, Iteration 20, Current loss 0.9900823794355056 Accuracy 86.25807826148711\n",
      "Training:: Epoch 30, Iteration 30, Current loss 0.8541820732816224 Accuracy 89.22718233559624\n",
      "Training:: Epoch 30, Iteration 40, Current loss 1.1378353673330885 Accuracy 86.84118825681679\n",
      "Training:: Epoch 30, Iteration 50, Current loss 1.5999724231546844 Accuracy 79.00281162136832\n",
      "Training:: Epoch 30, Iteration 60, Current loss 1.5450388326443643 Accuracy 87.56400628114973\n",
      "Training:: Epoch 30, Iteration 70, Current loss 1.135106687111908 Accuracy 87.19245962991198\n",
      "Training:: Epoch 30, Iteration 80, Current loss 1.363071826980295 Accuracy 89.88079745978867\n",
      "Training:: Epoch 30, Iteration 90, Current loss 1.0586825934204225 Accuracy 81.8103391067755\n",
      "Training:: Epoch 30, Iteration 100, Current loss 1.3547371854465076 Accuracy 86.2856115754471\n",
      "Training:: Epoch 30, Iteration 110, Current loss 1.142391287200174 Accuracy 87.17845195524282\n",
      "Training:: Epoch 30, Iteration 120, Current loss 1.042285889523127 Accuracy 88.68768640818065\n",
      "Training:: Epoch 30, Iteration 130, Current loss 0.9362649955094182 Accuracy 86.54416505480336\n",
      "Training:: Epoch 30, Iteration 140, Current loss 0.7089039480339652 Accuracy 90.71767170102524\n",
      "Training:: Epoch 30, Iteration 150, Current loss 1.6724670121079295 Accuracy 81.62054239920137\n",
      "Calculating Expectation\n",
      "Epoch 30 iter 0\n",
      "Epoch 30 iter 10\n",
      "Epoch 30 iter 20\n",
      "Epoch 30 iter 30\n",
      "Epoch 30 iter 40\n",
      "Epoch 30 iter 50\n",
      "Epoch 30 iter 60\n",
      "Epoch 30 iter 70\n",
      "Epoch 30 iter 80\n",
      "Epoch 30 iter 90\n",
      "Epoch 30 iter 100\n",
      "Epoch 30 iter 110\n",
      "Epoch 30 iter 120\n",
      "Epoch 30 iter 130\n",
      "Epoch 30 iter 140\n",
      "Epoch 30 iter 150\n",
      "Train Boundary avergage error = 94.610\n",
      "Train From boundary avergage accuracy = 88.187\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 30, Probability Accuracy 69.68711112103169\n",
      "Starting Training\n",
      "Training:: Epoch 31, Iteration 0, Current loss 0.8078183142935715 Accuracy 89.97006902449453\n",
      "Training:: Epoch 31, Iteration 10, Current loss 0.6761604986332826 Accuracy 82.92770867135388\n",
      "Training:: Epoch 31, Iteration 20, Current loss 0.9119586802238282 Accuracy 89.1090242785158\n",
      "Training:: Epoch 31, Iteration 30, Current loss 0.9838279552326767 Accuracy 85.18347565197323\n",
      "Training:: Epoch 31, Iteration 40, Current loss 0.7475253054572625 Accuracy 90.76532604451386\n",
      "Training:: Epoch 31, Iteration 50, Current loss 0.617345442578252 Accuracy 89.18641332257354\n",
      "Training:: Epoch 31, Iteration 60, Current loss 0.8281731240009866 Accuracy 83.57372531005971\n",
      "Training:: Epoch 31, Iteration 70, Current loss 0.7238092076584824 Accuracy 88.27826664452931\n",
      "Training:: Epoch 31, Iteration 80, Current loss 0.5844007495536558 Accuracy 77.72994690773425\n",
      "Training:: Epoch 31, Iteration 90, Current loss 0.7434580767437211 Accuracy 87.27867751950994\n",
      "Training:: Epoch 31, Iteration 100, Current loss 0.7060252831128572 Accuracy 81.91265221583402\n",
      "Training:: Epoch 31, Iteration 110, Current loss 0.6919703127714231 Accuracy 92.09119170984457\n",
      "Training:: Epoch 31, Iteration 120, Current loss 0.8286822863141152 Accuracy 85.90146750524109\n",
      "Training:: Epoch 31, Iteration 130, Current loss 0.5170143793041108 Accuracy 90.84432014915434\n",
      "Training:: Epoch 31, Iteration 140, Current loss 0.6801325093562017 Accuracy 90.56105610561056\n",
      "Training:: Epoch 31, Iteration 150, Current loss 0.563719027961188 Accuracy 90.91309453904874\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 31, Probability Accuracy 69.00765062694963\n",
      "Starting Training\n",
      "Training:: Epoch 32, Iteration 0, Current loss 0.5586881170978572 Accuracy 90.91973537849071\n",
      "Training:: Epoch 32, Iteration 10, Current loss 0.5890903214720598 Accuracy 83.05123618182652\n",
      "Training:: Epoch 32, Iteration 20, Current loss 0.5218914372795634 Accuracy 89.72055888223552\n",
      "Training:: Epoch 32, Iteration 30, Current loss 0.5747050459016959 Accuracy 87.9646294702246\n",
      "Training:: Epoch 32, Iteration 40, Current loss 0.6040850738650615 Accuracy 91.17374979594058\n",
      "Training:: Epoch 32, Iteration 50, Current loss 0.7653864923621413 Accuracy 89.501312335958\n",
      "Training:: Epoch 32, Iteration 60, Current loss 1.018920859490374 Accuracy 86.84293957263331\n",
      "Training:: Epoch 32, Iteration 70, Current loss 0.7210126795728098 Accuracy 92.00717835450028\n",
      "Training:: Epoch 32, Iteration 80, Current loss 0.5785403330465149 Accuracy 90.61835899030737\n",
      "Training:: Epoch 32, Iteration 90, Current loss 0.8229371989013302 Accuracy 89.52995008319468\n",
      "Training:: Epoch 32, Iteration 100, Current loss 0.6827539214999762 Accuracy 89.01161144151799\n",
      "Training:: Epoch 32, Iteration 110, Current loss 0.628334086732455 Accuracy 92.89220498723738\n",
      "Training:: Epoch 32, Iteration 120, Current loss 0.7882450470407976 Accuracy 89.22579341014756\n",
      "Training:: Epoch 32, Iteration 130, Current loss 0.7431654974364851 Accuracy 90.1560684883075\n",
      "Training:: Epoch 32, Iteration 140, Current loss 0.6430686839235076 Accuracy 90.0609756097561\n",
      "Training:: Epoch 32, Iteration 150, Current loss 1.4449374663594912 Accuracy 87.29411764705883\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 32, Probability Accuracy 67.92540220199665\n",
      "Starting Training\n",
      "Training:: Epoch 33, Iteration 0, Current loss 1.4591841968051185 Accuracy 87.80937204322494\n",
      "Training:: Epoch 33, Iteration 10, Current loss 0.986293489235139 Accuracy 85.72267057960381\n",
      "Training:: Epoch 33, Iteration 20, Current loss 0.711734064139469 Accuracy 87.26415094339623\n",
      "Training:: Epoch 33, Iteration 30, Current loss 1.0501102576731034 Accuracy 83.5590924483576\n",
      "Training:: Epoch 33, Iteration 40, Current loss 0.8737885876757346 Accuracy 89.39789310911375\n",
      "Training:: Epoch 33, Iteration 50, Current loss 0.5959198813065697 Accuracy 87.49259039715471\n",
      "Training:: Epoch 33, Iteration 60, Current loss 0.7717203307402188 Accuracy 90.3169818215036\n",
      "Training:: Epoch 33, Iteration 70, Current loss 0.7485681533560196 Accuracy 85.79067234379642\n",
      "Training:: Epoch 33, Iteration 80, Current loss 1.0065374596398717 Accuracy 83.1353354875499\n",
      "Training:: Epoch 33, Iteration 90, Current loss 0.6281331302337761 Accuracy 92.23606445852289\n",
      "Training:: Epoch 33, Iteration 100, Current loss 0.6072362936019212 Accuracy 86.35196523800118\n",
      "Training:: Epoch 33, Iteration 110, Current loss 0.8100290160533483 Accuracy 89.91334139459896\n",
      "Training:: Epoch 33, Iteration 120, Current loss 0.6191070296646906 Accuracy 91.20967741935483\n",
      "Training:: Epoch 33, Iteration 130, Current loss 0.7146397731589825 Accuracy 86.6887417218543\n",
      "Training:: Epoch 33, Iteration 140, Current loss 0.8988433319547983 Accuracy 85.04413619167717\n",
      "Training:: Epoch 33, Iteration 150, Current loss 0.964430833372786 Accuracy 86.6050129080749\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 33, Probability Accuracy 69.74927595270115\n",
      "Starting Training\n",
      "Training:: Epoch 34, Iteration 0, Current loss 0.6212393468268205 Accuracy 85.21875397060693\n",
      "Training:: Epoch 34, Iteration 10, Current loss 0.7456801734911284 Accuracy 87.74604114251886\n",
      "Training:: Epoch 34, Iteration 20, Current loss 0.6357712124638835 Accuracy 89.72624047285737\n",
      "Training:: Epoch 34, Iteration 30, Current loss 0.4510277847153204 Accuracy 89.95308387687379\n",
      "Training:: Epoch 34, Iteration 40, Current loss 0.6833704775017897 Accuracy 88.59860664523043\n",
      "Training:: Epoch 34, Iteration 50, Current loss 0.7399532311769125 Accuracy 80.66254765347706\n",
      "Training:: Epoch 34, Iteration 60, Current loss 0.6850950966462732 Accuracy 90.32331958897834\n",
      "Training:: Epoch 34, Iteration 70, Current loss 0.49661729330778037 Accuracy 91.12954186413901\n",
      "Training:: Epoch 34, Iteration 80, Current loss 0.9245019647102283 Accuracy 80.69871159563925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 34, Iteration 90, Current loss 0.8769996571842125 Accuracy 85.41378173425652\n",
      "Training:: Epoch 34, Iteration 100, Current loss 0.4953012704935208 Accuracy 75.88039046089213\n",
      "Training:: Epoch 34, Iteration 110, Current loss 0.579196436645447 Accuracy 87.32405259087393\n",
      "Training:: Epoch 34, Iteration 120, Current loss 0.7141961129188243 Accuracy 85.00243664717348\n",
      "Training:: Epoch 34, Iteration 130, Current loss 0.6681475224179354 Accuracy 87.28448275862068\n",
      "Training:: Epoch 34, Iteration 140, Current loss 0.5490142358706984 Accuracy 90.2105734767025\n",
      "Training:: Epoch 34, Iteration 150, Current loss 0.8033547502278438 Accuracy 83.57330363535121\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 34, Probability Accuracy 69.59693305282894\n",
      "Starting Training\n",
      "Training:: Epoch 35, Iteration 0, Current loss 0.46093596568663286 Accuracy 90.38353073886069\n",
      "Training:: Epoch 35, Iteration 10, Current loss 0.9963554170838094 Accuracy 89.06435057244374\n",
      "Training:: Epoch 35, Iteration 20, Current loss 0.4763765010085984 Accuracy 90.81771999781505\n",
      "Training:: Epoch 35, Iteration 30, Current loss 0.6846119037476812 Accuracy 85.79003181336161\n",
      "Training:: Epoch 35, Iteration 40, Current loss 0.6882827188148121 Accuracy 90.34860068738163\n",
      "Training:: Epoch 35, Iteration 50, Current loss 0.5732760438698236 Accuracy 89.3222881742874\n",
      "Training:: Epoch 35, Iteration 60, Current loss 0.4678789143365112 Accuracy 87.3858879305997\n",
      "Training:: Epoch 35, Iteration 70, Current loss 0.4726292076835499 Accuracy 90.46754425783023\n",
      "Training:: Epoch 35, Iteration 80, Current loss 0.447459035075074 Accuracy 79.80024688587139\n",
      "Training:: Epoch 35, Iteration 90, Current loss 0.8038233365722155 Accuracy 85.6279450932186\n",
      "Training:: Epoch 35, Iteration 100, Current loss 0.4787037902536463 Accuracy 87.84803799050238\n",
      "Training:: Epoch 35, Iteration 110, Current loss 0.44944580074340645 Accuracy 92.04587155963303\n",
      "Training:: Epoch 35, Iteration 120, Current loss 0.6054857990933299 Accuracy 87.94587333963484\n",
      "Training:: Epoch 35, Iteration 130, Current loss 0.40233418533207654 Accuracy 91.58045251913533\n",
      "Training:: Epoch 35, Iteration 140, Current loss 0.5008875255968358 Accuracy 86.77403903724105\n",
      "Training:: Epoch 35, Iteration 150, Current loss 0.4110593769976397 Accuracy 91.244959021725\n",
      "Calculating Expectation\n",
      "Epoch 35 iter 0\n",
      "Epoch 35 iter 10\n",
      "Epoch 35 iter 20\n",
      "Epoch 35 iter 30\n",
      "Epoch 35 iter 40\n",
      "Epoch 35 iter 50\n",
      "Epoch 35 iter 60\n",
      "Epoch 35 iter 70\n",
      "Epoch 35 iter 80\n",
      "Epoch 35 iter 90\n",
      "Epoch 35 iter 100\n",
      "Epoch 35 iter 110\n",
      "Epoch 35 iter 120\n",
      "Epoch 35 iter 130\n",
      "Epoch 35 iter 140\n",
      "Epoch 35 iter 150\n",
      "Train Boundary avergage error = 93.794\n",
      "Train From boundary avergage accuracy = 88.268\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 35, Probability Accuracy 69.72639661609031\n",
      "Starting Training\n",
      "Training:: Epoch 36, Iteration 0, Current loss 0.39571999020886867 Accuracy 86.66541105565496\n",
      "Training:: Epoch 36, Iteration 10, Current loss 0.390165440923395 Accuracy 87.2428810720268\n",
      "Training:: Epoch 36, Iteration 20, Current loss 0.6767185911135629 Accuracy 89.87354376182415\n",
      "Training:: Epoch 36, Iteration 30, Current loss 0.36898070914643055 Accuracy 90.64841798501249\n",
      "Training:: Epoch 36, Iteration 40, Current loss 0.3962654931633693 Accuracy 85.79885730019963\n",
      "Training:: Epoch 36, Iteration 50, Current loss 0.48499890469994933 Accuracy 91.31976362442548\n",
      "Training:: Epoch 36, Iteration 60, Current loss 0.4628789281642637 Accuracy 82.38733252131547\n",
      "Training:: Epoch 36, Iteration 70, Current loss 0.6424399825981625 Accuracy 88.45242591765958\n",
      "Training:: Epoch 36, Iteration 80, Current loss 0.5382627740408235 Accuracy 85.77356884443499\n",
      "Training:: Epoch 36, Iteration 90, Current loss 0.5680685981624732 Accuracy 83.10665271709028\n",
      "Training:: Epoch 36, Iteration 100, Current loss 0.5652208538079687 Accuracy 86.97929869032531\n",
      "Training:: Epoch 36, Iteration 110, Current loss 0.5375792734889236 Accuracy 90.14569797204175\n",
      "Training:: Epoch 36, Iteration 120, Current loss 0.5805348758278831 Accuracy 89.07984855574935\n",
      "Training:: Epoch 36, Iteration 130, Current loss 0.6102960024183535 Accuracy 87.90823983420282\n",
      "Training:: Epoch 36, Iteration 140, Current loss 0.4893212208578024 Accuracy 87.63636363636364\n",
      "Training:: Epoch 36, Iteration 150, Current loss 0.7241206504542658 Accuracy 87.45584216490035\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 36, Probability Accuracy 68.40162722306238\n",
      "Starting Training\n",
      "Training:: Epoch 37, Iteration 0, Current loss 0.39486309744480447 Accuracy 90.54660095022423\n",
      "Training:: Epoch 37, Iteration 10, Current loss 0.9128005426821186 Accuracy 86.03576670109257\n",
      "Training:: Epoch 37, Iteration 20, Current loss 0.7382135726445148 Accuracy 89.21174652241113\n",
      "Training:: Epoch 37, Iteration 30, Current loss 0.5178041984507419 Accuracy 87.6206408441642\n",
      "Training:: Epoch 37, Iteration 40, Current loss 0.799802730092807 Accuracy 89.57745359144572\n",
      "Training:: Epoch 37, Iteration 50, Current loss 0.46661410912562673 Accuracy 88.83433351518458\n",
      "Training:: Epoch 37, Iteration 60, Current loss 0.7639455078971065 Accuracy 88.97508442091814\n",
      "Training:: Epoch 37, Iteration 70, Current loss 1.4829637097025357 Accuracy 83.8175242095438\n",
      "Training:: Epoch 37, Iteration 80, Current loss 0.6027976860927434 Accuracy 89.14549653579677\n",
      "Training:: Epoch 37, Iteration 90, Current loss 0.6970656782701004 Accuracy 90.28975741239893\n",
      "Training:: Epoch 37, Iteration 100, Current loss 0.5212239454142868 Accuracy 87.51432664756447\n",
      "Training:: Epoch 37, Iteration 110, Current loss 0.9274280671269628 Accuracy 77.84709052799681\n",
      "Training:: Epoch 37, Iteration 120, Current loss 0.5783591580483212 Accuracy 88.44519015659955\n",
      "Training:: Epoch 37, Iteration 130, Current loss 0.6948382589057578 Accuracy 84.57051961823966\n",
      "Training:: Epoch 37, Iteration 140, Current loss 1.253249484668337 Accuracy 85.95153825211\n",
      "Training:: Epoch 37, Iteration 150, Current loss 2.123094771215059 Accuracy 80.22880757988106\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 37, Probability Accuracy 61.521866507441366\n",
      "Starting Training\n",
      "Training:: Epoch 38, Iteration 0, Current loss 6.557545745345415 Accuracy 67.44075829383887\n",
      "Training:: Epoch 38, Iteration 10, Current loss 4.697322697692444 Accuracy 71.29538763493622\n",
      "Training:: Epoch 38, Iteration 20, Current loss 3.0972961460149593 Accuracy 71.48964468934068\n",
      "Training:: Epoch 38, Iteration 30, Current loss 1.7113180896802072 Accuracy 86.24323279195669\n",
      "Training:: Epoch 38, Iteration 40, Current loss 2.66256433786928 Accuracy 78.910326416697\n",
      "Training:: Epoch 38, Iteration 50, Current loss 2.6376692708170304 Accuracy 78.79948914431674\n",
      "Training:: Epoch 38, Iteration 60, Current loss 3.5178328473853293 Accuracy 71.21858457110551\n",
      "Training:: Epoch 38, Iteration 70, Current loss 1.9320708492448566 Accuracy 77.52199929602253\n",
      "Training:: Epoch 38, Iteration 80, Current loss 3.323922015214376 Accuracy 63.857515204170284\n",
      "Training:: Epoch 38, Iteration 90, Current loss 1.7838547439140446 Accuracy 82.81305218518082\n",
      "Training:: Epoch 38, Iteration 100, Current loss 2.7120328308340538 Accuracy 79.68763944667559\n",
      "Training:: Epoch 38, Iteration 110, Current loss 2.514566929699443 Accuracy 79.07509440970718\n",
      "Training:: Epoch 38, Iteration 120, Current loss 3.46234433087124 Accuracy 72.07245453902215\n",
      "Training:: Epoch 38, Iteration 130, Current loss 2.395388399215837 Accuracy 81.85319605955114\n",
      "Training:: Epoch 38, Iteration 140, Current loss 3.6750108787547116 Accuracy 67.31266149870801\n",
      "Training:: Epoch 38, Iteration 150, Current loss 1.4336615674115996 Accuracy 86.85883849088597\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 38, Probability Accuracy 69.56177699901228\n",
      "Starting Training\n",
      "Training:: Epoch 39, Iteration 0, Current loss 1.0084046721353495 Accuracy 84.72801700385736\n",
      "Training:: Epoch 39, Iteration 10, Current loss 0.6313935519249563 Accuracy 89.90924805531547\n",
      "Training:: Epoch 39, Iteration 20, Current loss 0.6920661480990208 Accuracy 91.66959887403237\n",
      "Training:: Epoch 39, Iteration 30, Current loss 1.1883852620232331 Accuracy 83.41470351234773\n",
      "Training:: Epoch 39, Iteration 40, Current loss 0.9461801636194227 Accuracy 88.70340510291189\n",
      "Training:: Epoch 39, Iteration 50, Current loss 0.6865455554895517 Accuracy 89.67182057079998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 39, Iteration 60, Current loss 0.5941040145906463 Accuracy 82.8921655711494\n",
      "Training:: Epoch 39, Iteration 70, Current loss 0.6630801112090036 Accuracy 94.57524140175762\n",
      "Training:: Epoch 39, Iteration 80, Current loss 0.821842517639522 Accuracy 91.23213595983005\n",
      "Training:: Epoch 39, Iteration 90, Current loss 0.7725815850880525 Accuracy 83.10423304506145\n",
      "Training:: Epoch 39, Iteration 100, Current loss 0.8616609238154079 Accuracy 86.91983122362869\n",
      "Training:: Epoch 39, Iteration 110, Current loss 0.6254946963143027 Accuracy 90.52502729347934\n",
      "Training:: Epoch 39, Iteration 120, Current loss 0.8932337467290425 Accuracy 79.49219874489032\n",
      "Training:: Epoch 39, Iteration 130, Current loss 0.6836323433496566 Accuracy 86.16686557448193\n",
      "Training:: Epoch 39, Iteration 140, Current loss 1.061463959188944 Accuracy 85.62934967967922\n",
      "Training:: Epoch 39, Iteration 150, Current loss 1.5679888314153028 Accuracy 83.00643339086773\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 39, Probability Accuracy 64.92921356465645\n",
      "Starting Training\n",
      "Training:: Epoch 40, Iteration 0, Current loss 1.0305630353316786 Accuracy 82.91533812401846\n",
      "Training:: Epoch 40, Iteration 10, Current loss 0.6720770837161607 Accuracy 87.53628287448325\n",
      "Training:: Epoch 40, Iteration 20, Current loss 1.1317700606065737 Accuracy 83.13514084879235\n",
      "Training:: Epoch 40, Iteration 30, Current loss 0.7511573160312011 Accuracy 90.78508794420799\n",
      "Training:: Epoch 40, Iteration 40, Current loss 0.933528493934958 Accuracy 90.24284160927873\n",
      "Training:: Epoch 40, Iteration 50, Current loss 0.8100701220370188 Accuracy 89.24137931034483\n",
      "Training:: Epoch 40, Iteration 60, Current loss 0.6686169118021124 Accuracy 89.61214971897796\n",
      "Training:: Epoch 40, Iteration 70, Current loss 1.044221888194487 Accuracy 88.31270870163033\n",
      "Training:: Epoch 40, Iteration 80, Current loss 0.7625812091728329 Accuracy 89.5777371870635\n",
      "Training:: Epoch 40, Iteration 90, Current loss 0.5974487693926342 Accuracy 92.53314309494085\n",
      "Training:: Epoch 40, Iteration 100, Current loss 0.38994070408438347 Accuracy 87.7680806440701\n",
      "Training:: Epoch 40, Iteration 110, Current loss 0.5570722135363219 Accuracy 89.6200814111262\n",
      "Training:: Epoch 40, Iteration 120, Current loss 0.7621990275446004 Accuracy 84.44128113879003\n",
      "Training:: Epoch 40, Iteration 130, Current loss 0.6432284236456698 Accuracy 83.7287974080427\n",
      "Training:: Epoch 40, Iteration 140, Current loss 0.4689953834661235 Accuracy 85.66582914572864\n",
      "Training:: Epoch 40, Iteration 150, Current loss 0.49669482434160217 Accuracy 91.01766358892012\n",
      "Calculating Expectation\n",
      "Epoch 40 iter 0\n",
      "Epoch 40 iter 10\n",
      "Epoch 40 iter 20\n",
      "Epoch 40 iter 30\n",
      "Epoch 40 iter 40\n",
      "Epoch 40 iter 50\n",
      "Epoch 40 iter 60\n",
      "Epoch 40 iter 70\n",
      "Epoch 40 iter 80\n",
      "Epoch 40 iter 90\n",
      "Epoch 40 iter 100\n",
      "Epoch 40 iter 110\n",
      "Epoch 40 iter 120\n",
      "Epoch 40 iter 130\n",
      "Epoch 40 iter 140\n",
      "Epoch 40 iter 150\n",
      "Train Boundary avergage error = 93.634\n",
      "Train From boundary avergage accuracy = 88.362\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 40, Probability Accuracy 69.52126383223307\n",
      "Starting Training\n",
      "Training:: Epoch 41, Iteration 0, Current loss 0.5258988942671052 Accuracy 86.65316455696203\n",
      "Training:: Epoch 41, Iteration 10, Current loss 0.43977818081225567 Accuracy 82.10251954821894\n",
      "Training:: Epoch 41, Iteration 20, Current loss 1.4039487721541324 Accuracy 88.87535525781567\n",
      "Training:: Epoch 41, Iteration 30, Current loss 2.1082052126872304 Accuracy 71.30542721191642\n",
      "Training:: Epoch 41, Iteration 40, Current loss 1.5709535005935609 Accuracy 83.60623686397184\n",
      "Training:: Epoch 41, Iteration 50, Current loss 2.6636904378039494 Accuracy 77.96560769454969\n",
      "Training:: Epoch 41, Iteration 60, Current loss 2.5842546860511755 Accuracy 75.4816215577355\n",
      "Training:: Epoch 41, Iteration 70, Current loss 1.4397707211226876 Accuracy 84.4249726177437\n",
      "Training:: Epoch 41, Iteration 80, Current loss 0.9174538263967058 Accuracy 87.66276969869784\n",
      "Training:: Epoch 41, Iteration 90, Current loss 1.1872172122398457 Accuracy 87.60991207034373\n",
      "Training:: Epoch 41, Iteration 100, Current loss 0.6500869342136097 Accuracy 81.4756243865198\n",
      "Training:: Epoch 41, Iteration 110, Current loss 1.0957897083196064 Accuracy 85.81544589510953\n",
      "Training:: Epoch 41, Iteration 120, Current loss 1.5192762197811116 Accuracy 85.85830168331223\n",
      "Training:: Epoch 41, Iteration 130, Current loss 1.3913219526683676 Accuracy 86.14828978117697\n",
      "Training:: Epoch 41, Iteration 140, Current loss 2.1593496600727824 Accuracy 75.63238512035011\n",
      "Training:: Epoch 41, Iteration 150, Current loss 1.629783863963045 Accuracy 80.71774696540805\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 41, Probability Accuracy 67.07563015831384\n",
      "Starting Training\n",
      "Training:: Epoch 42, Iteration 0, Current loss 3.3575834952403145 Accuracy 66.92852633793926\n",
      "Training:: Epoch 42, Iteration 10, Current loss 1.2636836157468327 Accuracy 87.25729024862076\n",
      "Training:: Epoch 42, Iteration 20, Current loss 0.8694913985598038 Accuracy 88.31980763450557\n",
      "Training:: Epoch 42, Iteration 30, Current loss 0.8461027864204304 Accuracy 85.67888121791468\n",
      "Training:: Epoch 42, Iteration 40, Current loss 0.7950103058081757 Accuracy 87.67543573340296\n",
      "Training:: Epoch 42, Iteration 50, Current loss 2.9960101434425765 Accuracy 79.94901675163875\n",
      "Training:: Epoch 42, Iteration 60, Current loss 0.8884560719225272 Accuracy 91.2228710886429\n",
      "Training:: Epoch 42, Iteration 70, Current loss 0.8764222185122362 Accuracy 90.19038399483705\n",
      "Training:: Epoch 42, Iteration 80, Current loss 0.7043601033077733 Accuracy 89.32232002894007\n",
      "Training:: Epoch 42, Iteration 90, Current loss 0.6781905655600526 Accuracy 87.85210273779283\n",
      "Training:: Epoch 42, Iteration 100, Current loss 0.9896884025966126 Accuracy 86.48903313615662\n",
      "Training:: Epoch 42, Iteration 110, Current loss 0.6210960464213622 Accuracy 86.45277234526138\n",
      "Training:: Epoch 42, Iteration 120, Current loss 0.4797965032449214 Accuracy 86.47261386524592\n",
      "Training:: Epoch 42, Iteration 130, Current loss 1.0063146977711273 Accuracy 81.43402074144713\n",
      "Training:: Epoch 42, Iteration 140, Current loss 0.7281112177361366 Accuracy 83.28430218875029\n",
      "Training:: Epoch 42, Iteration 150, Current loss 0.5625859635215762 Accuracy 88.89848066298343\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 42, Probability Accuracy 70.49145931105295\n",
      "Starting Training\n",
      "Training:: Epoch 43, Iteration 0, Current loss 0.6144066045194196 Accuracy 89.57532577106966\n",
      "Training:: Epoch 43, Iteration 10, Current loss 0.5887532135186104 Accuracy 90.84318962228157\n",
      "Training:: Epoch 43, Iteration 20, Current loss 0.603078709007454 Accuracy 88.27336083060732\n",
      "Training:: Epoch 43, Iteration 30, Current loss 0.49668815817075135 Accuracy 90.95416616277663\n",
      "Training:: Epoch 43, Iteration 40, Current loss 0.4612802002173104 Accuracy 83.85422543156945\n",
      "Training:: Epoch 43, Iteration 50, Current loss 0.4730830213710388 Accuracy 89.35682394111258\n",
      "Training:: Epoch 43, Iteration 60, Current loss 0.6767208856884734 Accuracy 86.93666260657734\n",
      "Training:: Epoch 43, Iteration 70, Current loss 0.5947031974798687 Accuracy 85.94666666666667\n",
      "Training:: Epoch 43, Iteration 80, Current loss 0.6781081379368904 Accuracy 84.24851401075573\n",
      "Training:: Epoch 43, Iteration 90, Current loss 0.7490368836680183 Accuracy 90.17937219730942\n",
      "Training:: Epoch 43, Iteration 100, Current loss 0.4831781657977454 Accuracy 91.3904607922393\n",
      "Training:: Epoch 43, Iteration 110, Current loss 0.5687955890806801 Accuracy 88.80147227973315\n",
      "Training:: Epoch 43, Iteration 120, Current loss 0.7976625971827342 Accuracy 90.33529786556228\n",
      "Training:: Epoch 43, Iteration 130, Current loss 0.6058529158345908 Accuracy 92.93493437587266\n",
      "Training:: Epoch 43, Iteration 140, Current loss 1.2329953698527623 Accuracy 90.085832770759\n",
      "Training:: Epoch 43, Iteration 150, Current loss 0.7806734023685841 Accuracy 86.83113510558327\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 43, Probability Accuracy 69.7027360338391\n",
      "Starting Training\n",
      "Training:: Epoch 44, Iteration 0, Current loss 0.6462478019495239 Accuracy 87.10078805474906\n",
      "Training:: Epoch 44, Iteration 10, Current loss 0.6402010496192064 Accuracy 88.27200624106098\n",
      "Training:: Epoch 44, Iteration 20, Current loss 0.5215161199902828 Accuracy 91.77998658454784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 44, Iteration 30, Current loss 0.6260113199950795 Accuracy 89.52026082906382\n",
      "Training:: Epoch 44, Iteration 40, Current loss 0.4025550130564303 Accuracy 94.08173493097635\n",
      "Training:: Epoch 44, Iteration 50, Current loss 0.5682261443371323 Accuracy 89.41972381085228\n",
      "Training:: Epoch 44, Iteration 60, Current loss 0.43015562992324996 Accuracy 90.54103790945896\n",
      "Training:: Epoch 44, Iteration 70, Current loss 0.6174440865411133 Accuracy 89.3114406779661\n",
      "Training:: Epoch 44, Iteration 80, Current loss 0.4273712807252706 Accuracy 91.38361638361638\n",
      "Training:: Epoch 44, Iteration 90, Current loss 0.4642264706502186 Accuracy 88.96813267674194\n",
      "Training:: Epoch 44, Iteration 100, Current loss 0.4769049560175943 Accuracy 90.92880486240493\n",
      "Training:: Epoch 44, Iteration 110, Current loss 0.7175209116206966 Accuracy 88.7930055637561\n",
      "Training:: Epoch 44, Iteration 120, Current loss 0.44959738769389307 Accuracy 88.89715090795241\n",
      "Training:: Epoch 44, Iteration 130, Current loss 0.5898261379203398 Accuracy 85.93386120167676\n",
      "Training:: Epoch 44, Iteration 140, Current loss 0.3527829474726781 Accuracy 89.4120663134507\n",
      "Training:: Epoch 44, Iteration 150, Current loss 0.5479895545549325 Accuracy 80.21926972033819\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 44, Probability Accuracy 70.95250584539149\n",
      "Starting Training\n",
      "Training:: Epoch 45, Iteration 0, Current loss 0.3691750047257509 Accuracy 93.58558558558559\n",
      "Training:: Epoch 45, Iteration 10, Current loss 1.5145115145408363 Accuracy 82.80696977947183\n",
      "Training:: Epoch 45, Iteration 20, Current loss 0.36167706695778234 Accuracy 89.94426248347986\n",
      "Training:: Epoch 45, Iteration 30, Current loss 0.7741040936488919 Accuracy 82.54101104787412\n",
      "Training:: Epoch 45, Iteration 40, Current loss 0.43004471763902297 Accuracy 91.11111111111111\n",
      "Training:: Epoch 45, Iteration 50, Current loss 0.4751561027284803 Accuracy 91.4174482392497\n",
      "Training:: Epoch 45, Iteration 60, Current loss 0.4526216083431269 Accuracy 91.40531397561492\n",
      "Training:: Epoch 45, Iteration 70, Current loss 0.5279522627631934 Accuracy 84.40373776327499\n",
      "Training:: Epoch 45, Iteration 80, Current loss 0.43243312636266834 Accuracy 89.75243193164857\n",
      "Training:: Epoch 45, Iteration 90, Current loss 0.3837426306086695 Accuracy 86.85705628361488\n",
      "Training:: Epoch 45, Iteration 100, Current loss 0.467215514699368 Accuracy 88.71035585092959\n",
      "Training:: Epoch 45, Iteration 110, Current loss 0.46678502301910724 Accuracy 92.05217903030699\n",
      "Training:: Epoch 45, Iteration 120, Current loss 0.42606509683547444 Accuracy 84.91857123306418\n",
      "Training:: Epoch 45, Iteration 130, Current loss 0.4180707390068737 Accuracy 90.91011552550015\n",
      "Training:: Epoch 45, Iteration 140, Current loss 0.3852310407716134 Accuracy 91.16514938595955\n",
      "Training:: Epoch 45, Iteration 150, Current loss 0.44807351056153943 Accuracy 91.78717432424187\n",
      "Calculating Expectation\n",
      "Epoch 45 iter 0\n",
      "Epoch 45 iter 10\n",
      "Epoch 45 iter 20\n",
      "Epoch 45 iter 30\n",
      "Epoch 45 iter 40\n",
      "Epoch 45 iter 50\n",
      "Epoch 45 iter 60\n",
      "Epoch 45 iter 70\n",
      "Epoch 45 iter 80\n",
      "Epoch 45 iter 90\n",
      "Epoch 45 iter 100\n",
      "Epoch 45 iter 110\n",
      "Epoch 45 iter 120\n",
      "Epoch 45 iter 130\n",
      "Epoch 45 iter 140\n",
      "Epoch 45 iter 150\n",
      "Train Boundary avergage error = 93.365\n",
      "Train From boundary avergage accuracy = 88.357\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 45, Probability Accuracy 71.22192398479919\n",
      "Starting Training\n",
      "Training:: Epoch 46, Iteration 0, Current loss 0.4041170539792339 Accuracy 87.86573039685072\n",
      "Training:: Epoch 46, Iteration 10, Current loss 0.2918704132761051 Accuracy 91.46323951751867\n",
      "Training:: Epoch 46, Iteration 20, Current loss 0.35548981557273396 Accuracy 89.89358430214676\n",
      "Training:: Epoch 46, Iteration 30, Current loss 0.3423520848889863 Accuracy 90.97429423915538\n",
      "Training:: Epoch 46, Iteration 40, Current loss 0.389389227928565 Accuracy 80.84222039923435\n",
      "Training:: Epoch 46, Iteration 50, Current loss 0.43139116523195853 Accuracy 83.97065170479068\n",
      "Training:: Epoch 46, Iteration 60, Current loss 0.3122890177593166 Accuracy 80.85928620140942\n",
      "Training:: Epoch 46, Iteration 70, Current loss 0.7630047171662713 Accuracy 87.29528190117779\n",
      "Training:: Epoch 46, Iteration 80, Current loss 0.4363689145476763 Accuracy 82.42445914536027\n",
      "Training:: Epoch 46, Iteration 90, Current loss 0.30449158950689326 Accuracy 90.42167344750371\n",
      "Training:: Epoch 46, Iteration 100, Current loss 0.3878914727011079 Accuracy 86.70221916394289\n",
      "Training:: Epoch 46, Iteration 110, Current loss 0.342048116899383 Accuracy 91.61458589636337\n",
      "Training:: Epoch 46, Iteration 120, Current loss 0.3197768533475869 Accuracy 91.9439859432405\n",
      "Training:: Epoch 46, Iteration 130, Current loss 0.45693893413714215 Accuracy 89.71588916169765\n",
      "Training:: Epoch 46, Iteration 140, Current loss 0.5230217971704737 Accuracy 84.18201516793066\n",
      "Training:: Epoch 46, Iteration 150, Current loss 0.4087593567604036 Accuracy 88.98084653582407\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 46, Probability Accuracy 70.8491582078225\n",
      "Starting Training\n",
      "Training:: Epoch 47, Iteration 0, Current loss 0.29395739915193575 Accuracy 85.74141301312483\n",
      "Training:: Epoch 47, Iteration 10, Current loss 0.5683163245418729 Accuracy 85.27795733678087\n",
      "Training:: Epoch 47, Iteration 20, Current loss 0.4457534495446542 Accuracy 88.22129684711481\n",
      "Training:: Epoch 47, Iteration 30, Current loss 0.34120313057651586 Accuracy 86.78624813153961\n",
      "Training:: Epoch 47, Iteration 40, Current loss 0.3030008573220658 Accuracy 92.12792127921279\n",
      "Training:: Epoch 47, Iteration 50, Current loss 0.331825637231249 Accuracy 89.91137092211956\n",
      "Training:: Epoch 47, Iteration 60, Current loss 0.45550223152821834 Accuracy 88.78681655183529\n",
      "Training:: Epoch 47, Iteration 70, Current loss 0.6143573354126127 Accuracy 83.9339203049832\n",
      "Training:: Epoch 47, Iteration 80, Current loss 0.42695953863363084 Accuracy 88.67305998630003\n",
      "Training:: Epoch 47, Iteration 90, Current loss 0.3529185158532906 Accuracy 90.28801580667223\n",
      "Training:: Epoch 47, Iteration 100, Current loss 0.4378362049957826 Accuracy 83.993993993994\n",
      "Training:: Epoch 47, Iteration 110, Current loss 0.3516956738718704 Accuracy 88.69903152180618\n",
      "Training:: Epoch 47, Iteration 120, Current loss 0.32742235919114254 Accuracy 87.33635774465327\n",
      "Training:: Epoch 47, Iteration 130, Current loss 0.5134770307361278 Accuracy 91.1170812028772\n",
      "Training:: Epoch 47, Iteration 140, Current loss 0.42037973140078455 Accuracy 84.42410076613427\n",
      "Training:: Epoch 47, Iteration 150, Current loss 0.4165807234914856 Accuracy 85.12619099570878\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 47, Probability Accuracy 70.83252883633462\n",
      "Starting Training\n",
      "Training:: Epoch 48, Iteration 0, Current loss 0.39960130701300944 Accuracy 87.44595429277332\n",
      "Training:: Epoch 48, Iteration 10, Current loss 0.37315506422818656 Accuracy 84.48455185071887\n",
      "Training:: Epoch 48, Iteration 20, Current loss 0.4016390966352844 Accuracy 92.49056076073276\n",
      "Training:: Epoch 48, Iteration 30, Current loss 0.43613955505743185 Accuracy 86.77354709418837\n",
      "Training:: Epoch 48, Iteration 40, Current loss 0.35168930520198355 Accuracy 88.57393017401773\n",
      "Training:: Epoch 48, Iteration 50, Current loss 0.46030048023474823 Accuracy 83.60154969453137\n",
      "Training:: Epoch 48, Iteration 60, Current loss 0.3152061342936906 Accuracy 80.51382039224681\n",
      "Training:: Epoch 48, Iteration 70, Current loss 0.3362272592887953 Accuracy 84.49081693107762\n",
      "Training:: Epoch 48, Iteration 80, Current loss 0.3598445744367752 Accuracy 87.71929824561404\n",
      "Training:: Epoch 48, Iteration 90, Current loss 0.3234514937377014 Accuracy 87.03902065799541\n",
      "Training:: Epoch 48, Iteration 100, Current loss 0.6327757471092792 Accuracy 76.12219451371571\n",
      "Training:: Epoch 48, Iteration 110, Current loss 0.5798672178047103 Accuracy 89.39140145170296\n",
      "Training:: Epoch 48, Iteration 120, Current loss 0.3407913987092932 Accuracy 84.18868945611977\n",
      "Training:: Epoch 48, Iteration 130, Current loss 0.38724850180577247 Accuracy 86.86300959232614\n",
      "Training:: Epoch 48, Iteration 140, Current loss 0.35665832010492093 Accuracy 82.09690328141353\n",
      "Training:: Epoch 48, Iteration 150, Current loss 0.2408916928193248 Accuracy 91.61131611316114\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 48, Probability Accuracy 71.3126600856022\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 49, Iteration 0, Current loss 0.3430966510437109 Accuracy 85.60005762858378\n",
      "Training:: Epoch 49, Iteration 10, Current loss 0.32099189427204144 Accuracy 91.75989882284269\n",
      "Training:: Epoch 49, Iteration 20, Current loss 0.3717568990568056 Accuracy 90.29338516673754\n",
      "Training:: Epoch 49, Iteration 30, Current loss 0.3925410393947496 Accuracy 90.22090169228782\n",
      "Training:: Epoch 49, Iteration 40, Current loss 0.3044436936515229 Accuracy 87.5798650504568\n",
      "Training:: Epoch 49, Iteration 50, Current loss 0.3384213287901165 Accuracy 90.04747518342684\n",
      "Training:: Epoch 49, Iteration 60, Current loss 0.3186977755464281 Accuracy 92.64058476617659\n",
      "Training:: Epoch 49, Iteration 70, Current loss 0.42345676793213033 Accuracy 89.64037012305637\n",
      "Training:: Epoch 49, Iteration 80, Current loss 0.46738948389456164 Accuracy 89.33350164099974\n",
      "Training:: Epoch 49, Iteration 90, Current loss 0.3185897753341247 Accuracy 91.34028027308659\n",
      "Training:: Epoch 49, Iteration 100, Current loss 0.3012099440193569 Accuracy 90.24277099118602\n",
      "Training:: Epoch 49, Iteration 110, Current loss 0.432378960048656 Accuracy 78.80642693190512\n",
      "Training:: Epoch 49, Iteration 120, Current loss 0.36157641406456237 Accuracy 81.88596821571139\n",
      "Training:: Epoch 49, Iteration 130, Current loss 0.3476235006971312 Accuracy 89.63619978181474\n",
      "Training:: Epoch 49, Iteration 140, Current loss 0.3427624061213235 Accuracy 82.84132841328413\n",
      "Training:: Epoch 49, Iteration 150, Current loss 0.38328744268633763 Accuracy 90.84444444444445\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 49, Probability Accuracy 70.70306527307325\n",
      "Starting Training\n",
      "Training:: Epoch 50, Iteration 0, Current loss 0.34416196288390777 Accuracy 91.15356885364095\n",
      "Training:: Epoch 50, Iteration 10, Current loss 0.2945335504931351 Accuracy 89.5104895104895\n",
      "Training:: Epoch 50, Iteration 20, Current loss 0.37165129949700487 Accuracy 86.84283113587466\n",
      "Training:: Epoch 50, Iteration 30, Current loss 0.3195291046975747 Accuracy 91.24710245711637\n",
      "Training:: Epoch 50, Iteration 40, Current loss 0.41979995091456035 Accuracy 89.94089905080294\n",
      "Training:: Epoch 50, Iteration 50, Current loss 0.4385879620377988 Accuracy 83.88157894736842\n",
      "Training:: Epoch 50, Iteration 60, Current loss 0.5727004596015688 Accuracy 90.44318420499894\n",
      "Training:: Epoch 50, Iteration 70, Current loss 0.30601495228583986 Accuracy 83.49378042184965\n",
      "Training:: Epoch 50, Iteration 80, Current loss 0.2902388962236177 Accuracy 88.90227661868222\n",
      "Training:: Epoch 50, Iteration 90, Current loss 0.8475702126900392 Accuracy 82.93518798508215\n",
      "Training:: Epoch 50, Iteration 100, Current loss 0.2910317430657418 Accuracy 91.9706158708465\n",
      "Training:: Epoch 50, Iteration 110, Current loss 0.36449712307033827 Accuracy 86.75210792580101\n",
      "Training:: Epoch 50, Iteration 120, Current loss 0.4165797305694788 Accuracy 88.18876009448992\n",
      "Training:: Epoch 50, Iteration 130, Current loss 0.3923609948469016 Accuracy 83.2961686600446\n",
      "Training:: Epoch 50, Iteration 140, Current loss 0.34889859825516617 Accuracy 91.94630872483222\n",
      "Training:: Epoch 50, Iteration 150, Current loss 0.35653632062524754 Accuracy 92.78538486289371\n",
      "Calculating Expectation\n",
      "Epoch 50 iter 0\n",
      "Epoch 50 iter 10\n",
      "Epoch 50 iter 20\n",
      "Epoch 50 iter 30\n",
      "Epoch 50 iter 40\n",
      "Epoch 50 iter 50\n",
      "Epoch 50 iter 60\n",
      "Epoch 50 iter 70\n",
      "Epoch 50 iter 80\n",
      "Epoch 50 iter 90\n",
      "Epoch 50 iter 100\n",
      "Epoch 50 iter 110\n",
      "Epoch 50 iter 120\n",
      "Epoch 50 iter 130\n",
      "Epoch 50 iter 140\n",
      "Epoch 50 iter 150\n",
      "Train Boundary avergage error = 93.462\n",
      "Train From boundary avergage accuracy = 88.344\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 50, Probability Accuracy 70.57739633149369\n",
      "Starting Training\n",
      "Training:: Epoch 51, Iteration 0, Current loss 0.35214763290698037 Accuracy 87.88749564611634\n",
      "Training:: Epoch 51, Iteration 10, Current loss 0.31357159281314223 Accuracy 92.3084017338375\n",
      "Training:: Epoch 51, Iteration 20, Current loss 0.2983766645712193 Accuracy 89.59071534945822\n",
      "Training:: Epoch 51, Iteration 30, Current loss 0.2907571239860849 Accuracy 88.04909560723515\n",
      "Training:: Epoch 51, Iteration 40, Current loss 0.3175549646564919 Accuracy 89.9905623716205\n",
      "Training:: Epoch 51, Iteration 50, Current loss 0.30868821771804006 Accuracy 89.52326395519063\n",
      "Training:: Epoch 51, Iteration 60, Current loss 0.3893301332244634 Accuracy 92.56913227080778\n",
      "Training:: Epoch 51, Iteration 70, Current loss 0.3588349363701957 Accuracy 83.89305347326336\n",
      "Training:: Epoch 51, Iteration 80, Current loss 0.3697906558929266 Accuracy 90.73464912280701\n",
      "Training:: Epoch 51, Iteration 90, Current loss 0.26941918478675614 Accuracy 89.07379977345997\n",
      "Training:: Epoch 51, Iteration 100, Current loss 0.6230900692282082 Accuracy 89.17939833044574\n",
      "Training:: Epoch 51, Iteration 110, Current loss 0.3701087970803879 Accuracy 88.45294863282429\n",
      "Training:: Epoch 51, Iteration 120, Current loss 0.3946742030942369 Accuracy 88.00678541136557\n",
      "Training:: Epoch 51, Iteration 130, Current loss 0.37777535426325054 Accuracy 88.6065105653912\n",
      "Training:: Epoch 51, Iteration 140, Current loss 0.483594637040711 Accuracy 86.36269214790195\n",
      "Training:: Epoch 51, Iteration 150, Current loss 0.5750796848613762 Accuracy 83.53240348308546\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 51, Probability Accuracy 70.4550755855157\n",
      "Starting Training\n",
      "Training:: Epoch 52, Iteration 0, Current loss 0.3007437740177217 Accuracy 72.14461430328589\n",
      "Training:: Epoch 52, Iteration 10, Current loss 0.37019805139438805 Accuracy 87.43907221693092\n",
      "Training:: Epoch 52, Iteration 20, Current loss 0.7461791061723916 Accuracy 85.41815582558971\n",
      "Training:: Epoch 52, Iteration 30, Current loss 0.4715001502143496 Accuracy 86.25406052316636\n",
      "Training:: Epoch 52, Iteration 40, Current loss 0.440394749507213 Accuracy 85.81030055882798\n",
      "Training:: Epoch 52, Iteration 50, Current loss 0.398278925209788 Accuracy 90.91735302470889\n",
      "Training:: Epoch 52, Iteration 60, Current loss 0.3975181479944828 Accuracy 87.75368201322046\n",
      "Training:: Epoch 52, Iteration 70, Current loss 0.5792740380646206 Accuracy 88.73163134015033\n",
      "Training:: Epoch 52, Iteration 80, Current loss 0.4347989374618283 Accuracy 89.38577586206897\n",
      "Training:: Epoch 52, Iteration 90, Current loss 0.3885309960989853 Accuracy 91.99633928200008\n",
      "Training:: Epoch 52, Iteration 100, Current loss 0.5117741872439262 Accuracy 91.3635349252399\n",
      "Training:: Epoch 52, Iteration 110, Current loss 0.4002361083791664 Accuracy 88.04411888524038\n",
      "Training:: Epoch 52, Iteration 120, Current loss 0.3258479965605588 Accuracy 87.83126269545089\n",
      "Training:: Epoch 52, Iteration 130, Current loss 0.5708639469307168 Accuracy 88.94779771615008\n",
      "Training:: Epoch 52, Iteration 140, Current loss 0.6865564093948875 Accuracy 86.93787668057487\n",
      "Training:: Epoch 52, Iteration 150, Current loss 0.34948397437286116 Accuracy 81.3140348024069\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 52, Probability Accuracy 70.46913800704237\n",
      "Starting Training\n",
      "Training:: Epoch 53, Iteration 0, Current loss 0.40502534283538355 Accuracy 90.48043958108299\n",
      "Training:: Epoch 53, Iteration 10, Current loss 0.44978769747167185 Accuracy 85.5221189848842\n",
      "Training:: Epoch 53, Iteration 20, Current loss 0.42945483141366714 Accuracy 88.63776915724968\n",
      "Training:: Epoch 53, Iteration 30, Current loss 0.3461002032212873 Accuracy 91.52792283590342\n",
      "Training:: Epoch 53, Iteration 40, Current loss 0.6044387663874828 Accuracy 85.4535468334108\n",
      "Training:: Epoch 53, Iteration 50, Current loss 0.6655617185308104 Accuracy 83.01304049416609\n",
      "Training:: Epoch 53, Iteration 60, Current loss 0.6667955056845655 Accuracy 89.60313024035774\n",
      "Training:: Epoch 53, Iteration 70, Current loss 0.5425366714395516 Accuracy 86.17174225591425\n",
      "Training:: Epoch 53, Iteration 80, Current loss 0.3425493683820891 Accuracy 87.85109228711546\n",
      "Training:: Epoch 53, Iteration 90, Current loss 0.6921825228452181 Accuracy 84.67084428273027\n",
      "Training:: Epoch 53, Iteration 100, Current loss 0.7054732929890253 Accuracy 84.69971401334604\n",
      "Training:: Epoch 53, Iteration 110, Current loss 1.8531818018661237 Accuracy 86.86152510490523\n",
      "Training:: Epoch 53, Iteration 120, Current loss 3.2099486944063584 Accuracy 76.81005562868911\n",
      "Training:: Epoch 53, Iteration 130, Current loss 4.220105060909214 Accuracy 73.69874527225791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 53, Iteration 140, Current loss 2.8617145685747545 Accuracy 73.21710318712528\n",
      "Training:: Epoch 53, Iteration 150, Current loss 2.269406848281786 Accuracy 81.60071942446044\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 53, Probability Accuracy 65.95543551654288\n",
      "Starting Training\n",
      "Training:: Epoch 54, Iteration 0, Current loss 0.8501961624028086 Accuracy 83.05317512634586\n",
      "Training:: Epoch 54, Iteration 10, Current loss 1.4186353484012635 Accuracy 83.42310306960205\n",
      "Training:: Epoch 54, Iteration 20, Current loss 1.3842017155696462 Accuracy 82.53674812877627\n",
      "Training:: Epoch 54, Iteration 30, Current loss 1.771448031144173 Accuracy 81.62435983077266\n",
      "Training:: Epoch 54, Iteration 40, Current loss 1.5454037368557851 Accuracy 84.68072921637874\n",
      "Training:: Epoch 54, Iteration 50, Current loss 1.2774369311385918 Accuracy 82.77624390530458\n",
      "Training:: Epoch 54, Iteration 60, Current loss 1.5617137154224532 Accuracy 80.99370427088651\n",
      "Training:: Epoch 54, Iteration 70, Current loss 0.8844823404677838 Accuracy 85.89203013755443\n",
      "Training:: Epoch 54, Iteration 80, Current loss 1.0758284942162626 Accuracy 85.90346534653466\n",
      "Training:: Epoch 54, Iteration 90, Current loss 0.8504086224869478 Accuracy 86.22242647058823\n",
      "Training:: Epoch 54, Iteration 100, Current loss 0.5042972830554645 Accuracy 92.01059114718241\n",
      "Training:: Epoch 54, Iteration 110, Current loss 0.5995716994137236 Accuracy 90.5121644124934\n",
      "Training:: Epoch 54, Iteration 120, Current loss 0.3625118813171708 Accuracy 90.10103968370186\n",
      "Training:: Epoch 54, Iteration 130, Current loss 0.8381608800328392 Accuracy 80.7763469508585\n",
      "Training:: Epoch 54, Iteration 140, Current loss 2.112581990746535 Accuracy 84.01820372105475\n",
      "Training:: Epoch 54, Iteration 150, Current loss 1.0531859473535528 Accuracy 86.15497612926919\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 54, Probability Accuracy 69.05586464361248\n",
      "Starting Training\n",
      "Training:: Epoch 55, Iteration 0, Current loss 1.022866680380245 Accuracy 87.75492341356674\n",
      "Training:: Epoch 55, Iteration 10, Current loss 0.7940105300202434 Accuracy 89.84379640078399\n",
      "Training:: Epoch 55, Iteration 20, Current loss 0.6441980637207512 Accuracy 89.3041302904988\n",
      "Training:: Epoch 55, Iteration 30, Current loss 0.58627906298003 Accuracy 85.37373993533254\n",
      "Training:: Epoch 55, Iteration 40, Current loss 0.5267153715902709 Accuracy 91.08662295996652\n",
      "Training:: Epoch 55, Iteration 50, Current loss 0.5046510431225992 Accuracy 87.55799240826656\n",
      "Training:: Epoch 55, Iteration 60, Current loss 0.4751423068200711 Accuracy 86.27186069203633\n",
      "Training:: Epoch 55, Iteration 70, Current loss 0.9113482438484608 Accuracy 90.4604754292786\n",
      "Training:: Epoch 55, Iteration 80, Current loss 0.6695177892293946 Accuracy 89.0760658286899\n",
      "Training:: Epoch 55, Iteration 90, Current loss 0.9295339422105517 Accuracy 89.97589070452719\n",
      "Training:: Epoch 55, Iteration 100, Current loss 0.4678930183411267 Accuracy 88.17846478131038\n",
      "Training:: Epoch 55, Iteration 110, Current loss 0.685193480680463 Accuracy 82.99447960145416\n",
      "Training:: Epoch 55, Iteration 120, Current loss 0.5283339396853006 Accuracy 89.70543017034623\n",
      "Training:: Epoch 55, Iteration 130, Current loss 0.5871143208218619 Accuracy 89.28849794009575\n",
      "Training:: Epoch 55, Iteration 140, Current loss 0.5217547084820391 Accuracy 86.17651205413789\n",
      "Training:: Epoch 55, Iteration 150, Current loss 0.5839306578241598 Accuracy 92.25877192982456\n",
      "Calculating Expectation\n",
      "Epoch 55 iter 0\n",
      "Epoch 55 iter 10\n",
      "Epoch 55 iter 20\n",
      "Epoch 55 iter 30\n",
      "Epoch 55 iter 40\n",
      "Epoch 55 iter 50\n",
      "Epoch 55 iter 60\n",
      "Epoch 55 iter 70\n",
      "Epoch 55 iter 80\n",
      "Epoch 55 iter 90\n",
      "Epoch 55 iter 100\n",
      "Epoch 55 iter 110\n",
      "Epoch 55 iter 120\n",
      "Epoch 55 iter 130\n",
      "Epoch 55 iter 140\n",
      "Epoch 55 iter 150\n",
      "Train Boundary avergage error = 93.663\n",
      "Train From boundary avergage accuracy = 88.191\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 55, Probability Accuracy 70.48911557413184\n",
      "Starting Training\n",
      "Training:: Epoch 56, Iteration 0, Current loss 0.3107700743434801 Accuracy 88.45592191222812\n",
      "Training:: Epoch 56, Iteration 10, Current loss 0.47926060390291875 Accuracy 90.29100388359845\n",
      "Training:: Epoch 56, Iteration 20, Current loss 0.5287550076558426 Accuracy 89.89347536617844\n",
      "Training:: Epoch 56, Iteration 30, Current loss 0.49980324846605506 Accuracy 83.83042693926639\n",
      "Training:: Epoch 56, Iteration 40, Current loss 0.3398038408372272 Accuracy 86.50072969028702\n",
      "Training:: Epoch 56, Iteration 50, Current loss 0.5567609276095926 Accuracy 87.22991017237193\n",
      "Training:: Epoch 56, Iteration 60, Current loss 0.570911856763102 Accuracy 83.05129736545226\n",
      "Training:: Epoch 56, Iteration 70, Current loss 0.49883835118140096 Accuracy 88.36561422127886\n",
      "Training:: Epoch 56, Iteration 80, Current loss 0.4658926587007952 Accuracy 87.98889523965053\n",
      "Training:: Epoch 56, Iteration 90, Current loss 0.3531721671168657 Accuracy 88.20619831517119\n",
      "Training:: Epoch 56, Iteration 100, Current loss 0.5776851870410085 Accuracy 87.93738489871086\n",
      "Training:: Epoch 56, Iteration 110, Current loss 0.3904255652351949 Accuracy 90.84660630493688\n",
      "Training:: Epoch 56, Iteration 120, Current loss 0.3337238090916512 Accuracy 86.81011597037865\n",
      "Training:: Epoch 56, Iteration 130, Current loss 0.5318604497287107 Accuracy 87.87988860636881\n",
      "Training:: Epoch 56, Iteration 140, Current loss 0.281241292521947 Accuracy 82.97713717693837\n",
      "Training:: Epoch 56, Iteration 150, Current loss 0.3709005923383884 Accuracy 90.58420004425759\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 56, Probability Accuracy 70.76902472642452\n",
      "Starting Training\n",
      "Training:: Epoch 57, Iteration 0, Current loss 0.34249254242468574 Accuracy 87.94999530031018\n",
      "Training:: Epoch 57, Iteration 10, Current loss 0.28179587772523795 Accuracy 84.82901945966371\n",
      "Training:: Epoch 57, Iteration 20, Current loss 0.2457590815894633 Accuracy 90.84068704695872\n",
      "Training:: Epoch 57, Iteration 30, Current loss 0.3857087446606713 Accuracy 90.7883275261324\n",
      "Training:: Epoch 57, Iteration 40, Current loss 0.5453917342398762 Accuracy 84.09117612501468\n",
      "Training:: Epoch 57, Iteration 50, Current loss 0.3699514984590164 Accuracy 87.17254950190629\n",
      "Training:: Epoch 57, Iteration 60, Current loss 0.3592631433568172 Accuracy 77.03165455608452\n",
      "Training:: Epoch 57, Iteration 70, Current loss 0.29577342140927476 Accuracy 87.80300411048366\n",
      "Training:: Epoch 57, Iteration 80, Current loss 0.4173096127218354 Accuracy 86.02993585174626\n",
      "Training:: Epoch 57, Iteration 90, Current loss 0.2926379057288857 Accuracy 89.68487545761252\n",
      "Training:: Epoch 57, Iteration 100, Current loss 0.34536468483789173 Accuracy 83.7038444486668\n",
      "Training:: Epoch 57, Iteration 110, Current loss 0.32211389970731813 Accuracy 90.51713842111549\n",
      "Training:: Epoch 57, Iteration 120, Current loss 0.3456575261537394 Accuracy 84.71634208298053\n",
      "Training:: Epoch 57, Iteration 130, Current loss 0.3249048164109647 Accuracy 90.44416166757559\n",
      "Training:: Epoch 57, Iteration 140, Current loss 0.33973613876293735 Accuracy 88.14624675025505\n",
      "Training:: Epoch 57, Iteration 150, Current loss 0.3866145139284779 Accuracy 91.6594013368207\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 57, Probability Accuracy 70.71735090764003\n",
      "Starting Training\n",
      "Training:: Epoch 58, Iteration 0, Current loss 0.30709663697410355 Accuracy 91.23316796598158\n",
      "Training:: Epoch 58, Iteration 10, Current loss 0.21848386335691006 Accuracy 92.64999232775817\n",
      "Training:: Epoch 58, Iteration 20, Current loss 0.25998462601684375 Accuracy 89.65842272992504\n",
      "Training:: Epoch 58, Iteration 30, Current loss 0.31770924961059543 Accuracy 89.69151312116136\n",
      "Training:: Epoch 58, Iteration 40, Current loss 0.3340200951742344 Accuracy 89.95883400089008\n",
      "Training:: Epoch 58, Iteration 50, Current loss 0.2823856737589785 Accuracy 87.1657455479261\n",
      "Training:: Epoch 58, Iteration 60, Current loss 0.2490607938451374 Accuracy 90.43026706231454\n",
      "Training:: Epoch 58, Iteration 70, Current loss 0.3883312786489613 Accuracy 84.00560037335822\n",
      "Training:: Epoch 58, Iteration 80, Current loss 0.21419384915081052 Accuracy 87.31982622112145\n",
      "Training:: Epoch 58, Iteration 90, Current loss 0.27858664771139074 Accuracy 84.28380563954715\n",
      "Training:: Epoch 58, Iteration 100, Current loss 0.31458884246511903 Accuracy 89.70486351669669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 58, Iteration 110, Current loss 0.396274595675183 Accuracy 87.51559251559252\n",
      "Training:: Epoch 58, Iteration 120, Current loss 0.3547026184906913 Accuracy 89.8051282051282\n",
      "Training:: Epoch 58, Iteration 130, Current loss 0.29641228583884005 Accuracy 87.29513987001978\n",
      "Training:: Epoch 58, Iteration 140, Current loss 0.3078593841316219 Accuracy 86.34297833661566\n",
      "Training:: Epoch 58, Iteration 150, Current loss 0.3247105506035527 Accuracy 89.86245542536933\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 58, Probability Accuracy 70.99770648601292\n",
      "Starting Training\n",
      "Training:: Epoch 59, Iteration 0, Current loss 0.3205933587432677 Accuracy 83.24198250728863\n",
      "Training:: Epoch 59, Iteration 10, Current loss 0.3264130481014301 Accuracy 93.55982465188241\n",
      "Training:: Epoch 59, Iteration 20, Current loss 0.3254342374624605 Accuracy 83.18823757012962\n",
      "Training:: Epoch 59, Iteration 30, Current loss 0.38935231838260537 Accuracy 89.09265920259385\n",
      "Training:: Epoch 59, Iteration 40, Current loss 0.28308947056685346 Accuracy 90.35423352258701\n",
      "Training:: Epoch 59, Iteration 50, Current loss 0.3173668027638774 Accuracy 88.85028949545078\n",
      "Training:: Epoch 59, Iteration 60, Current loss 0.2926352296796319 Accuracy 85.36585365853658\n",
      "Training:: Epoch 59, Iteration 70, Current loss 0.30980418034214807 Accuracy 89.73830491537068\n",
      "Training:: Epoch 59, Iteration 80, Current loss 0.29502339907202013 Accuracy 89.55072341145613\n",
      "Training:: Epoch 59, Iteration 90, Current loss 0.43521868661985263 Accuracy 87.17696767220203\n",
      "Training:: Epoch 59, Iteration 100, Current loss 0.3185180298247487 Accuracy 84.00392541707556\n",
      "Training:: Epoch 59, Iteration 110, Current loss 0.2907467661430673 Accuracy 91.37962512171373\n",
      "Training:: Epoch 59, Iteration 120, Current loss 0.4106118358694136 Accuracy 92.41433635289484\n",
      "Training:: Epoch 59, Iteration 130, Current loss 0.3209466855252029 Accuracy 91.12630251543108\n",
      "Training:: Epoch 59, Iteration 140, Current loss 0.35480774870818715 Accuracy 86.5345657128387\n",
      "Training:: Epoch 59, Iteration 150, Current loss 0.3721158520449767 Accuracy 90.96330738906298\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 59, Probability Accuracy 70.52951713439099\n",
      "Starting Training\n",
      "Training:: Epoch 60, Iteration 0, Current loss 0.34104186512077955 Accuracy 89.94053242927805\n",
      "Training:: Epoch 60, Iteration 10, Current loss 0.2836210295138651 Accuracy 87.91603729360904\n",
      "Training:: Epoch 60, Iteration 20, Current loss 0.2666351200340427 Accuracy 91.7933781642181\n",
      "Training:: Epoch 60, Iteration 30, Current loss 0.27952158743658917 Accuracy 86.41043559282554\n",
      "Training:: Epoch 60, Iteration 40, Current loss 0.32044946373749117 Accuracy 89.80506385839122\n",
      "Training:: Epoch 60, Iteration 50, Current loss 0.24789378990213604 Accuracy 88.82754140954856\n",
      "Training:: Epoch 60, Iteration 60, Current loss 0.3928070229293857 Accuracy 90.73540957864434\n",
      "Training:: Epoch 60, Iteration 70, Current loss 0.6127606477687022 Accuracy 86.81743788126767\n",
      "Training:: Epoch 60, Iteration 80, Current loss 0.2900712541922361 Accuracy 85.73182552504039\n",
      "Training:: Epoch 60, Iteration 90, Current loss 0.2901764864773838 Accuracy 86.53817196205391\n",
      "Training:: Epoch 60, Iteration 100, Current loss 0.31850499714505726 Accuracy 93.38248356724107\n",
      "Training:: Epoch 60, Iteration 110, Current loss 0.2565747373344901 Accuracy 89.87029030265596\n",
      "Training:: Epoch 60, Iteration 120, Current loss 0.2941055980537892 Accuracy 89.18303726062645\n",
      "Training:: Epoch 60, Iteration 130, Current loss 0.31314322890110946 Accuracy 90.95277320153761\n",
      "Training:: Epoch 60, Iteration 140, Current loss 0.2543702598590375 Accuracy 86.35519801980197\n",
      "Training:: Epoch 60, Iteration 150, Current loss 0.26807691771296727 Accuracy 90.01628460478517\n",
      "Calculating Expectation\n",
      "Epoch 60 iter 0\n",
      "Epoch 60 iter 10\n",
      "Epoch 60 iter 20\n",
      "Epoch 60 iter 30\n",
      "Epoch 60 iter 40\n",
      "Epoch 60 iter 50\n",
      "Epoch 60 iter 60\n",
      "Epoch 60 iter 70\n",
      "Epoch 60 iter 80\n",
      "Epoch 60 iter 90\n",
      "Epoch 60 iter 100\n",
      "Epoch 60 iter 110\n",
      "Epoch 60 iter 120\n",
      "Epoch 60 iter 130\n",
      "Epoch 60 iter 140\n",
      "Epoch 60 iter 150\n",
      "Train Boundary avergage error = 93.959\n",
      "Train From boundary avergage accuracy = 88.107\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 60, Probability Accuracy 70.48208436336851\n",
      "Starting Training\n",
      "Training:: Epoch 61, Iteration 0, Current loss 0.3156545550641472 Accuracy 86.84628834843427\n",
      "Training:: Epoch 61, Iteration 10, Current loss 0.27209413054602616 Accuracy 85.12859208954285\n",
      "Training:: Epoch 61, Iteration 20, Current loss 0.23536617503860563 Accuracy 90.58445286485245\n",
      "Training:: Epoch 61, Iteration 30, Current loss 0.22174201970799445 Accuracy 91.80405833861762\n",
      "Training:: Epoch 61, Iteration 40, Current loss 0.35232156488760263 Accuracy 86.98429886302111\n",
      "Training:: Epoch 61, Iteration 50, Current loss 0.24922300075741982 Accuracy 89.74203133441382\n",
      "Training:: Epoch 61, Iteration 60, Current loss 0.45948442685149005 Accuracy 80.79165388155876\n",
      "Training:: Epoch 61, Iteration 70, Current loss 0.3642081402111771 Accuracy 85.71940833706859\n",
      "Training:: Epoch 61, Iteration 80, Current loss 0.29652959305607873 Accuracy 87.85644371941272\n",
      "Training:: Epoch 61, Iteration 90, Current loss 0.29261284462226245 Accuracy 84.75705062861026\n",
      "Training:: Epoch 61, Iteration 100, Current loss 0.2682741609547431 Accuracy 90.65927443654333\n",
      "Training:: Epoch 61, Iteration 110, Current loss 0.2952991428016524 Accuracy 84.10077326016463\n",
      "Training:: Epoch 61, Iteration 120, Current loss 0.3351242014548053 Accuracy 84.19800409754808\n",
      "Training:: Epoch 61, Iteration 130, Current loss 0.2529903387835283 Accuracy 91.98380566801619\n",
      "Training:: Epoch 61, Iteration 140, Current loss 0.3398629975400006 Accuracy 90.45790804382433\n",
      "Training:: Epoch 61, Iteration 150, Current loss 0.22190591750911648 Accuracy 92.03836200334906\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 61, Probability Accuracy 70.32315667881318\n",
      "Starting Training\n",
      "Training:: Epoch 62, Iteration 0, Current loss 0.24882276434396106 Accuracy 91.38867339022498\n",
      "Training:: Epoch 62, Iteration 10, Current loss 0.26765553221648 Accuracy 81.48330750809973\n",
      "Training:: Epoch 62, Iteration 20, Current loss 0.3000201802982086 Accuracy 82.300826880168\n",
      "Training:: Epoch 62, Iteration 30, Current loss 0.2712647049121038 Accuracy 88.07979859627709\n",
      "Training:: Epoch 62, Iteration 40, Current loss 0.4352557236668007 Accuracy 86.76900584795321\n",
      "Training:: Epoch 62, Iteration 50, Current loss 0.3115557726840985 Accuracy 89.59117456197275\n",
      "Training:: Epoch 62, Iteration 60, Current loss 0.28988160463670365 Accuracy 83.3028083028083\n",
      "Training:: Epoch 62, Iteration 70, Current loss 0.24899563004533146 Accuracy 91.994708994709\n",
      "Training:: Epoch 62, Iteration 80, Current loss 0.32823682011909394 Accuracy 86.64702090431899\n",
      "Training:: Epoch 62, Iteration 90, Current loss 0.43744791328652627 Accuracy 86.78733031674209\n",
      "Training:: Epoch 62, Iteration 100, Current loss 0.2575981152097514 Accuracy 89.84305999048848\n",
      "Training:: Epoch 62, Iteration 110, Current loss 0.39249846488338885 Accuracy 80.87212728344137\n",
      "Training:: Epoch 62, Iteration 120, Current loss 0.49438728992116376 Accuracy 84.97399927439835\n",
      "Training:: Epoch 62, Iteration 130, Current loss 0.3148396959180504 Accuracy 88.35610833810654\n",
      "Training:: Epoch 62, Iteration 140, Current loss 0.3726423656411512 Accuracy 88.54009595613434\n",
      "Training:: Epoch 62, Iteration 150, Current loss 0.23894026439919366 Accuracy 93.8863088589736\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 62, Probability Accuracy 69.5814197465416\n",
      "Starting Training\n",
      "Training:: Epoch 63, Iteration 0, Current loss 0.27853649341450865 Accuracy 89.66047557080327\n",
      "Training:: Epoch 63, Iteration 10, Current loss 0.2485874712133765 Accuracy 85.68903726250674\n",
      "Training:: Epoch 63, Iteration 20, Current loss 0.3154486024634704 Accuracy 86.84982511564932\n",
      "Training:: Epoch 63, Iteration 30, Current loss 0.2073599943017364 Accuracy 90.86507161458333\n",
      "Training:: Epoch 63, Iteration 40, Current loss 0.4036874763221948 Accuracy 87.07022883553151\n",
      "Training:: Epoch 63, Iteration 50, Current loss 0.2952861819882194 Accuracy 89.56196943972836\n",
      "Training:: Epoch 63, Iteration 60, Current loss 0.30671391402710657 Accuracy 87.63045337895637\n",
      "Training:: Epoch 63, Iteration 70, Current loss 0.3440131356762304 Accuracy 90.40791841631673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 63, Iteration 80, Current loss 0.3546572975380524 Accuracy 88.82940240196788\n",
      "Training:: Epoch 63, Iteration 90, Current loss 0.26620173444996753 Accuracy 71.77514382754558\n",
      "Training:: Epoch 63, Iteration 100, Current loss 0.3430187120307773 Accuracy 87.70242914979757\n",
      "Training:: Epoch 63, Iteration 110, Current loss 0.4812592385743737 Accuracy 86.74033149171271\n",
      "Training:: Epoch 63, Iteration 120, Current loss 0.2599361842835155 Accuracy 91.67492566897918\n",
      "Training:: Epoch 63, Iteration 130, Current loss 0.2930186125951291 Accuracy 89.27547314089084\n",
      "Training:: Epoch 63, Iteration 140, Current loss 0.2559941554893771 Accuracy 90.29032735890979\n",
      "Training:: Epoch 63, Iteration 150, Current loss 0.3417904173280929 Accuracy 88.65583938627275\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 63, Probability Accuracy 70.12226494271795\n",
      "Starting Training\n",
      "Training:: Epoch 64, Iteration 0, Current loss 0.22337694933519228 Accuracy 90.64089126974885\n",
      "Training:: Epoch 64, Iteration 10, Current loss 0.20384650719301137 Accuracy 91.03166794213038\n",
      "Training:: Epoch 64, Iteration 20, Current loss 0.21637017414104245 Accuracy 84.87946230933312\n",
      "Training:: Epoch 64, Iteration 30, Current loss 0.3137004981144166 Accuracy 76.02015818576328\n",
      "Training:: Epoch 64, Iteration 40, Current loss 0.24710703331487116 Accuracy 89.44080451013257\n",
      "Training:: Epoch 64, Iteration 50, Current loss 0.2659980916794298 Accuracy 92.82204020848846\n",
      "Training:: Epoch 64, Iteration 60, Current loss 0.27879520261833 Accuracy 90.15874515732779\n",
      "Training:: Epoch 64, Iteration 70, Current loss 0.3294702743482831 Accuracy 91.18902612556207\n",
      "Training:: Epoch 64, Iteration 80, Current loss 0.29265973252065697 Accuracy 81.93502035603098\n",
      "Training:: Epoch 64, Iteration 90, Current loss 0.26842543361289367 Accuracy 91.85446009389672\n",
      "Training:: Epoch 64, Iteration 100, Current loss 0.2371830009811728 Accuracy 88.86284761346735\n",
      "Training:: Epoch 64, Iteration 110, Current loss 0.2865052181633065 Accuracy 92.54750593824228\n",
      "Training:: Epoch 64, Iteration 120, Current loss 0.4033423648104586 Accuracy 85.11559272011806\n",
      "Training:: Epoch 64, Iteration 130, Current loss 0.2591492238038611 Accuracy 90.86165314623986\n",
      "Training:: Epoch 64, Iteration 140, Current loss 0.3373666188682786 Accuracy 88.6789912949834\n",
      "Training:: Epoch 64, Iteration 150, Current loss 0.2637719879637385 Accuracy 87.20282715784964\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 64, Probability Accuracy 69.30262665944944\n",
      "Starting Training\n",
      "Training:: Epoch 65, Iteration 0, Current loss 0.32323826366339764 Accuracy 86.62790697674419\n",
      "Training:: Epoch 65, Iteration 10, Current loss 0.2877089704169087 Accuracy 81.78478630947048\n",
      "Training:: Epoch 65, Iteration 20, Current loss 0.22108428426685875 Accuracy 93.79578871868436\n",
      "Training:: Epoch 65, Iteration 30, Current loss 0.2956880882224891 Accuracy 85.05370471509194\n",
      "Training:: Epoch 65, Iteration 40, Current loss 0.2039192371330322 Accuracy 91.40522014236753\n",
      "Training:: Epoch 65, Iteration 50, Current loss 0.26389145190314084 Accuracy 81.69404892296458\n",
      "Training:: Epoch 65, Iteration 60, Current loss 0.46696687216342675 Accuracy 84.95414745349981\n",
      "Training:: Epoch 65, Iteration 70, Current loss 0.25479130669180533 Accuracy 86.34267654525672\n",
      "Training:: Epoch 65, Iteration 80, Current loss 0.3969219361422677 Accuracy 88.108368581678\n",
      "Training:: Epoch 65, Iteration 90, Current loss 0.3569397904530932 Accuracy 87.87846595134388\n",
      "Training:: Epoch 65, Iteration 100, Current loss 0.2889815940016123 Accuracy 89.00141978230005\n",
      "Training:: Epoch 65, Iteration 110, Current loss 0.5153717562745372 Accuracy 91.17171575173965\n",
      "Training:: Epoch 65, Iteration 120, Current loss 0.6062738567773225 Accuracy 82.53499034749035\n",
      "Training:: Epoch 65, Iteration 130, Current loss 0.6188257090025523 Accuracy 89.05894519131334\n",
      "Training:: Epoch 65, Iteration 140, Current loss 0.5923945058401083 Accuracy 89.69509841759938\n",
      "Training:: Epoch 65, Iteration 150, Current loss 2.6829585744189743 Accuracy 86.69479468184271\n",
      "Calculating Expectation\n",
      "Epoch 65 iter 0\n",
      "Epoch 65 iter 10\n",
      "Epoch 65 iter 20\n",
      "Epoch 65 iter 30\n",
      "Epoch 65 iter 40\n",
      "Epoch 65 iter 50\n",
      "Epoch 65 iter 60\n",
      "Epoch 65 iter 70\n",
      "Epoch 65 iter 80\n",
      "Epoch 65 iter 90\n",
      "Epoch 65 iter 100\n",
      "Epoch 65 iter 110\n",
      "Epoch 65 iter 120\n",
      "Epoch 65 iter 130\n",
      "Epoch 65 iter 140\n",
      "Epoch 65 iter 150\n",
      "Train Boundary avergage error = 107.293\n",
      "Train From boundary avergage accuracy = 87.399\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 65, Probability Accuracy 65.00499439177237\n",
      "Starting Training\n",
      "Training:: Epoch 66, Iteration 0, Current loss 0.5094499576137472 Accuracy 83.38166118950963\n",
      "Training:: Epoch 66, Iteration 10, Current loss 2.0858859749702723 Accuracy 82.24788298691301\n",
      "Training:: Epoch 66, Iteration 20, Current loss 5.052782949105471 Accuracy 59.0220207253886\n",
      "Training:: Epoch 66, Iteration 30, Current loss 3.6168865247324695 Accuracy 76.16673970201578\n",
      "Training:: Epoch 66, Iteration 40, Current loss 5.030252610521019 Accuracy 59.792837743952504\n",
      "Training:: Epoch 66, Iteration 50, Current loss 6.295132728283157 Accuracy 62.50454380225373\n",
      "Training:: Epoch 66, Iteration 60, Current loss 2.256279076058645 Accuracy 71.07908351810791\n",
      "Training:: Epoch 66, Iteration 70, Current loss 1.2881933835992374 Accuracy 84.98832425219615\n",
      "Training:: Epoch 66, Iteration 80, Current loss 4.676505054213921 Accuracy 53.647405226352596\n",
      "Training:: Epoch 66, Iteration 90, Current loss 4.873084700822151 Accuracy 78.60120820216115\n",
      "Training:: Epoch 66, Iteration 100, Current loss 2.3494757793066783 Accuracy 74.86718430731509\n",
      "Training:: Epoch 66, Iteration 110, Current loss 1.917781525852218 Accuracy 77.09682599154311\n",
      "Training:: Epoch 66, Iteration 120, Current loss 1.3265468358976573 Accuracy 83.96700143472023\n",
      "Training:: Epoch 66, Iteration 130, Current loss 1.2671021201201822 Accuracy 85.15397579286042\n",
      "Training:: Epoch 66, Iteration 140, Current loss 1.9582698530499765 Accuracy 89.09428416737566\n",
      "Training:: Epoch 66, Iteration 150, Current loss 1.2204046431720261 Accuracy 80.40555935292777\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 66, Probability Accuracy 65.33802824761023\n",
      "Starting Training\n",
      "Training:: Epoch 67, Iteration 0, Current loss 1.1991918337917167 Accuracy 91.59787095372583\n",
      "Training:: Epoch 67, Iteration 10, Current loss 1.0646538593468524 Accuracy 89.87305797650625\n",
      "Training:: Epoch 67, Iteration 20, Current loss 1.4712390746477935 Accuracy 81.71507781488249\n",
      "Training:: Epoch 67, Iteration 30, Current loss 0.8452877886429584 Accuracy 84.1859550837879\n",
      "Training:: Epoch 67, Iteration 40, Current loss 2.858418820470235 Accuracy 79.50186949704499\n",
      "Training:: Epoch 67, Iteration 50, Current loss 0.82141009071605 Accuracy 88.10938025327805\n",
      "Training:: Epoch 67, Iteration 60, Current loss 1.3961507335396974 Accuracy 82.66831814562505\n",
      "Training:: Epoch 67, Iteration 70, Current loss 0.9959115379141606 Accuracy 90.27120600115407\n",
      "Training:: Epoch 67, Iteration 80, Current loss 1.114099221413801 Accuracy 86.76047155973271\n",
      "Training:: Epoch 67, Iteration 90, Current loss 0.5369661348557015 Accuracy 91.07757673430518\n",
      "Training:: Epoch 67, Iteration 100, Current loss 1.1458873821345388 Accuracy 83.07507867525851\n",
      "Training:: Epoch 67, Iteration 110, Current loss 0.788009812649179 Accuracy 88.94465894465894\n",
      "Training:: Epoch 67, Iteration 120, Current loss 0.8548037438916056 Accuracy 84.146069917613\n",
      "Training:: Epoch 67, Iteration 130, Current loss 0.6834685304633998 Accuracy 87.57136172204024\n",
      "Training:: Epoch 67, Iteration 140, Current loss 0.7297792656956932 Accuracy 89.51856088177186\n",
      "Training:: Epoch 67, Iteration 150, Current loss 0.5551748090394404 Accuracy 84.16467730451899\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 67, Probability Accuracy 67.55777032494238\n",
      "Starting Training\n",
      "Training:: Epoch 68, Iteration 0, Current loss 0.5641918935936059 Accuracy 86.39375130762257\n",
      "Training:: Epoch 68, Iteration 10, Current loss 0.5251236785853467 Accuracy 82.90893125940792\n",
      "Training:: Epoch 68, Iteration 20, Current loss 0.6199626759845627 Accuracy 89.34562490554632\n",
      "Training:: Epoch 68, Iteration 30, Current loss 0.5433261892059104 Accuracy 91.42048854795713\n",
      "Training:: Epoch 68, Iteration 40, Current loss 1.514916137005014 Accuracy 82.93289146644574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 68, Iteration 50, Current loss 1.21734885028795 Accuracy 84.66012542990087\n",
      "Training:: Epoch 68, Iteration 60, Current loss 1.453906178256922 Accuracy 83.84207424867414\n",
      "Training:: Epoch 68, Iteration 70, Current loss 0.6769170484979425 Accuracy 87.59341267644616\n",
      "Training:: Epoch 68, Iteration 80, Current loss 0.7703497843281049 Accuracy 88.1555104057987\n",
      "Training:: Epoch 68, Iteration 90, Current loss 0.6916404150462527 Accuracy 83.81714649782981\n",
      "Training:: Epoch 68, Iteration 100, Current loss 1.2890359619639917 Accuracy 80.73142285904699\n",
      "Training:: Epoch 68, Iteration 110, Current loss 1.8397302921216263 Accuracy 83.49114331723027\n",
      "Training:: Epoch 68, Iteration 120, Current loss 1.0183785256147793 Accuracy 81.53363304775638\n",
      "Training:: Epoch 68, Iteration 130, Current loss 1.2673310290034168 Accuracy 83.26612903225806\n",
      "Training:: Epoch 68, Iteration 140, Current loss 0.889184958714668 Accuracy 91.22456529781724\n",
      "Training:: Epoch 68, Iteration 150, Current loss 0.6854508059561469 Accuracy 87.40543686091945\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 68, Probability Accuracy 68.22428446269831\n",
      "Starting Training\n",
      "Training:: Epoch 69, Iteration 0, Current loss 0.6478478888642454 Accuracy 90.53124016013675\n",
      "Training:: Epoch 69, Iteration 10, Current loss 0.5753371902289065 Accuracy 82.95168307762766\n",
      "Training:: Epoch 69, Iteration 20, Current loss 0.6087158489339788 Accuracy 90.13755341880342\n",
      "Training:: Epoch 69, Iteration 30, Current loss 0.6071750861555016 Accuracy 83.28875302509235\n",
      "Training:: Epoch 69, Iteration 40, Current loss 0.5546547365179175 Accuracy 87.54113415474094\n",
      "Training:: Epoch 69, Iteration 50, Current loss 0.4624177133207815 Accuracy 88.0827560381951\n",
      "Training:: Epoch 69, Iteration 60, Current loss 0.6055309246185429 Accuracy 85.72150874709273\n",
      "Training:: Epoch 69, Iteration 70, Current loss 0.5588005459653455 Accuracy 88.31278818104828\n",
      "Training:: Epoch 69, Iteration 80, Current loss 0.45739891461566273 Accuracy 90.83106939985181\n",
      "Training:: Epoch 69, Iteration 90, Current loss 0.5273976348431526 Accuracy 88.05543989054786\n",
      "Training:: Epoch 69, Iteration 100, Current loss 0.5902042612625976 Accuracy 88.66282873217322\n",
      "Training:: Epoch 69, Iteration 110, Current loss 1.0785155326595606 Accuracy 83.15496872828354\n",
      "Training:: Epoch 69, Iteration 120, Current loss 0.4564622792706661 Accuracy 90.14311967477863\n",
      "Training:: Epoch 69, Iteration 130, Current loss 0.3953673742033436 Accuracy 89.51128245832861\n",
      "Training:: Epoch 69, Iteration 140, Current loss 0.4170410001507092 Accuracy 88.77851613345207\n",
      "Training:: Epoch 69, Iteration 150, Current loss 0.4515144655503817 Accuracy 90.85248332097851\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 69, Probability Accuracy 67.23466944938923\n",
      "Starting Training\n",
      "Training:: Epoch 70, Iteration 0, Current loss 0.39663438048340793 Accuracy 85.47954393024816\n",
      "Training:: Epoch 70, Iteration 10, Current loss 0.4164416893034049 Accuracy 86.1663399607953\n",
      "Training:: Epoch 70, Iteration 20, Current loss 1.0368630121676488 Accuracy 87.1660466689212\n",
      "Training:: Epoch 70, Iteration 30, Current loss 0.4677086517382116 Accuracy 86.86946055367108\n",
      "Training:: Epoch 70, Iteration 40, Current loss 0.6499129694872963 Accuracy 89.68912490319725\n",
      "Training:: Epoch 70, Iteration 50, Current loss 1.1373898524406532 Accuracy 85.92334494773519\n",
      "Training:: Epoch 70, Iteration 60, Current loss 0.5719789125800259 Accuracy 90.32802375809935\n",
      "Training:: Epoch 70, Iteration 70, Current loss 0.5019473074924037 Accuracy 85.5682229460731\n",
      "Training:: Epoch 70, Iteration 80, Current loss 0.37488766156187014 Accuracy 77.53731343283582\n",
      "Training:: Epoch 70, Iteration 90, Current loss 0.4275237640831784 Accuracy 83.73114580576872\n",
      "Training:: Epoch 70, Iteration 100, Current loss 0.5158493652168141 Accuracy 76.14720878546215\n",
      "Training:: Epoch 70, Iteration 110, Current loss 0.4150400385996858 Accuracy 89.87722955756313\n",
      "Training:: Epoch 70, Iteration 120, Current loss 0.37439119128059256 Accuracy 87.84336131499143\n",
      "Training:: Epoch 70, Iteration 130, Current loss 0.35463358422773533 Accuracy 88.56973394339943\n",
      "Training:: Epoch 70, Iteration 140, Current loss 0.3972152714365864 Accuracy 90.37074256182034\n",
      "Training:: Epoch 70, Iteration 150, Current loss 0.3894818307856372 Accuracy 86.4759022740421\n",
      "Calculating Expectation\n",
      "Epoch 70 iter 0\n",
      "Epoch 70 iter 10\n",
      "Epoch 70 iter 20\n",
      "Epoch 70 iter 30\n",
      "Epoch 70 iter 40\n",
      "Epoch 70 iter 50\n",
      "Epoch 70 iter 60\n",
      "Epoch 70 iter 70\n",
      "Epoch 70 iter 80\n",
      "Epoch 70 iter 90\n",
      "Epoch 70 iter 100\n",
      "Epoch 70 iter 110\n",
      "Epoch 70 iter 120\n",
      "Epoch 70 iter 130\n",
      "Epoch 70 iter 140\n",
      "Epoch 70 iter 150\n",
      "Train Boundary avergage error = 102.288\n",
      "Train From boundary avergage accuracy = 87.680\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 70, Probability Accuracy 68.67829978627351\n",
      "Starting Training\n",
      "Training:: Epoch 71, Iteration 0, Current loss 0.3106628663434033 Accuracy 86.32183062320654\n",
      "Training:: Epoch 71, Iteration 10, Current loss 0.24806942955449574 Accuracy 89.68956170408633\n",
      "Training:: Epoch 71, Iteration 20, Current loss 0.32972301760593226 Accuracy 88.0945558739255\n",
      "Training:: Epoch 71, Iteration 30, Current loss 0.35704187635798423 Accuracy 89.53922789539227\n",
      "Training:: Epoch 71, Iteration 40, Current loss 0.299652221153482 Accuracy 88.81794237369303\n",
      "Training:: Epoch 71, Iteration 50, Current loss 0.2630244998152459 Accuracy 89.25360937074366\n",
      "Training:: Epoch 71, Iteration 60, Current loss 0.2736949222523507 Accuracy 84.10703173615433\n",
      "Training:: Epoch 71, Iteration 70, Current loss 0.3415357109017157 Accuracy 85.1691042047532\n",
      "Training:: Epoch 71, Iteration 80, Current loss 0.38639665284973734 Accuracy 87.1622846781505\n",
      "Training:: Epoch 71, Iteration 90, Current loss 0.41913552166366375 Accuracy 89.15736040609137\n",
      "Training:: Epoch 71, Iteration 100, Current loss 0.35491129436055857 Accuracy 88.18596751937162\n",
      "Training:: Epoch 71, Iteration 110, Current loss 0.3287601372982507 Accuracy 89.10795087265676\n",
      "Training:: Epoch 71, Iteration 120, Current loss 0.36493859445733196 Accuracy 86.69274674533445\n",
      "Training:: Epoch 71, Iteration 130, Current loss 0.29505669619395625 Accuracy 86.85736589717854\n",
      "Training:: Epoch 71, Iteration 140, Current loss 0.3181484554746373 Accuracy 85.66838984783435\n",
      "Training:: Epoch 71, Iteration 150, Current loss 0.4171922949557337 Accuracy 89.89090439610096\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 71, Probability Accuracy 68.46189474389094\n",
      "Starting Training\n",
      "Training:: Epoch 72, Iteration 0, Current loss 0.3364592648676479 Accuracy 86.58400243927228\n",
      "Training:: Epoch 72, Iteration 10, Current loss 0.4146199720481853 Accuracy 85.85291522976983\n",
      "Training:: Epoch 72, Iteration 20, Current loss 0.4817889884921121 Accuracy 87.66306973747785\n",
      "Training:: Epoch 72, Iteration 30, Current loss 0.4321418750510633 Accuracy 81.61747796090457\n",
      "Training:: Epoch 72, Iteration 40, Current loss 0.2513802653679168 Accuracy 90.71709756357059\n",
      "Training:: Epoch 72, Iteration 50, Current loss 0.24451607058538657 Accuracy 89.92676191619643\n",
      "Training:: Epoch 72, Iteration 60, Current loss 0.4732816408734003 Accuracy 85.55919705038919\n",
      "Training:: Epoch 72, Iteration 70, Current loss 0.2821703734542765 Accuracy 90.5720403793209\n",
      "Training:: Epoch 72, Iteration 80, Current loss 0.2516327800636761 Accuracy 89.88092272432863\n",
      "Training:: Epoch 72, Iteration 90, Current loss 0.33625571594897236 Accuracy 87.36084452975048\n",
      "Training:: Epoch 72, Iteration 100, Current loss 0.45760308897683066 Accuracy 85.19253459186957\n",
      "Training:: Epoch 72, Iteration 110, Current loss 0.43491868954436097 Accuracy 83.56122759039806\n",
      "Training:: Epoch 72, Iteration 120, Current loss 0.312405277263673 Accuracy 89.5036783752979\n",
      "Training:: Epoch 72, Iteration 130, Current loss 0.2425266565760894 Accuracy 89.92619752738213\n",
      "Training:: Epoch 72, Iteration 140, Current loss 0.45165686422748474 Accuracy 82.41827491138244\n",
      "Training:: Epoch 72, Iteration 150, Current loss 0.2086826944762104 Accuracy 91.22421195936748\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 72, Probability Accuracy 69.447268709438\n",
      "Starting Training\n",
      "Training:: Epoch 73, Iteration 0, Current loss 0.2645021272679258 Accuracy 88.65929453547501\n",
      "Training:: Epoch 73, Iteration 10, Current loss 0.3685366501164403 Accuracy 83.71719709659408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 73, Iteration 20, Current loss 0.25029487230226133 Accuracy 90.31296572280179\n",
      "Training:: Epoch 73, Iteration 30, Current loss 0.2374917098844282 Accuracy 89.58108836206897\n",
      "Training:: Epoch 73, Iteration 40, Current loss 0.35008125666366513 Accuracy 87.06355701036551\n",
      "Training:: Epoch 73, Iteration 50, Current loss 0.30064650660227277 Accuracy 89.17880698702616\n",
      "Training:: Epoch 73, Iteration 60, Current loss 0.3607264700458399 Accuracy 81.50885372749367\n",
      "Training:: Epoch 73, Iteration 70, Current loss 0.19757363828572522 Accuracy 93.56097961867192\n",
      "Training:: Epoch 73, Iteration 80, Current loss 0.3470398976499126 Accuracy 88.43531653609993\n",
      "Training:: Epoch 73, Iteration 90, Current loss 0.33891828193388074 Accuracy 89.6095409246855\n",
      "Training:: Epoch 73, Iteration 100, Current loss 0.1862411101901788 Accuracy 92.1571584781871\n",
      "Training:: Epoch 73, Iteration 110, Current loss 0.2858925349011372 Accuracy 89.63565617262115\n",
      "Training:: Epoch 73, Iteration 120, Current loss 0.29024503489160297 Accuracy 85.86535737890662\n",
      "Training:: Epoch 73, Iteration 130, Current loss 0.2842861027563551 Accuracy 88.71295452953129\n",
      "Training:: Epoch 73, Iteration 140, Current loss 0.4344707248807418 Accuracy 80.90671985271555\n",
      "Training:: Epoch 73, Iteration 150, Current loss 0.466016592146254 Accuracy 93.42919721931244\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 73, Probability Accuracy 68.66937126466928\n",
      "Starting Training\n",
      "Training:: Epoch 74, Iteration 0, Current loss 0.4027780250945194 Accuracy 86.37289390853546\n",
      "Training:: Epoch 74, Iteration 10, Current loss 0.542545759687647 Accuracy 81.06868336226134\n",
      "Training:: Epoch 74, Iteration 20, Current loss 0.5328476858062657 Accuracy 85.90310776121034\n",
      "Training:: Epoch 74, Iteration 30, Current loss 0.426243932575294 Accuracy 89.15016501650165\n",
      "Training:: Epoch 74, Iteration 40, Current loss 0.2969975457176002 Accuracy 85.02147340601256\n",
      "Training:: Epoch 74, Iteration 50, Current loss 0.38088126728400745 Accuracy 85.35035526543815\n",
      "Training:: Epoch 74, Iteration 60, Current loss 0.4060151496178588 Accuracy 87.78528261642374\n",
      "Training:: Epoch 74, Iteration 70, Current loss 0.4499785095279094 Accuracy 86.97145165634258\n",
      "Training:: Epoch 74, Iteration 80, Current loss 0.4984685406437545 Accuracy 91.20724934229757\n",
      "Training:: Epoch 74, Iteration 90, Current loss 0.31796289941109057 Accuracy 89.9532873178554\n",
      "Training:: Epoch 74, Iteration 100, Current loss 0.42589332143905045 Accuracy 87.6699484294421\n",
      "Training:: Epoch 74, Iteration 110, Current loss 0.3722688622531576 Accuracy 88.5616589455107\n",
      "Training:: Epoch 74, Iteration 120, Current loss 0.29457559780668224 Accuracy 78.01684633177672\n",
      "Training:: Epoch 74, Iteration 130, Current loss 0.3531735085793858 Accuracy 86.06829062976799\n",
      "Training:: Epoch 74, Iteration 140, Current loss 0.3756183983159458 Accuracy 85.70353649360422\n",
      "Training:: Epoch 74, Iteration 150, Current loss 0.452563298955548 Accuracy 83.77796901893288\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 74, Probability Accuracy 68.70765230104743\n",
      "Starting Training\n",
      "Training:: Epoch 75, Iteration 0, Current loss 0.2978109752670205 Accuracy 87.96250124663409\n",
      "Training:: Epoch 75, Iteration 10, Current loss 0.4478773238366064 Accuracy 82.43780569337414\n",
      "Training:: Epoch 75, Iteration 20, Current loss 0.41589153582531757 Accuracy 87.7445652173913\n",
      "Training:: Epoch 75, Iteration 30, Current loss 0.3344316981902518 Accuracy 86.95197521301317\n",
      "Training:: Epoch 75, Iteration 40, Current loss 0.29092627714326025 Accuracy 88.14253436264357\n",
      "Training:: Epoch 75, Iteration 50, Current loss 0.33931285351731116 Accuracy 75.189405605174\n",
      "Training:: Epoch 75, Iteration 60, Current loss 0.27475411339696587 Accuracy 78.13903822078208\n",
      "Training:: Epoch 75, Iteration 70, Current loss 0.3719100062078336 Accuracy 89.01515151515152\n",
      "Training:: Epoch 75, Iteration 80, Current loss 0.31583043937984956 Accuracy 89.96329433356274\n",
      "Training:: Epoch 75, Iteration 90, Current loss 0.33228443262354096 Accuracy 92.49832551908908\n",
      "Training:: Epoch 75, Iteration 100, Current loss 0.3414261085412425 Accuracy 87.22278927345272\n",
      "Training:: Epoch 75, Iteration 110, Current loss 0.307925030511595 Accuracy 89.74634146341464\n",
      "Training:: Epoch 75, Iteration 120, Current loss 0.3110465823674744 Accuracy 92.33088274184165\n",
      "Training:: Epoch 75, Iteration 130, Current loss 0.2457776412080914 Accuracy 89.7776405188388\n",
      "Training:: Epoch 75, Iteration 140, Current loss 0.3191359252221316 Accuracy 88.03644597800302\n",
      "Training:: Epoch 75, Iteration 150, Current loss 0.23661339037363793 Accuracy 87.41130511042016\n",
      "Calculating Expectation\n",
      "Epoch 75 iter 0\n",
      "Epoch 75 iter 10\n",
      "Epoch 75 iter 20\n",
      "Epoch 75 iter 30\n",
      "Epoch 75 iter 40\n",
      "Epoch 75 iter 50\n",
      "Epoch 75 iter 60\n",
      "Epoch 75 iter 70\n",
      "Epoch 75 iter 80\n",
      "Epoch 75 iter 90\n",
      "Epoch 75 iter 100\n",
      "Epoch 75 iter 110\n",
      "Epoch 75 iter 120\n",
      "Epoch 75 iter 130\n",
      "Epoch 75 iter 140\n",
      "Epoch 75 iter 150\n",
      "Train Boundary avergage error = 102.114\n",
      "Train From boundary avergage accuracy = 87.621\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 75, Probability Accuracy 69.07539578462173\n",
      "Starting Training\n",
      "Training:: Epoch 76, Iteration 0, Current loss 0.21182963764189555 Accuracy 89.37558247903075\n",
      "Training:: Epoch 76, Iteration 10, Current loss 0.22364655612891726 Accuracy 86.78340478093439\n",
      "Training:: Epoch 76, Iteration 20, Current loss 0.2841147784159831 Accuracy 86.66121112929623\n",
      "Training:: Epoch 76, Iteration 30, Current loss 0.296061428081657 Accuracy 84.07932942529995\n",
      "Training:: Epoch 76, Iteration 40, Current loss 0.23646099872206885 Accuracy 84.83899042645778\n",
      "Training:: Epoch 76, Iteration 50, Current loss 0.2132195008707498 Accuracy 82.26028745816106\n",
      "Training:: Epoch 76, Iteration 60, Current loss 0.444275215526173 Accuracy 79.46472317491425\n",
      "Training:: Epoch 76, Iteration 70, Current loss 0.24708680019148413 Accuracy 81.27049424670602\n",
      "Training:: Epoch 76, Iteration 80, Current loss 0.24248036814581192 Accuracy 91.10671936758894\n",
      "Training:: Epoch 76, Iteration 90, Current loss 0.27536257818711757 Accuracy 90.5458089668616\n",
      "Training:: Epoch 76, Iteration 100, Current loss 0.28739940315233936 Accuracy 80.60580998656053\n",
      "Training:: Epoch 76, Iteration 110, Current loss 0.2508184653790777 Accuracy 85.68732443820225\n",
      "Training:: Epoch 76, Iteration 120, Current loss 0.2924623447034214 Accuracy 88.1986970684039\n",
      "Training:: Epoch 76, Iteration 130, Current loss 0.2600242904558841 Accuracy 90.5866712411013\n",
      "Training:: Epoch 76, Iteration 140, Current loss 0.30176908647356787 Accuracy 80.87997224791859\n",
      "Training:: Epoch 76, Iteration 150, Current loss 0.33070936414797253 Accuracy 87.36756866185303\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 76, Probability Accuracy 68.0887941473541\n",
      "Starting Training\n",
      "Training:: Epoch 77, Iteration 0, Current loss 0.3379029548529368 Accuracy 89.64372469635627\n",
      "Training:: Epoch 77, Iteration 10, Current loss 0.3266627091588691 Accuracy 84.42824991962276\n",
      "Training:: Epoch 77, Iteration 20, Current loss 0.21874195429701715 Accuracy 93.94801295725685\n",
      "Training:: Epoch 77, Iteration 30, Current loss 0.2457995364038313 Accuracy 81.97980824179312\n",
      "Training:: Epoch 77, Iteration 40, Current loss 0.2871336377206334 Accuracy 87.77255954377726\n",
      "Training:: Epoch 77, Iteration 50, Current loss 0.27865897451673416 Accuracy 87.99685163321527\n",
      "Training:: Epoch 77, Iteration 60, Current loss 0.2806271292463853 Accuracy 82.6949860724234\n",
      "Training:: Epoch 77, Iteration 70, Current loss 0.2335311092049653 Accuracy 90.89483119211233\n",
      "Training:: Epoch 77, Iteration 80, Current loss 0.18734696853906657 Accuracy 92.60049627791564\n",
      "Training:: Epoch 77, Iteration 90, Current loss 0.2949074102605001 Accuracy 84.68975133627701\n",
      "Training:: Epoch 77, Iteration 100, Current loss 0.23384069788939366 Accuracy 90.87975543478261\n",
      "Training:: Epoch 77, Iteration 110, Current loss 0.21686565783422962 Accuracy 90.31943088296833\n",
      "Training:: Epoch 77, Iteration 120, Current loss 0.27893855788518246 Accuracy 90.01103752759381\n",
      "Training:: Epoch 77, Iteration 130, Current loss 0.3702241623309437 Accuracy 90.63940092165899\n",
      "Training:: Epoch 77, Iteration 140, Current loss 0.259916098993927 Accuracy 89.89852041211557\n",
      "Training:: Epoch 77, Iteration 150, Current loss 0.31004761386867097 Accuracy 90.13347291285004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 77, Probability Accuracy 68.23310137778249\n",
      "Starting Training\n",
      "Training:: Epoch 78, Iteration 0, Current loss 0.32474709185043765 Accuracy 83.77417060078898\n",
      "Training:: Epoch 78, Iteration 10, Current loss 0.3893854872713797 Accuracy 87.11025393764064\n",
      "Training:: Epoch 78, Iteration 20, Current loss 0.2940789066540651 Accuracy 85.59772643931059\n",
      "Training:: Epoch 78, Iteration 30, Current loss 0.35441780316587995 Accuracy 87.03703703703704\n",
      "Training:: Epoch 78, Iteration 40, Current loss 0.22829584951933715 Accuracy 86.60778845160624\n",
      "Training:: Epoch 78, Iteration 50, Current loss 0.32905499708789815 Accuracy 84.8186794389326\n",
      "Training:: Epoch 78, Iteration 60, Current loss 0.321469380335497 Accuracy 86.02363286617202\n",
      "Training:: Epoch 78, Iteration 70, Current loss 0.3402457434211712 Accuracy 88.44551927986028\n",
      "Training:: Epoch 78, Iteration 80, Current loss 0.3437190554733634 Accuracy 81.51432920775697\n",
      "Training:: Epoch 78, Iteration 90, Current loss 0.25738064424540047 Accuracy 90.32724933665675\n",
      "Training:: Epoch 78, Iteration 100, Current loss 0.19181441315037187 Accuracy 89.93341329252657\n",
      "Training:: Epoch 78, Iteration 110, Current loss 0.3600227935572734 Accuracy 85.85087799944837\n",
      "Training:: Epoch 78, Iteration 120, Current loss 0.3779987651015758 Accuracy 84.27075724373022\n",
      "Training:: Epoch 78, Iteration 130, Current loss 0.3263811400402274 Accuracy 83.88704318936877\n",
      "Training:: Epoch 78, Iteration 140, Current loss 0.4430666268424026 Accuracy 91.90063952581501\n",
      "Training:: Epoch 78, Iteration 150, Current loss 0.2903730173795013 Accuracy 87.32504355139064\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 78, Probability Accuracy 67.37875346677752\n",
      "Starting Training\n",
      "Training:: Epoch 79, Iteration 0, Current loss 0.2302397806498318 Accuracy 79.62923389250989\n",
      "Training:: Epoch 79, Iteration 10, Current loss 0.3830442443659601 Accuracy 88.55882352941177\n",
      "Training:: Epoch 79, Iteration 20, Current loss 0.3255022186400865 Accuracy 83.39214655754937\n",
      "Training:: Epoch 79, Iteration 30, Current loss 0.2247600605315807 Accuracy 93.18356809638118\n",
      "Training:: Epoch 79, Iteration 40, Current loss 0.42599529156676663 Accuracy 88.1389252948886\n",
      "Training:: Epoch 79, Iteration 50, Current loss 0.27578132343445294 Accuracy 91.3702834446651\n",
      "Training:: Epoch 79, Iteration 60, Current loss 0.3549916738022467 Accuracy 87.47301880974406\n",
      "Training:: Epoch 79, Iteration 70, Current loss 0.22178437676494878 Accuracy 90.3280929596719\n",
      "Training:: Epoch 79, Iteration 80, Current loss 0.26971659858725533 Accuracy 89.21026695804944\n",
      "Training:: Epoch 79, Iteration 90, Current loss 0.20041113167202648 Accuracy 90.44041983947314\n",
      "Training:: Epoch 79, Iteration 100, Current loss 0.267283328167875 Accuracy 89.5997934417764\n",
      "Training:: Epoch 79, Iteration 110, Current loss 0.2784457036233479 Accuracy 84.6586119696544\n",
      "Training:: Epoch 79, Iteration 120, Current loss 0.23486263932273269 Accuracy 90.39977210141487\n",
      "Training:: Epoch 79, Iteration 130, Current loss 0.24049849499154768 Accuracy 88.11760923153871\n",
      "Training:: Epoch 79, Iteration 140, Current loss 0.18534546914618139 Accuracy 92.72194251481741\n",
      "Training:: Epoch 79, Iteration 150, Current loss 0.28251702966482833 Accuracy 90.14235609655456\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 79, Probability Accuracy 69.00988275735068\n",
      "Starting Training\n",
      "Training:: Epoch 80, Iteration 0, Current loss 0.26466751340654393 Accuracy 80.44531887326647\n",
      "Training:: Epoch 80, Iteration 10, Current loss 0.2528295046798047 Accuracy 84.43824435745815\n",
      "Training:: Epoch 80, Iteration 20, Current loss 0.24707045167027097 Accuracy 86.73247993057062\n",
      "Training:: Epoch 80, Iteration 30, Current loss 0.2920943015455324 Accuracy 88.93650793650794\n",
      "Training:: Epoch 80, Iteration 40, Current loss 0.28701291114700606 Accuracy 87.53681885125184\n",
      "Training:: Epoch 80, Iteration 50, Current loss 0.331466399359991 Accuracy 91.28750248360818\n",
      "Training:: Epoch 80, Iteration 60, Current loss 0.17863465133960899 Accuracy 81.84338952972493\n",
      "Training:: Epoch 80, Iteration 70, Current loss 0.2763886294285805 Accuracy 85.23407631825724\n",
      "Training:: Epoch 80, Iteration 80, Current loss 0.2649917867478587 Accuracy 88.48792609799578\n",
      "Training:: Epoch 80, Iteration 90, Current loss 0.25083372634067946 Accuracy 89.13105278119966\n",
      "Training:: Epoch 80, Iteration 100, Current loss 0.2542316815703378 Accuracy 91.79225701651475\n",
      "Training:: Epoch 80, Iteration 110, Current loss 0.2654044272945127 Accuracy 85.93309456679113\n",
      "Training:: Epoch 80, Iteration 120, Current loss 0.1960899639238692 Accuracy 92.22554077292062\n",
      "Training:: Epoch 80, Iteration 130, Current loss 0.23125831487390597 Accuracy 84.53823953823954\n",
      "Training:: Epoch 80, Iteration 140, Current loss 0.300964982077428 Accuracy 89.00631945957726\n",
      "Training:: Epoch 80, Iteration 150, Current loss 0.3454265532414058 Accuracy 83.84324510140942\n",
      "Calculating Expectation\n",
      "Epoch 80 iter 0\n",
      "Epoch 80 iter 10\n",
      "Epoch 80 iter 20\n",
      "Epoch 80 iter 30\n",
      "Epoch 80 iter 40\n",
      "Epoch 80 iter 50\n",
      "Epoch 80 iter 60\n",
      "Epoch 80 iter 70\n",
      "Epoch 80 iter 80\n",
      "Epoch 80 iter 90\n",
      "Epoch 80 iter 100\n",
      "Epoch 80 iter 110\n",
      "Epoch 80 iter 120\n",
      "Epoch 80 iter 130\n",
      "Epoch 80 iter 140\n",
      "Epoch 80 iter 150\n",
      "Train Boundary avergage error = 100.733\n",
      "Train From boundary avergage accuracy = 87.467\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 80, Probability Accuracy 69.00474885742825\n",
      "Starting Training\n",
      "Training:: Epoch 81, Iteration 0, Current loss 0.2421793639158728 Accuracy 87.5218790582124\n",
      "Training:: Epoch 81, Iteration 10, Current loss 0.2667908324642649 Accuracy 90.39679893297766\n",
      "Training:: Epoch 81, Iteration 20, Current loss 0.2026233885794907 Accuracy 83.12240184757506\n",
      "Training:: Epoch 81, Iteration 30, Current loss 0.40603594609777305 Accuracy 86.49677019732766\n",
      "Training:: Epoch 81, Iteration 40, Current loss 0.2854037072623906 Accuracy 85.05913053134196\n",
      "Training:: Epoch 81, Iteration 50, Current loss 0.29080364128701575 Accuracy 84.06001409727116\n",
      "Training:: Epoch 81, Iteration 60, Current loss 0.26497067784110495 Accuracy 88.44149459193707\n",
      "Training:: Epoch 81, Iteration 70, Current loss 0.3609984501408958 Accuracy 81.98633364750236\n",
      "Training:: Epoch 81, Iteration 80, Current loss 0.2637217113803246 Accuracy 89.84870668618838\n",
      "Training:: Epoch 81, Iteration 90, Current loss 0.25593761872265086 Accuracy 89.5104895104895\n",
      "Training:: Epoch 81, Iteration 100, Current loss 0.29631050933358055 Accuracy 84.95196423475697\n",
      "Training:: Epoch 81, Iteration 110, Current loss 0.3512629547354219 Accuracy 79.1602119853241\n",
      "Training:: Epoch 81, Iteration 120, Current loss 0.21954820214004636 Accuracy 88.08321205376252\n",
      "Training:: Epoch 81, Iteration 130, Current loss 0.24946394057754084 Accuracy 87.4622721236267\n",
      "Training:: Epoch 81, Iteration 140, Current loss 0.2604269732890612 Accuracy 86.84154060723098\n",
      "Training:: Epoch 81, Iteration 150, Current loss 0.4894562674844431 Accuracy 85.19464505901004\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 81, Probability Accuracy 66.68813232069017\n",
      "Starting Training\n",
      "Training:: Epoch 82, Iteration 0, Current loss 0.7161839839252853 Accuracy 84.7655953195046\n",
      "Training:: Epoch 82, Iteration 10, Current loss 0.6093325318404352 Accuracy 89.17934944792599\n",
      "Training:: Epoch 82, Iteration 20, Current loss 0.3436566041274437 Accuracy 92.93864478030227\n",
      "Training:: Epoch 82, Iteration 30, Current loss 0.4871066931345346 Accuracy 87.74747116936277\n",
      "Training:: Epoch 82, Iteration 40, Current loss 0.4204232410759783 Accuracy 86.51228070175439\n",
      "Training:: Epoch 82, Iteration 50, Current loss 0.5008414756370095 Accuracy 83.83138043402899\n",
      "Training:: Epoch 82, Iteration 60, Current loss 0.2945306728543814 Accuracy 91.96828679765598\n",
      "Training:: Epoch 82, Iteration 70, Current loss 0.3530539335136503 Accuracy 89.58252048380804\n",
      "Training:: Epoch 82, Iteration 80, Current loss 0.2979700227221459 Accuracy 84.45777637441672\n",
      "Training:: Epoch 82, Iteration 90, Current loss 0.6656535028684059 Accuracy 79.9394437031715\n",
      "Training:: Epoch 82, Iteration 100, Current loss 0.41179953062013175 Accuracy 87.33792544570503\n",
      "Training:: Epoch 82, Iteration 110, Current loss 0.4074870340289789 Accuracy 85.8114607667995\n",
      "Training:: Epoch 82, Iteration 120, Current loss 0.3231661732556299 Accuracy 94.36049454124792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 82, Iteration 130, Current loss 0.7222092311287425 Accuracy 78.37856312803336\n",
      "Training:: Epoch 82, Iteration 140, Current loss 1.059534601916567 Accuracy 89.0793232256647\n",
      "Training:: Epoch 82, Iteration 150, Current loss 0.7121267504733277 Accuracy 87.0041187947106\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 82, Probability Accuracy 68.54883622301215\n",
      "Starting Training\n",
      "Training:: Epoch 83, Iteration 0, Current loss 0.4837715323237375 Accuracy 87.35249042145594\n",
      "Training:: Epoch 83, Iteration 10, Current loss 0.4483520642811675 Accuracy 89.15127726658517\n",
      "Training:: Epoch 83, Iteration 20, Current loss 0.48114899111351056 Accuracy 82.18974222694659\n",
      "Training:: Epoch 83, Iteration 30, Current loss 0.35478713548656216 Accuracy 84.76457463241604\n",
      "Training:: Epoch 83, Iteration 40, Current loss 0.49268086011987505 Accuracy 86.47058823529412\n",
      "Training:: Epoch 83, Iteration 50, Current loss 0.3784281246055424 Accuracy 89.18159236501504\n",
      "Training:: Epoch 83, Iteration 60, Current loss 0.5847115350076056 Accuracy 88.47485966798041\n",
      "Training:: Epoch 83, Iteration 70, Current loss 0.36515343958515417 Accuracy 85.77456968350916\n",
      "Training:: Epoch 83, Iteration 80, Current loss 1.1072421958271148 Accuracy 89.82425388624937\n",
      "Training:: Epoch 83, Iteration 90, Current loss 0.93936166312317 Accuracy 89.18482647296207\n",
      "Training:: Epoch 83, Iteration 100, Current loss 1.4252309324675903 Accuracy 84.71058644325971\n",
      "Training:: Epoch 83, Iteration 110, Current loss 10.035589291715887 Accuracy 52.736046617499774\n",
      "Training:: Epoch 83, Iteration 120, Current loss 4.402359084329061 Accuracy 62.67566048341765\n",
      "Training:: Epoch 83, Iteration 130, Current loss 6.879803607397616 Accuracy 57.48373101952278\n",
      "Training:: Epoch 83, Iteration 140, Current loss 4.160494046373079 Accuracy 72.29380231355215\n",
      "Training:: Epoch 83, Iteration 150, Current loss 4.142811041449034 Accuracy 68.07696765967312\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 83, Probability Accuracy 56.32245355773684\n",
      "Starting Training\n",
      "Training:: Epoch 84, Iteration 0, Current loss 2.4017780735172733 Accuracy 75.01600170684873\n",
      "Training:: Epoch 84, Iteration 10, Current loss 4.503110491036158 Accuracy 65.4663518299882\n",
      "Training:: Epoch 84, Iteration 20, Current loss 3.350031158237627 Accuracy 75.7705286839145\n",
      "Training:: Epoch 84, Iteration 30, Current loss 4.065372675794706 Accuracy 61.468144899786914\n",
      "Training:: Epoch 84, Iteration 40, Current loss 2.2963524423204675 Accuracy 73.39964024970902\n",
      "Training:: Epoch 84, Iteration 50, Current loss 1.3646165898277673 Accuracy 88.96983940462201\n",
      "Training:: Epoch 84, Iteration 60, Current loss 1.215903059503792 Accuracy 89.93808049535603\n",
      "Training:: Epoch 84, Iteration 70, Current loss 1.035277164669215 Accuracy 86.53789587214433\n",
      "Training:: Epoch 84, Iteration 80, Current loss 0.7582153942371485 Accuracy 84.4304191297391\n",
      "Training:: Epoch 84, Iteration 90, Current loss 0.8715705317041917 Accuracy 90.27321763602251\n",
      "Training:: Epoch 84, Iteration 100, Current loss 0.7922283697482941 Accuracy 88.8736934648823\n",
      "Training:: Epoch 84, Iteration 110, Current loss 2.5915573101250837 Accuracy 78.33757648845415\n",
      "Training:: Epoch 84, Iteration 120, Current loss 0.9613000855975546 Accuracy 86.36288134654781\n",
      "Training:: Epoch 84, Iteration 130, Current loss 1.2103898808656133 Accuracy 78.92765957446808\n",
      "Training:: Epoch 84, Iteration 140, Current loss 0.7995733069039829 Accuracy 90.69504699927694\n",
      "Training:: Epoch 84, Iteration 150, Current loss 0.890579200718856 Accuracy 87.28798213315628\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 84, Probability Accuracy 67.86837127024961\n",
      "Starting Training\n",
      "Training:: Epoch 85, Iteration 0, Current loss 0.70546424424958 Accuracy 88.44155844155844\n",
      "Training:: Epoch 85, Iteration 10, Current loss 0.7476429752410899 Accuracy 84.50636328576938\n",
      "Training:: Epoch 85, Iteration 20, Current loss 0.45015219970120807 Accuracy 86.9812393405344\n",
      "Training:: Epoch 85, Iteration 30, Current loss 0.6686437215043054 Accuracy 87.52007821775264\n",
      "Training:: Epoch 85, Iteration 40, Current loss 0.9634630513144427 Accuracy 87.4106562703054\n",
      "Training:: Epoch 85, Iteration 50, Current loss 0.4549089473616309 Accuracy 89.60355151765435\n",
      "Training:: Epoch 85, Iteration 60, Current loss 0.4427097220196107 Accuracy 78.97109520021215\n",
      "Training:: Epoch 85, Iteration 70, Current loss 2.9139120518183192 Accuracy 70.80167043198466\n",
      "Training:: Epoch 85, Iteration 80, Current loss 2.074459282437258 Accuracy 85.52102376599635\n",
      "Training:: Epoch 85, Iteration 90, Current loss 2.855359305904117 Accuracy 84.03437769996818\n",
      "Training:: Epoch 85, Iteration 100, Current loss 1.7336411753795065 Accuracy 79.43469785575049\n",
      "Training:: Epoch 85, Iteration 110, Current loss 0.7749782196819612 Accuracy 82.60202368963698\n",
      "Training:: Epoch 85, Iteration 120, Current loss 0.6550819115160676 Accuracy 91.97221150135083\n",
      "Training:: Epoch 85, Iteration 130, Current loss 0.843375366903188 Accuracy 79.89119875655722\n",
      "Training:: Epoch 85, Iteration 140, Current loss 0.7135787265701837 Accuracy 88.06122971381764\n",
      "Training:: Epoch 85, Iteration 150, Current loss 1.1210817876157442 Accuracy 91.35900434346809\n",
      "Calculating Expectation\n",
      "Epoch 85 iter 0\n",
      "Epoch 85 iter 10\n",
      "Epoch 85 iter 20\n",
      "Epoch 85 iter 30\n",
      "Epoch 85 iter 40\n",
      "Epoch 85 iter 50\n",
      "Epoch 85 iter 60\n",
      "Epoch 85 iter 70\n",
      "Epoch 85 iter 80\n",
      "Epoch 85 iter 90\n",
      "Epoch 85 iter 100\n",
      "Epoch 85 iter 110\n",
      "Epoch 85 iter 120\n",
      "Epoch 85 iter 130\n",
      "Epoch 85 iter 140\n",
      "Epoch 85 iter 150\n",
      "Train Boundary avergage error = 100.050\n",
      "Train From boundary avergage accuracy = 87.313\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 85, Probability Accuracy 68.0373435416097\n",
      "Starting Training\n",
      "Training:: Epoch 86, Iteration 0, Current loss 0.4076537539969233 Accuracy 88.63932068752996\n",
      "Training:: Epoch 86, Iteration 10, Current loss 0.6561789877767599 Accuracy 86.80792891319207\n",
      "Training:: Epoch 86, Iteration 20, Current loss 0.6944985442385807 Accuracy 86.11963949688027\n",
      "Training:: Epoch 86, Iteration 30, Current loss 0.5769533551543703 Accuracy 88.17620540964327\n",
      "Training:: Epoch 86, Iteration 40, Current loss 0.6500642551391657 Accuracy 89.45054945054945\n",
      "Training:: Epoch 86, Iteration 50, Current loss 0.5929215715883861 Accuracy 83.03740851179181\n",
      "Training:: Epoch 86, Iteration 60, Current loss 0.5425691926556028 Accuracy 87.6582083101809\n",
      "Training:: Epoch 86, Iteration 70, Current loss 0.48806397791382267 Accuracy 82.27652512303995\n",
      "Training:: Epoch 86, Iteration 80, Current loss 0.4822160820784095 Accuracy 89.87850787132102\n",
      "Training:: Epoch 86, Iteration 90, Current loss 0.7340985473769215 Accuracy 84.11619654778373\n",
      "Training:: Epoch 86, Iteration 100, Current loss 0.8164915511159672 Accuracy 83.41917515546908\n",
      "Training:: Epoch 86, Iteration 110, Current loss 0.7333703731455468 Accuracy 81.11317911902863\n",
      "Training:: Epoch 86, Iteration 120, Current loss 0.5708897383426288 Accuracy 86.07491250279246\n",
      "Training:: Epoch 86, Iteration 130, Current loss 0.6230983370592368 Accuracy 89.76701085517607\n",
      "Training:: Epoch 86, Iteration 140, Current loss 0.5892472644508452 Accuracy 86.02970494417863\n",
      "Training:: Epoch 86, Iteration 150, Current loss 0.3965611440496577 Accuracy 89.50989310893792\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 86, Probability Accuracy 69.11992678612285\n",
      "Starting Training\n",
      "Training:: Epoch 87, Iteration 0, Current loss 0.3722103227472594 Accuracy 91.524347660466\n",
      "Training:: Epoch 87, Iteration 10, Current loss 0.47316318610280755 Accuracy 89.94402499349128\n",
      "Training:: Epoch 87, Iteration 20, Current loss 0.3565742447138336 Accuracy 91.57980603643614\n",
      "Training:: Epoch 87, Iteration 30, Current loss 0.43522834486806494 Accuracy 83.60553417247478\n",
      "Training:: Epoch 87, Iteration 40, Current loss 0.2824178886057507 Accuracy 91.2722751761293\n",
      "Training:: Epoch 87, Iteration 50, Current loss 0.7205163495571587 Accuracy 84.77035439439243\n",
      "Training:: Epoch 87, Iteration 60, Current loss 0.5064199245654525 Accuracy 88.49845201238391\n",
      "Training:: Epoch 87, Iteration 70, Current loss 0.5590170861559838 Accuracy 84.85056681552732\n",
      "Training:: Epoch 87, Iteration 80, Current loss 0.5033223785382065 Accuracy 81.64764051479678\n",
      "Training:: Epoch 87, Iteration 90, Current loss 0.5352918462276611 Accuracy 86.99097512656834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 87, Iteration 100, Current loss 0.6376789806298289 Accuracy 84.85320862561704\n",
      "Training:: Epoch 87, Iteration 110, Current loss 0.582098515352846 Accuracy 79.98492628008856\n",
      "Training:: Epoch 87, Iteration 120, Current loss 0.47828705451393383 Accuracy 89.95684044666713\n",
      "Training:: Epoch 87, Iteration 130, Current loss 0.34590366281472823 Accuracy 91.45236855804269\n",
      "Training:: Epoch 87, Iteration 140, Current loss 0.7781249681149293 Accuracy 76.46071345301935\n",
      "Training:: Epoch 87, Iteration 150, Current loss 0.4629686284618859 Accuracy 81.75744536292605\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 87, Probability Accuracy 69.8512843120295\n",
      "Starting Training\n",
      "Training:: Epoch 88, Iteration 0, Current loss 0.360887423208672 Accuracy 85.23446658851114\n",
      "Training:: Epoch 88, Iteration 10, Current loss 0.37640106152101427 Accuracy 88.67966723320512\n",
      "Training:: Epoch 88, Iteration 20, Current loss 0.48628494984209614 Accuracy 87.5057348218382\n",
      "Training:: Epoch 88, Iteration 30, Current loss 0.3712222509500813 Accuracy 91.86349426884335\n",
      "Training:: Epoch 88, Iteration 40, Current loss 0.3167417184509778 Accuracy 84.75159509642268\n",
      "Training:: Epoch 88, Iteration 50, Current loss 0.31082692655639277 Accuracy 88.65404506003507\n",
      "Training:: Epoch 88, Iteration 60, Current loss 0.40038394843619846 Accuracy 91.95281230250684\n",
      "Training:: Epoch 88, Iteration 70, Current loss 0.4334447021822588 Accuracy 84.42752243676911\n",
      "Training:: Epoch 88, Iteration 80, Current loss 0.2693023714894322 Accuracy 89.14006588662956\n",
      "Training:: Epoch 88, Iteration 90, Current loss 0.45122667674483397 Accuracy 82.15525219805646\n",
      "Training:: Epoch 88, Iteration 100, Current loss 0.43975375048632737 Accuracy 85.894016182093\n",
      "Training:: Epoch 88, Iteration 110, Current loss 0.33864396291774146 Accuracy 89.22899416316004\n",
      "Training:: Epoch 88, Iteration 120, Current loss 0.4893187704999495 Accuracy 89.80414383777315\n",
      "Training:: Epoch 88, Iteration 130, Current loss 0.3999019546762784 Accuracy 87.37081800665615\n",
      "Training:: Epoch 88, Iteration 140, Current loss 0.30406247293607075 Accuracy 90.06101918531142\n",
      "Training:: Epoch 88, Iteration 150, Current loss 0.31084620198646506 Accuracy 90.4661216051123\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 88, Probability Accuracy 70.0818633824588\n",
      "Starting Training\n",
      "Training:: Epoch 89, Iteration 0, Current loss 0.33614489172004325 Accuracy 90.72601334017445\n",
      "Training:: Epoch 89, Iteration 10, Current loss 0.40427095574689936 Accuracy 82.88824199468422\n",
      "Training:: Epoch 89, Iteration 20, Current loss 0.3581721035915331 Accuracy 88.55964248882778\n",
      "Training:: Epoch 89, Iteration 30, Current loss 0.3160189833363655 Accuracy 87.30357702466759\n",
      "Training:: Epoch 89, Iteration 40, Current loss 0.35163284834856895 Accuracy 87.93921208014713\n",
      "Training:: Epoch 89, Iteration 50, Current loss 0.4219942827452164 Accuracy 87.06590833054533\n",
      "Training:: Epoch 89, Iteration 60, Current loss 0.24973753476490984 Accuracy 83.97615708274895\n",
      "Training:: Epoch 89, Iteration 70, Current loss 0.25270218524321875 Accuracy 89.2342609038879\n",
      "Training:: Epoch 89, Iteration 80, Current loss 0.271141908485398 Accuracy 90.34890264490714\n",
      "Training:: Epoch 89, Iteration 90, Current loss 0.25052923146911804 Accuracy 88.82142857142857\n",
      "Training:: Epoch 89, Iteration 100, Current loss 0.33152647121585666 Accuracy 86.40299305184394\n",
      "Training:: Epoch 89, Iteration 110, Current loss 0.39844245149904783 Accuracy 85.48387096774194\n",
      "Training:: Epoch 89, Iteration 120, Current loss 0.32335592217469034 Accuracy 92.66495836002562\n",
      "Training:: Epoch 89, Iteration 130, Current loss 0.38568495627962335 Accuracy 88.2626836790228\n",
      "Training:: Epoch 89, Iteration 140, Current loss 0.35578627408030655 Accuracy 88.29067061561244\n",
      "Training:: Epoch 89, Iteration 150, Current loss 0.3331376087193294 Accuracy 90.59172538009217\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 89, Probability Accuracy 69.63041500884482\n",
      "Starting Training\n",
      "Training:: Epoch 90, Iteration 0, Current loss 0.34394632135561015 Accuracy 88.49200186364342\n",
      "Training:: Epoch 90, Iteration 10, Current loss 0.4353720542737179 Accuracy 83.3990425232329\n",
      "Training:: Epoch 90, Iteration 20, Current loss 0.21143650679422574 Accuracy 86.99618411638446\n",
      "Training:: Epoch 90, Iteration 30, Current loss 0.2440450062204625 Accuracy 89.78833202134173\n",
      "Training:: Epoch 90, Iteration 40, Current loss 0.2786495791447418 Accuracy 89.5658835546476\n",
      "Training:: Epoch 90, Iteration 50, Current loss 0.556802613633968 Accuracy 82.53184299454121\n",
      "Training:: Epoch 90, Iteration 60, Current loss 0.3690485231746505 Accuracy 85.45493378897906\n",
      "Training:: Epoch 90, Iteration 70, Current loss 0.2343689992058714 Accuracy 83.60075870200441\n",
      "Training:: Epoch 90, Iteration 80, Current loss 0.2911034484674811 Accuracy 84.61281337047353\n",
      "Training:: Epoch 90, Iteration 90, Current loss 0.269848481390995 Accuracy 91.29950005395101\n",
      "Training:: Epoch 90, Iteration 100, Current loss 0.27367787128079535 Accuracy 89.37772832320465\n",
      "Training:: Epoch 90, Iteration 110, Current loss 0.2876074138712994 Accuracy 88.52695103552325\n",
      "Training:: Epoch 90, Iteration 120, Current loss 0.2714514436348731 Accuracy 84.77937530986614\n",
      "Training:: Epoch 90, Iteration 130, Current loss 0.26264815037279216 Accuracy 88.14339116265695\n",
      "Training:: Epoch 90, Iteration 140, Current loss 0.27037312597304336 Accuracy 87.42283950617283\n",
      "Training:: Epoch 90, Iteration 150, Current loss 0.25698534459924627 Accuracy 77.22702320778303\n",
      "Calculating Expectation\n",
      "Epoch 90 iter 0\n",
      "Epoch 90 iter 10\n",
      "Epoch 90 iter 20\n",
      "Epoch 90 iter 30\n",
      "Epoch 90 iter 40\n",
      "Epoch 90 iter 50\n",
      "Epoch 90 iter 60\n",
      "Epoch 90 iter 70\n",
      "Epoch 90 iter 80\n",
      "Epoch 90 iter 90\n",
      "Epoch 90 iter 100\n",
      "Epoch 90 iter 110\n",
      "Epoch 90 iter 120\n",
      "Epoch 90 iter 130\n",
      "Epoch 90 iter 140\n",
      "Epoch 90 iter 150\n",
      "Train Boundary avergage error = 100.178\n",
      "Train From boundary avergage accuracy = 87.304\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 90, Probability Accuracy 69.93588205422961\n",
      "Starting Training\n",
      "Training:: Epoch 91, Iteration 0, Current loss 0.209836832311579 Accuracy 90.48440722191827\n",
      "Training:: Epoch 91, Iteration 10, Current loss 0.23871955147136015 Accuracy 83.08723821003466\n",
      "Training:: Epoch 91, Iteration 20, Current loss 0.24004935205563246 Accuracy 88.43502112832678\n",
      "Training:: Epoch 91, Iteration 30, Current loss 0.24082217100000028 Accuracy 87.90406673618352\n",
      "Training:: Epoch 91, Iteration 40, Current loss 0.17691908099124676 Accuracy 89.56043956043956\n",
      "Training:: Epoch 91, Iteration 50, Current loss 0.25830488572968047 Accuracy 91.10646237349465\n",
      "Training:: Epoch 91, Iteration 60, Current loss 0.26798033474471616 Accuracy 86.97788697788698\n",
      "Training:: Epoch 91, Iteration 70, Current loss 0.346639805805182 Accuracy 80.4224553444854\n",
      "Training:: Epoch 91, Iteration 80, Current loss 0.21269448735596153 Accuracy 88.75935364927882\n",
      "Training:: Epoch 91, Iteration 90, Current loss 0.2508090809548258 Accuracy 82.84128054791678\n",
      "Training:: Epoch 91, Iteration 100, Current loss 0.28659294270054514 Accuracy 88.24615751221256\n",
      "Training:: Epoch 91, Iteration 110, Current loss 0.22663226630397243 Accuracy 89.27930779782632\n",
      "Training:: Epoch 91, Iteration 120, Current loss 0.14729421327499242 Accuracy 92.0646551724138\n",
      "Training:: Epoch 91, Iteration 130, Current loss 0.2441876931709234 Accuracy 88.10607105105933\n",
      "Training:: Epoch 91, Iteration 140, Current loss 0.26619699128198915 Accuracy 90.48357725770553\n",
      "Training:: Epoch 91, Iteration 150, Current loss 0.20913135782734515 Accuracy 88.15844745022264\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 91, Probability Accuracy 69.6474908064129\n",
      "Starting Training\n",
      "Training:: Epoch 92, Iteration 0, Current loss 0.2833442328935752 Accuracy 89.9858457183298\n",
      "Training:: Epoch 92, Iteration 10, Current loss 0.24978843726248037 Accuracy 88.72432697815236\n",
      "Training:: Epoch 92, Iteration 20, Current loss 0.24990529938950884 Accuracy 87.77599816954582\n",
      "Training:: Epoch 92, Iteration 30, Current loss 0.22704405172840045 Accuracy 86.78284346812296\n",
      "Training:: Epoch 92, Iteration 40, Current loss 0.25546065893207287 Accuracy 94.17136334451024\n",
      "Training:: Epoch 92, Iteration 50, Current loss 0.2417156703447916 Accuracy 89.03446048807491\n",
      "Training:: Epoch 92, Iteration 60, Current loss 0.20242110496624355 Accuracy 91.89749765823632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 92, Iteration 70, Current loss 0.298840816914285 Accuracy 81.24718932693749\n",
      "Training:: Epoch 92, Iteration 80, Current loss 0.23195890042385953 Accuracy 88.68007232480412\n",
      "Training:: Epoch 92, Iteration 90, Current loss 0.22655158542521814 Accuracy 91.38502319416833\n",
      "Training:: Epoch 92, Iteration 100, Current loss 0.31768234676528984 Accuracy 86.1317100166021\n",
      "Training:: Epoch 92, Iteration 110, Current loss 0.2799369393194526 Accuracy 84.76656439174062\n",
      "Training:: Epoch 92, Iteration 120, Current loss 0.19574841360989584 Accuracy 85.0445717924228\n",
      "Training:: Epoch 92, Iteration 130, Current loss 0.31907132182010733 Accuracy 82.46563931695127\n",
      "Training:: Epoch 92, Iteration 140, Current loss 0.32574741835372745 Accuracy 88.33834992668056\n",
      "Training:: Epoch 92, Iteration 150, Current loss 0.3577308456267755 Accuracy 84.81336287710926\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 92, Probability Accuracy 69.9896763968951\n",
      "Starting Training\n",
      "Training:: Epoch 93, Iteration 0, Current loss 0.3177306236663667 Accuracy 85.95304055588356\n",
      "Training:: Epoch 93, Iteration 10, Current loss 0.26200305314851235 Accuracy 89.81752251725348\n",
      "Training:: Epoch 93, Iteration 20, Current loss 0.24346257550314448 Accuracy 84.41777928004056\n",
      "Training:: Epoch 93, Iteration 30, Current loss 0.2802621765671 Accuracy 83.41382432840327\n",
      "Training:: Epoch 93, Iteration 40, Current loss 0.20289402573615337 Accuracy 89.20980522846774\n",
      "Training:: Epoch 93, Iteration 50, Current loss 0.19802505953845784 Accuracy 89.87210508123056\n",
      "Training:: Epoch 93, Iteration 60, Current loss 0.25216671570464017 Accuracy 91.510099673635\n",
      "Training:: Epoch 93, Iteration 70, Current loss 0.29055428857734317 Accuracy 73.92290249433107\n",
      "Training:: Epoch 93, Iteration 80, Current loss 0.2047067400638298 Accuracy 84.3168675538215\n",
      "Training:: Epoch 93, Iteration 90, Current loss 0.1680701404278291 Accuracy 88.01487414187643\n",
      "Training:: Epoch 93, Iteration 100, Current loss 0.18724615167965672 Accuracy 88.95037550756405\n",
      "Training:: Epoch 93, Iteration 110, Current loss 0.35913746274664027 Accuracy 83.89466389466389\n",
      "Training:: Epoch 93, Iteration 120, Current loss 0.2677267681229414 Accuracy 79.66113811838719\n",
      "Training:: Epoch 93, Iteration 130, Current loss 0.2580081166468211 Accuracy 86.52793614595211\n",
      "Training:: Epoch 93, Iteration 140, Current loss 0.22559334197522077 Accuracy 86.53837149412371\n",
      "Training:: Epoch 93, Iteration 150, Current loss 0.19143204283422635 Accuracy 88.0896810241177\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 93, Probability Accuracy 69.60965619611498\n",
      "Starting Training\n",
      "Training:: Epoch 94, Iteration 0, Current loss 0.35421430632944995 Accuracy 85.69871545348384\n",
      "Training:: Epoch 94, Iteration 10, Current loss 0.23342045575104137 Accuracy 89.06654343807763\n",
      "Training:: Epoch 94, Iteration 20, Current loss 0.2924000629867563 Accuracy 85.58778981708028\n",
      "Training:: Epoch 94, Iteration 30, Current loss 0.22420628042162874 Accuracy 89.00242901415528\n",
      "Training:: Epoch 94, Iteration 40, Current loss 0.2108387190784491 Accuracy 89.975177705066\n",
      "Training:: Epoch 94, Iteration 50, Current loss 0.3631585099174454 Accuracy 84.84235373461473\n",
      "Training:: Epoch 94, Iteration 60, Current loss 0.3415848602438842 Accuracy 88.64940696339752\n",
      "Training:: Epoch 94, Iteration 70, Current loss 0.18841583122308128 Accuracy 90.60865694892622\n",
      "Training:: Epoch 94, Iteration 80, Current loss 0.2077571422130373 Accuracy 89.56150562669771\n",
      "Training:: Epoch 94, Iteration 90, Current loss 0.2425254031884989 Accuracy 84.19344870210136\n",
      "Training:: Epoch 94, Iteration 100, Current loss 0.18788381340588964 Accuracy 85.92395195290749\n",
      "Training:: Epoch 94, Iteration 110, Current loss 0.20763675200473158 Accuracy 88.4221799143265\n",
      "Training:: Epoch 94, Iteration 120, Current loss 0.18917542526125147 Accuracy 91.36378086256225\n",
      "Training:: Epoch 94, Iteration 130, Current loss 0.28375148812534845 Accuracy 82.85774087769482\n",
      "Training:: Epoch 94, Iteration 140, Current loss 0.26116194373011087 Accuracy 90.05242825607064\n",
      "Training:: Epoch 94, Iteration 150, Current loss 0.21380523116390854 Accuracy 87.40873333647369\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 94, Probability Accuracy 69.70351727947947\n",
      "Starting Training\n",
      "Training:: Epoch 95, Iteration 0, Current loss 0.27222414705530734 Accuracy 84.98896247240619\n",
      "Training:: Epoch 95, Iteration 10, Current loss 0.20645910696616632 Accuracy 89.0574518893103\n",
      "Training:: Epoch 95, Iteration 20, Current loss 0.3702231808256044 Accuracy 83.78928170594837\n",
      "Training:: Epoch 95, Iteration 30, Current loss 0.1943921790158999 Accuracy 91.60402599057204\n",
      "Training:: Epoch 95, Iteration 40, Current loss 0.2652327312673652 Accuracy 87.52588622243879\n",
      "Training:: Epoch 95, Iteration 50, Current loss 0.23344750078782964 Accuracy 74.47634392851911\n",
      "Training:: Epoch 95, Iteration 60, Current loss 0.20709862970879023 Accuracy 88.59423811176674\n",
      "Training:: Epoch 95, Iteration 70, Current loss 0.20757143768370626 Accuracy 89.2393762647304\n",
      "Training:: Epoch 95, Iteration 80, Current loss 0.25236856560759174 Accuracy 89.02602230483271\n",
      "Training:: Epoch 95, Iteration 90, Current loss 0.18708191328663437 Accuracy 91.9402325923745\n",
      "Training:: Epoch 95, Iteration 100, Current loss 0.2516489869725513 Accuracy 89.89661173098577\n",
      "Training:: Epoch 95, Iteration 110, Current loss 0.2060615110953463 Accuracy 89.42135490644105\n",
      "Training:: Epoch 95, Iteration 120, Current loss 0.2223470830074254 Accuracy 90.13655277501026\n",
      "Training:: Epoch 95, Iteration 130, Current loss 0.2230022591229609 Accuracy 87.7564472274862\n",
      "Training:: Epoch 95, Iteration 140, Current loss 0.21897059060751495 Accuracy 90.74346353001343\n",
      "Training:: Epoch 95, Iteration 150, Current loss 0.24929089932353146 Accuracy 84.17892687148421\n",
      "Calculating Expectation\n",
      "Epoch 95 iter 0\n",
      "Epoch 95 iter 10\n",
      "Epoch 95 iter 20\n",
      "Epoch 95 iter 30\n",
      "Epoch 95 iter 40\n",
      "Epoch 95 iter 50\n",
      "Epoch 95 iter 60\n",
      "Epoch 95 iter 70\n",
      "Epoch 95 iter 80\n",
      "Epoch 95 iter 90\n",
      "Epoch 95 iter 100\n",
      "Epoch 95 iter 110\n",
      "Epoch 95 iter 120\n",
      "Epoch 95 iter 130\n",
      "Epoch 95 iter 140\n",
      "Epoch 95 iter 150\n",
      "Train Boundary avergage error = 100.351\n",
      "Train From boundary avergage accuracy = 87.270\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 95, Probability Accuracy 69.8297442536593\n",
      "Starting Training\n",
      "Training:: Epoch 96, Iteration 0, Current loss 0.1680711669101452 Accuracy 91.19947064485082\n",
      "Training:: Epoch 96, Iteration 10, Current loss 0.22045386405110406 Accuracy 88.45407775997302\n",
      "Training:: Epoch 96, Iteration 20, Current loss 0.2231191651467415 Accuracy 85.41749502982107\n",
      "Training:: Epoch 96, Iteration 30, Current loss 0.21867129303361837 Accuracy 88.15879962488277\n",
      "Training:: Epoch 96, Iteration 40, Current loss 0.2658382199973257 Accuracy 83.59236671257132\n",
      "Training:: Epoch 96, Iteration 50, Current loss 0.18088766047573668 Accuracy 89.30021406953568\n",
      "Training:: Epoch 96, Iteration 60, Current loss 0.2760919644220958 Accuracy 87.42615467239527\n",
      "Training:: Epoch 96, Iteration 70, Current loss 0.2340447573672823 Accuracy 88.5977522216414\n",
      "Training:: Epoch 96, Iteration 80, Current loss 0.2877677615517213 Accuracy 85.288926843154\n",
      "Training:: Epoch 96, Iteration 90, Current loss 0.24176411622357924 Accuracy 87.40237346586875\n",
      "Training:: Epoch 96, Iteration 100, Current loss 0.20949862002767822 Accuracy 87.18758338521747\n",
      "Training:: Epoch 96, Iteration 110, Current loss 0.3045874462964391 Accuracy 85.72834000131174\n",
      "Training:: Epoch 96, Iteration 120, Current loss 0.18440726682871075 Accuracy 89.33700570529216\n",
      "Training:: Epoch 96, Iteration 130, Current loss 0.2216445506159958 Accuracy 86.43660531697341\n",
      "Training:: Epoch 96, Iteration 140, Current loss 0.27856826329059636 Accuracy 78.05583250249252\n",
      "Training:: Epoch 96, Iteration 150, Current loss 0.18440929417862262 Accuracy 85.71545749087478\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 96, Probability Accuracy 69.71880737272672\n",
      "Starting Training\n",
      "Training:: Epoch 97, Iteration 0, Current loss 0.30812502203258474 Accuracy 78.56775916983459\n",
      "Training:: Epoch 97, Iteration 10, Current loss 0.15999230753454402 Accuracy 89.58004248597418\n",
      "Training:: Epoch 97, Iteration 20, Current loss 0.24198469521414734 Accuracy 85.87857715966837\n",
      "Training:: Epoch 97, Iteration 30, Current loss 0.21995729255822968 Accuracy 89.01771336553945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 97, Iteration 40, Current loss 0.22814961414160018 Accuracy 86.15058324496289\n",
      "Training:: Epoch 97, Iteration 50, Current loss 0.3263257063244444 Accuracy 82.9226431286012\n",
      "Training:: Epoch 97, Iteration 60, Current loss 0.24396088203828897 Accuracy 84.41743086656714\n",
      "Training:: Epoch 97, Iteration 70, Current loss 0.22085486644844576 Accuracy 82.02174788562223\n",
      "Training:: Epoch 97, Iteration 80, Current loss 0.23078766023321165 Accuracy 88.33208302075519\n",
      "Training:: Epoch 97, Iteration 90, Current loss 0.2306113312257225 Accuracy 89.9465093951447\n",
      "Training:: Epoch 97, Iteration 100, Current loss 0.5433882041545253 Accuracy 79.02846389084921\n",
      "Training:: Epoch 97, Iteration 110, Current loss 0.24408744122297224 Accuracy 88.94368170355843\n",
      "Training:: Epoch 97, Iteration 120, Current loss 0.4020965428712281 Accuracy 87.43840438013297\n",
      "Training:: Epoch 97, Iteration 130, Current loss 0.26213124509425995 Accuracy 89.35575556608242\n",
      "Training:: Epoch 97, Iteration 140, Current loss 0.2740330821768089 Accuracy 89.2175332830947\n",
      "Training:: Epoch 97, Iteration 150, Current loss 0.1896491494686069 Accuracy 86.49924729711236\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 97, Probability Accuracy 69.28856423792278\n",
      "Starting Training\n",
      "Training:: Epoch 98, Iteration 0, Current loss 0.2207041564050174 Accuracy 87.12334171721655\n",
      "Training:: Epoch 98, Iteration 10, Current loss 0.36796049374766965 Accuracy 80.48359240069085\n",
      "Training:: Epoch 98, Iteration 20, Current loss 0.20976204784720473 Accuracy 88.71758604431872\n",
      "Training:: Epoch 98, Iteration 30, Current loss 0.18942117025740912 Accuracy 89.26258818981347\n",
      "Training:: Epoch 98, Iteration 40, Current loss 0.20167996281391157 Accuracy 87.13654223968565\n",
      "Training:: Epoch 98, Iteration 50, Current loss 0.38539995518683107 Accuracy 87.55106760194249\n",
      "Training:: Epoch 98, Iteration 60, Current loss 0.33419705272228983 Accuracy 84.6943887775551\n",
      "Training:: Epoch 98, Iteration 70, Current loss 0.24332047872673948 Accuracy 88.0126881085866\n",
      "Training:: Epoch 98, Iteration 80, Current loss 0.3687812669118706 Accuracy 86.64697722289345\n",
      "Training:: Epoch 98, Iteration 90, Current loss 0.6883503881018551 Accuracy 90.17922649617441\n",
      "Training:: Epoch 98, Iteration 100, Current loss 1.0770119547066588 Accuracy 78.35361684671133\n",
      "Training:: Epoch 98, Iteration 110, Current loss 0.5818049209905323 Accuracy 81.25620381603618\n",
      "Training:: Epoch 98, Iteration 120, Current loss 0.38636624019758414 Accuracy 75.86685159500693\n",
      "Training:: Epoch 98, Iteration 130, Current loss 0.29224267640207013 Accuracy 92.29649987874869\n",
      "Training:: Epoch 98, Iteration 140, Current loss 0.35191624081773587 Accuracy 89.9574972818029\n",
      "Training:: Epoch 98, Iteration 150, Current loss 0.5880347516280467 Accuracy 84.79072885738914\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 98, Probability Accuracy 62.633913873248474\n",
      "Starting Training\n",
      "Training:: Epoch 99, Iteration 0, Current loss 1.229703372802191 Accuracy 78.75487563953193\n",
      "Training:: Epoch 99, Iteration 10, Current loss 1.9658323723986884 Accuracy 80.47363324236288\n",
      "Training:: Epoch 99, Iteration 20, Current loss 1.4248279606104404 Accuracy 85.60408921933086\n",
      "Training:: Epoch 99, Iteration 30, Current loss 2.0426085112932983 Accuracy 79.40089228808158\n",
      "Training:: Epoch 99, Iteration 40, Current loss 2.625687129925285 Accuracy 78.15357816809406\n",
      "Training:: Epoch 99, Iteration 50, Current loss 6.0370026784276485 Accuracy 71.3926742050836\n",
      "Training:: Epoch 99, Iteration 60, Current loss 1.3920541648625837 Accuracy 79.00791872105185\n",
      "Training:: Epoch 99, Iteration 70, Current loss 3.135251911919064 Accuracy 75.48751282928498\n",
      "Training:: Epoch 99, Iteration 80, Current loss 1.8938036520913673 Accuracy 79.17191499735891\n",
      "Training:: Epoch 99, Iteration 90, Current loss 1.139443113949706 Accuracy 86.03864053024961\n",
      "Training:: Epoch 99, Iteration 100, Current loss 1.4636002524983394 Accuracy 86.22380193651183\n",
      "Training:: Epoch 99, Iteration 110, Current loss 0.8588679115162052 Accuracy 87.27836879432624\n",
      "Training:: Epoch 99, Iteration 120, Current loss 1.5779268753542897 Accuracy 86.1433896075422\n",
      "Training:: Epoch 99, Iteration 130, Current loss 0.9613312789728581 Accuracy 85.31661058427653\n",
      "Training:: Epoch 99, Iteration 140, Current loss 0.7546395661791621 Accuracy 76.85032894736842\n",
      "Training:: Epoch 99, Iteration 150, Current loss 0.541925734235791 Accuracy 90.27371650448205\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 99, Probability Accuracy 69.68007991026836\n",
      "Starting Training\n",
      "Training:: Epoch 100, Iteration 0, Current loss 0.4672211232278055 Accuracy 88.19317235636969\n",
      "Training:: Epoch 100, Iteration 10, Current loss 0.4178066293343099 Accuracy 85.49661048572672\n",
      "Training:: Epoch 100, Iteration 20, Current loss 0.5126725764673639 Accuracy 91.95822185634904\n",
      "Training:: Epoch 100, Iteration 30, Current loss 0.3186010907965943 Accuracy 88.14574898785425\n",
      "Training:: Epoch 100, Iteration 40, Current loss 0.3398332460211698 Accuracy 88.91421816953732\n",
      "Training:: Epoch 100, Iteration 50, Current loss 0.4425714333742837 Accuracy 84.81458025473225\n",
      "Training:: Epoch 100, Iteration 60, Current loss 0.4291199007906801 Accuracy 88.18555758683729\n",
      "Training:: Epoch 100, Iteration 70, Current loss 0.4657010832800245 Accuracy 84.10336726703211\n",
      "Training:: Epoch 100, Iteration 80, Current loss 0.39159883629818126 Accuracy 80.87950080107935\n",
      "Training:: Epoch 100, Iteration 90, Current loss 0.37362489421223044 Accuracy 88.15488617158763\n",
      "Training:: Epoch 100, Iteration 100, Current loss 0.3878233787111247 Accuracy 89.1934607596187\n",
      "Training:: Epoch 100, Iteration 110, Current loss 0.3127326127588683 Accuracy 89.87685243164266\n",
      "Training:: Epoch 100, Iteration 120, Current loss 0.5799820251424475 Accuracy 84.3204653622422\n",
      "Training:: Epoch 100, Iteration 130, Current loss 1.3153689898870327 Accuracy 82.48708102214005\n",
      "Training:: Epoch 100, Iteration 140, Current loss 0.3693637128562549 Accuracy 89.16122794295383\n",
      "Training:: Epoch 100, Iteration 150, Current loss 0.29237689613772866 Accuracy 90.33827618164968\n",
      "Calculating Expectation\n",
      "Epoch 100 iter 0\n",
      "Epoch 100 iter 10\n",
      "Epoch 100 iter 20\n",
      "Epoch 100 iter 30\n",
      "Epoch 100 iter 40\n",
      "Epoch 100 iter 50\n",
      "Epoch 100 iter 60\n",
      "Epoch 100 iter 70\n",
      "Epoch 100 iter 80\n",
      "Epoch 100 iter 90\n",
      "Epoch 100 iter 100\n",
      "Epoch 100 iter 110\n",
      "Epoch 100 iter 120\n",
      "Epoch 100 iter 130\n",
      "Epoch 100 iter 140\n",
      "Epoch 100 iter 150\n",
      "Train Boundary avergage error = 102.469\n",
      "Train From boundary avergage accuracy = 87.203\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 100, Probability Accuracy 69.71981183140718\n",
      "Starting Training\n",
      "Training:: Epoch 101, Iteration 0, Current loss 0.47443156873293046 Accuracy 89.01277496409404\n",
      "Training:: Epoch 101, Iteration 10, Current loss 0.25465124275795464 Accuracy 88.91284910324515\n",
      "Training:: Epoch 101, Iteration 20, Current loss 0.27634142153004115 Accuracy 89.62185375164023\n",
      "Training:: Epoch 101, Iteration 30, Current loss 0.2448255694086186 Accuracy 91.73744127213588\n",
      "Training:: Epoch 101, Iteration 40, Current loss 0.2837899085913528 Accuracy 88.75477329587851\n",
      "Training:: Epoch 101, Iteration 50, Current loss 0.3072120529523977 Accuracy 87.58291685597456\n",
      "Training:: Epoch 101, Iteration 60, Current loss 0.25573793099281306 Accuracy 85.46259116610669\n",
      "Training:: Epoch 101, Iteration 70, Current loss 0.32368201538708224 Accuracy 78.10233416853488\n",
      "Training:: Epoch 101, Iteration 80, Current loss 0.40360065564689795 Accuracy 82.90330133458207\n",
      "Training:: Epoch 101, Iteration 90, Current loss 0.27049398446068984 Accuracy 87.6479670612455\n",
      "Training:: Epoch 101, Iteration 100, Current loss 0.44250906852263744 Accuracy 84.92528976399944\n",
      "Training:: Epoch 101, Iteration 110, Current loss 0.3042043178396286 Accuracy 85.32682705401724\n",
      "Training:: Epoch 101, Iteration 120, Current loss 0.2431765893935083 Accuracy 90.22154316271963\n",
      "Training:: Epoch 101, Iteration 130, Current loss 0.2909344924918986 Accuracy 80.76167861546189\n",
      "Training:: Epoch 101, Iteration 140, Current loss 0.31839675372409837 Accuracy 88.84909264565425\n",
      "Training:: Epoch 101, Iteration 150, Current loss 0.2798225477243879 Accuracy 77.5197628458498\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 101, Probability Accuracy 69.7128922271639\n",
      "Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 102, Iteration 0, Current loss 0.3177907557146252 Accuracy 86.00267891312667\n",
      "Training:: Epoch 102, Iteration 10, Current loss 0.2660973645735235 Accuracy 82.63384005287509\n",
      "Training:: Epoch 102, Iteration 20, Current loss 0.41947640149538806 Accuracy 86.32923954844313\n",
      "Training:: Epoch 102, Iteration 30, Current loss 0.21162231018324923 Accuracy 89.71903863823202\n",
      "Training:: Epoch 102, Iteration 40, Current loss 0.23765063570882686 Accuracy 87.49656499038197\n",
      "Training:: Epoch 102, Iteration 50, Current loss 0.2520681476352024 Accuracy 89.19210053859965\n",
      "Training:: Epoch 102, Iteration 60, Current loss 0.232453817292341 Accuracy 89.90585774058577\n",
      "Training:: Epoch 102, Iteration 70, Current loss 0.22747213192496124 Accuracy 87.22054535222796\n",
      "Training:: Epoch 102, Iteration 80, Current loss 0.2172201842281882 Accuracy 87.1563425894026\n",
      "Training:: Epoch 102, Iteration 90, Current loss 0.330595685917359 Accuracy 85.19652565144035\n",
      "Training:: Epoch 102, Iteration 100, Current loss 0.19712040037808612 Accuracy 85.46174028990494\n",
      "Training:: Epoch 102, Iteration 110, Current loss 0.2064131104274037 Accuracy 89.54478842278806\n",
      "Training:: Epoch 102, Iteration 120, Current loss 0.22208774389708713 Accuracy 82.59261399757267\n",
      "Training:: Epoch 102, Iteration 130, Current loss 0.2550084625655484 Accuracy 90.75021036960321\n",
      "Training:: Epoch 102, Iteration 140, Current loss 0.2145913523179235 Accuracy 89.23811161750795\n",
      "Training:: Epoch 102, Iteration 150, Current loss 0.32816540984194587 Accuracy 89.9478059153296\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 102, Probability Accuracy 70.73543116388859\n",
      "Starting Training\n",
      "Training:: Epoch 103, Iteration 0, Current loss 0.3273196162455505 Accuracy 87.6179822414878\n",
      "Training:: Epoch 103, Iteration 10, Current loss 0.32603943042592415 Accuracy 89.84158913754086\n",
      "Training:: Epoch 103, Iteration 20, Current loss 0.24595245896131535 Accuracy 89.70792767732962\n",
      "Training:: Epoch 103, Iteration 30, Current loss 0.2502916720149295 Accuracy 88.37293575606978\n",
      "Training:: Epoch 103, Iteration 40, Current loss 0.21415252245864888 Accuracy 89.70457902511079\n",
      "Training:: Epoch 103, Iteration 50, Current loss 0.24545218874880276 Accuracy 90.28976328081704\n",
      "Training:: Epoch 103, Iteration 60, Current loss 0.2715474286565121 Accuracy 89.4161032575292\n",
      "Training:: Epoch 103, Iteration 70, Current loss 0.24114171474554172 Accuracy 90.48726982649737\n",
      "Training:: Epoch 103, Iteration 80, Current loss 0.28756165212977935 Accuracy 88.96885813148789\n",
      "Training:: Epoch 103, Iteration 90, Current loss 0.35415059592800124 Accuracy 85.96536241180243\n",
      "Training:: Epoch 103, Iteration 100, Current loss 0.19125987624147314 Accuracy 90.37755493451697\n",
      "Training:: Epoch 103, Iteration 110, Current loss 0.21265931935319582 Accuracy 91.86166997668595\n",
      "Training:: Epoch 103, Iteration 120, Current loss 0.30466821722549325 Accuracy 86.69590643274854\n",
      "Training:: Epoch 103, Iteration 130, Current loss 0.22678313325260965 Accuracy 88.72033998347302\n",
      "Training:: Epoch 103, Iteration 140, Current loss 0.24701865923926533 Accuracy 92.8176440329218\n",
      "Training:: Epoch 103, Iteration 150, Current loss 0.19933711586682448 Accuracy 93.40836754462845\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 103, Probability Accuracy 70.11489891239447\n",
      "Starting Training\n",
      "Training:: Epoch 104, Iteration 0, Current loss 0.24718844749800462 Accuracy 84.0225156960381\n",
      "Training:: Epoch 104, Iteration 10, Current loss 0.3940158982262359 Accuracy 80.833815865663\n",
      "Training:: Epoch 104, Iteration 20, Current loss 0.22490400434364588 Accuracy 82.31066512983931\n",
      "Training:: Epoch 104, Iteration 30, Current loss 0.3371766118635334 Accuracy 85.16230968112612\n",
      "Training:: Epoch 104, Iteration 40, Current loss 0.2152883565644617 Accuracy 90.92133455769819\n",
      "Training:: Epoch 104, Iteration 50, Current loss 0.2875461995024967 Accuracy 91.10513639164286\n",
      "Training:: Epoch 104, Iteration 60, Current loss 0.2018903333542061 Accuracy 87.92924037460978\n",
      "Training:: Epoch 104, Iteration 70, Current loss 0.28335036572502753 Accuracy 84.12077697288288\n",
      "Training:: Epoch 104, Iteration 80, Current loss 0.35491429096034227 Accuracy 81.67072181670721\n",
      "Training:: Epoch 104, Iteration 90, Current loss 0.3072707255927722 Accuracy 77.0035505959929\n",
      "Training:: Epoch 104, Iteration 100, Current loss 0.18407871002870702 Accuracy 93.21002877106453\n",
      "Training:: Epoch 104, Iteration 110, Current loss 0.24500731711925344 Accuracy 88.52168601099572\n",
      "Training:: Epoch 104, Iteration 120, Current loss 0.2447183824099175 Accuracy 71.72308679608535\n",
      "Training:: Epoch 104, Iteration 130, Current loss 0.23005664689601332 Accuracy 92.98549012991396\n",
      "Training:: Epoch 104, Iteration 140, Current loss 0.20211898374755904 Accuracy 85.36585365853658\n",
      "Training:: Epoch 104, Iteration 150, Current loss 0.22289131456441877 Accuracy 88.74265569917743\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 104, Probability Accuracy 70.17282269630192\n",
      "Starting Training\n",
      "Training:: Epoch 105, Iteration 0, Current loss 0.25779099808060607 Accuracy 88.7841103318206\n",
      "Training:: Epoch 105, Iteration 10, Current loss 0.1897989189319226 Accuracy 83.75493304004658\n",
      "Training:: Epoch 105, Iteration 20, Current loss 0.22378123385896642 Accuracy 88.03886684001642\n",
      "Training:: Epoch 105, Iteration 30, Current loss 0.2578880851211012 Accuracy 65.66408105113187\n",
      "Training:: Epoch 105, Iteration 40, Current loss 0.21434203678550331 Accuracy 89.07178783721993\n",
      "Training:: Epoch 105, Iteration 50, Current loss 0.27240360427466903 Accuracy 83.29635792198188\n",
      "Training:: Epoch 105, Iteration 60, Current loss 0.1870599681875195 Accuracy 84.75673617061791\n",
      "Training:: Epoch 105, Iteration 70, Current loss 0.18457564015408168 Accuracy 88.800832532821\n",
      "Training:: Epoch 105, Iteration 80, Current loss 0.21582075353112926 Accuracy 73.69229456438262\n",
      "Training:: Epoch 105, Iteration 90, Current loss 0.20977235878267436 Accuracy 89.73780841332217\n",
      "Training:: Epoch 105, Iteration 100, Current loss 0.23547752455510468 Accuracy 87.89390659965515\n",
      "Training:: Epoch 105, Iteration 110, Current loss 0.24574224946969772 Accuracy 88.22023887649299\n",
      "Training:: Epoch 105, Iteration 120, Current loss 0.214156413552469 Accuracy 80.18150343597544\n",
      "Training:: Epoch 105, Iteration 130, Current loss 0.19276625088115218 Accuracy 90.16781931614838\n",
      "Training:: Epoch 105, Iteration 140, Current loss 0.1994791455379796 Accuracy 75.10333480476744\n",
      "Training:: Epoch 105, Iteration 150, Current loss 0.1943997584952895 Accuracy 90.48600056185036\n",
      "Calculating Expectation\n",
      "Epoch 105 iter 0\n",
      "Epoch 105 iter 10\n",
      "Epoch 105 iter 20\n",
      "Epoch 105 iter 30\n",
      "Epoch 105 iter 40\n",
      "Epoch 105 iter 50\n",
      "Epoch 105 iter 60\n",
      "Epoch 105 iter 70\n",
      "Epoch 105 iter 80\n",
      "Epoch 105 iter 90\n",
      "Epoch 105 iter 100\n",
      "Epoch 105 iter 110\n",
      "Epoch 105 iter 120\n",
      "Epoch 105 iter 130\n",
      "Epoch 105 iter 140\n",
      "Epoch 105 iter 150\n",
      "Train Boundary avergage error = 102.569\n",
      "Train From boundary avergage accuracy = 87.094\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 105, Probability Accuracy 70.47148174396348\n",
      "Starting Training\n",
      "Training:: Epoch 106, Iteration 0, Current loss 0.19473997139866187 Accuracy 85.96480433177454\n",
      "Training:: Epoch 106, Iteration 10, Current loss 0.21437515416454456 Accuracy 85.82899305555556\n",
      "Training:: Epoch 106, Iteration 20, Current loss 0.23437599031808354 Accuracy 87.54847928148602\n",
      "Training:: Epoch 106, Iteration 30, Current loss 0.15871547387074147 Accuracy 87.7372157033174\n",
      "Training:: Epoch 106, Iteration 40, Current loss 0.19253540391715393 Accuracy 88.09958506224066\n",
      "Training:: Epoch 106, Iteration 50, Current loss 0.23557500507568566 Accuracy 80.34896254378873\n",
      "Training:: Epoch 106, Iteration 60, Current loss 0.23269712460811484 Accuracy 92.71173420395621\n",
      "Training:: Epoch 106, Iteration 70, Current loss 0.12895532925101086 Accuracy 91.71700700441018\n",
      "Training:: Epoch 106, Iteration 80, Current loss 0.14959191263346774 Accuracy 87.63755895383736\n",
      "Training:: Epoch 106, Iteration 90, Current loss 0.1958836502102681 Accuracy 89.85775719483956\n",
      "Training:: Epoch 106, Iteration 100, Current loss 0.19783762305202174 Accuracy 87.9488950276243\n",
      "Training:: Epoch 106, Iteration 110, Current loss 0.2221278983828224 Accuracy 86.40791476407915\n",
      "Training:: Epoch 106, Iteration 120, Current loss 0.2523191978286785 Accuracy 84.94588744588745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 106, Iteration 130, Current loss 0.2613301306588092 Accuracy 85.93120128997582\n",
      "Training:: Epoch 106, Iteration 140, Current loss 0.21777245826005642 Accuracy 88.61648890461507\n",
      "Training:: Epoch 106, Iteration 150, Current loss 0.21354171749863046 Accuracy 87.7673051586095\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 106, Probability Accuracy 70.27750961211154\n",
      "Starting Training\n",
      "Training:: Epoch 107, Iteration 0, Current loss 0.200488073836741 Accuracy 89.13959978623598\n",
      "Training:: Epoch 107, Iteration 10, Current loss 0.20804323760918703 Accuracy 84.11965811965813\n",
      "Training:: Epoch 107, Iteration 20, Current loss 0.23598854346350362 Accuracy 91.1188369152971\n",
      "Training:: Epoch 107, Iteration 30, Current loss 0.2191636101072333 Accuracy 85.00958689210388\n",
      "Training:: Epoch 107, Iteration 40, Current loss 0.15538033361619813 Accuracy 89.00225772837791\n",
      "Training:: Epoch 107, Iteration 50, Current loss 0.13373628363793533 Accuracy 88.722512193035\n",
      "Training:: Epoch 107, Iteration 60, Current loss 0.21345909203806618 Accuracy 84.2874251497006\n",
      "Training:: Epoch 107, Iteration 70, Current loss 0.15303803606579802 Accuracy 88.6810249960698\n",
      "Training:: Epoch 107, Iteration 80, Current loss 0.21349963713345432 Accuracy 86.16497477357\n",
      "Training:: Epoch 107, Iteration 90, Current loss 0.1596276835309577 Accuracy 91.00972647643613\n",
      "Training:: Epoch 107, Iteration 100, Current loss 0.1854367989476325 Accuracy 88.57837181044957\n",
      "Training:: Epoch 107, Iteration 110, Current loss 0.2567114944912215 Accuracy 83.44186046511628\n",
      "Training:: Epoch 107, Iteration 120, Current loss 0.1908316160650061 Accuracy 87.2947560462179\n",
      "Training:: Epoch 107, Iteration 130, Current loss 0.20173620011663385 Accuracy 90.75094940585569\n",
      "Training:: Epoch 107, Iteration 140, Current loss 0.23498552571180154 Accuracy 87.02908245898176\n",
      "Training:: Epoch 107, Iteration 150, Current loss 0.20758934279836655 Accuracy 91.5401694684852\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 107, Probability Accuracy 70.32650487441477\n",
      "Starting Training\n",
      "Training:: Epoch 108, Iteration 0, Current loss 0.2224443898901976 Accuracy 87.65488756310233\n",
      "Training:: Epoch 108, Iteration 10, Current loss 0.23292422642592642 Accuracy 88.01396942540853\n",
      "Training:: Epoch 108, Iteration 20, Current loss 0.28083233658770107 Accuracy 87.23576796237228\n",
      "Training:: Epoch 108, Iteration 30, Current loss 0.22751450713254187 Accuracy 89.35513073113584\n",
      "Training:: Epoch 108, Iteration 40, Current loss 0.16292107979756223 Accuracy 86.91175287587483\n",
      "Training:: Epoch 108, Iteration 50, Current loss 0.33703392803421395 Accuracy 83.66995459527165\n",
      "Training:: Epoch 108, Iteration 60, Current loss 0.23403968282235418 Accuracy 92.76468906945408\n",
      "Training:: Epoch 108, Iteration 70, Current loss 0.1353572073744095 Accuracy 90.99555083880975\n",
      "Training:: Epoch 108, Iteration 80, Current loss 0.15481785441439253 Accuracy 87.51867146999385\n",
      "Training:: Epoch 108, Iteration 90, Current loss 0.20185846745772176 Accuracy 89.86154533273783\n",
      "Training:: Epoch 108, Iteration 100, Current loss 0.20958768156673446 Accuracy 83.55835159397752\n",
      "Training:: Epoch 108, Iteration 110, Current loss 0.2662278369972573 Accuracy 83.98912259281869\n",
      "Training:: Epoch 108, Iteration 120, Current loss 0.30566000940464205 Accuracy 79.79686638847335\n",
      "Training:: Epoch 108, Iteration 130, Current loss 0.20900413972666462 Accuracy 84.90281634272114\n",
      "Training:: Epoch 108, Iteration 140, Current loss 0.2608949347672934 Accuracy 77.4078052273541\n",
      "Training:: Epoch 108, Iteration 150, Current loss 0.23562007295563087 Accuracy 84.68284954450291\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 108, Probability Accuracy 70.06802417397225\n",
      "Starting Training\n",
      "Training:: Epoch 109, Iteration 0, Current loss 0.18406158609270099 Accuracy 90.24065594718347\n",
      "Training:: Epoch 109, Iteration 10, Current loss 0.2038643331780367 Accuracy 84.75279555524298\n",
      "Training:: Epoch 109, Iteration 20, Current loss 0.1789772969200265 Accuracy 90.03540191586839\n",
      "Training:: Epoch 109, Iteration 30, Current loss 0.2132366537159867 Accuracy 88.05486628067273\n",
      "Training:: Epoch 109, Iteration 40, Current loss 0.3071293946938756 Accuracy 86.68623265741729\n",
      "Training:: Epoch 109, Iteration 50, Current loss 0.2726444552490272 Accuracy 84.4256663918659\n",
      "Training:: Epoch 109, Iteration 60, Current loss 0.1606210928257049 Accuracy 86.008719778042\n",
      "Training:: Epoch 109, Iteration 70, Current loss 0.14367025971779773 Accuracy 90.17068151555502\n",
      "Training:: Epoch 109, Iteration 80, Current loss 0.14996006125106837 Accuracy 90.6698667123816\n",
      "Training:: Epoch 109, Iteration 90, Current loss 0.1524957068273285 Accuracy 91.09050740646843\n",
      "Training:: Epoch 109, Iteration 100, Current loss 0.1963719529664201 Accuracy 86.3234729158663\n",
      "Training:: Epoch 109, Iteration 110, Current loss 0.23732138539187392 Accuracy 88.33300244854742\n",
      "Training:: Epoch 109, Iteration 120, Current loss 0.18495065154841342 Accuracy 90.33008636668376\n",
      "Training:: Epoch 109, Iteration 130, Current loss 0.2042447585960106 Accuracy 90.22616056077239\n",
      "Training:: Epoch 109, Iteration 140, Current loss 0.241657336805775 Accuracy 88.34597694283495\n",
      "Training:: Epoch 109, Iteration 150, Current loss 0.16083771001197752 Accuracy 92.21562156215622\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 109, Probability Accuracy 69.48331761541509\n",
      "Starting Training\n",
      "Training:: Epoch 110, Iteration 0, Current loss 0.2392736440842671 Accuracy 84.43994211287989\n",
      "Training:: Epoch 110, Iteration 10, Current loss 0.18456598579442585 Accuracy 89.92038040473294\n",
      "Training:: Epoch 110, Iteration 20, Current loss 0.17774049092041525 Accuracy 90.92468691027621\n",
      "Training:: Epoch 110, Iteration 30, Current loss 0.2664564865898037 Accuracy 78.84839839190766\n",
      "Training:: Epoch 110, Iteration 40, Current loss 0.2367523519547425 Accuracy 88.87787470261696\n",
      "Training:: Epoch 110, Iteration 50, Current loss 0.16267393141371092 Accuracy 86.2431495358461\n",
      "Training:: Epoch 110, Iteration 60, Current loss 0.17408858369279867 Accuracy 81.96800580247411\n",
      "Training:: Epoch 110, Iteration 70, Current loss 0.2395590666471436 Accuracy 89.60403975633216\n",
      "Training:: Epoch 110, Iteration 80, Current loss 0.21455855826906994 Accuracy 87.83708731872879\n",
      "Training:: Epoch 110, Iteration 90, Current loss 0.17425298846010562 Accuracy 89.60144333278662\n",
      "Training:: Epoch 110, Iteration 100, Current loss 0.1801908443891069 Accuracy 86.2258197283578\n",
      "Training:: Epoch 110, Iteration 110, Current loss 0.283559287724699 Accuracy 87.82251639394497\n",
      "Training:: Epoch 110, Iteration 120, Current loss 0.2524449608728141 Accuracy 88.93684044731454\n",
      "Training:: Epoch 110, Iteration 130, Current loss 0.23681288194025216 Accuracy 83.83145516903478\n",
      "Training:: Epoch 110, Iteration 140, Current loss 0.24204060484882983 Accuracy 87.95180722891567\n",
      "Training:: Epoch 110, Iteration 150, Current loss 0.18289940053706621 Accuracy 90.00917737360254\n",
      "Calculating Expectation\n",
      "Epoch 110 iter 0\n",
      "Epoch 110 iter 10\n",
      "Epoch 110 iter 20\n",
      "Epoch 110 iter 30\n",
      "Epoch 110 iter 40\n",
      "Epoch 110 iter 50\n",
      "Epoch 110 iter 60\n",
      "Epoch 110 iter 70\n",
      "Epoch 110 iter 80\n",
      "Epoch 110 iter 90\n",
      "Epoch 110 iter 100\n",
      "Epoch 110 iter 110\n",
      "Epoch 110 iter 120\n",
      "Epoch 110 iter 130\n",
      "Epoch 110 iter 140\n",
      "Epoch 110 iter 150\n",
      "Train Boundary avergage error = 102.913\n",
      "Train From boundary avergage accuracy = 86.977\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 110, Probability Accuracy 69.52271471699376\n",
      "Starting Training\n",
      "Training:: Epoch 111, Iteration 0, Current loss 0.24267968656786815 Accuracy 85.46345447121274\n",
      "Training:: Epoch 111, Iteration 10, Current loss 0.1391711316308974 Accuracy 92.07035236208657\n",
      "Training:: Epoch 111, Iteration 20, Current loss 0.2848545891359647 Accuracy 86.2684530009698\n",
      "Training:: Epoch 111, Iteration 30, Current loss 0.2458971799474651 Accuracy 85.52527123577666\n",
      "Training:: Epoch 111, Iteration 40, Current loss 0.28294135233851586 Accuracy 83.11212015368494\n",
      "Training:: Epoch 111, Iteration 50, Current loss 0.21353056805758883 Accuracy 81.6066903193107\n",
      "Training:: Epoch 111, Iteration 60, Current loss 0.15672966153068782 Accuracy 92.14026199126695\n",
      "Training:: Epoch 111, Iteration 70, Current loss 0.2734842203313877 Accuracy 86.3015924601885\n",
      "Training:: Epoch 111, Iteration 80, Current loss 0.29488888816287834 Accuracy 87.93018682399213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 111, Iteration 90, Current loss 0.23370487594213854 Accuracy 86.14720864954776\n",
      "Training:: Epoch 111, Iteration 100, Current loss 0.21590076066503058 Accuracy 87.57079760976877\n",
      "Training:: Epoch 111, Iteration 110, Current loss 0.18773457126442863 Accuracy 88.24279711884753\n",
      "Training:: Epoch 111, Iteration 120, Current loss 0.23101083818721196 Accuracy 86.47116934435606\n",
      "Training:: Epoch 111, Iteration 130, Current loss 0.3655477366504754 Accuracy 82.17255717255718\n",
      "Training:: Epoch 111, Iteration 140, Current loss 0.20563592049703036 Accuracy 86.06878537222464\n",
      "Training:: Epoch 111, Iteration 150, Current loss 0.2074083541204913 Accuracy 87.16512702078522\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 111, Probability Accuracy 69.08488233882623\n",
      "Starting Training\n",
      "Training:: Epoch 112, Iteration 0, Current loss 0.1671624288681774 Accuracy 89.62967896629812\n",
      "Training:: Epoch 112, Iteration 10, Current loss 0.3760179152128812 Accuracy 77.79954293176624\n",
      "Training:: Epoch 112, Iteration 20, Current loss 0.32712977387317826 Accuracy 89.0797055970788\n",
      "Training:: Epoch 112, Iteration 30, Current loss 0.3630575310373791 Accuracy 79.20181291703386\n",
      "Training:: Epoch 112, Iteration 40, Current loss 0.2344160434054629 Accuracy 92.32571763327475\n",
      "Training:: Epoch 112, Iteration 50, Current loss 0.24970082736138666 Accuracy 90.48460898502496\n",
      "Training:: Epoch 112, Iteration 60, Current loss 0.23625590467924784 Accuracy 88.94973596714257\n",
      "Training:: Epoch 112, Iteration 70, Current loss 0.3243838994949871 Accuracy 89.62777380100215\n",
      "Training:: Epoch 112, Iteration 80, Current loss 0.15452285610294303 Accuracy 86.6994125012039\n",
      "Training:: Epoch 112, Iteration 90, Current loss 0.3554353793067172 Accuracy 82.22929586740574\n",
      "Training:: Epoch 112, Iteration 100, Current loss 0.38820107431613565 Accuracy 88.57261410788382\n",
      "Training:: Epoch 112, Iteration 110, Current loss 0.32153437663322554 Accuracy 81.8128443681691\n",
      "Training:: Epoch 112, Iteration 120, Current loss 0.3259442391733936 Accuracy 82.61194827401945\n",
      "Training:: Epoch 112, Iteration 130, Current loss 0.19347505630007483 Accuracy 89.00040966816879\n",
      "Training:: Epoch 112, Iteration 140, Current loss 0.19491643282021184 Accuracy 81.99233716475096\n",
      "Training:: Epoch 112, Iteration 150, Current loss 0.30592044401654855 Accuracy 88.27586206896552\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 112, Probability Accuracy 69.6276248458435\n",
      "Starting Training\n",
      "Training:: Epoch 113, Iteration 0, Current loss 0.2674611807049293 Accuracy 85.69604086845466\n",
      "Training:: Epoch 113, Iteration 10, Current loss 0.21205060422629152 Accuracy 88.89567874290702\n",
      "Training:: Epoch 113, Iteration 20, Current loss 0.1902434311659017 Accuracy 91.8188313750397\n",
      "Training:: Epoch 113, Iteration 30, Current loss 0.22997082835127106 Accuracy 79.78880947781856\n",
      "Training:: Epoch 113, Iteration 40, Current loss 0.3282109843308451 Accuracy 88.06752037252619\n",
      "Training:: Epoch 113, Iteration 50, Current loss 0.44147294580935087 Accuracy 83.73983739837398\n",
      "Training:: Epoch 113, Iteration 60, Current loss 0.28950348358546263 Accuracy 85.20297209133744\n",
      "Training:: Epoch 113, Iteration 70, Current loss 0.19666894166266213 Accuracy 89.33434190620272\n",
      "Training:: Epoch 113, Iteration 80, Current loss 0.22959529893380576 Accuracy 87.20997867252633\n",
      "Training:: Epoch 113, Iteration 90, Current loss 0.2973170173283793 Accuracy 86.9262778709397\n",
      "Training:: Epoch 113, Iteration 100, Current loss 0.26953210681644235 Accuracy 91.33039774778027\n",
      "Training:: Epoch 113, Iteration 110, Current loss 0.4665508815722451 Accuracy 86.4529105537151\n",
      "Training:: Epoch 113, Iteration 120, Current loss 0.2948393325809067 Accuracy 81.93124320234548\n",
      "Training:: Epoch 113, Iteration 130, Current loss 0.4486014470681092 Accuracy 87.45805573116763\n",
      "Training:: Epoch 113, Iteration 140, Current loss 0.34157316213556793 Accuracy 88.03935801274297\n",
      "Training:: Epoch 113, Iteration 150, Current loss 0.6794176604283748 Accuracy 82.44200718237407\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 113, Probability Accuracy 65.32831848036562\n",
      "Starting Training\n",
      "Training:: Epoch 114, Iteration 0, Current loss 0.6699433570697709 Accuracy 88.04839752470676\n",
      "Training:: Epoch 114, Iteration 10, Current loss 0.6550454204298228 Accuracy 84.4480140186916\n",
      "Training:: Epoch 114, Iteration 20, Current loss 0.5369726396567737 Accuracy 84.75501666312132\n",
      "Training:: Epoch 114, Iteration 30, Current loss 0.28335610683820467 Accuracy 84.79889589905363\n",
      "Training:: Epoch 114, Iteration 40, Current loss 0.5865271916068687 Accuracy 81.19715549582844\n",
      "Training:: Epoch 114, Iteration 50, Current loss 0.488919384860326 Accuracy 85.25428229982738\n",
      "Training:: Epoch 114, Iteration 60, Current loss 0.2820815651366016 Accuracy 90.41037454142138\n",
      "Training:: Epoch 114, Iteration 70, Current loss 0.18167872658121773 Accuracy 92.71872491686733\n",
      "Training:: Epoch 114, Iteration 80, Current loss 0.39056054798773776 Accuracy 82.71097642405876\n",
      "Training:: Epoch 114, Iteration 90, Current loss 0.34976573734307403 Accuracy 82.26755218216319\n",
      "Training:: Epoch 114, Iteration 100, Current loss 0.2753668243366687 Accuracy 85.31837677334214\n",
      "Training:: Epoch 114, Iteration 110, Current loss 0.35651310559454163 Accuracy 88.43634721072047\n",
      "Training:: Epoch 114, Iteration 120, Current loss 0.33936298624653094 Accuracy 87.93211816467631\n",
      "Training:: Epoch 114, Iteration 130, Current loss 0.4104311579490398 Accuracy 90.35571142284569\n",
      "Training:: Epoch 114, Iteration 140, Current loss 0.4546602814196381 Accuracy 86.90092165898618\n",
      "Training:: Epoch 114, Iteration 150, Current loss 0.45262492475899985 Accuracy 86.52070146311092\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 114, Probability Accuracy 68.45251979620649\n",
      "Starting Training\n",
      "Training:: Epoch 115, Iteration 0, Current loss 0.3113887998408234 Accuracy 82.42206741256773\n",
      "Training:: Epoch 115, Iteration 10, Current loss 0.3263798610866193 Accuracy 88.57629593575079\n",
      "Training:: Epoch 115, Iteration 20, Current loss 0.22470639663880065 Accuracy 89.84492246123061\n",
      "Training:: Epoch 115, Iteration 30, Current loss 0.2550884470203249 Accuracy 81.33644016837042\n",
      "Training:: Epoch 115, Iteration 40, Current loss 0.2775504434508652 Accuracy 87.52623518066822\n",
      "Training:: Epoch 115, Iteration 50, Current loss 0.2507716837879082 Accuracy 85.28988764044944\n",
      "Training:: Epoch 115, Iteration 60, Current loss 0.32310336078061475 Accuracy 91.78241739280476\n",
      "Training:: Epoch 115, Iteration 70, Current loss 0.32850517610738716 Accuracy 86.56597067969791\n",
      "Training:: Epoch 115, Iteration 80, Current loss 0.2834678507933101 Accuracy 84.66582824290334\n",
      "Training:: Epoch 115, Iteration 90, Current loss 0.2698737421288041 Accuracy 82.97637447560167\n",
      "Training:: Epoch 115, Iteration 100, Current loss 0.27878817741344536 Accuracy 86.3529641948738\n",
      "Training:: Epoch 115, Iteration 110, Current loss 0.2814257358870741 Accuracy 91.74541110024981\n",
      "Training:: Epoch 115, Iteration 120, Current loss 0.30286724685974453 Accuracy 88.80553952683208\n",
      "Training:: Epoch 115, Iteration 130, Current loss 0.19032719558960293 Accuracy 89.18491163281456\n",
      "Training:: Epoch 115, Iteration 140, Current loss 0.20838302593565716 Accuracy 91.00984267224676\n",
      "Training:: Epoch 115, Iteration 150, Current loss 0.29465972789065165 Accuracy 85.71543797386676\n",
      "Calculating Expectation\n",
      "Epoch 115 iter 0\n",
      "Epoch 115 iter 10\n",
      "Epoch 115 iter 20\n",
      "Epoch 115 iter 30\n",
      "Epoch 115 iter 40\n",
      "Epoch 115 iter 50\n",
      "Epoch 115 iter 60\n",
      "Epoch 115 iter 70\n",
      "Epoch 115 iter 80\n",
      "Epoch 115 iter 90\n",
      "Epoch 115 iter 100\n",
      "Epoch 115 iter 110\n",
      "Epoch 115 iter 120\n",
      "Epoch 115 iter 130\n",
      "Epoch 115 iter 140\n",
      "Epoch 115 iter 150\n",
      "Train Boundary avergage error = 103.809\n",
      "Train From boundary avergage accuracy = 86.684\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 115, Probability Accuracy 68.66836680598881\n",
      "Starting Training\n",
      "Training:: Epoch 116, Iteration 0, Current loss 0.24457457889389914 Accuracy 89.72120683070544\n",
      "Training:: Epoch 116, Iteration 10, Current loss 0.17237819154887238 Accuracy 88.5632448468109\n",
      "Training:: Epoch 116, Iteration 20, Current loss 0.23862395714821039 Accuracy 88.93626698504747\n",
      "Training:: Epoch 116, Iteration 30, Current loss 0.23639238655172035 Accuracy 87.7206531332745\n",
      "Training:: Epoch 116, Iteration 40, Current loss 0.24720234486323261 Accuracy 88.76149269875609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 116, Iteration 50, Current loss 0.20973531369795823 Accuracy 82.7944111776447\n",
      "Training:: Epoch 116, Iteration 60, Current loss 0.212663410802047 Accuracy 91.36096845194425\n",
      "Training:: Epoch 116, Iteration 70, Current loss 0.279393541151358 Accuracy 81.67747432195769\n",
      "Training:: Epoch 116, Iteration 80, Current loss 0.2106181314648345 Accuracy 87.33845512476923\n",
      "Training:: Epoch 116, Iteration 90, Current loss 0.24478807120453472 Accuracy 77.39415818838202\n",
      "Training:: Epoch 116, Iteration 100, Current loss 0.2314285300715253 Accuracy 89.16906327033689\n",
      "Training:: Epoch 116, Iteration 110, Current loss 0.26492841243147974 Accuracy 86.35365011612579\n",
      "Training:: Epoch 116, Iteration 120, Current loss 0.2006192567736638 Accuracy 91.46134527930496\n",
      "Training:: Epoch 116, Iteration 130, Current loss 0.22029117094106432 Accuracy 85.68151697420736\n",
      "Training:: Epoch 116, Iteration 140, Current loss 0.23429164592084187 Accuracy 89.31880108991825\n",
      "Training:: Epoch 116, Iteration 150, Current loss 0.24821947848166448 Accuracy 83.15797328557571\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 116, Probability Accuracy 67.56212297922444\n",
      "Starting Training\n",
      "Training:: Epoch 117, Iteration 0, Current loss 0.23077818701981404 Accuracy 87.81809451951437\n",
      "Training:: Epoch 117, Iteration 10, Current loss 0.2454772466755245 Accuracy 84.94162497021682\n",
      "Training:: Epoch 117, Iteration 20, Current loss 0.25122739335734123 Accuracy 87.89595248570171\n",
      "Training:: Epoch 117, Iteration 30, Current loss 0.15355852614806728 Accuracy 89.21182539242332\n",
      "Training:: Epoch 117, Iteration 40, Current loss 0.16022192872170146 Accuracy 91.27789046653145\n",
      "Training:: Epoch 117, Iteration 50, Current loss 0.3099484918194142 Accuracy 87.23058661835447\n",
      "Training:: Epoch 117, Iteration 60, Current loss 0.2531564599091909 Accuracy 88.17689530685921\n",
      "Training:: Epoch 117, Iteration 70, Current loss 0.25078168463978284 Accuracy 90.22546054440473\n",
      "Training:: Epoch 117, Iteration 80, Current loss 0.2610574155087562 Accuracy 83.26188434790893\n",
      "Training:: Epoch 117, Iteration 90, Current loss 0.20993797960696484 Accuracy 90.14833127317677\n",
      "Training:: Epoch 117, Iteration 100, Current loss 0.197580774028924 Accuracy 73.11841137533709\n",
      "Training:: Epoch 117, Iteration 110, Current loss 0.1841904166628227 Accuracy 88.82092555331992\n",
      "Training:: Epoch 117, Iteration 120, Current loss 0.20526334475070213 Accuracy 80.37714631720081\n",
      "Training:: Epoch 117, Iteration 130, Current loss 0.2200531740664816 Accuracy 89.53105911098581\n",
      "Training:: Epoch 117, Iteration 140, Current loss 0.1962581174148616 Accuracy 86.34169628175887\n",
      "Training:: Epoch 117, Iteration 150, Current loss 0.2287246536633073 Accuracy 88.36569218180466\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 117, Probability Accuracy 68.46066707217035\n",
      "Starting Training\n",
      "Training:: Epoch 118, Iteration 0, Current loss 0.16969609885575312 Accuracy 88.18560584441528\n",
      "Training:: Epoch 118, Iteration 10, Current loss 0.16186923540730547 Accuracy 88.86483018565299\n",
      "Training:: Epoch 118, Iteration 20, Current loss 0.16595808243946822 Accuracy 85.86416909770203\n",
      "Training:: Epoch 118, Iteration 30, Current loss 0.14455386927737907 Accuracy 90.92700674600167\n",
      "Training:: Epoch 118, Iteration 40, Current loss 0.2216341090144034 Accuracy 84.48022158746646\n",
      "Training:: Epoch 118, Iteration 50, Current loss 0.2208559944735366 Accuracy 89.40719947159842\n",
      "Training:: Epoch 118, Iteration 60, Current loss 0.17534424256329176 Accuracy 88.61639652337327\n",
      "Training:: Epoch 118, Iteration 70, Current loss 0.20865941288509232 Accuracy 83.8564484186521\n",
      "Training:: Epoch 118, Iteration 80, Current loss 0.21051976588904447 Accuracy 87.8695945295194\n",
      "Training:: Epoch 118, Iteration 90, Current loss 0.2523576545924237 Accuracy 84.78210744754439\n",
      "Training:: Epoch 118, Iteration 100, Current loss 0.15744922347329945 Accuracy 90.24977430033103\n",
      "Training:: Epoch 118, Iteration 110, Current loss 0.282341640843066 Accuracy 88.76846610520502\n",
      "Training:: Epoch 118, Iteration 120, Current loss 0.22223439234741504 Accuracy 86.17796610169492\n",
      "Training:: Epoch 118, Iteration 130, Current loss 0.21424400660575296 Accuracy 86.98660385691153\n",
      "Training:: Epoch 118, Iteration 140, Current loss 0.22740152210726985 Accuracy 87.1415801416489\n",
      "Training:: Epoch 118, Iteration 150, Current loss 0.28157680746539243 Accuracy 88.9732266077836\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 118, Probability Accuracy 67.79694309741575\n",
      "Starting Training\n",
      "Training:: Epoch 119, Iteration 0, Current loss 0.22481420851733497 Accuracy 89.53141119617744\n",
      "Training:: Epoch 119, Iteration 10, Current loss 0.19036972026963456 Accuracy 85.01593571845402\n",
      "Training:: Epoch 119, Iteration 20, Current loss 0.17128599989335205 Accuracy 86.93972179289027\n",
      "Training:: Epoch 119, Iteration 30, Current loss 0.2639239257274377 Accuracy 80.9985234403839\n",
      "Training:: Epoch 119, Iteration 40, Current loss 0.1876688585953122 Accuracy 89.03083962208093\n",
      "Training:: Epoch 119, Iteration 50, Current loss 0.18660395483311099 Accuracy 87.71563828933644\n",
      "Training:: Epoch 119, Iteration 60, Current loss 0.2513396880485206 Accuracy 82.15911159657746\n",
      "Training:: Epoch 119, Iteration 70, Current loss 0.20811496226068213 Accuracy 83.56569497253908\n",
      "Training:: Epoch 119, Iteration 80, Current loss 0.25473497901406666 Accuracy 91.42900256526332\n",
      "Training:: Epoch 119, Iteration 90, Current loss 0.27944277790521405 Accuracy 88.54989231873654\n",
      "Training:: Epoch 119, Iteration 100, Current loss 0.5218755847163621 Accuracy 88.2129963898917\n",
      "Training:: Epoch 119, Iteration 110, Current loss 0.467962901263442 Accuracy 87.06123689408905\n",
      "Training:: Epoch 119, Iteration 120, Current loss 0.4127873790250619 Accuracy 87.65252951652266\n",
      "Training:: Epoch 119, Iteration 130, Current loss 0.6227805360271795 Accuracy 84.97287096013211\n",
      "Training:: Epoch 119, Iteration 140, Current loss 0.23021575600852845 Accuracy 88.91505466778806\n",
      "Training:: Epoch 119, Iteration 150, Current loss 0.28466827548570073 Accuracy 79.96338891320785\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 119, Probability Accuracy 67.5989531308419\n",
      "Starting Training\n",
      "Training:: Epoch 120, Iteration 0, Current loss 0.4654325883641307 Accuracy 79.28694872943737\n",
      "Training:: Epoch 120, Iteration 10, Current loss 0.23279179367477965 Accuracy 88.57693956279469\n",
      "Training:: Epoch 120, Iteration 20, Current loss 0.19070408829943825 Accuracy 86.68484998760228\n",
      "Training:: Epoch 120, Iteration 30, Current loss 0.5157493269747679 Accuracy 82.15455140798952\n",
      "Training:: Epoch 120, Iteration 40, Current loss 0.32146700306518666 Accuracy 81.84353293109568\n",
      "Training:: Epoch 120, Iteration 50, Current loss 0.40986103375013244 Accuracy 87.26960561531081\n",
      "Training:: Epoch 120, Iteration 60, Current loss 0.3512847301822114 Accuracy 88.60903814262024\n",
      "Training:: Epoch 120, Iteration 70, Current loss 0.37838112871724366 Accuracy 86.12238273007628\n",
      "Training:: Epoch 120, Iteration 80, Current loss 0.30530645606046963 Accuracy 85.40094339622641\n",
      "Training:: Epoch 120, Iteration 90, Current loss 0.3225225604764289 Accuracy 88.71184919210054\n",
      "Training:: Epoch 120, Iteration 100, Current loss 0.21748256640194313 Accuracy 87.75415467458917\n",
      "Training:: Epoch 120, Iteration 110, Current loss 0.25358847407997614 Accuracy 88.20439350525311\n",
      "Training:: Epoch 120, Iteration 120, Current loss 0.2728261086612693 Accuracy 75.99068778784351\n",
      "Training:: Epoch 120, Iteration 130, Current loss 0.29988408354413787 Accuracy 82.18072628319415\n",
      "Training:: Epoch 120, Iteration 140, Current loss 0.34485104798667027 Accuracy 78.95859050611604\n",
      "Training:: Epoch 120, Iteration 150, Current loss 0.37839936258029183 Accuracy 85.44120396335764\n",
      "Calculating Expectation\n",
      "Epoch 120 iter 0\n",
      "Epoch 120 iter 10\n",
      "Epoch 120 iter 20\n",
      "Epoch 120 iter 30\n",
      "Epoch 120 iter 40\n",
      "Epoch 120 iter 50\n",
      "Epoch 120 iter 60\n",
      "Epoch 120 iter 70\n",
      "Epoch 120 iter 80\n",
      "Epoch 120 iter 90\n",
      "Epoch 120 iter 100\n",
      "Epoch 120 iter 110\n",
      "Epoch 120 iter 120\n",
      "Epoch 120 iter 130\n",
      "Epoch 120 iter 140\n",
      "Epoch 120 iter 150\n",
      "Train Boundary avergage error = 104.697\n",
      "Train From boundary avergage accuracy = 86.554\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 120, Probability Accuracy 67.59080585487804\n",
      "Starting Training\n",
      "Training:: Epoch 121, Iteration 0, Current loss 0.20044913719610163 Accuracy 90.8650742414461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 121, Iteration 10, Current loss 0.1741438091507269 Accuracy 86.21556509898397\n",
      "Training:: Epoch 121, Iteration 20, Current loss 0.1353752294167687 Accuracy 88.01010617884099\n",
      "Training:: Epoch 121, Iteration 30, Current loss 0.32092804017341714 Accuracy 77.02020202020202\n",
      "Training:: Epoch 121, Iteration 40, Current loss 0.22465338533456616 Accuracy 86.18380541871922\n",
      "Training:: Epoch 121, Iteration 50, Current loss 0.16612487643704568 Accuracy 88.12405446293495\n",
      "Training:: Epoch 121, Iteration 60, Current loss 0.35832498853335476 Accuracy 84.24806201550388\n",
      "Training:: Epoch 121, Iteration 70, Current loss 0.21384798046599984 Accuracy 91.16065426842931\n",
      "Training:: Epoch 121, Iteration 80, Current loss 0.23831464032639138 Accuracy 89.9848858483812\n",
      "Training:: Epoch 121, Iteration 90, Current loss 0.28762403194903685 Accuracy 87.712185101092\n",
      "Training:: Epoch 121, Iteration 100, Current loss 0.21564937055257155 Accuracy 92.8217994285316\n",
      "Training:: Epoch 121, Iteration 110, Current loss 0.36437597441165237 Accuracy 81.04575163398692\n",
      "Training:: Epoch 121, Iteration 120, Current loss 0.22208409018698244 Accuracy 78.98465171192444\n",
      "Training:: Epoch 121, Iteration 130, Current loss 0.22514425769248478 Accuracy 89.8126815586497\n",
      "Training:: Epoch 121, Iteration 140, Current loss 0.34257234715048057 Accuracy 83.84243775548123\n",
      "Training:: Epoch 121, Iteration 150, Current loss 0.18322940422822087 Accuracy 90.44147428108546\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 121, Probability Accuracy 68.5875636854705\n",
      "Starting Training\n",
      "Training:: Epoch 122, Iteration 0, Current loss 0.22906847100497738 Accuracy 91.2820094601207\n",
      "Training:: Epoch 122, Iteration 10, Current loss 0.1806571255847607 Accuracy 90.69748211849341\n",
      "Training:: Epoch 122, Iteration 20, Current loss 0.15807306118361092 Accuracy 91.37266828872669\n",
      "Training:: Epoch 122, Iteration 30, Current loss 0.42159893787548974 Accuracy 86.55160544819786\n",
      "Training:: Epoch 122, Iteration 40, Current loss 0.3530196384470654 Accuracy 87.43486853925855\n",
      "Training:: Epoch 122, Iteration 50, Current loss 0.4019243974953892 Accuracy 82.30159307485269\n",
      "Training:: Epoch 122, Iteration 60, Current loss 0.5680180086972226 Accuracy 83.9569762157249\n",
      "Training:: Epoch 122, Iteration 70, Current loss 0.4702297734544155 Accuracy 84.80475382003395\n",
      "Training:: Epoch 122, Iteration 80, Current loss 0.5761020277578486 Accuracy 83.99727870587346\n",
      "Training:: Epoch 122, Iteration 90, Current loss 0.7217875780710115 Accuracy 88.80330544786779\n",
      "Training:: Epoch 122, Iteration 100, Current loss 2.165928846612602 Accuracy 81.8944099378882\n",
      "Training:: Epoch 122, Iteration 110, Current loss 5.331480378804294 Accuracy 47.95675076240643\n",
      "Training:: Epoch 122, Iteration 120, Current loss 3.7767355057967977 Accuracy 69.1409291461199\n",
      "Training:: Epoch 122, Iteration 130, Current loss 3.8322180815915288 Accuracy 74.22811378072356\n",
      "Training:: Epoch 122, Iteration 140, Current loss 1.8238572490796763 Accuracy 87.61994159365874\n",
      "Training:: Epoch 122, Iteration 150, Current loss 1.8000352984781436 Accuracy 82.67525674555081\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 122, Probability Accuracy 65.97050239675002\n",
      "Starting Training\n",
      "Training:: Epoch 123, Iteration 0, Current loss 1.6398622425487304 Accuracy 80.824674971441\n",
      "Training:: Epoch 123, Iteration 10, Current loss 1.5330165146480372 Accuracy 82.90311766677841\n",
      "Training:: Epoch 123, Iteration 20, Current loss 2.33445304068942 Accuracy 76.82248927947482\n",
      "Training:: Epoch 123, Iteration 30, Current loss 1.229576260599313 Accuracy 87.17062182408716\n",
      "Training:: Epoch 123, Iteration 40, Current loss 1.0026256841729355 Accuracy 83.037714712472\n",
      "Training:: Epoch 123, Iteration 50, Current loss 0.7046219613560386 Accuracy 88.49106694410561\n",
      "Training:: Epoch 123, Iteration 60, Current loss 0.9131608029821594 Accuracy 87.41480330025111\n",
      "Training:: Epoch 123, Iteration 70, Current loss 4.789668722615732 Accuracy 68.60220088972137\n",
      "Training:: Epoch 123, Iteration 80, Current loss 1.9385573722271279 Accuracy 79.69796510387782\n",
      "Training:: Epoch 123, Iteration 90, Current loss 0.6591926045583062 Accuracy 87.23308883455583\n",
      "Training:: Epoch 123, Iteration 100, Current loss 3.40399261403537 Accuracy 73.34161600922927\n",
      "Training:: Epoch 123, Iteration 110, Current loss 0.8309083989238679 Accuracy 83.91357675252382\n",
      "Training:: Epoch 123, Iteration 120, Current loss 2.575809548629839 Accuracy 79.12920412920413\n",
      "Training:: Epoch 123, Iteration 130, Current loss 4.284901780809031 Accuracy 79.03444912745132\n",
      "Training:: Epoch 123, Iteration 140, Current loss 1.6517494149739376 Accuracy 86.01201652271874\n",
      "Training:: Epoch 123, Iteration 150, Current loss 1.311223860382654 Accuracy 84.41254028713742\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 123, Probability Accuracy 66.53054391437547\n",
      "Starting Training\n",
      "Training:: Epoch 124, Iteration 0, Current loss 0.7347809283908795 Accuracy 88.38164905626299\n",
      "Training:: Epoch 124, Iteration 10, Current loss 0.758390643468557 Accuracy 84.54422817498555\n",
      "Training:: Epoch 124, Iteration 20, Current loss 0.5185282269902558 Accuracy 89.43781041952869\n",
      "Training:: Epoch 124, Iteration 30, Current loss 0.7190816349126444 Accuracy 86.58699309624645\n",
      "Training:: Epoch 124, Iteration 40, Current loss 0.6376464973808311 Accuracy 88.24065172291657\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-3bc684dbca6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mmiddle_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mboundary_target_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_single_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/c2f_active_learn/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_stages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mmiddle_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmiddle_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/c2f_active_learn/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mfinal_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/c2f_active_learn/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dilated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    258\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 259\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initialize_epoch = 15\n",
    "expectation_cal_gap = 5\n",
    "best_val_acc = 0\n",
    "for epoch in range(15, 1000):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        boundary_target_tensor = get_single_random(item_2, item[4])\n",
    "        \n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            if epoch <= initialize_epoch:\n",
    "                loss += ce_criterion(p, boundary_target_tensor)\n",
    "                loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                    F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                            max=16) * src_mask_mse[:, :, 1:])\n",
    "            else:\n",
    "                prob = torch.softmax(p, dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                es_loss, _ = get_estimated_loss(prob, item_1, item[4], item_2)\n",
    "                loss += es_loss\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(predictions[-1], dim=1)\n",
    "                correct = float(torch.sum((pred == item_2) * src_mask).item())\n",
    "                total = float(torch.sum(src_mask).item())\n",
    "                print(f\"Training:: Epoch {epoch}, Iteration {i}, Current loss {loss.item()}\" +\n",
    "                      f\" Accuracy {correct * 100.0 / total}\")\n",
    "    if epoch == initialize_epoch:\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-initial-15-epochs.wt\")\n",
    "    # Calculating Expectation Step\n",
    "    model.eval()\n",
    "    if (epoch >= initialize_epoch) and (epoch % expectation_cal_gap == 0):\n",
    "        print(\"Calculating Expectation\")\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "\n",
    "        for i, item in enumerate(trainloader):\n",
    "            with torch.no_grad():\n",
    "                item_0 = item[0].to(device)\n",
    "                item_1 = item[1].to(device)\n",
    "                item_2 = item[2].to(device)\n",
    "                src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "                src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "                middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "                prob = torch.softmax(predictions[-1], dim=1)\n",
    "                prob = prob.permute(0, 2, 1)\n",
    "                calculate_element_probb(prob, item_1, item[4], item_2)\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "#                     pred = torch.argmax(prob, dim=2)\n",
    "#                     correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "#                     total += float(torch.sum(src_mask).item())\n",
    "                    print(f\"Epoch {epoch} iter {i}\")\n",
    "                    \n",
    "#         print(f\"Epoch {epoch} After Expectation}, train acc. {correct * 100.0 / total: .3f}\")\n",
    "        get_boundary_err()\n",
    "\n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if val_acc > best_val_acc:\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-emmax-last-model.wt\")\n",
    "    print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split3/ms-tcn-initial-15-epochs.wt\r\n"
     ]
    }
   ],
   "source": [
    "!ls '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split3/ms-tcn-initial-15-epochs.wt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split3/ms-tcn-initial-15-epochs.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 15, Probability Accuracy 57.770101729343025\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Validation Data Accuracy\")\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "        pred = torch.argmax(predictions[-1], dim=1)\n",
    "        correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "        total += float(torch.sum(src_mask).item())\n",
    "\n",
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_labels(labels_arr):\n",
    "    unique_ids = []\n",
    "    \n",
    "    prev_ele = None\n",
    "    start = 0\n",
    "    for i, ele in enumerate(labels_arr):\n",
    "        if prev_ele is not None and prev_ele != ele:\n",
    "            select_item = np.random.randint(start, i, 1)[0]\n",
    "            unique_ids.append(select_item)\n",
    "            start = i\n",
    "        prev_ele = ele\n",
    "    \n",
    "    select_item = np.random.randint(start, len(labels_arr), 1)[0]\n",
    "    unique_ids.append(select_item)\n",
    "    return unique_ids\n",
    "# get_selected_labels(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary(labels_arr):\n",
    "    unique_ids = []\n",
    "    \n",
    "    prev_ele = None\n",
    "    start = 0\n",
    "    for i, ele in enumerate(labels_arr):\n",
    "        if prev_ele is not None and prev_ele != ele:\n",
    "            unique_ids.append(i - 1)\n",
    "            start = i\n",
    "        prev_ele = ele\n",
    "    \n",
    "    unique_ids.append(len(labels_arr) - 1)\n",
    "    return unique_ids\n",
    "# get_boundary(np.array([2, 2, 2, 2, 3, 3, 4, 4, 4, 1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "boundary_dict = {}\n",
    "for file in glob.glob(\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/*txt\"):\n",
    "    video_id = file.split(\"/\")[-1].split(\".txt\")[0]\n",
    "    data = open(file).read().split(\"\\n\")[0:-1]\n",
    "    data = np.array(data)\n",
    "    boundary = get_boundary(data)\n",
    "    boundary_dict[video_id] = boundary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vidid_selected_frames = {}\n",
    "for batch in trainloader:\n",
    "    count_all = batch[1]\n",
    "    labels_all = batch[2]\n",
    "    video_ids = batch[5]\n",
    "    for i, count in enumerate(count_all):\n",
    "        video_id = video_ids[i]\n",
    "        labels = labels_all[i][:count]\n",
    "        selected_ids = get_selected_labels(labels)\n",
    "\n",
    "        loaded_vidid_selected_frames[video_id] = selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id_boundary_frames = {}\n",
    "for batch in trainloader:\n",
    "    count_all = batch[1]\n",
    "    labels_all = batch[2]\n",
    "    video_ids = batch[4]\n",
    "    for i, count in enumerate(count_all):\n",
    "        \n",
    "        labels = labels_all[i][:count]\n",
    "        selected_ids = get_boundary(labels)\n",
    "        video_id = video_ids[i]\n",
    "        video_id_boundary_frames[video_id] = selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in video_id_boundary_frames.keys():\n",
    "    if len(video_id_boundary_frames[ele]) != len(loaded_vidid_selected_frames[ele + \".txt\"]):\n",
    "        print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(video_id_boundary_frames, open(\"dump_dir/video_id_boundary_frames_dict.pkl\", \"wb\"))\n",
    "# pickle.dump(loaded_vidid_selected_frames, open(\"dump_dir/loaded_vidid_selected_frames_dict.pkl\", \"wb\"))\n",
    "pickle.dump(boundary_dict, open(\"dump_dir/chunk_1_video_id_boundary_frames_dict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_out(outp):\n",
    "    \n",
    "    weights = [1, 1, 1, 1, 0, 0]\n",
    "    ensemble_prob = F.softmax(outp[0], dim=1) * weights[0] / sum(weights)\n",
    "\n",
    "    for i, outp_ele in enumerate(outp[1]):\n",
    "        upped_logit = F.upsample(outp_ele, size=outp[0].shape[-1], mode='linear', align_corners=True)\n",
    "        ensemble_prob = ensemble_prob + F.softmax(upped_logit, dim=1) * weights[i + 1] / sum(weights)\n",
    "    \n",
    "    return ensemble_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/results/c2f-tcn-model/split2_c2ftcn_model.wt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iteration done\n",
      "11 iteration done\n",
      "21 iteration done\n",
      "31 iteration done\n",
      "41 iteration done\n",
      "51 iteration done\n",
      "61 iteration done\n",
      "71 iteration done\n",
      "81 iteration done\n",
      "91 iteration done\n",
      "101 iteration done\n",
      "111 iteration done\n",
      "121 iteration done\n",
      "131 iteration done\n",
      "141 iteration done\n",
      "151 iteration done\n",
      "Train Boundary avergage error = 107.269\n",
      "Train From boundary avergage accuracy = 87.407\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        prob = torch.softmax(predictions[-1], dim=1)\n",
    "        prob = prob.permute(0, 2, 1)\n",
    "        calculate_element_probb(prob, item_1, item[4], item_2)\n",
    "\n",
    "        if i%10==0:\n",
    "            print(f'{i+1} iteration done')\n",
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    idx = 4\n",
    "\n",
    "    cur_vid_feat = torch.softmax(predictions[-1], dim=1).permute(0, 2, 1)[idx]\n",
    "    cur_vidid = item[4][idx]\n",
    "\n",
    "    selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "    \n",
    "    bound_list = video_id_boundary_frames[cur_vidid]\n",
    "    \n",
    "    cumsum_feat = torch.cumsum(cur_vid_feat, dim=0)\n",
    "    prob_each_segment = prob_vals_per_segment(selected_frames, cur_vid_feat, item_2[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min prob 0 = 7.953912266787591e-36\n",
      "Min prob 1 = 2.7495868628582206e-249\n",
      "Min prob 2 = 8.185175464823537e-201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 442)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "ymax = 1\n",
    "selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "\n",
    "plt.plot([0, item[1][idx].item()], [0, 0])\n",
    "\n",
    "for pivot in loaded_vidid_selected_frames[cur_vidid + \".txt\"]:\n",
    "    plt.plot([pivot, pivot], [0, ymax], '--')\n",
    "    \n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, ymax])\n",
    "    \n",
    "all_prob = []\n",
    "for i, segment in enumerate(prob_each_segment):\n",
    "    segment = segment.cpu().numpy()\n",
    "    print(f\"Min prob {i} = {np.min(segment).item()}\")\n",
    "    xs = np.arange(loaded_vidid_selected_frames[cur_vidid + \".txt\"][i], \n",
    "                   loaded_vidid_selected_frames[cur_vidid + \".txt\"][i+1])\n",
    "    plt.plot(xs, segment, '*')\n",
    "\n",
    "    \n",
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "\n",
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]], item_2[idx].unsqueeze(0))\n",
    "loss_arr = -loss_arr[0].detach().cpu().numpy()\n",
    "plt.plot(np.arange(selected_frames[0] - 1, selected_frames[-1] + 1), loss_arr/np.max(loss_arr), 'k+')\n",
    "\n",
    "plt.ylim([0, ymax])\n",
    "plt.xlim([0, item[1][idx].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1895, 48])\n"
     ]
    }
   ],
   "source": [
    "loss_prob = torch.softmax(cur_vid_feat.unsqueeze(0), dim=2)\n",
    "print(loss_prob.shape)\n",
    "es_loss, loss_arr = get_estimated_loss(loss_prob, torch.tensor([item_1[idx]]), [item[4][idx]], item_2[idx].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1387])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_arr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faf5b8ecb00>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_frames = loaded_vidid_selected_frames[cur_vidid + \".txt\"]\n",
    "plt.plot(np.arange(selected_frames[0] - 1, selected_frames[-1] + 1), loss_arr[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3987, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([75, 345, 1305, 1415, 1440, 1519],\n",
       " [73, 282, 455, 1312, 1434, 1458],\n",
       " tensor(1520, device='cuda:0', dtype=torch.int32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid], loaded_vidid_selected_frames[cur_vidid + \".txt\"], item_1[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_arr = []\n",
    "for i in range(item[1][idx].item()):\n",
    "    plt_arr.append(cur_vid_feat[i,item[2][idx][i]].item()) \n",
    "\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "plt.plot(np.arange(item[1][idx].item()), plt_arr)\n",
    "\n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([334, 334])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_features_shortened = cur_vid_feat[:item[1][idx]]\n",
    "cur_features_shortened[:, item[2][idx][:item[1][idx]]].shape\n",
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47, 47, 47, 47, 47, 47, 47,  4,  4,  4,  4,  4,  4,  4,  4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[2][idx][video_id_boundary_frames[cur_vidid][1]-6:video_id_boundary_frames[cur_vidid][1]+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id_boundary_frames[cur_vidid][0]-6,video_id_boundary_frames[cur_vidid][0]+9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0794, 13.3350],\n",
       "        [ 1.0831, 13.5102],\n",
       "        [ 1.1767, 13.7662],\n",
       "        [ 1.3750, 14.0177],\n",
       "        [ 1.7298, 14.1727],\n",
       "        [ 2.1706, 14.0367],\n",
       "        [ 2.7338, 13.4563],\n",
       "        [ 4.5600, 12.1745],\n",
       "        [ 7.8450, 10.3246],\n",
       "        [11.0151,  8.3563],\n",
       "        [13.4775,  6.6546],\n",
       "        [14.1836,  5.2898],\n",
       "        [11.2142,  4.2791],\n",
       "        [ 5.9829,  3.5694],\n",
       "        [ 2.3440,  2.9389],\n",
       "        [ 0.7406,  2.3515]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_vid_feat[video_id_boundary_frames[cur_vidid][1]-7:video_id_boundary_frames[cur_vidid][1]+9][:,[47,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_frames_and_get_classification_value(model_output, count_list, video_ids_list, labels_all, p_criterion):\n",
    "    new_selected_frames = {}\n",
    "#     new_selected_frames_probs_values = {}\n",
    "#     new_selected_frames_labels = {}\n",
    "    \n",
    "    labels_arr = []\n",
    "    probs_arr = []\n",
    "    \n",
    "    for i, video_id in enumerate(video_ids_list):\n",
    "        current_boundary_frames = boundaries_dict[video_id]\n",
    "        current_video_logits = model_output[i].T\n",
    "        current_video_count = count_list[i]\n",
    "        current_selected_frames = loaded_vidid_selected_frames[video_id]\n",
    "        labels = labels_all[i]\n",
    "        cur_seg_start = 0\n",
    "        for seg_num, ele in enumerate(current_boundary_frames):\n",
    "            cur_seg_end = ele + 1\n",
    "            total_seg_len = cur_seg_end - cur_seg_start\n",
    "            per_frames_far_from_boundary = int(0.3 * total_seg_len)\n",
    "            new_frames_start = cur_seg_start + per_frames_far_from_boundary\n",
    "            new_frames_end = cur_seg_end - per_frames_far_from_boundary\n",
    "            \n",
    "            frames_added = list(range(new_frames_start, new_frames_end))\n",
    "            frames_added.append(current_selected_frames[seg_num])\n",
    "            frames_added = list(set(frames_added))\n",
    "            frames_added.sort()\n",
    "            new_selected_frames[video_id] = frames_added\n",
    "\n",
    "            \n",
    "            labels_seg = torch.stack([labels[current_selected_frames[seg_num]]] * len(frames_added))\n",
    "            frames_added = torch.tensor(np.array(frames_added), dtype=torch.long, device=current_video_logits.device)\n",
    "            prob_seg = current_video_logits[frames_added, :]\n",
    "            \n",
    "            labels_arr.append(labels_seg)\n",
    "            probs_arr.append(prob_seg)\n",
    "            \n",
    "            cur_seg_start = cur_seg_end\n",
    "            \n",
    "    labels_arr = torch.cat(labels_arr)\n",
    "    probs_arr = torch.cat(probs_arr)\n",
    "    loss = p_criterion(probs_arr, labels_arr)\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
