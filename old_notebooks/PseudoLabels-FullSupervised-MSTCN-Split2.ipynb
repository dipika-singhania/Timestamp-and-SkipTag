{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mstcn_model import *\n",
    "from utility.adaptive_data_loader import Breakfast, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 8, 'learning_rate': 0.0005, 'weight_decay': 0, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 1, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 2, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split2/', 'project_name': 'breakfast-split-2', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split2.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split2.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split2_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=8,\n",
    "    learning_rate=5e-4,\n",
    "    weight_decay=0,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=1,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=2,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split2/\",\n",
    "    project_name=\"breakfast-split-2\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(config.label_id_csv)\n",
    "label_id_to_label_name = {}\n",
    "label_name_to_label_id_dict = {}\n",
    "for i, ele in df.iterrows():\n",
    "    label_id_to_label_name[ele.label_id] = ele.label_name\n",
    "    label_name_to_label_id_dict[ele.label_name] = ele.label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1261\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 451\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "traindataset = Breakfast(config, fold='train', fold_file_name=config.train_split_file)\n",
    "testdataset = Breakfast(config, fold='test', fold_file_name=config.test_split_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, \n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4,\n",
    "                                          collate_fn=lambda x: collate_fn_override(x, config.max_frames_per_video),\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MultiStageModel(num_stages=4, num_layers=10, num_f_maps=64, dim=2048, num_classes=48).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "mse_criterion = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels_dir = \"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/length_segmentation_output/\"\n",
    "def get_single_random(output_p, video_ids):\n",
    "    # Generate target for only timestamps. Do not generate pseudo labels at first 30 epochs.\n",
    "    boundary_target_tensor = torch.ones((output_p.shape[0], output_p.shape[2]), dtype=torch.long, \n",
    "                                        device=output_p.device) * (-100)\n",
    "    for iter_num, cur_vidid in enumerate(video_ids):\n",
    "        pseudo_l = open(pseudo_labels_dir + cur_vidid + \".txt\").read().split(\"\\n\")[0:-1]\n",
    "        pseudo_l = [label_name_to_label_id_dict[ele] for ele in pseudo_l]\n",
    "        abc = torch.tensor(pseudo_l).to(torch.long).to(boundary_target_tensor.device)\n",
    "        frame_idx_tensor = torch.arange(0, len(pseudo_l), 1).to(device)\n",
    "        boundary_target_tensor[iter_num, frame_idx_tensor] = abc\n",
    "\n",
    "    return boundary_target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Training:: Epoch 0, Iteration 0, Current loss 15.693472862243652 Accuracy 1.0729173785279846\n",
      "Training:: Epoch 0, Iteration 10, Current loss 14.211379051208496 Accuracy 6.276704579647349\n",
      "Training:: Epoch 0, Iteration 20, Current loss 13.300257682800293 Accuracy 9.14622178606477\n",
      "Training:: Epoch 0, Iteration 30, Current loss 14.41281509399414 Accuracy 11.566045116703611\n",
      "Training:: Epoch 0, Iteration 40, Current loss 12.287521362304688 Accuracy 19.669512256003195\n",
      "Training:: Epoch 0, Iteration 50, Current loss 11.137622833251953 Accuracy 24.671816009144123\n",
      "Training:: Epoch 0, Iteration 60, Current loss 11.745620727539062 Accuracy 19.477620270119434\n",
      "Training:: Epoch 0, Iteration 70, Current loss 12.002619743347168 Accuracy 5.896333182435491\n",
      "Training:: Epoch 0, Iteration 80, Current loss 12.47575569152832 Accuracy 11.876788672992921\n",
      "Training:: Epoch 0, Iteration 90, Current loss 12.001688003540039 Accuracy 5.0972927241962775\n",
      "Training:: Epoch 0, Iteration 100, Current loss 10.583322525024414 Accuracy 25.103241792277515\n",
      "Training:: Epoch 0, Iteration 110, Current loss 9.998018264770508 Accuracy 26.092071210101167\n",
      "Training:: Epoch 0, Iteration 120, Current loss 10.966602325439453 Accuracy 10.134661788744454\n",
      "Training:: Epoch 0, Iteration 130, Current loss 11.17221450805664 Accuracy 12.073696589572716\n",
      "Training:: Epoch 0, Iteration 140, Current loss 11.026495933532715 Accuracy 14.953446816514624\n",
      "Training:: Epoch 0, Iteration 150, Current loss 10.016366958618164 Accuracy 16.759703158862546\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 0, Probability Accuracy 18.437254008368892\n",
      "Starting Training\n",
      "Training:: Epoch 1, Iteration 0, Current loss 10.33945369720459 Accuracy 30.063634952661804\n",
      "Training:: Epoch 1, Iteration 10, Current loss 9.015961647033691 Accuracy 14.397153414534008\n",
      "Training:: Epoch 1, Iteration 20, Current loss 9.63492202758789 Accuracy 18.396805896805898\n",
      "Training:: Epoch 1, Iteration 30, Current loss 8.973413467407227 Accuracy 25.750721847930702\n",
      "Training:: Epoch 1, Iteration 40, Current loss 8.94939136505127 Accuracy 23.793833843257236\n",
      "Training:: Epoch 1, Iteration 50, Current loss 9.841599464416504 Accuracy 30.449507389162562\n",
      "Training:: Epoch 1, Iteration 60, Current loss 8.283394813537598 Accuracy 30.18846373500857\n",
      "Training:: Epoch 1, Iteration 70, Current loss 8.897313117980957 Accuracy 26.597418948693736\n",
      "Training:: Epoch 1, Iteration 80, Current loss 8.968170166015625 Accuracy 25.948051948051948\n",
      "Training:: Epoch 1, Iteration 90, Current loss 8.599664688110352 Accuracy 20.046210720887245\n",
      "Training:: Epoch 1, Iteration 100, Current loss 8.91353702545166 Accuracy 23.87798474809351\n",
      "Training:: Epoch 1, Iteration 110, Current loss 8.295273780822754 Accuracy 23.87530562347188\n",
      "Training:: Epoch 1, Iteration 120, Current loss 7.6849284172058105 Accuracy 26.91963580864165\n",
      "Training:: Epoch 1, Iteration 130, Current loss 8.475507736206055 Accuracy 22.16135881104034\n",
      "Training:: Epoch 1, Iteration 140, Current loss 7.982297420501709 Accuracy 34.41880220869319\n",
      "Training:: Epoch 1, Iteration 150, Current loss 10.177506446838379 Accuracy 16.982496745262548\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 1, Probability Accuracy 29.177507561005925\n",
      "Starting Training\n",
      "Training:: Epoch 2, Iteration 0, Current loss 7.510021209716797 Accuracy 30.668206090344928\n",
      "Training:: Epoch 2, Iteration 10, Current loss 6.928406715393066 Accuracy 33.91292687287681\n",
      "Training:: Epoch 2, Iteration 20, Current loss 9.309460639953613 Accuracy 19.605928818674005\n",
      "Training:: Epoch 2, Iteration 30, Current loss 7.348832607269287 Accuracy 22.393941259774646\n",
      "Training:: Epoch 2, Iteration 40, Current loss 7.213558197021484 Accuracy 35.44303797468354\n",
      "Training:: Epoch 2, Iteration 50, Current loss 6.26914119720459 Accuracy 31.917109236696867\n",
      "Training:: Epoch 2, Iteration 60, Current loss 5.729090690612793 Accuracy 40.08793969849246\n",
      "Training:: Epoch 2, Iteration 70, Current loss 6.205019950866699 Accuracy 45.204396867591065\n",
      "Training:: Epoch 2, Iteration 80, Current loss 7.6917338371276855 Accuracy 22.034705322188127\n",
      "Training:: Epoch 2, Iteration 90, Current loss 7.219960689544678 Accuracy 24.953303759047397\n",
      "Training:: Epoch 2, Iteration 100, Current loss 6.666484355926514 Accuracy 40.869401934090696\n",
      "Training:: Epoch 2, Iteration 110, Current loss 6.807589530944824 Accuracy 28.221893037748377\n",
      "Training:: Epoch 2, Iteration 120, Current loss 9.257026672363281 Accuracy 31.20083041958042\n",
      "Training:: Epoch 2, Iteration 130, Current loss 9.737393379211426 Accuracy 31.71969086340145\n",
      "Training:: Epoch 2, Iteration 140, Current loss 6.557971000671387 Accuracy 33.53287812178468\n",
      "Training:: Epoch 2, Iteration 150, Current loss 6.15479040145874 Accuracy 41.88500212434499\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 2, Probability Accuracy 30.43398102498239\n",
      "Starting Training\n",
      "Training:: Epoch 3, Iteration 0, Current loss 7.473956108093262 Accuracy 22.34297706490781\n",
      "Training:: Epoch 3, Iteration 10, Current loss 5.230389595031738 Accuracy 40.31884633194417\n",
      "Training:: Epoch 3, Iteration 20, Current loss 6.5925068855285645 Accuracy 32.97252718932014\n",
      "Training:: Epoch 3, Iteration 30, Current loss 6.8773417472839355 Accuracy 26.62594322673374\n",
      "Training:: Epoch 3, Iteration 40, Current loss 5.4835028648376465 Accuracy 36.75469643343316\n",
      "Training:: Epoch 3, Iteration 50, Current loss 5.470138072967529 Accuracy 33.31096497114481\n",
      "Training:: Epoch 3, Iteration 60, Current loss 6.668852806091309 Accuracy 36.42230252968508\n",
      "Training:: Epoch 3, Iteration 70, Current loss 6.324427127838135 Accuracy 53.84842229430846\n",
      "Training:: Epoch 3, Iteration 80, Current loss 5.368295669555664 Accuracy 49.89117910638843\n",
      "Training:: Epoch 3, Iteration 90, Current loss 6.536893367767334 Accuracy 31.740047287366604\n",
      "Training:: Epoch 3, Iteration 100, Current loss 6.313006401062012 Accuracy 41.86209499164375\n",
      "Training:: Epoch 3, Iteration 110, Current loss 6.346843242645264 Accuracy 45.10458256361361\n",
      "Training:: Epoch 3, Iteration 120, Current loss 5.967839241027832 Accuracy 47.36051099004321\n",
      "Training:: Epoch 3, Iteration 130, Current loss 9.23605728149414 Accuracy 20.528953823184388\n",
      "Training:: Epoch 3, Iteration 140, Current loss 6.198215484619141 Accuracy 41.730338812996834\n",
      "Training:: Epoch 3, Iteration 150, Current loss 5.7743682861328125 Accuracy 40.791801378637224\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 3, Probability Accuracy 36.91697394042342\n",
      "Starting Training\n",
      "Training:: Epoch 4, Iteration 0, Current loss 5.141078948974609 Accuracy 48.33185448092281\n",
      "Training:: Epoch 4, Iteration 10, Current loss 6.406179428100586 Accuracy 47.70090698164944\n",
      "Training:: Epoch 4, Iteration 20, Current loss 6.064571380615234 Accuracy 36.532051282051285\n",
      "Training:: Epoch 4, Iteration 30, Current loss 5.670587062835693 Accuracy 39.31506259949232\n",
      "Training:: Epoch 4, Iteration 40, Current loss 7.097456455230713 Accuracy 39.514276337381034\n",
      "Training:: Epoch 4, Iteration 50, Current loss 5.621209144592285 Accuracy 40.48917047296302\n",
      "Training:: Epoch 4, Iteration 60, Current loss 6.013073444366455 Accuracy 49.79220923145121\n",
      "Training:: Epoch 4, Iteration 70, Current loss 8.402527809143066 Accuracy 31.194189784498153\n",
      "Training:: Epoch 4, Iteration 80, Current loss 7.514925956726074 Accuracy 50.30003925747294\n",
      "Training:: Epoch 4, Iteration 90, Current loss 6.3782758712768555 Accuracy 35.0921052631579\n",
      "Training:: Epoch 4, Iteration 100, Current loss 5.6068115234375 Accuracy 51.199400299850076\n",
      "Training:: Epoch 4, Iteration 110, Current loss 6.39921236038208 Accuracy 32.4467736652473\n",
      "Training:: Epoch 4, Iteration 120, Current loss 6.072743892669678 Accuracy 50.80141996557659\n",
      "Training:: Epoch 4, Iteration 130, Current loss 6.328180313110352 Accuracy 40.755431353105564\n",
      "Training:: Epoch 4, Iteration 140, Current loss 5.8747334480285645 Accuracy 48.93997927070574\n",
      "Training:: Epoch 4, Iteration 150, Current loss 5.7942214012146 Accuracy 47.99785962721841\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 4, Probability Accuracy 45.56179309773377\n",
      "Starting Training\n",
      "Training:: Epoch 5, Iteration 0, Current loss 6.551041126251221 Accuracy 38.57125946969697\n",
      "Training:: Epoch 5, Iteration 10, Current loss 5.2526936531066895 Accuracy 42.08511452816946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 5, Iteration 20, Current loss 5.061407089233398 Accuracy 53.11252055438102\n",
      "Training:: Epoch 5, Iteration 30, Current loss 5.921935558319092 Accuracy 50.64615681357894\n",
      "Training:: Epoch 5, Iteration 40, Current loss 5.548762321472168 Accuracy 52.94337507008036\n",
      "Training:: Epoch 5, Iteration 50, Current loss 5.490309238433838 Accuracy 40.46831806601984\n",
      "Training:: Epoch 5, Iteration 60, Current loss 5.163252830505371 Accuracy 43.79336931380108\n",
      "Training:: Epoch 5, Iteration 70, Current loss 5.947635173797607 Accuracy 37.71370535462393\n",
      "Training:: Epoch 5, Iteration 80, Current loss 5.593697547912598 Accuracy 49.99327414581652\n",
      "Training:: Epoch 5, Iteration 90, Current loss 5.365443706512451 Accuracy 43.9320006296238\n",
      "Training:: Epoch 5, Iteration 100, Current loss 5.97140645980835 Accuracy 53.53922452660054\n",
      "Training:: Epoch 5, Iteration 110, Current loss 4.366034507751465 Accuracy 58.29713891761462\n",
      "Training:: Epoch 5, Iteration 120, Current loss 5.584264755249023 Accuracy 39.828228476821195\n",
      "Training:: Epoch 5, Iteration 130, Current loss 5.886402606964111 Accuracy 48.82919291572566\n",
      "Training:: Epoch 5, Iteration 140, Current loss 6.843181133270264 Accuracy 50.37075844281454\n",
      "Training:: Epoch 5, Iteration 150, Current loss 6.248328685760498 Accuracy 24.92986483040041\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 5, Probability Accuracy 45.44444214276837\n",
      "Starting Training\n",
      "Training:: Epoch 6, Iteration 0, Current loss 5.443305969238281 Accuracy 52.01358106196359\n",
      "Training:: Epoch 6, Iteration 10, Current loss 4.7800703048706055 Accuracy 54.32033950212189\n",
      "Training:: Epoch 6, Iteration 20, Current loss 6.096224308013916 Accuracy 37.17277486910995\n",
      "Training:: Epoch 6, Iteration 30, Current loss 5.290088176727295 Accuracy 43.77502197051069\n",
      "Training:: Epoch 6, Iteration 40, Current loss 6.296031951904297 Accuracy 39.13887259105474\n",
      "Training:: Epoch 6, Iteration 50, Current loss 4.6668171882629395 Accuracy 61.90076047224907\n",
      "Training:: Epoch 6, Iteration 60, Current loss 6.023809432983398 Accuracy 49.596060203629925\n",
      "Training:: Epoch 6, Iteration 70, Current loss 4.451329708099365 Accuracy 62.3491468997087\n",
      "Training:: Epoch 6, Iteration 80, Current loss 5.504332542419434 Accuracy 59.38994843759707\n",
      "Training:: Epoch 6, Iteration 90, Current loss 6.220942497253418 Accuracy 39.71163432778587\n",
      "Training:: Epoch 6, Iteration 100, Current loss 5.232811450958252 Accuracy 53.41265375030147\n",
      "Training:: Epoch 6, Iteration 110, Current loss 4.877970218658447 Accuracy 59.391797730439976\n",
      "Training:: Epoch 6, Iteration 120, Current loss 6.771461486816406 Accuracy 48.966472159034716\n",
      "Training:: Epoch 6, Iteration 130, Current loss 7.006464004516602 Accuracy 39.620836286321754\n",
      "Training:: Epoch 6, Iteration 140, Current loss 6.263021469116211 Accuracy 36.72555151720057\n",
      "Training:: Epoch 6, Iteration 150, Current loss 5.31699800491333 Accuracy 56.862588404523116\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 6, Probability Accuracy 49.34778555744293\n",
      "Starting Training\n",
      "Training:: Epoch 7, Iteration 0, Current loss 5.785682201385498 Accuracy 38.312226298970295\n",
      "Training:: Epoch 7, Iteration 10, Current loss 6.21064567565918 Accuracy 46.270427700771265\n",
      "Training:: Epoch 7, Iteration 20, Current loss 6.240155220031738 Accuracy 54.869943382292604\n",
      "Training:: Epoch 7, Iteration 30, Current loss 5.299489498138428 Accuracy 62.366949305430275\n",
      "Training:: Epoch 7, Iteration 40, Current loss 6.018286228179932 Accuracy 43.75101974220917\n",
      "Training:: Epoch 7, Iteration 50, Current loss 5.814239501953125 Accuracy 50.193374027305346\n",
      "Training:: Epoch 7, Iteration 60, Current loss 6.262054443359375 Accuracy 42.15038399714235\n",
      "Training:: Epoch 7, Iteration 70, Current loss 8.108723640441895 Accuracy 19.372561509674338\n",
      "Training:: Epoch 7, Iteration 80, Current loss 6.038597583770752 Accuracy 36.47381660187514\n",
      "Training:: Epoch 7, Iteration 90, Current loss 5.3238348960876465 Accuracy 36.99804481876974\n",
      "Training:: Epoch 7, Iteration 100, Current loss 5.560389518737793 Accuracy 51.2462876537972\n",
      "Training:: Epoch 7, Iteration 110, Current loss 6.659701347351074 Accuracy 41.030185227532584\n",
      "Training:: Epoch 7, Iteration 120, Current loss 6.048285007476807 Accuracy 46.012067112984546\n",
      "Training:: Epoch 7, Iteration 130, Current loss 4.631276607513428 Accuracy 64.57930518305994\n",
      "Training:: Epoch 7, Iteration 140, Current loss 4.52477502822876 Accuracy 61.00332912409597\n",
      "Training:: Epoch 7, Iteration 150, Current loss 5.975498676300049 Accuracy 44.88146551724138\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 7, Probability Accuracy 43.68189915896756\n",
      "Starting Training\n",
      "Training:: Epoch 8, Iteration 0, Current loss 5.507381916046143 Accuracy 48.23247787117965\n",
      "Training:: Epoch 8, Iteration 10, Current loss 6.54689359664917 Accuracy 55.1534143737732\n",
      "Training:: Epoch 8, Iteration 20, Current loss 4.989388942718506 Accuracy 57.05203279237075\n",
      "Training:: Epoch 8, Iteration 30, Current loss 5.097029209136963 Accuracy 56.80363543266769\n",
      "Training:: Epoch 8, Iteration 40, Current loss 4.906767845153809 Accuracy 42.434533917240145\n",
      "Training:: Epoch 8, Iteration 50, Current loss 6.128808975219727 Accuracy 45.98916688160949\n",
      "Training:: Epoch 8, Iteration 60, Current loss 5.270493984222412 Accuracy 45.33798588006167\n",
      "Training:: Epoch 8, Iteration 70, Current loss 6.470535755157471 Accuracy 40.02366163856847\n",
      "Training:: Epoch 8, Iteration 80, Current loss 7.127804279327393 Accuracy 32.539638997092226\n",
      "Training:: Epoch 8, Iteration 90, Current loss 4.9684834480285645 Accuracy 46.95791399817018\n",
      "Training:: Epoch 8, Iteration 100, Current loss 5.600648403167725 Accuracy 50.90273076055067\n",
      "Training:: Epoch 8, Iteration 110, Current loss 5.8872761726379395 Accuracy 37.84290339069688\n",
      "Training:: Epoch 8, Iteration 120, Current loss 6.102625370025635 Accuracy 45.29759748883255\n",
      "Training:: Epoch 8, Iteration 130, Current loss 3.8543875217437744 Accuracy 53.102387843704776\n",
      "Training:: Epoch 8, Iteration 140, Current loss 5.288999557495117 Accuracy 36.70021983107717\n",
      "Training:: Epoch 8, Iteration 150, Current loss 10.033305168151855 Accuracy 20.327868852459016\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 8, Probability Accuracy 48.07525790280482\n",
      "Starting Training\n",
      "Training:: Epoch 9, Iteration 0, Current loss 6.341564655303955 Accuracy 41.55025223127668\n",
      "Training:: Epoch 9, Iteration 10, Current loss 5.622201919555664 Accuracy 46.99796378845413\n",
      "Training:: Epoch 9, Iteration 20, Current loss 4.4027323722839355 Accuracy 70.41719342604299\n",
      "Training:: Epoch 9, Iteration 30, Current loss 5.622786521911621 Accuracy 53.54319915931832\n",
      "Training:: Epoch 9, Iteration 40, Current loss 3.905857563018799 Accuracy 56.34643201542912\n",
      "Training:: Epoch 9, Iteration 50, Current loss 5.053160190582275 Accuracy 58.587591827980056\n",
      "Training:: Epoch 9, Iteration 60, Current loss 5.8123779296875 Accuracy 54.906649884623455\n",
      "Training:: Epoch 9, Iteration 70, Current loss 4.589599609375 Accuracy 53.43019445051344\n",
      "Training:: Epoch 9, Iteration 80, Current loss 5.168215274810791 Accuracy 53.773462783171524\n",
      "Training:: Epoch 9, Iteration 90, Current loss 5.603267192840576 Accuracy 56.76015069066555\n",
      "Training:: Epoch 9, Iteration 100, Current loss 4.764922618865967 Accuracy 61.79372197309417\n",
      "Training:: Epoch 9, Iteration 110, Current loss 4.646462440490723 Accuracy 69.79876406274758\n",
      "Training:: Epoch 9, Iteration 120, Current loss 5.607251167297363 Accuracy 48.77246821569487\n",
      "Training:: Epoch 9, Iteration 130, Current loss 5.271690368652344 Accuracy 58.73332178132039\n",
      "Training:: Epoch 9, Iteration 140, Current loss 6.074963092803955 Accuracy 47.51731538386499\n",
      "Training:: Epoch 9, Iteration 150, Current loss 4.690813064575195 Accuracy 57.17638468759779\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 9, Probability Accuracy 46.26393089447736\n",
      "Starting Training\n",
      "Training:: Epoch 10, Iteration 0, Current loss 5.896881580352783 Accuracy 46.31054131054131\n",
      "Training:: Epoch 10, Iteration 10, Current loss 4.056939601898193 Accuracy 61.91483734461782\n",
      "Training:: Epoch 10, Iteration 20, Current loss 5.851150035858154 Accuracy 42.01405471788224\n",
      "Training:: Epoch 10, Iteration 30, Current loss 5.261874675750732 Accuracy 50.333575934012615\n",
      "Training:: Epoch 10, Iteration 40, Current loss 4.668957233428955 Accuracy 64.05542352360881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 10, Iteration 50, Current loss 5.959776401519775 Accuracy 51.14178683224714\n",
      "Training:: Epoch 10, Iteration 60, Current loss 4.2059807777404785 Accuracy 64.28117792559415\n",
      "Training:: Epoch 10, Iteration 70, Current loss 4.595099449157715 Accuracy 53.57114228456914\n",
      "Training:: Epoch 10, Iteration 80, Current loss 3.8198883533477783 Accuracy 66.82602921646746\n",
      "Training:: Epoch 10, Iteration 90, Current loss 4.246981620788574 Accuracy 53.6848792884371\n",
      "Training:: Epoch 10, Iteration 100, Current loss 5.0094685554504395 Accuracy 43.80563798219585\n",
      "Training:: Epoch 10, Iteration 110, Current loss 4.2515106201171875 Accuracy 63.09654531632739\n",
      "Training:: Epoch 10, Iteration 120, Current loss 4.159738063812256 Accuracy 67.70468230430484\n",
      "Training:: Epoch 10, Iteration 130, Current loss 6.123836517333984 Accuracy 38.18364274962368\n",
      "Training:: Epoch 10, Iteration 140, Current loss 4.195005416870117 Accuracy 66.78538162292477\n",
      "Training:: Epoch 10, Iteration 150, Current loss 4.483700275421143 Accuracy 53.01309460181721\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 10, Probability Accuracy 36.59702945685048\n",
      "Starting Training\n",
      "Training:: Epoch 11, Iteration 0, Current loss 6.011621952056885 Accuracy 49.370889333714615\n",
      "Training:: Epoch 11, Iteration 10, Current loss 5.751695156097412 Accuracy 38.778067361668\n",
      "Training:: Epoch 11, Iteration 20, Current loss 4.365035057067871 Accuracy 63.16136114160263\n",
      "Training:: Epoch 11, Iteration 30, Current loss 5.0913262367248535 Accuracy 52.41717158695372\n",
      "Training:: Epoch 11, Iteration 40, Current loss 4.234102249145508 Accuracy 59.98319945398225\n",
      "Training:: Epoch 11, Iteration 50, Current loss 6.272489070892334 Accuracy 39.50102574283635\n",
      "Training:: Epoch 11, Iteration 60, Current loss 4.435470104217529 Accuracy 48.48398005387746\n",
      "Training:: Epoch 11, Iteration 70, Current loss 4.166530609130859 Accuracy 57.33016186111272\n",
      "Training:: Epoch 11, Iteration 80, Current loss 3.8721940517425537 Accuracy 51.054876979720646\n",
      "Training:: Epoch 11, Iteration 90, Current loss 5.73552131652832 Accuracy 39.673849052160605\n",
      "Training:: Epoch 11, Iteration 100, Current loss 4.5696001052856445 Accuracy 56.20993154406172\n",
      "Training:: Epoch 11, Iteration 110, Current loss 3.17163348197937 Accuracy 64.42086517771017\n",
      "Training:: Epoch 11, Iteration 120, Current loss 5.061671733856201 Accuracy 56.62930852188624\n",
      "Training:: Epoch 11, Iteration 130, Current loss 5.222996234893799 Accuracy 44.011709303805524\n",
      "Training:: Epoch 11, Iteration 140, Current loss 5.697227954864502 Accuracy 42.95591537643305\n",
      "Training:: Epoch 11, Iteration 150, Current loss 6.601910591125488 Accuracy 42.794504530838935\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 11, Probability Accuracy 47.264883788374696\n",
      "Starting Training\n",
      "Training:: Epoch 12, Iteration 0, Current loss 4.283528804779053 Accuracy 56.79122846274334\n",
      "Training:: Epoch 12, Iteration 10, Current loss 3.534336566925049 Accuracy 63.63345081704582\n",
      "Training:: Epoch 12, Iteration 20, Current loss 5.009424209594727 Accuracy 45.80160030849321\n",
      "Training:: Epoch 12, Iteration 30, Current loss 3.5234322547912598 Accuracy 55.47957695113056\n",
      "Training:: Epoch 12, Iteration 40, Current loss 4.557610511779785 Accuracy 47.58527306725127\n",
      "Training:: Epoch 12, Iteration 50, Current loss 4.408904552459717 Accuracy 58.052565707133915\n",
      "Training:: Epoch 12, Iteration 60, Current loss 4.952645778656006 Accuracy 61.10791140897429\n",
      "Training:: Epoch 12, Iteration 70, Current loss 5.32997465133667 Accuracy 42.646495595557255\n",
      "Training:: Epoch 12, Iteration 80, Current loss 3.7833163738250732 Accuracy 54.273530684135714\n",
      "Training:: Epoch 12, Iteration 90, Current loss 4.531954288482666 Accuracy 62.82280533954339\n",
      "Training:: Epoch 12, Iteration 100, Current loss 3.912280321121216 Accuracy 58.92386530014641\n",
      "Training:: Epoch 12, Iteration 110, Current loss 3.803286075592041 Accuracy 64.41008157798612\n",
      "Training:: Epoch 12, Iteration 120, Current loss 4.161825180053711 Accuracy 55.0410355641556\n",
      "Training:: Epoch 12, Iteration 130, Current loss 4.6565680503845215 Accuracy 55.6920457309657\n",
      "Training:: Epoch 12, Iteration 140, Current loss 4.65672492980957 Accuracy 63.28455910666153\n",
      "Training:: Epoch 12, Iteration 150, Current loss 4.294006824493408 Accuracy 50.26125625347415\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 12, Probability Accuracy 47.794672080208805\n",
      "Starting Training\n",
      "Training:: Epoch 13, Iteration 0, Current loss 3.5418336391448975 Accuracy 63.93900033674893\n",
      "Training:: Epoch 13, Iteration 10, Current loss 4.299198150634766 Accuracy 63.091615956727516\n",
      "Training:: Epoch 13, Iteration 20, Current loss 3.9610989093780518 Accuracy 56.88083010166649\n",
      "Training:: Epoch 13, Iteration 30, Current loss 6.146846294403076 Accuracy 48.061438823735344\n",
      "Training:: Epoch 13, Iteration 40, Current loss 4.395328521728516 Accuracy 57.420565759485186\n",
      "Training:: Epoch 13, Iteration 50, Current loss 4.480691432952881 Accuracy 54.01487942534633\n",
      "Training:: Epoch 13, Iteration 60, Current loss 4.253509521484375 Accuracy 52.58926007466258\n",
      "Training:: Epoch 13, Iteration 70, Current loss 4.572169780731201 Accuracy 47.862936298186455\n",
      "Training:: Epoch 13, Iteration 80, Current loss 3.7590084075927734 Accuracy 61.5273218768102\n",
      "Training:: Epoch 13, Iteration 90, Current loss 3.946843147277832 Accuracy 58.82317622335635\n",
      "Training:: Epoch 13, Iteration 100, Current loss 5.1012444496154785 Accuracy 55.46597257491112\n",
      "Training:: Epoch 13, Iteration 110, Current loss 4.112919330596924 Accuracy 65.18259589734156\n",
      "Training:: Epoch 13, Iteration 120, Current loss 4.485960960388184 Accuracy 43.684081432425806\n",
      "Training:: Epoch 13, Iteration 130, Current loss 5.165204048156738 Accuracy 53.68223421731988\n",
      "Training:: Epoch 13, Iteration 140, Current loss 6.008881092071533 Accuracy 39.491600137140615\n",
      "Training:: Epoch 13, Iteration 150, Current loss 3.9935030937194824 Accuracy 70.57611568962837\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 13, Probability Accuracy 49.81832870696441\n",
      "Starting Training\n",
      "Training:: Epoch 14, Iteration 0, Current loss 4.183994770050049 Accuracy 53.612836438923395\n",
      "Training:: Epoch 14, Iteration 10, Current loss 4.42789888381958 Accuracy 49.06276870163371\n",
      "Training:: Epoch 14, Iteration 20, Current loss 3.849698781967163 Accuracy 61.54517677869926\n",
      "Training:: Epoch 14, Iteration 30, Current loss 3.7570083141326904 Accuracy 60.84720530518338\n",
      "Training:: Epoch 14, Iteration 40, Current loss 5.002195358276367 Accuracy 58.19704202206746\n",
      "Training:: Epoch 14, Iteration 50, Current loss 3.210995674133301 Accuracy 67.31348907309722\n",
      "Training:: Epoch 14, Iteration 60, Current loss 3.807124614715576 Accuracy 63.37337044089644\n",
      "Training:: Epoch 14, Iteration 70, Current loss 3.256610870361328 Accuracy 66.4103491948616\n",
      "Training:: Epoch 14, Iteration 80, Current loss 3.9605979919433594 Accuracy 58.47122047800877\n",
      "Training:: Epoch 14, Iteration 90, Current loss 3.6755764484405518 Accuracy 57.09478021978022\n",
      "Training:: Epoch 14, Iteration 100, Current loss 3.1998789310455322 Accuracy 57.82396742915305\n",
      "Training:: Epoch 14, Iteration 110, Current loss 4.384973526000977 Accuracy 59.14304263146505\n",
      "Training:: Epoch 14, Iteration 120, Current loss 4.62241268157959 Accuracy 59.98984943326003\n",
      "Training:: Epoch 14, Iteration 130, Current loss 4.671204090118408 Accuracy 60.949988581868006\n",
      "Training:: Epoch 14, Iteration 140, Current loss 4.222866058349609 Accuracy 55.96167727541177\n",
      "Training:: Epoch 14, Iteration 150, Current loss 4.350496768951416 Accuracy 51.280417887629\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 14, Probability Accuracy 51.20779301487343\n",
      "Starting Training\n",
      "Training:: Epoch 15, Iteration 0, Current loss 3.602790117263794 Accuracy 68.44860843207495\n",
      "Training:: Epoch 15, Iteration 10, Current loss 3.1063482761383057 Accuracy 71.49078966157361\n",
      "Training:: Epoch 15, Iteration 20, Current loss 5.1603240966796875 Accuracy 55.14046495813677\n",
      "Training:: Epoch 15, Iteration 30, Current loss 3.684380292892456 Accuracy 64.68733805493177\n",
      "Training:: Epoch 15, Iteration 40, Current loss 2.8846726417541504 Accuracy 65.43307086614173\n",
      "Training:: Epoch 15, Iteration 50, Current loss 5.8319478034973145 Accuracy 50.25097150259067\n",
      "Training:: Epoch 15, Iteration 60, Current loss 3.7654998302459717 Accuracy 66.06422646678335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 15, Iteration 70, Current loss 3.196843147277832 Accuracy 58.04139414031001\n",
      "Training:: Epoch 15, Iteration 80, Current loss 3.788417339324951 Accuracy 58.47253775223841\n",
      "Training:: Epoch 15, Iteration 90, Current loss 4.681201934814453 Accuracy 56.672386724597466\n",
      "Training:: Epoch 15, Iteration 100, Current loss 3.9759609699249268 Accuracy 55.2106959532052\n",
      "Training:: Epoch 15, Iteration 110, Current loss 6.86570930480957 Accuracy 50.14230534661517\n",
      "Training:: Epoch 15, Iteration 120, Current loss 5.8196940422058105 Accuracy 44.182648401826484\n",
      "Training:: Epoch 15, Iteration 130, Current loss 4.762230396270752 Accuracy 49.19566644780039\n",
      "Training:: Epoch 15, Iteration 140, Current loss 5.319911003112793 Accuracy 51.261436096479066\n",
      "Training:: Epoch 15, Iteration 150, Current loss 5.391932964324951 Accuracy 52.984078068823834\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 15, Probability Accuracy 50.38675063181008\n",
      "Starting Training\n",
      "Training:: Epoch 16, Iteration 0, Current loss 3.4037365913391113 Accuracy 66.45141131132173\n",
      "Training:: Epoch 16, Iteration 10, Current loss 3.2582132816314697 Accuracy 60.45860792633385\n",
      "Training:: Epoch 16, Iteration 20, Current loss 3.6320035457611084 Accuracy 61.27972577304863\n",
      "Training:: Epoch 16, Iteration 30, Current loss 4.56968355178833 Accuracy 62.22142558403537\n",
      "Training:: Epoch 16, Iteration 40, Current loss 4.554482460021973 Accuracy 63.931421589216846\n",
      "Training:: Epoch 16, Iteration 50, Current loss 4.184885025024414 Accuracy 47.27983679020741\n",
      "Training:: Epoch 16, Iteration 60, Current loss 3.442850351333618 Accuracy 62.648109073202406\n",
      "Training:: Epoch 16, Iteration 70, Current loss 3.653303623199463 Accuracy 61.324461675485935\n",
      "Training:: Epoch 16, Iteration 80, Current loss 3.480428695678711 Accuracy 66.87604410290679\n",
      "Training:: Epoch 16, Iteration 90, Current loss 3.341231107711792 Accuracy 68.33893422947672\n",
      "Training:: Epoch 16, Iteration 100, Current loss 4.13120698928833 Accuracy 60.29352471574873\n",
      "Training:: Epoch 16, Iteration 110, Current loss 2.912668466567993 Accuracy 65.51262433052793\n",
      "Training:: Epoch 16, Iteration 120, Current loss 5.710804462432861 Accuracy 37.12889544532547\n",
      "Training:: Epoch 16, Iteration 130, Current loss 4.240419864654541 Accuracy 66.26584476471609\n",
      "Training:: Epoch 16, Iteration 140, Current loss 4.038693428039551 Accuracy 60.633782201405154\n",
      "Training:: Epoch 16, Iteration 150, Current loss 2.833310127258301 Accuracy 66.14089458346824\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 16, Probability Accuracy 49.84090814931433\n",
      "Starting Training\n",
      "Training:: Epoch 17, Iteration 0, Current loss 3.5912492275238037 Accuracy 67.87506740221494\n",
      "Training:: Epoch 17, Iteration 10, Current loss 4.613368511199951 Accuracy 55.5942995755003\n",
      "Training:: Epoch 17, Iteration 20, Current loss 3.539332628250122 Accuracy 61.79955814420566\n",
      "Training:: Epoch 17, Iteration 30, Current loss 5.7170939445495605 Accuracy 40.508912777248604\n",
      "Training:: Epoch 17, Iteration 40, Current loss 3.7944557666778564 Accuracy 60.44664548682489\n",
      "Training:: Epoch 17, Iteration 50, Current loss 3.152501344680786 Accuracy 71.28222893056862\n",
      "Training:: Epoch 17, Iteration 60, Current loss 3.5329229831695557 Accuracy 60.32677264698461\n",
      "Training:: Epoch 17, Iteration 70, Current loss 3.503777503967285 Accuracy 56.00162206001622\n",
      "Training:: Epoch 17, Iteration 80, Current loss 4.5079121589660645 Accuracy 54.22823984526112\n",
      "Training:: Epoch 17, Iteration 90, Current loss 3.1003174781799316 Accuracy 57.0932332916493\n",
      "Training:: Epoch 17, Iteration 100, Current loss 5.248306751251221 Accuracy 46.17673579801623\n",
      "Training:: Epoch 17, Iteration 110, Current loss 3.9964375495910645 Accuracy 62.45140855209483\n",
      "Training:: Epoch 17, Iteration 120, Current loss 3.3014323711395264 Accuracy 58.71010638297872\n",
      "Training:: Epoch 17, Iteration 130, Current loss 4.77202033996582 Accuracy 52.586483023702755\n",
      "Training:: Epoch 17, Iteration 140, Current loss 3.3773324489593506 Accuracy 60.34310791940953\n",
      "Training:: Epoch 17, Iteration 150, Current loss 3.5593721866607666 Accuracy 63.483778528298025\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 17, Probability Accuracy 55.03894435928243\n",
      "Starting Training\n",
      "Training:: Epoch 18, Iteration 0, Current loss 2.779947280883789 Accuracy 68.80063086959639\n",
      "Training:: Epoch 18, Iteration 10, Current loss 3.3287885189056396 Accuracy 56.15002161694769\n",
      "Training:: Epoch 18, Iteration 20, Current loss 3.246119976043701 Accuracy 66.75088187625131\n",
      "Training:: Epoch 18, Iteration 30, Current loss 5.184728622436523 Accuracy 51.581805838424984\n",
      "Training:: Epoch 18, Iteration 40, Current loss 3.6123852729797363 Accuracy 58.24045930428909\n",
      "Training:: Epoch 18, Iteration 50, Current loss 4.160691261291504 Accuracy 58.293741668660495\n",
      "Training:: Epoch 18, Iteration 60, Current loss 3.972416877746582 Accuracy 53.835008179481186\n",
      "Training:: Epoch 18, Iteration 70, Current loss 3.668421745300293 Accuracy 64.00956937799043\n",
      "Training:: Epoch 18, Iteration 80, Current loss 4.8784379959106445 Accuracy 55.33718689788054\n",
      "Training:: Epoch 18, Iteration 90, Current loss 4.857880115509033 Accuracy 57.454878367774\n",
      "Training:: Epoch 18, Iteration 100, Current loss 7.196495056152344 Accuracy 49.26603841971729\n",
      "Training:: Epoch 18, Iteration 110, Current loss 6.144066333770752 Accuracy 49.89793603991835\n",
      "Training:: Epoch 18, Iteration 120, Current loss 7.791391849517822 Accuracy 38.83586406362979\n",
      "Training:: Epoch 18, Iteration 130, Current loss 4.267977714538574 Accuracy 65.71656686626747\n",
      "Training:: Epoch 18, Iteration 140, Current loss 5.221024990081787 Accuracy 45.77501296008295\n",
      "Training:: Epoch 18, Iteration 150, Current loss 4.564459323883057 Accuracy 64.40598690364827\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 18, Probability Accuracy 53.648029995442684\n",
      "Starting Training\n",
      "Training:: Epoch 19, Iteration 0, Current loss 3.368650436401367 Accuracy 74.86189386752972\n",
      "Training:: Epoch 19, Iteration 10, Current loss 4.024941921234131 Accuracy 53.98950606115433\n",
      "Training:: Epoch 19, Iteration 20, Current loss 3.7930715084075928 Accuracy 67.73573268512136\n",
      "Training:: Epoch 19, Iteration 30, Current loss 4.658729076385498 Accuracy 46.26692845995066\n",
      "Training:: Epoch 19, Iteration 40, Current loss 3.4234728813171387 Accuracy 59.21602227696262\n",
      "Training:: Epoch 19, Iteration 50, Current loss 3.032561779022217 Accuracy 63.457330415754925\n",
      "Training:: Epoch 19, Iteration 60, Current loss 3.3642501831054688 Accuracy 63.45183116743637\n",
      "Training:: Epoch 19, Iteration 70, Current loss 2.7703964710235596 Accuracy 62.130849613811904\n",
      "Training:: Epoch 19, Iteration 80, Current loss 3.2547101974487305 Accuracy 61.059737377473645\n",
      "Training:: Epoch 19, Iteration 90, Current loss 3.352790117263794 Accuracy 60.65593368932813\n",
      "Training:: Epoch 19, Iteration 100, Current loss 3.105319023132324 Accuracy 61.98950023863094\n",
      "Training:: Epoch 19, Iteration 110, Current loss 5.110281467437744 Accuracy 45.337280609008246\n",
      "Training:: Epoch 19, Iteration 120, Current loss 3.7719855308532715 Accuracy 61.23373197326767\n",
      "Training:: Epoch 19, Iteration 130, Current loss 4.393395900726318 Accuracy 56.748690804662424\n",
      "Training:: Epoch 19, Iteration 140, Current loss 3.7747702598571777 Accuracy 64.42668797443068\n",
      "Training:: Epoch 19, Iteration 150, Current loss 3.1290743350982666 Accuracy 70.06802721088435\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 19, Probability Accuracy 55.13381944732154\n",
      "Starting Training\n",
      "Training:: Epoch 20, Iteration 0, Current loss 3.2483112812042236 Accuracy 58.460187353629976\n",
      "Training:: Epoch 20, Iteration 10, Current loss 2.9525680541992188 Accuracy 59.82831114225648\n",
      "Training:: Epoch 20, Iteration 20, Current loss 2.683048725128174 Accuracy 59.515122984582796\n",
      "Training:: Epoch 20, Iteration 30, Current loss 2.25877046585083 Accuracy 64.9866149727684\n",
      "Training:: Epoch 20, Iteration 40, Current loss 3.038956642150879 Accuracy 56.59323611542042\n",
      "Training:: Epoch 20, Iteration 50, Current loss 5.6049981117248535 Accuracy 52.13807573184134\n",
      "Training:: Epoch 20, Iteration 60, Current loss 3.7859668731689453 Accuracy 63.48964773772155\n",
      "Training:: Epoch 20, Iteration 70, Current loss 3.079960584640503 Accuracy 65.54226582448595\n",
      "Training:: Epoch 20, Iteration 80, Current loss 3.8021271228790283 Accuracy 61.2662712143681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 20, Iteration 90, Current loss 3.1407456398010254 Accuracy 65.94149043983515\n",
      "Training:: Epoch 20, Iteration 100, Current loss 3.091240882873535 Accuracy 70.54435662907379\n",
      "Training:: Epoch 20, Iteration 110, Current loss 2.8897907733917236 Accuracy 59.20873966177015\n",
      "Training:: Epoch 20, Iteration 120, Current loss 2.893315076828003 Accuracy 70.64614983373541\n",
      "Training:: Epoch 20, Iteration 130, Current loss 3.020702600479126 Accuracy 66.06771915247195\n",
      "Training:: Epoch 20, Iteration 140, Current loss 3.5447447299957275 Accuracy 66.86967530023608\n",
      "Training:: Epoch 20, Iteration 150, Current loss 4.137700080871582 Accuracy 57.346005430898956\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 20, Probability Accuracy 52.8105191200232\n",
      "Starting Training\n",
      "Training:: Epoch 21, Iteration 0, Current loss 3.4592385292053223 Accuracy 58.119758143163644\n",
      "Training:: Epoch 21, Iteration 10, Current loss 5.798767566680908 Accuracy 42.748284214775936\n",
      "Training:: Epoch 21, Iteration 20, Current loss 3.3236355781555176 Accuracy 58.818465070514925\n",
      "Training:: Epoch 21, Iteration 30, Current loss 2.9829907417297363 Accuracy 64.36615352825706\n",
      "Training:: Epoch 21, Iteration 40, Current loss 2.8988595008850098 Accuracy 71.21799844840962\n",
      "Training:: Epoch 21, Iteration 50, Current loss 3.3178422451019287 Accuracy 59.99525869732709\n",
      "Training:: Epoch 21, Iteration 60, Current loss 4.1461710929870605 Accuracy 58.81430065608063\n",
      "Training:: Epoch 21, Iteration 70, Current loss 3.158022403717041 Accuracy 63.055937643282896\n",
      "Training:: Epoch 21, Iteration 80, Current loss 3.5374326705932617 Accuracy 67.69539078156312\n",
      "Training:: Epoch 21, Iteration 90, Current loss 2.958190441131592 Accuracy 57.979359043997825\n",
      "Training:: Epoch 21, Iteration 100, Current loss 2.540114164352417 Accuracy 72.21388000261148\n",
      "Training:: Epoch 21, Iteration 110, Current loss 4.924219608306885 Accuracy 42.92413331100318\n",
      "Training:: Epoch 21, Iteration 120, Current loss 4.550306797027588 Accuracy 53.782786885245905\n",
      "Training:: Epoch 21, Iteration 130, Current loss 2.7235944271087646 Accuracy 58.243260032302146\n",
      "Training:: Epoch 21, Iteration 140, Current loss 2.7741355895996094 Accuracy 71.683820978374\n",
      "Training:: Epoch 21, Iteration 150, Current loss 3.776317834854126 Accuracy 67.2495446265938\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 21, Probability Accuracy 51.38190330198451\n",
      "Starting Training\n",
      "Training:: Epoch 22, Iteration 0, Current loss 2.85087251663208 Accuracy 70.94058110112556\n",
      "Training:: Epoch 22, Iteration 10, Current loss 2.8882832527160645 Accuracy 71.45454545454545\n",
      "Training:: Epoch 22, Iteration 20, Current loss 2.9410533905029297 Accuracy 66.85261303581915\n",
      "Training:: Epoch 22, Iteration 30, Current loss 2.777250051498413 Accuracy 57.12850629781315\n",
      "Training:: Epoch 22, Iteration 40, Current loss 3.2830498218536377 Accuracy 62.25463048427789\n",
      "Training:: Epoch 22, Iteration 50, Current loss 3.2564711570739746 Accuracy 55.484623610616026\n",
      "Training:: Epoch 22, Iteration 60, Current loss 3.53212571144104 Accuracy 60.25404454362099\n",
      "Training:: Epoch 22, Iteration 70, Current loss 3.1702749729156494 Accuracy 71.3512331164215\n",
      "Training:: Epoch 22, Iteration 80, Current loss 2.919764280319214 Accuracy 63.17145688800793\n",
      "Training:: Epoch 22, Iteration 90, Current loss 2.794461727142334 Accuracy 66.0901353120908\n",
      "Training:: Epoch 22, Iteration 100, Current loss 2.526073455810547 Accuracy 70.09357377455537\n",
      "Training:: Epoch 22, Iteration 110, Current loss 2.9139926433563232 Accuracy 67.35491434898717\n",
      "Training:: Epoch 22, Iteration 120, Current loss 3.1870334148406982 Accuracy 61.65696959763992\n",
      "Training:: Epoch 22, Iteration 130, Current loss 2.7863264083862305 Accuracy 61.8374928059436\n",
      "Training:: Epoch 22, Iteration 140, Current loss 5.434828281402588 Accuracy 43.234662851010555\n",
      "Training:: Epoch 22, Iteration 150, Current loss 2.4143946170806885 Accuracy 69.26846548975615\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 22, Probability Accuracy 51.09168496499151\n",
      "Starting Training\n",
      "Training:: Epoch 23, Iteration 0, Current loss 3.0228304862976074 Accuracy 62.87787182587666\n",
      "Training:: Epoch 23, Iteration 10, Current loss 3.2656409740448 Accuracy 56.255948458891574\n",
      "Training:: Epoch 23, Iteration 20, Current loss 3.058992385864258 Accuracy 55.00273373428103\n",
      "Training:: Epoch 23, Iteration 30, Current loss 2.9200875759124756 Accuracy 62.458788189610964\n",
      "Training:: Epoch 23, Iteration 40, Current loss 3.3766028881073 Accuracy 67.61152908763378\n",
      "Training:: Epoch 23, Iteration 50, Current loss 3.374446392059326 Accuracy 68.54505240888547\n",
      "Training:: Epoch 23, Iteration 60, Current loss 2.8973937034606934 Accuracy 67.77707006369427\n",
      "Training:: Epoch 23, Iteration 70, Current loss 3.271894931793213 Accuracy 64.73540800229456\n",
      "Training:: Epoch 23, Iteration 80, Current loss 3.062544822692871 Accuracy 72.76217338504328\n",
      "Training:: Epoch 23, Iteration 90, Current loss 3.2645158767700195 Accuracy 69.8311763915633\n",
      "Training:: Epoch 23, Iteration 100, Current loss 3.2699596881866455 Accuracy 68.9667057282691\n",
      "Training:: Epoch 23, Iteration 110, Current loss 3.1709794998168945 Accuracy 69.31470288091687\n",
      "Training:: Epoch 23, Iteration 120, Current loss 2.7946338653564453 Accuracy 59.23168160253031\n",
      "Training:: Epoch 23, Iteration 130, Current loss 3.700523614883423 Accuracy 63.733992361267134\n",
      "Training:: Epoch 23, Iteration 140, Current loss 2.6313445568084717 Accuracy 66.77364142062473\n",
      "Training:: Epoch 23, Iteration 150, Current loss 2.980107069015503 Accuracy 64.85094427969409\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 23, Probability Accuracy 48.55698719807764\n",
      "Starting Training\n",
      "Training:: Epoch 24, Iteration 0, Current loss 2.5471351146698 Accuracy 73.80226090077157\n",
      "Training:: Epoch 24, Iteration 10, Current loss 3.253633499145508 Accuracy 64.78625353156407\n",
      "Training:: Epoch 24, Iteration 20, Current loss 2.229626178741455 Accuracy 59.794365068767526\n",
      "Training:: Epoch 24, Iteration 30, Current loss 3.4187934398651123 Accuracy 52.52651278852152\n",
      "Training:: Epoch 24, Iteration 40, Current loss 2.923085927963257 Accuracy 62.53200568990043\n",
      "Training:: Epoch 24, Iteration 50, Current loss 2.700255870819092 Accuracy 71.37329949660939\n",
      "Training:: Epoch 24, Iteration 60, Current loss 2.6189756393432617 Accuracy 65.69386000633456\n",
      "Training:: Epoch 24, Iteration 70, Current loss 2.619734525680542 Accuracy 63.76177144311529\n",
      "Training:: Epoch 24, Iteration 80, Current loss 2.4747631549835205 Accuracy 71.82169861086689\n",
      "Training:: Epoch 24, Iteration 90, Current loss 2.183441638946533 Accuracy 68.83341334613539\n",
      "Training:: Epoch 24, Iteration 100, Current loss 2.6319122314453125 Accuracy 70.36078965282505\n",
      "Training:: Epoch 24, Iteration 110, Current loss 4.080997943878174 Accuracy 62.94005708848716\n",
      "Training:: Epoch 24, Iteration 120, Current loss 2.8298728466033936 Accuracy 71.49203998519067\n",
      "Training:: Epoch 24, Iteration 130, Current loss 3.086337089538574 Accuracy 57.61523046092184\n",
      "Training:: Epoch 24, Iteration 140, Current loss 2.7562432289123535 Accuracy 71.26721604333545\n",
      "Training:: Epoch 24, Iteration 150, Current loss 2.544569730758667 Accuracy 71.69746513704747\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 24, Probability Accuracy 54.156067448315866\n",
      "Starting Training\n",
      "Training:: Epoch 25, Iteration 0, Current loss 1.673453450202942 Accuracy 65.09453563266155\n",
      "Training:: Epoch 25, Iteration 10, Current loss 2.9302806854248047 Accuracy 58.90840652446675\n",
      "Training:: Epoch 25, Iteration 20, Current loss 2.224667549133301 Accuracy 64.88809510520734\n",
      "Training:: Epoch 25, Iteration 30, Current loss 3.0956008434295654 Accuracy 61.988188976377955\n",
      "Training:: Epoch 25, Iteration 40, Current loss 2.8145976066589355 Accuracy 52.78467773565172\n",
      "Training:: Epoch 25, Iteration 50, Current loss 3.960096597671509 Accuracy 58.59578156602138\n",
      "Training:: Epoch 25, Iteration 60, Current loss 3.9116973876953125 Accuracy 45.095424618718226\n",
      "Training:: Epoch 25, Iteration 70, Current loss 3.4276721477508545 Accuracy 66.46866646866647\n",
      "Training:: Epoch 25, Iteration 80, Current loss 3.0289528369903564 Accuracy 65.10325131810194\n",
      "Training:: Epoch 25, Iteration 90, Current loss 4.028380870819092 Accuracy 69.94017042364175\n",
      "Training:: Epoch 25, Iteration 100, Current loss 4.314260482788086 Accuracy 54.552157714995346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 25, Iteration 110, Current loss 4.253875255584717 Accuracy 52.74508254996445\n",
      "Training:: Epoch 25, Iteration 120, Current loss 3.464813470840454 Accuracy 55.069240877388054\n",
      "Training:: Epoch 25, Iteration 130, Current loss 3.3248579502105713 Accuracy 60.970129526830554\n",
      "Training:: Epoch 25, Iteration 140, Current loss 3.8698794841766357 Accuracy 58.38920880334464\n",
      "Training:: Epoch 25, Iteration 150, Current loss 2.973176956176758 Accuracy 63.05624636224139\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 25, Probability Accuracy 55.46132493681899\n",
      "Starting Training\n",
      "Training:: Epoch 26, Iteration 0, Current loss 3.374666213989258 Accuracy 58.43350285097858\n",
      "Training:: Epoch 26, Iteration 10, Current loss 3.181309700012207 Accuracy 59.44004690706538\n",
      "Training:: Epoch 26, Iteration 20, Current loss 3.2264745235443115 Accuracy 64.0451803002666\n",
      "Training:: Epoch 26, Iteration 30, Current loss 3.1254286766052246 Accuracy 69.07715881567891\n",
      "Training:: Epoch 26, Iteration 40, Current loss 3.6267292499542236 Accuracy 47.078756080231734\n",
      "Training:: Epoch 26, Iteration 50, Current loss 2.4167497158050537 Accuracy 67.66823161189359\n",
      "Training:: Epoch 26, Iteration 60, Current loss 2.7596147060394287 Accuracy 62.469365334234766\n",
      "Training:: Epoch 26, Iteration 70, Current loss 2.1070523262023926 Accuracy 73.955143590168\n",
      "Training:: Epoch 26, Iteration 80, Current loss 2.8326528072357178 Accuracy 65.97458385537855\n",
      "Training:: Epoch 26, Iteration 90, Current loss 2.7782018184661865 Accuracy 66.17528271405493\n",
      "Training:: Epoch 26, Iteration 100, Current loss 3.2599740028381348 Accuracy 50.77436987549347\n",
      "Training:: Epoch 26, Iteration 110, Current loss 2.6180129051208496 Accuracy 66.24741633317208\n",
      "Training:: Epoch 26, Iteration 120, Current loss 1.8998106718063354 Accuracy 73.6872291613561\n",
      "Training:: Epoch 26, Iteration 130, Current loss 1.8897565603256226 Accuracy 56.26777799828008\n",
      "Training:: Epoch 26, Iteration 140, Current loss 2.8759090900421143 Accuracy 58.75486381322957\n",
      "Training:: Epoch 26, Iteration 150, Current loss 3.0893383026123047 Accuracy 63.34302034271971\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 26, Probability Accuracy 53.81851514272693\n",
      "Starting Training\n",
      "Training:: Epoch 27, Iteration 0, Current loss 2.260035276412964 Accuracy 63.05374696795608\n",
      "Training:: Epoch 27, Iteration 10, Current loss 2.9030368328094482 Accuracy 62.384392088030786\n",
      "Training:: Epoch 27, Iteration 20, Current loss 2.212493419647217 Accuracy 66.5355380717429\n",
      "Training:: Epoch 27, Iteration 30, Current loss 2.5730161666870117 Accuracy 63.763640107061974\n",
      "Training:: Epoch 27, Iteration 40, Current loss 3.039351224899292 Accuracy 65.36191081645627\n",
      "Training:: Epoch 27, Iteration 50, Current loss 2.84553861618042 Accuracy 65.91143682906689\n",
      "Training:: Epoch 27, Iteration 60, Current loss 3.405747413635254 Accuracy 48.3751846381093\n",
      "Training:: Epoch 27, Iteration 70, Current loss 2.3485703468322754 Accuracy 60.04749725977347\n",
      "Training:: Epoch 27, Iteration 80, Current loss 2.995004653930664 Accuracy 49.4793945227054\n",
      "Training:: Epoch 27, Iteration 90, Current loss 2.355024576187134 Accuracy 64.67955889403868\n",
      "Training:: Epoch 27, Iteration 100, Current loss 2.967400074005127 Accuracy 68.84934277047523\n",
      "Training:: Epoch 27, Iteration 110, Current loss 2.7595529556274414 Accuracy 67.19262724289604\n",
      "Training:: Epoch 27, Iteration 120, Current loss 2.251209020614624 Accuracy 70.66416441616698\n",
      "Training:: Epoch 27, Iteration 130, Current loss 2.90824294090271 Accuracy 68.97730637736561\n",
      "Training:: Epoch 27, Iteration 140, Current loss 2.9798943996429443 Accuracy 66.87548270831546\n",
      "Training:: Epoch 27, Iteration 150, Current loss 2.7053613662719727 Accuracy 54.25367362722351\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 27, Probability Accuracy 53.23642126196296\n",
      "Starting Training\n",
      "Training:: Epoch 28, Iteration 0, Current loss 2.155067205429077 Accuracy 55.70846467286846\n",
      "Training:: Epoch 28, Iteration 10, Current loss 2.8011181354522705 Accuracy 63.603089198784815\n",
      "Training:: Epoch 28, Iteration 20, Current loss 2.3457610607147217 Accuracy 68.76159382651926\n",
      "Training:: Epoch 28, Iteration 30, Current loss 2.622751235961914 Accuracy 54.99310262100402\n",
      "Training:: Epoch 28, Iteration 40, Current loss 2.1638150215148926 Accuracy 76.03655818100758\n",
      "Training:: Epoch 28, Iteration 50, Current loss 2.2125937938690186 Accuracy 54.33702379914567\n",
      "Training:: Epoch 28, Iteration 60, Current loss 3.088594913482666 Accuracy 61.56781130766563\n",
      "Training:: Epoch 28, Iteration 70, Current loss 2.0033767223358154 Accuracy 72.26231956197113\n",
      "Training:: Epoch 28, Iteration 80, Current loss 3.109896659851074 Accuracy 64.31601272534465\n",
      "Training:: Epoch 28, Iteration 90, Current loss 3.0605950355529785 Accuracy 52.02279839070183\n",
      "Training:: Epoch 28, Iteration 100, Current loss 2.5018765926361084 Accuracy 68.65310077519379\n",
      "Training:: Epoch 28, Iteration 110, Current loss 2.1336302757263184 Accuracy 67.24498327759197\n",
      "Training:: Epoch 28, Iteration 120, Current loss 2.414379596710205 Accuracy 72.21549318026226\n",
      "Training:: Epoch 28, Iteration 130, Current loss 2.6340503692626953 Accuracy 63.90578491005565\n",
      "Training:: Epoch 28, Iteration 140, Current loss 2.6153838634490967 Accuracy 67.9647266313933\n",
      "Training:: Epoch 28, Iteration 150, Current loss 2.161816358566284 Accuracy 65.38292447023653\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 28, Probability Accuracy 51.33177279695074\n",
      "Starting Training\n",
      "Training:: Epoch 29, Iteration 0, Current loss 3.2073822021484375 Accuracy 62.33329833035808\n",
      "Training:: Epoch 29, Iteration 10, Current loss 1.853354573249817 Accuracy 61.33795997417689\n",
      "Training:: Epoch 29, Iteration 20, Current loss 2.595517158508301 Accuracy 60.21068347710683\n",
      "Training:: Epoch 29, Iteration 30, Current loss 2.093419075012207 Accuracy 61.607078105736456\n",
      "Training:: Epoch 29, Iteration 40, Current loss 3.4862101078033447 Accuracy 60.819250551065394\n",
      "Training:: Epoch 29, Iteration 50, Current loss 2.435046434402466 Accuracy 54.19634561783834\n",
      "Training:: Epoch 29, Iteration 60, Current loss 2.21045184135437 Accuracy 75.66875875936871\n",
      "Training:: Epoch 29, Iteration 70, Current loss 3.3146183490753174 Accuracy 59.05400372439479\n",
      "Training:: Epoch 29, Iteration 80, Current loss 2.326840877532959 Accuracy 69.5882798686537\n",
      "Training:: Epoch 29, Iteration 90, Current loss 2.24250864982605 Accuracy 66.30471239309072\n",
      "Training:: Epoch 29, Iteration 100, Current loss 1.93575918674469 Accuracy 71.30619924737572\n",
      "Training:: Epoch 29, Iteration 110, Current loss 2.0324056148529053 Accuracy 64.66287571080423\n",
      "Training:: Epoch 29, Iteration 120, Current loss 2.1785054206848145 Accuracy 59.99060591827149\n",
      "Training:: Epoch 29, Iteration 130, Current loss 2.784493923187256 Accuracy 59.45635528330781\n",
      "Training:: Epoch 29, Iteration 140, Current loss 2.43613600730896 Accuracy 63.39412264953227\n",
      "Training:: Epoch 29, Iteration 150, Current loss 2.8412325382232666 Accuracy 72.03845877879027\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 29, Probability Accuracy 52.807308281890876\n",
      "Starting Training\n",
      "Training:: Epoch 30, Iteration 0, Current loss 2.8127427101135254 Accuracy 64.91869689979183\n",
      "Training:: Epoch 30, Iteration 10, Current loss 2.2597293853759766 Accuracy 68.90904806786051\n",
      "Training:: Epoch 30, Iteration 20, Current loss 2.477370500564575 Accuracy 59.84228849461012\n",
      "Training:: Epoch 30, Iteration 30, Current loss 2.692704677581787 Accuracy 50.58760107816712\n",
      "Training:: Epoch 30, Iteration 40, Current loss 2.745591878890991 Accuracy 60.45529070500694\n",
      "Training:: Epoch 30, Iteration 50, Current loss 2.9850165843963623 Accuracy 55.425634914724064\n",
      "Training:: Epoch 30, Iteration 60, Current loss 2.3426456451416016 Accuracy 66.43384553981241\n",
      "Training:: Epoch 30, Iteration 70, Current loss 2.628516674041748 Accuracy 64.16087087995162\n",
      "Training:: Epoch 30, Iteration 80, Current loss 2.2131426334381104 Accuracy 71.85910893398648\n",
      "Training:: Epoch 30, Iteration 90, Current loss 2.414746046066284 Accuracy 66.21761658031087\n",
      "Training:: Epoch 30, Iteration 100, Current loss 2.8936736583709717 Accuracy 63.23990141609925\n",
      "Training:: Epoch 30, Iteration 110, Current loss 2.651068687438965 Accuracy 64.09455628693605\n",
      "Training:: Epoch 30, Iteration 120, Current loss 2.295938491821289 Accuracy 67.1999105045307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 30, Iteration 130, Current loss 2.6234376430511475 Accuracy 73.23383963263865\n",
      "Training:: Epoch 30, Iteration 140, Current loss 2.2357916831970215 Accuracy 67.4499970843781\n",
      "Training:: Epoch 30, Iteration 150, Current loss 2.2764673233032227 Accuracy 66.3452566096423\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 30, Probability Accuracy 51.04559390147906\n",
      "Starting Training\n",
      "Training:: Epoch 31, Iteration 0, Current loss 2.4612395763397217 Accuracy 68.08035714285714\n",
      "Training:: Epoch 31, Iteration 10, Current loss 2.2597451210021973 Accuracy 63.360297042832514\n",
      "Training:: Epoch 31, Iteration 20, Current loss 1.8844285011291504 Accuracy 71.71239837398375\n",
      "Training:: Epoch 31, Iteration 30, Current loss 1.3557124137878418 Accuracy 76.35499718128372\n",
      "Training:: Epoch 31, Iteration 40, Current loss 2.649503469467163 Accuracy 65.29836000790358\n",
      "Training:: Epoch 31, Iteration 50, Current loss 1.7850632667541504 Accuracy 63.77431254191818\n",
      "Training:: Epoch 31, Iteration 60, Current loss 2.7725887298583984 Accuracy 58.12675033710196\n",
      "Training:: Epoch 31, Iteration 70, Current loss 2.399315595626831 Accuracy 56.04667007324136\n",
      "Training:: Epoch 31, Iteration 80, Current loss 2.046032667160034 Accuracy 63.96898684554404\n",
      "Training:: Epoch 31, Iteration 90, Current loss 2.3075404167175293 Accuracy 65.22321802496022\n",
      "Training:: Epoch 31, Iteration 100, Current loss 2.5279667377471924 Accuracy 55.09475418840978\n",
      "Training:: Epoch 31, Iteration 110, Current loss 1.7212231159210205 Accuracy 65.44026061128677\n",
      "Training:: Epoch 31, Iteration 120, Current loss 2.0730395317077637 Accuracy 66.66948221978208\n",
      "Training:: Epoch 31, Iteration 130, Current loss 2.7686312198638916 Accuracy 59.1763965601622\n",
      "Training:: Epoch 31, Iteration 140, Current loss 2.286764144897461 Accuracy 58.77296477330187\n",
      "Training:: Epoch 31, Iteration 150, Current loss 3.053140163421631 Accuracy 53.89492753623188\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 31, Probability Accuracy 51.09520652939471\n",
      "Starting Training\n",
      "Training:: Epoch 32, Iteration 0, Current loss 1.7116302251815796 Accuracy 59.34139784946237\n",
      "Training:: Epoch 32, Iteration 10, Current loss 2.1616952419281006 Accuracy 56.89750692520776\n",
      "Training:: Epoch 32, Iteration 20, Current loss 2.52349853515625 Accuracy 65.00841278743691\n",
      "Training:: Epoch 32, Iteration 30, Current loss 2.8769845962524414 Accuracy 64.23968594918895\n",
      "Training:: Epoch 32, Iteration 40, Current loss 3.257840156555176 Accuracy 50.53973262476127\n",
      "Training:: Epoch 32, Iteration 50, Current loss 2.308734893798828 Accuracy 48.3442265795207\n",
      "Training:: Epoch 32, Iteration 60, Current loss 2.5518531799316406 Accuracy 61.72454905580555\n",
      "Training:: Epoch 32, Iteration 70, Current loss 3.288921594619751 Accuracy 70.2301054650048\n",
      "Training:: Epoch 32, Iteration 80, Current loss 2.321442127227783 Accuracy 63.82319360626325\n",
      "Training:: Epoch 32, Iteration 90, Current loss 2.4496357440948486 Accuracy 63.59013475718281\n",
      "Training:: Epoch 32, Iteration 100, Current loss 2.0764544010162354 Accuracy 62.00020610057708\n",
      "Training:: Epoch 32, Iteration 110, Current loss 2.1029882431030273 Accuracy 63.105856613934705\n",
      "Training:: Epoch 32, Iteration 120, Current loss 2.293833017349243 Accuracy 67.68609700899138\n",
      "Training:: Epoch 32, Iteration 130, Current loss 2.786332607269287 Accuracy 49.332587881752744\n",
      "Training:: Epoch 32, Iteration 140, Current loss 2.2298331260681152 Accuracy 61.58416864730805\n",
      "Training:: Epoch 32, Iteration 150, Current loss 1.9747170209884644 Accuracy 70.5719557195572\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 32, Probability Accuracy 50.46246426647885\n",
      "Starting Training\n",
      "Training:: Epoch 33, Iteration 0, Current loss 2.185645341873169 Accuracy 55.250554841724096\n",
      "Training:: Epoch 33, Iteration 10, Current loss 2.13691782951355 Accuracy 68.07204668947475\n",
      "Training:: Epoch 33, Iteration 20, Current loss 1.7476023435592651 Accuracy 65.56791104050833\n",
      "Training:: Epoch 33, Iteration 30, Current loss 2.4371795654296875 Accuracy 67.66181036541677\n",
      "Training:: Epoch 33, Iteration 40, Current loss 2.7149856090545654 Accuracy 54.6554113644954\n",
      "Training:: Epoch 33, Iteration 50, Current loss 1.5304994583129883 Accuracy 70.1332187365707\n",
      "Training:: Epoch 33, Iteration 60, Current loss 1.6920499801635742 Accuracy 72.12505465675558\n",
      "Training:: Epoch 33, Iteration 70, Current loss 2.5427181720733643 Accuracy 63.52297966854604\n",
      "Training:: Epoch 33, Iteration 80, Current loss 2.123398542404175 Accuracy 61.32605144957125\n",
      "Training:: Epoch 33, Iteration 90, Current loss 1.956173062324524 Accuracy 66.54659144973833\n",
      "Training:: Epoch 33, Iteration 100, Current loss 2.572248697280884 Accuracy 65.11396384595231\n",
      "Training:: Epoch 33, Iteration 110, Current loss 1.9512267112731934 Accuracy 63.75108567925203\n",
      "Training:: Epoch 33, Iteration 120, Current loss 1.8019683361053467 Accuracy 55.31554426090639\n",
      "Training:: Epoch 33, Iteration 130, Current loss 1.8157439231872559 Accuracy 68.22635135135135\n",
      "Training:: Epoch 33, Iteration 140, Current loss 2.0794332027435303 Accuracy 60.57412065317204\n",
      "Training:: Epoch 33, Iteration 150, Current loss 2.0031795501708984 Accuracy 54.182058047493406\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 33, Probability Accuracy 51.880618966731575\n",
      "Starting Training\n",
      "Training:: Epoch 34, Iteration 0, Current loss 2.677654504776001 Accuracy 47.0911874461774\n",
      "Training:: Epoch 34, Iteration 10, Current loss 1.836418867111206 Accuracy 73.7200259235256\n",
      "Training:: Epoch 34, Iteration 20, Current loss 1.7693513631820679 Accuracy 69.287109375\n",
      "Training:: Epoch 34, Iteration 30, Current loss 1.9523566961288452 Accuracy 57.77573740387926\n",
      "Training:: Epoch 34, Iteration 40, Current loss 2.360057830810547 Accuracy 51.46106986483914\n",
      "Training:: Epoch 34, Iteration 50, Current loss 1.7362961769104004 Accuracy 75.17797816801139\n",
      "Training:: Epoch 34, Iteration 60, Current loss 2.0630457401275635 Accuracy 65.98432055749129\n",
      "Training:: Epoch 34, Iteration 70, Current loss 2.697925329208374 Accuracy 60.95284081764043\n",
      "Training:: Epoch 34, Iteration 80, Current loss 1.9430477619171143 Accuracy 69.31501393866985\n",
      "Training:: Epoch 34, Iteration 90, Current loss 2.4623003005981445 Accuracy 61.80135636254301\n",
      "Training:: Epoch 34, Iteration 100, Current loss 2.432619333267212 Accuracy 62.57624315103897\n",
      "Training:: Epoch 34, Iteration 110, Current loss 1.9181902408599854 Accuracy 66.03786251342642\n",
      "Training:: Epoch 34, Iteration 120, Current loss 1.7737432718276978 Accuracy 66.41584542938978\n",
      "Training:: Epoch 34, Iteration 130, Current loss 1.904623031616211 Accuracy 66.36845593108019\n",
      "Training:: Epoch 34, Iteration 140, Current loss 1.996659755706787 Accuracy 74.54866008462623\n",
      "Training:: Epoch 34, Iteration 150, Current loss 2.2378621101379395 Accuracy 71.28772393892028\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 34, Probability Accuracy 52.58420681940589\n",
      "Starting Training\n",
      "Training:: Epoch 35, Iteration 0, Current loss 1.9605917930603027 Accuracy 59.643217771794006\n",
      "Training:: Epoch 35, Iteration 10, Current loss 2.306962490081787 Accuracy 64.9164677804296\n",
      "Training:: Epoch 35, Iteration 20, Current loss 1.7615139484405518 Accuracy 58.587994105964505\n",
      "Training:: Epoch 35, Iteration 30, Current loss 1.8631315231323242 Accuracy 66.93407384552093\n",
      "Training:: Epoch 35, Iteration 40, Current loss 1.7467480897903442 Accuracy 61.90909090909091\n",
      "Training:: Epoch 35, Iteration 50, Current loss 1.6366298198699951 Accuracy 63.4329563812601\n",
      "Training:: Epoch 35, Iteration 60, Current loss 1.7537667751312256 Accuracy 68.46073213997742\n",
      "Training:: Epoch 35, Iteration 70, Current loss 1.9876683950424194 Accuracy 53.526707877635125\n",
      "Training:: Epoch 35, Iteration 80, Current loss 2.661489963531494 Accuracy 63.22884597443792\n",
      "Training:: Epoch 35, Iteration 90, Current loss 1.7941097021102905 Accuracy 70.11310711909515\n",
      "Training:: Epoch 35, Iteration 100, Current loss 1.787731409072876 Accuracy 74.62937398715563\n",
      "Training:: Epoch 35, Iteration 110, Current loss 1.9513102769851685 Accuracy 63.88325685625867\n",
      "Training:: Epoch 35, Iteration 120, Current loss 1.9221129417419434 Accuracy 61.14427403802002\n",
      "Training:: Epoch 35, Iteration 130, Current loss 1.5179105997085571 Accuracy 70.015140543743\n",
      "Training:: Epoch 35, Iteration 140, Current loss 2.1469533443450928 Accuracy 61.767769853353634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:: Epoch 35, Iteration 150, Current loss 2.2645649909973145 Accuracy 71.05367793240556\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 35, Probability Accuracy 51.85731449641629\n",
      "Starting Training\n",
      "Training:: Epoch 36, Iteration 0, Current loss 1.7844520807266235 Accuracy 65.67769130998703\n",
      "Training:: Epoch 36, Iteration 10, Current loss 2.8463640213012695 Accuracy 54.83798379837984\n",
      "Training:: Epoch 36, Iteration 20, Current loss 1.8433791399002075 Accuracy 70.42580438610533\n",
      "Training:: Epoch 36, Iteration 30, Current loss 2.213423252105713 Accuracy 59.485116653258245\n",
      "Training:: Epoch 36, Iteration 40, Current loss 2.001297950744629 Accuracy 57.43120848788062\n",
      "Training:: Epoch 36, Iteration 50, Current loss 1.604368805885315 Accuracy 59.79952962257811\n",
      "Training:: Epoch 36, Iteration 60, Current loss 1.9590870141983032 Accuracy 55.709010864162465\n",
      "Training:: Epoch 36, Iteration 70, Current loss 1.3344309329986572 Accuracy 72.15124130050899\n",
      "Training:: Epoch 36, Iteration 80, Current loss 2.477557420730591 Accuracy 62.23416038989809\n",
      "Training:: Epoch 36, Iteration 90, Current loss 1.952754259109497 Accuracy 57.85675821217017\n",
      "Training:: Epoch 36, Iteration 100, Current loss 1.5255537033081055 Accuracy 68.20599184541749\n",
      "Training:: Epoch 36, Iteration 110, Current loss 2.1386654376983643 Accuracy 59.74344023323615\n",
      "Training:: Epoch 36, Iteration 120, Current loss 2.45674204826355 Accuracy 55.12404700728697\n",
      "Training:: Epoch 36, Iteration 130, Current loss 2.7179760932922363 Accuracy 61.21401063634696\n",
      "Training:: Epoch 36, Iteration 140, Current loss 1.7936383485794067 Accuracy 55.575248918313086\n",
      "Training:: Epoch 36, Iteration 150, Current loss 1.9297783374786377 Accuracy 63.94478063540091\n",
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 36, Probability Accuracy 52.853813647097816\n",
      "Starting Training\n",
      "Training:: Epoch 37, Iteration 0, Current loss 1.5421910285949707 Accuracy 71.2674412951529\n",
      "Training:: Epoch 37, Iteration 10, Current loss 1.759064793586731 Accuracy 64.12573988161894\n",
      "Training:: Epoch 37, Iteration 20, Current loss 1.4415419101715088 Accuracy 70.74812322029511\n",
      "Training:: Epoch 37, Iteration 30, Current loss 1.8792685270309448 Accuracy 68.4891706286318\n",
      "Training:: Epoch 37, Iteration 40, Current loss 2.165022850036621 Accuracy 49.78451478674394\n",
      "Training:: Epoch 37, Iteration 50, Current loss 2.078566312789917 Accuracy 65.75334252653036\n",
      "Training:: Epoch 37, Iteration 60, Current loss 1.5788440704345703 Accuracy 59.40461887598452\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-95645851addf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmiddle_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpsuedo_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_single_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmiddle_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtower_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_stages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mfinal_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ar/single_frame_and_weakly_supervised/mstcn_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_dilated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    258\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 259\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_epoch = -1\n",
    "for epoch in range(100):\n",
    "    print(\"Starting Training\")\n",
    "    model.train()\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "        psuedo_l = get_single_random(predictions[-1], item[4])\n",
    "        loss = 0\n",
    "        for p in predictions:\n",
    "            loss += ce_criterion(p, psuedo_l)\n",
    "            loss += 0.15 * torch.mean(torch.clamp(mse_criterion(F.log_softmax(p[:, :, 1:], dim=1), \n",
    "                                                                F.log_softmax(p.detach()[:, :, :-1], dim=1)), min=0,\n",
    "                                        max=16) * src_mask_mse[:, :, 1:])\n",
    "            \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                pred = torch.argmax(predictions[-1], dim=1)\n",
    "                correct = float(torch.sum((pred == item_2) * src_mask).item())\n",
    "                total = float(torch.sum(src_mask).item())\n",
    "                print(f\"Training:: Epoch {epoch}, Iteration {i}, Current loss {loss.item()}\" +\n",
    "                      f\" Accuracy {correct * 100.0 / total}\")\n",
    "    # Calculating Expectation Step\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Calculating Validation Data Accuracy\")\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, item in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "            item_0 = item[0].to(device)\n",
    "            item_1 = item[1].to(device)\n",
    "            item_2 = item[2].to(device)\n",
    "            src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "            src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "            middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "            pred = torch.argmax(predictions[-1], dim=1)\n",
    "            correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "            total += float(torch.sum(src_mask).item())\n",
    "    val_acc = correct * 100.0 / total\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), config.output_dir + \"ms-tcn-best-model.wt\")\n",
    "    torch.save(model.state_dict(), config.output_dir + \"ms-tcn-last-model.wt\")\n",
    "    print(f\"Validation:: Epoch {epoch}, Probability Accuracy {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/mstcn-lenpsuedo-full-supervised-split1/ms-tcn-best-model.wt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_dir + \"ms-tcn-best-model.wt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\n",
    "\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-speed/final-em-maximized.wt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize-mstcn-split3/ms-tcn-initial-15-epochs.wt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Validation Data Accuracy\n",
      "Validation:: Epoch 15, Probability Accuracy 57.770101729343025\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating Validation Data Accuracy\")\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "for i, item in enumerate(testloader):\n",
    "    with torch.no_grad():\n",
    "        item_0 = item[0].to(device)\n",
    "        item_1 = item[1].to(device)\n",
    "        item_2 = item[2].to(device)\n",
    "        src_mask = torch.arange(item_2.shape[1], device=item_2.device)[None, :] < item_1[:, None]\n",
    "        src_mask_mse = src_mask.unsqueeze(1).to(torch.float32).to(device)\n",
    "\n",
    "        middle_pred, predictions = model(item_0, src_mask_mse)\n",
    "\n",
    "        pred = torch.argmax(predictions[-1], dim=1)\n",
    "        correct += float(torch.sum((pred == item_2) * src_mask).item())\n",
    "        total += float(torch.sum(src_mask).item())\n",
    "\n",
    "print(f\"Validation:: Epoch {epoch}, Probability Accuracy {correct * 100.0 / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(video_id_boundary_frames, open(\"dump_dir/video_id_boundary_frames_dict.pkl\", \"wb\"))\n",
    "# pickle.dump(loaded_vidid_selected_frames, open(\"dump_dir/loaded_vidid_selected_frames_dict.pkl\", \"wb\"))\n",
    "pickle.dump(boundary_dict, open(\"dump_dir/chunk_1_video_id_boundary_frames_dict.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
