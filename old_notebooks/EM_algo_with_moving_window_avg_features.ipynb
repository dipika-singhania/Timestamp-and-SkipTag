{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os, sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import C2F_TCN\n",
    "from dataset import AugmentDataset, collate_fn_override\n",
    "from utils import calculate_mof, dotdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipika_singhania\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"992b3b1371ba79f48484cfca522b3786d7fa52c2\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "def set_seed():\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='4'\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING']='6'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epochs': 500, 'num_class': 48, 'batch_size': 50, 'learning_rate': 0.0001, 'weight_decay': 0.003, 'dataset': 'Breakfast', 'architecture': 'unet-ensemble', 'features_file_name': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/', 'chunk_size': 10, 'max_frames_per_video': 1200, 'feature_size': 2048, 'ground_truth_files_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/', 'label_id_csv': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv', 'gamma': 0.1, 'step_size': 500, 'split': 2, 'output_dir': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize/', 'project_name': 'breakfast-split-2', 'train_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split2.bundle', 'test_split_file': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split2.bundle', 'all_files': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt', 'cutoff': 8, 'data_per': 0.2, 'budget': 40, 'semi_supervised_split': '/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split2_amt0.2.bundle'}\n"
     ]
    }
   ],
   "source": [
    "config = dotdict(\n",
    "    epochs=500,\n",
    "    num_class=48,\n",
    "    batch_size=50,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=3e-3,\n",
    "    dataset=\"Breakfast\",\n",
    "    architecture=\"unet-ensemble\",\n",
    "    features_file_name=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/features/\",\n",
    "    chunk_size=10,\n",
    "    max_frames_per_video=1200,\n",
    "    feature_size=2048,\n",
    "    ground_truth_files_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/groundTruth/\",\n",
    "    label_id_csv=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/mapping.csv\",\n",
    "    gamma=0.1,\n",
    "    step_size=500,\n",
    "    split=2,\n",
    "#     output_dir=\"/mnt/data/ar-datasets/dipika/breakfast/ms_tcn/data/breakfast/results/unsuper-finetune-split2-0.05-data-llr/\",\n",
    "    output_dir=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast//results/em-maximize/\",\n",
    "    project_name=\"breakfast-split-2\",\n",
    "    train_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/train.split{}.bundle\",\n",
    "    test_split_file=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/test.split{}.bundle\",\n",
    "    all_files=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/splits/all_files.txt\",\n",
    "    cutoff=8,\n",
    "    data_per = 0.2,\n",
    "    budget=40,\n",
    "    semi_supervised_split=\"/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/semi_supervised/train.split{}_amt{}.bundle\")\n",
    "\n",
    "config.train_split_file = config.train_split_file.format(config.split)\n",
    "config.semi_supervised_split = config.semi_supervised_split.format(config.split, config.data_per)\n",
    "config.test_split_file = config.test_split_file.format(config.split)\n",
    "\n",
    "if not os.path.exists(config.output_dir):\n",
    "    os.mkdir(config.output_dir)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos logged in train fold is 1261\n",
      "Number of videos not found in train fold is 0\n",
      "Number of videos logged in test fold is 451\n",
      "Number of videos not found in test fold is 0\n"
     ]
    }
   ],
   "source": [
    "# traindataset = AugmentDataset(config, fold='train', fold_file_name=config.semi_supervised_split, augment=False)\n",
    "traindataset = AugmentDataset(config, fold='train', fold_file_name=config.train_split_file, augment=False)\n",
    "testdataset = AugmentDataset(config, fold='test', fold_file_name=config.test_split_file, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=7, collate_fn=collate_fn_override,\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))\n",
    "trainloader = torch.utils.data.DataLoader(dataset=traindataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          pin_memory=True, num_workers=4, collate_fn=collate_fn_override,\n",
    "                                          worker_init_fn=_init_fn)\n",
    "testloader = torch.utils.data.DataLoader(dataset=testdataset,\n",
    "                                          batch_size=config.batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          pin_memory=True, num_workers=4, collate_fn=collate_fn_override,\n",
    "                                          worker_init_fn=_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item = iter(trainloader).next()\n",
    "# print(item[0]) # -- data feature\n",
    "# print(item[1]) # -- valid count\n",
    "# item[2] # -- Actual labels\n",
    "# print(item[5]) # video names\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vidid_selected_frames = pickle.load(open(\"dump_dir/breakfast_split2_selected_frames_dict.pkl\", \"rb\"))\n",
    "# loaded_vidid_selected_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id_boundary_frames = pickle.load(open(\"dump_dir/breakfast_split2_boundary_frames_dict.pkl\", \"rb\"))\n",
    "# video_id_boundary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = C2F_TCN(n_channels=config.feature_size, n_classes=config.num_class).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=3e-3)\n",
    "\n",
    "# Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "ce_criterion = nn.CrossEntropyLoss(ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_vals_per_segment(selected_frames, cur_vid_feat, cumsum_feat, cur_vid_count, window=2):\n",
    "    prob_each_segment = []\n",
    "    window = 5\n",
    "    \n",
    "    for i, cur_ele in enumerate(selected_frames[:-1]):\n",
    "\n",
    "        next_ele = selected_frames[i + 1]\n",
    "\n",
    "        distance = []\n",
    "        for j in range(cur_ele, next_ele):\n",
    "            leftmost = max(j - window, 0)\n",
    "            rightmost = min(j + window, cur_vid_count - 1)\n",
    "            avg_feature = torch.mean(cur_vid_feat[leftmost: rightmost+1], dim=0)\n",
    "            dist = cos(avg_feature, cur_vid_feat[leftmost]) + cos(avg_feature, cur_vid_feat[rightmost])\n",
    "#             dist = -torch.max(torch.abs(avg_feature - cur_vid_feat[leftmost]))\n",
    "#             dist += -torch.max(torch.abs(avg_feature - cur_vid_feat[rightmost+1]))\n",
    "            distance.append(dist)\n",
    "            \n",
    "        prob = torch.softmax(-torch.stack(distance)*10, dim=0)\n",
    "        prob_each_segment.append(prob)\n",
    "\n",
    "    return prob_each_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_boundary(data_feat, data_count, video_ids, window=2): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    global boundaries_dict\n",
    "    # Requires loaded_vidid_selected_frames, boundaries_dict\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        \n",
    "        selected_frames = loaded_vidid_selected_frames[cur_vidid]\n",
    "        cumsum_feat = torch.cumsum(cur_vid_feat, dim=0)\n",
    "        prob_each_segment = prob_vals_per_segment(selected_frames, cur_vid_feat, cumsum_feat, cur_vid_count)\n",
    "        bound_list = []\n",
    "        for i, cur_seg_prob in enumerate(prob_each_segment):\n",
    "            sum_prob = torch.sum(cur_seg_prob)\n",
    "            \n",
    "            current_frame_index = torch.tensor(np.arange(selected_frames[i],\n",
    "                                                         selected_frames[i + 1], 1), \n",
    "                                               dtype=torch.long, device=cur_vid_feat.device)\n",
    "            sum_prob_ele = torch.sum(cur_seg_prob * current_frame_index)\n",
    "            expected_bound = sum_prob_ele / sum_prob\n",
    "        \n",
    "            bound_list.append(int(expected_bound.item() + 1e-3))\n",
    "\n",
    "        bound_list.append((cur_vid_count - 1).item())\n",
    "        boundaries_dict[cur_vidid] = torch.tensor(bound_list, dtype=torch.long, device=cur_vid_feat.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_probabilities(data_feat, data_count, video_ids, p_boundary): #, loaded_vidid_selected_frames, boundaries_dict):\n",
    "    prob_list = []\n",
    "    for iter_num in range(len(data_count)):\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        cur_vid_feat = data_feat[iter_num]\n",
    "        cur_vid_count = data_count[iter_num]\n",
    "        \n",
    "        selected_frames = torch.tensor(loaded_vidid_selected_frames[cur_vidid], dtype=torch.long, \n",
    "                                       device=cur_vid_feat.device)\n",
    "        bound_list = p_boundary[cur_vidid].to(device)\n",
    "\n",
    "        cumsum_feat = torch.cumsum(cur_vid_feat, dim=0)\n",
    "        \n",
    "        avg_from_st_ele = (cumsum_feat[bound_list[:-1], :] - cumsum_feat[(selected_frames[:-1] - 1), :]) / \\\n",
    "                            ((bound_list[:-1] - (selected_frames[:-1] - 1))[:, None])\n",
    "            \n",
    "        avg_from_end_ele = cumsum_feat[selected_frames[1:], :] - cumsum_feat[(bound_list[:-1] - 1), :] / \\\n",
    "                               ((selected_frames[1:] - (bound_list[:-1] - 1))[:, None])\n",
    "        \n",
    "        dist_value_1 = cos(cur_vid_feat[selected_frames[:-1], :], avg_from_st_ele)\n",
    "        dist_value_2 = cos(cur_vid_feat[selected_frames[1:], :], avg_from_end_ele)\n",
    "#         dist_value_1 = torch.norm(cur_vid_feat[selected_frames[:-1], :] - avg_from_st_ele, dim=1)\n",
    "#         dist_value_2 = torch.norm(cur_vid_feat[selected_frames[1:], :] - avg_from_end_ele, dim=1)\n",
    "        \n",
    "        dist_value_1 = torch.exp(dist_value_1 / 0.1)\n",
    "        dist_value_2 = torch.exp(dist_value_2 / 0.1)\n",
    "\n",
    "        prob = dist_value_1 #/ (dist_value_1 + dist_value_2)\n",
    "#         prob = dist_value_2 / (dist_value_1 + dist_value_2)\n",
    "        if torch.any(torch.isnan(prob)):\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        \n",
    "        sum_prob_list = []\n",
    "        prob_each_segment = prob_vals_per_segment(selected_frames, cur_vid_feat, cumsum_feat)\n",
    "        for i, cur_seg_prob in enumerate(prob_each_segment):\n",
    "            sum_prob = torch.sum(cur_seg_prob)\n",
    "            sum_prob_list.append(sum_prob)\n",
    "\n",
    "        final_prob = prob / torch.tensor(sum_prob_list, dtype=prob.dtype, device=prob.device)\n",
    "        prob_list.append(final_prob)\n",
    "        \n",
    "    return torch.cat(prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_err():\n",
    "    err_list = []\n",
    "    for ele in boundaries_dict.keys():\n",
    "        estimated = boundaries_dict[ele].detach().cpu().numpy()\n",
    "        actual = np.array(video_id_boundary_frames[ele])\n",
    "        if len(actual) != len(estimated):\n",
    "            print(ele)\n",
    "            continue\n",
    "        \n",
    "        mse_err = (actual - estimated)**2\n",
    "        err_list.append(mse_err)\n",
    "    print(f\"Avergage error = {np.sqrt(np.mean(np.concatenate(err_list))):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_loss(features, labels_all, video_ids):\n",
    "    global ce_criterion\n",
    "    labels_arr = []\n",
    "    selected_probs_arr = []\n",
    "    for iter_num in range(len(features)):\n",
    "        cur_vid_feat = features[iter_num].T\n",
    "        cur_vidid = video_ids[iter_num]\n",
    "        labels = labels_all[iter_num]\n",
    "        \n",
    "        selected_frames = torch.tensor(loaded_vidid_selected_frames[cur_vidid], dtype=torch.long, \n",
    "                                       device=cur_vid_feat.device)\n",
    "        selected_labels = labels[selected_frames]\n",
    "        selected_probs = cur_vid_feat[selected_frames, :]\n",
    "        \n",
    "        labels_arr.append(selected_labels)\n",
    "        selected_probs_arr.append(selected_probs)\n",
    "        \n",
    "    labels_arr = torch.cat(labels_arr)\n",
    "    selected_probs_arr = torch.cat(selected_probs_arr)\n",
    "    \n",
    "    return ce_criterion(selected_probs_arr, labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avergage error = 20.112\n",
      "Starting Maximization\n",
      "Current loss 5.865112781524658\n",
      "Calculating Expectation\n",
      "Avergage error = 20.208\n",
      "Starting Maximization\n",
      "Current loss 5.755773544311523\n",
      "Starting Maximization\n",
      "Current loss 5.732485771179199\n",
      "Starting Maximization\n",
      "Current loss 5.352148056030273\n",
      "Starting Maximization\n",
      "Current loss 5.064152717590332\n",
      "Starting Maximization\n",
      "Current loss 5.00228214263916\n",
      "Starting Maximization\n",
      "Current loss 4.6894426345825195\n",
      "Starting Maximization\n",
      "Current loss 4.816783428192139\n",
      "Starting Maximization\n",
      "Current loss 4.721427917480469\n",
      "Starting Maximization\n",
      "Current loss 4.450620651245117\n",
      "Starting Maximization\n",
      "Current loss 4.39108943939209\n",
      "Calculating Expectation\n",
      "Avergage error = 20.185\n",
      "Starting Maximization\n",
      "Current loss 4.473072052001953\n",
      "Starting Maximization\n",
      "Current loss 4.365487098693848\n",
      "Starting Maximization\n",
      "Current loss 4.183102130889893\n",
      "Starting Maximization\n",
      "Current loss 4.162242889404297\n",
      "Starting Maximization\n",
      "Current loss 3.819270372390747\n",
      "Starting Maximization\n",
      "Current loss 3.953507423400879\n",
      "Starting Maximization\n",
      "Current loss 3.9773788452148438\n",
      "Starting Maximization\n",
      "Current loss 3.7886064052581787\n",
      "Starting Maximization\n",
      "Current loss 3.5276529788970947\n",
      "Starting Maximization\n",
      "Current loss 3.6104836463928223\n",
      "Calculating Expectation\n",
      "Avergage error = 19.971\n",
      "Starting Maximization\n",
      "Current loss 3.6840062141418457\n",
      "Starting Maximization\n",
      "Current loss 3.38993501663208\n",
      "Starting Maximization\n",
      "Current loss 3.3740365505218506\n",
      "Starting Maximization\n",
      "Current loss 3.3565690517425537\n",
      "Starting Maximization\n",
      "Current loss 3.4671342372894287\n",
      "Starting Maximization\n",
      "Current loss 3.3785245418548584\n",
      "Starting Maximization\n",
      "Current loss 3.4785308837890625\n",
      "Starting Maximization\n",
      "Current loss 3.622549533843994\n",
      "Starting Maximization\n",
      "Current loss 3.3723320960998535\n",
      "Starting Maximization\n",
      "Current loss 3.3460171222686768\n",
      "Calculating Expectation\n",
      "Avergage error = 19.956\n",
      "Starting Maximization\n",
      "Current loss 3.327150583267212\n",
      "Starting Maximization\n",
      "Current loss 3.55696439743042\n",
      "Starting Maximization\n",
      "Current loss 3.5804412364959717\n",
      "Starting Maximization\n",
      "Current loss 3.616877555847168\n",
      "Starting Maximization\n",
      "Current loss 3.33453106880188\n",
      "Starting Maximization\n",
      "Current loss 3.4315648078918457\n",
      "Starting Maximization\n",
      "Current loss 3.257889986038208\n",
      "Starting Maximization\n",
      "Current loss 3.1707406044006348\n",
      "Starting Maximization\n",
      "Current loss 3.108433246612549\n",
      "Starting Maximization\n",
      "Current loss 3.01628041267395\n",
      "Calculating Expectation\n",
      "Avergage error = 20.030\n",
      "Starting Maximization\n",
      "Current loss 3.004364490509033\n",
      "Starting Maximization\n",
      "Current loss 3.119765043258667\n",
      "Starting Maximization\n",
      "Current loss 2.9445858001708984\n",
      "Starting Maximization\n",
      "Current loss 3.0518293380737305\n",
      "Starting Maximization\n",
      "Current loss 2.89442777633667\n",
      "Starting Maximization\n",
      "Current loss 2.9315152168273926\n",
      "Starting Maximization\n",
      "Current loss 2.946450710296631\n",
      "Starting Maximization\n",
      "Current loss 2.769810914993286\n",
      "Starting Maximization\n",
      "Current loss 2.8646397590637207\n",
      "Starting Maximization\n",
      "Current loss 2.918936014175415\n",
      "Calculating Expectation\n",
      "Avergage error = 19.928\n",
      "Starting Maximization\n",
      "Current loss 3.1843528747558594\n",
      "Starting Maximization\n",
      "Current loss 2.8897159099578857\n",
      "Starting Maximization\n",
      "Current loss 3.2217204570770264\n",
      "Starting Maximization\n",
      "Current loss 3.385744571685791\n",
      "Starting Maximization\n",
      "Current loss 3.289123058319092\n",
      "Starting Maximization\n",
      "Current loss 3.060670852661133\n",
      "Starting Maximization\n",
      "Current loss 2.954813003540039\n",
      "Starting Maximization\n",
      "Current loss 2.843250274658203\n",
      "Starting Maximization\n",
      "Current loss 2.8063013553619385\n",
      "Starting Maximization\n",
      "Current loss 2.7875778675079346\n",
      "Calculating Expectation\n",
      "Avergage error = 19.988\n",
      "Starting Maximization\n",
      "Current loss 2.6595237255096436\n",
      "Starting Maximization\n",
      "Current loss 2.6652045249938965\n",
      "Starting Maximization\n",
      "Current loss 2.6351237297058105\n",
      "Starting Maximization\n",
      "Current loss 2.6849281787872314\n",
      "Starting Maximization\n",
      "Current loss 2.6440327167510986\n",
      "Starting Maximization\n",
      "Current loss 2.6922953128814697\n",
      "Starting Maximization\n",
      "Current loss 2.6358847618103027\n",
      "Starting Maximization\n",
      "Current loss 2.714280366897583\n",
      "Starting Maximization\n",
      "Current loss 2.5360798835754395\n",
      "Starting Maximization\n",
      "Current loss 2.603071928024292\n",
      "Calculating Expectation\n",
      "Avergage error = 19.920\n",
      "Starting Maximization\n",
      "Current loss 2.646090269088745\n",
      "Starting Maximization\n",
      "Current loss 2.606037139892578\n",
      "Starting Maximization\n",
      "Current loss 2.6011669635772705\n",
      "Starting Maximization\n",
      "Current loss 2.4974377155303955\n",
      "Starting Maximization\n",
      "Current loss 2.6505701541900635\n",
      "Starting Maximization\n",
      "Current loss 2.5965077877044678\n",
      "Starting Maximization\n",
      "Current loss 2.743781328201294\n",
      "Starting Maximization\n",
      "Current loss 2.752922773361206\n",
      "Starting Maximization\n",
      "Current loss 2.7353570461273193\n",
      "Starting Maximization\n",
      "Current loss 2.6618075370788574\n",
      "Calculating Expectation\n",
      "Avergage error = 19.855\n",
      "Starting Maximization\n",
      "Current loss 2.5342488288879395\n",
      "Starting Maximization\n",
      "Current loss 2.5827724933624268\n",
      "Starting Maximization\n",
      "Current loss 2.4985477924346924\n",
      "Starting Maximization\n",
      "Current loss 2.5451841354370117\n",
      "Starting Maximization\n",
      "Current loss 2.6468586921691895\n",
      "Starting Maximization\n",
      "Current loss 2.457188367843628\n",
      "Starting Maximization\n",
      "Current loss 2.5233941078186035\n",
      "Starting Maximization\n",
      "Current loss 2.5883257389068604\n",
      "Starting Maximization\n",
      "Current loss 2.565250873565674\n",
      "Starting Maximization\n",
      "Current loss 2.5228803157806396\n",
      "Calculating Expectation\n",
      "Avergage error = 19.905\n",
      "Starting Maximization\n",
      "Current loss 2.553593158721924\n",
      "Starting Maximization\n",
      "Current loss 2.5679807662963867\n",
      "Starting Maximization\n",
      "Current loss 2.606584072113037\n",
      "Starting Maximization\n",
      "Current loss 2.486295461654663\n",
      "Starting Maximization\n",
      "Current loss 2.5482518672943115\n",
      "Starting Maximization\n",
      "Current loss 2.527451992034912\n",
      "Starting Maximization\n",
      "Current loss 2.4996848106384277\n",
      "Starting Maximization\n",
      "Current loss 2.524101495742798\n",
      "Starting Maximization\n",
      "Current loss 2.5516107082366943\n",
      "Starting Maximization\n",
      "Current loss 2.558800458908081\n",
      "Calculating Expectation\n",
      "Avergage error = 20.077\n",
      "Starting Maximization\n",
      "Current loss 2.4473202228546143\n",
      "Starting Maximization\n",
      "Current loss 2.5955169200897217\n",
      "Starting Maximization\n",
      "Current loss 2.5723814964294434\n",
      "Starting Maximization\n",
      "Current loss 2.4787936210632324\n",
      "Starting Maximization\n",
      "Current loss 2.715998888015747\n",
      "Starting Maximization\n",
      "Current loss 2.626840353012085\n",
      "Starting Maximization\n",
      "Current loss 2.571302890777588\n",
      "Starting Maximization\n",
      "Current loss 2.644163131713867\n",
      "Starting Maximization\n",
      "Current loss 2.5507335662841797\n",
      "Starting Maximization\n",
      "Current loss 2.717036485671997\n",
      "Calculating Expectation\n",
      "Avergage error = 20.101\n",
      "Starting Maximization\n",
      "Current loss 2.5863454341888428\n",
      "Starting Maximization\n",
      "Current loss 2.4915130138397217\n",
      "Starting Maximization\n",
      "Current loss 2.621616840362549\n",
      "Starting Maximization\n",
      "Current loss 2.5505998134613037\n",
      "Starting Maximization\n",
      "Current loss 2.553128957748413\n",
      "Starting Maximization\n",
      "Current loss 2.7174758911132812\n",
      "Starting Maximization\n",
      "Current loss 2.774289131164551\n",
      "Starting Maximization\n",
      "Current loss 2.7670249938964844\n",
      "Starting Maximization\n",
      "Current loss 2.6445682048797607\n",
      "Starting Maximization\n",
      "Current loss 2.5516886711120605\n",
      "Calculating Expectation\n",
      "Avergage error = 20.237\n",
      "Starting Maximization\n",
      "Current loss 2.488281011581421\n",
      "Starting Maximization\n",
      "Current loss 2.4317994117736816\n",
      "Starting Maximization\n",
      "Current loss 2.5133347511291504\n",
      "Starting Maximization\n",
      "Current loss 2.6617276668548584\n",
      "Starting Maximization\n",
      "Current loss 2.677480697631836\n",
      "Starting Maximization\n",
      "Current loss 2.6057567596435547\n",
      "Starting Maximization\n",
      "Current loss 2.7178726196289062\n",
      "Starting Maximization\n",
      "Current loss 2.6227307319641113\n",
      "Starting Maximization\n",
      "Current loss 2.6369917392730713\n",
      "Starting Maximization\n",
      "Current loss 2.6036360263824463\n",
      "Calculating Expectation\n",
      "Avergage error = 19.894\n",
      "Starting Maximization\n",
      "Current loss 2.506899118423462\n",
      "Starting Maximization\n",
      "Current loss 2.568363666534424\n",
      "Starting Maximization\n",
      "Current loss 2.614121198654175\n",
      "Starting Maximization\n",
      "Current loss 2.531175136566162\n",
      "Starting Maximization\n",
      "Current loss 2.6761438846588135\n",
      "Starting Maximization\n",
      "Current loss 2.728044271469116\n",
      "Starting Maximization\n",
      "Current loss 2.7865285873413086\n",
      "Starting Maximization\n",
      "Current loss 2.672376871109009\n",
      "Starting Maximization\n",
      "Current loss 2.746605634689331\n",
      "Starting Maximization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss 2.60371470451355\n",
      "Calculating Expectation\n",
      "Avergage error = 20.055\n",
      "Starting Maximization\n",
      "Current loss 2.52912974357605\n",
      "Starting Maximization\n",
      "Current loss 2.6835691928863525\n",
      "Starting Maximization\n",
      "Current loss 2.741072177886963\n",
      "Starting Maximization\n",
      "Current loss 2.7119293212890625\n",
      "Starting Maximization\n",
      "Current loss 2.5977976322174072\n",
      "Starting Maximization\n",
      "Current loss 2.5738778114318848\n",
      "Starting Maximization\n",
      "Current loss 2.4984257221221924\n",
      "Starting Maximization\n",
      "Current loss 2.455995798110962\n",
      "Starting Maximization\n",
      "Current loss 2.5851333141326904\n",
      "Starting Maximization\n",
      "Current loss 2.5419442653656006\n",
      "Calculating Expectation\n",
      "Avergage error = 20.021\n",
      "Starting Maximization\n",
      "Current loss 2.509307384490967\n",
      "Starting Maximization\n",
      "Current loss 2.575324535369873\n",
      "Starting Maximization\n",
      "Current loss 2.7005209922790527\n",
      "Starting Maximization\n",
      "Current loss 2.565095901489258\n",
      "Starting Maximization\n",
      "Current loss 2.5789401531219482\n",
      "Starting Maximization\n",
      "Current loss 2.457075357437134\n",
      "Starting Maximization\n",
      "Current loss 2.550447940826416\n",
      "Starting Maximization\n",
      "Current loss 2.532252550125122\n",
      "Starting Maximization\n",
      "Current loss 2.58476185798645\n",
      "Starting Maximization\n",
      "Current loss 2.5186104774475098\n",
      "Calculating Expectation\n",
      "Avergage error = 20.007\n",
      "Starting Maximization\n",
      "Current loss 2.5343310832977295\n",
      "Starting Maximization\n",
      "Current loss 2.7264833450317383\n",
      "Starting Maximization\n",
      "Current loss 2.634915351867676\n",
      "Starting Maximization\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b12b6bc2f6bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting Maximization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/video_r/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        get_estimated_boundary(item[0], item[1], item[5])\n",
    "get_boundary_err()\n",
    "\n",
    "for epoch in range(500):\n",
    "    print(\"Starting Maximization\")\n",
    "    for i, item in enumerate(trainloader):\n",
    "        item[0] = item[0].to(device)\n",
    "        item[1] = item[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y, _, features = model(item[0].permute(0,2,1))\n",
    "        loss_ce = get_classification_loss(y, item[2].to(device), item[5])\n",
    "\n",
    "        features = features.permute(0, 2, 1)\n",
    "        frame_proba = get_boundary_probabilities(features, item[1], item[5], boundaries_dict)\n",
    "        loss_em = -torch.mean(torch.log(frame_proba + 1e-4))\n",
    "        \n",
    "        loss = loss_ce + loss_em\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%10==0:\n",
    "            print(f\"Current loss {loss.item()}\")\n",
    "            \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"Calculating Expectation\")\n",
    "        for i, item in enumerate(trainloader):\n",
    "            with torch.no_grad():\n",
    "                item[0] = item[0].to(device)\n",
    "                item[1] = item[1].to(device)\n",
    "                _, _, features = model(item[0].permute(0,2,1))\n",
    "                features = features.permute(0,2,1)\n",
    "                get_estimated_boundary(features, item[1], item[5])\n",
    "        get_boundary_err()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_labels(labels_arr):\n",
    "    unique_ids = []\n",
    "    \n",
    "    prev_ele = None\n",
    "    start = 0\n",
    "    for i, ele in enumerate(labels_arr):\n",
    "        if prev_ele is not None and prev_ele != ele:\n",
    "            select_item = np.random.randint(start, i, 1)[0]\n",
    "            unique_ids.append(select_item)\n",
    "            start = i\n",
    "        prev_ele = ele\n",
    "    \n",
    "    select_item = np.random.randint(start, len(labels_arr), 1)[0]\n",
    "    unique_ids.append(select_item)\n",
    "    return unique_ids\n",
    "# get_selected_labels(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary(labels_arr):\n",
    "    unique_ids = []\n",
    "    \n",
    "    prev_ele = None\n",
    "    start = 0\n",
    "    for i, ele in enumerate(labels_arr):\n",
    "        if prev_ele is not None and prev_ele != ele:\n",
    "            unique_ids.append(i - 1)\n",
    "            start = i\n",
    "        prev_ele = ele\n",
    "    \n",
    "    unique_ids.append(len(labels_arr) - 1)\n",
    "    return unique_ids\n",
    "# get_boundary(np.array([2, 2, 2, 2, 3, 3, 4, 4, 4, 1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/queues.py\", line 232, in _feed\n",
      "    close()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/home/dipika16/anaconda3/envs/video_r/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    }
   ],
   "source": [
    "loaded_vidid_selected_frames = {}\n",
    "for batch in trainloader:\n",
    "    count_all = batch[1]\n",
    "    labels_all = batch[2]\n",
    "    video_ids = batch[5]\n",
    "    for i, count in enumerate(count_all):\n",
    "        video_id = video_ids[i]\n",
    "        labels = labels_all[i][:count]\n",
    "        selected_ids = get_selected_labels(labels)\n",
    "\n",
    "        loaded_vidid_selected_frames[video_id] = selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id_boundary_frames = {}\n",
    "for batch in trainloader:\n",
    "    count_all = batch[1]\n",
    "    labels_all = batch[2]\n",
    "    video_ids = batch[5]\n",
    "    for i, count in enumerate(count_all):\n",
    "        \n",
    "        labels = labels_all[i][:count]\n",
    "        selected_ids = get_boundary(labels)\n",
    "        video_id = video_ids[i]\n",
    "        video_id_boundary_frames[video_id] = selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ele in video_id_boundary_frames.keys():\n",
    "    if len(video_id_boundary_frames[ele]) != len(loaded_vidid_selected_frames[ele]):\n",
    "        print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(video_id_boundary_frames, open(\"dump_dir/video_id_boundary_frames_dict.pkl\", \"wb\"))\n",
    "pickle.dump(loaded_vidid_selected_frames, open(\"dump_dir/loaded_vidid_selected_frames_dict.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = C2F_TCN(n_channels=config.feature_size, n_classes=config.num_class).to(device)\n",
    "model.load_state_dict(torch.load(f'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/results/c2f-tcn-model/'\n",
    "                                 f'split2_c2ftcn_model.wt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avergage error = 49.585\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        item[0] = item[0].to(device)\n",
    "        item[1] = item[1].to(device)\n",
    "        _, _, features = model(item[0].permute(0,2,1))\n",
    "#         _, _, features = model(item[0].permute(0,2,1))\n",
    "        features = features.permute(0,2,1)\n",
    "        get_estimated_boundary(features, item[1], item[5])\n",
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from c2f_unsupervised_c2f_model_file import UNetSSLContrastive\n",
    "model = UNetSSLContrastive(2048, 48, 256).to(device)\n",
    "model.load_state_dict(torch.load(f'/mnt/ssd/all_users/dipika/ms_tcn/data/breakfast/results/'\n",
    "                                 f'cluster-100_chul_all_layer_model_split2_clustTypeKMEANS_fti3d_notimeFalse_lr0.001000/'\n",
    "                                 f'best_breakfast_unet.wt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avergage error = 48.193\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, item in enumerate(trainloader):\n",
    "    with torch.no_grad():\n",
    "        item[0] = item[0].to(device)\n",
    "        item[1] = item[1].to(device)\n",
    "        features, _  = model(item[0].permute(0,2,1), [1,1,1,1,1,1])\n",
    "#         _, _, features = model(item[0].permute(0,2,1))\n",
    "        features = features.permute(0,2,1)\n",
    "        get_estimated_boundary(features, item[1], item[5])\n",
    "get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    idx = 0\n",
    "\n",
    "    cur_vid_feat = features[idx]\n",
    "    cur_vidid = item[5][idx]\n",
    "\n",
    "    selected_frames = torch.tensor(loaded_vidid_selected_frames[cur_vidid], dtype=torch.long, \n",
    "                                   device=cur_vid_feat.device)\n",
    "    bound_list = boundaries_dict[cur_vidid].to(device)\n",
    "\n",
    "    cumsum_feat = torch.cumsum(cur_vid_feat, dim=0)\n",
    "\n",
    "    prob_each_segment = prob_vals_per_segment(selected_frames, cur_vid_feat, cumsum_feat, item[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98294a9630>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.plot([0, item[1][idx].item()], [0, 0])\n",
    "\n",
    "for pivot in loaded_vidid_selected_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, 1], '--')\n",
    "    \n",
    "for pivot in video_id_boundary_frames[cur_vidid]:\n",
    "    plt.plot([pivot, pivot], [0, 1])\n",
    "    \n",
    "all_prob = []\n",
    "for segment in prob_each_segment:\n",
    "    all_prob.append(segment/torch.sum(segment))\n",
    "\n",
    "all_prob = torch.cat(all_prob).cpu().numpy()\n",
    "xs = np.arange(loaded_vidid_selected_frames[cur_vidid][0], loaded_vidid_selected_frames[cur_vidid][-1])\n",
    "plt.plot(xs, all_prob, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 21 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 23 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 25 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dipika16/anaconda3/envs/video_r/lib/python3.7/site-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avergage error = 48.193\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "gt_seg = 0\n",
    "pred_seg = 0\n",
    "err = []\n",
    "\n",
    "for i, item in enumerate(trainloader):\n",
    "    print(f'Batch {i} started')\n",
    "    with torch.no_grad():\n",
    "        item[0] = item[0].to(device)\n",
    "        item[1] = item[1].to(device)\n",
    "        features, _  = model(item[0].permute(0,2,1), [1,1,1,1,1,1])\n",
    "        features = features.permute(0,2,1)\n",
    "        \n",
    "        for j in range(len(features)):\n",
    "            vid_count = item[1][j].item()\n",
    "            vid_labels = item[2][j][:vid_count]\n",
    "            vid_feat = features[j][:vid_count]\n",
    "            segments = vid_labels[:-1][vid_labels[1:]!=vid_labels[:-1]]\n",
    "            segments = torch.cat([segments, vid_labels[-1].unsqueeze(dim=0)])\n",
    "            np_features = vid_feat.cpu().numpy()\n",
    "            \n",
    "            num_seg = len(segments)\n",
    "            \n",
    "            clust = KMeans(n_clusters=num_seg).fit(np_features)\n",
    "            cluster_labels = clust.labels_\n",
    "            cluster_centers = clust.cluster_centers_\n",
    "\n",
    "            nearest_points = [np.argmin(np.linalg.norm(np_features[cluster_labels==k] - cluster_centers[k][None,:], \n",
    "                                                       axis=-1)) for k in range(num_seg)]\n",
    "            actual_pos = [np.arange(vid_count)[cluster_labels==k][pt] for k,pt in enumerate(nearest_points)]\n",
    "\n",
    "            predicted_segment_arr = vid_labels[np.sort(actual_pos)]\n",
    "            num_predicted_segments = torch.sum(predicted_segment_arr[1:]!=predicted_segment_arr[:-1]) + 1\n",
    "            \n",
    "            gt_seg += num_seg\n",
    "            pred_seg += num_predicted_segments\n",
    "            err.append(num_seg - num_predicted_segments)\n",
    "\n",
    "#         get_estimated_boundary(features, item[1], item[5])\n",
    "# get_boundary_err()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([378., 413., 196., 196.,  37.,  18.,  15.,   2.,   2.,   4.]),\n",
       "  array([ 0. ,  1.3,  2.6,  3.9,  5.2,  6.5,  7.8,  9.1, 10.4, 11.7, 13. ]),\n",
       "  <a list of 10 Patch objects>),\n",
       " tensor(37.2266))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(err), 100*(gt_seg - pred_seg)/gt_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=2\n",
    "vid_count = item[1][j].item()\n",
    "vid_labels = item[2][j][:vid_count]\n",
    "vid_feat = features[j][:vid_count]\n",
    "segments = vid_labels[:-1][vid_labels[1:]!=vid_labels[:-1]]\n",
    "segments = torch.cat([segments, vid_labels[-1].unsqueeze(dim=0)])\n",
    "np_features = vid_feat.cpu().numpy()\n",
    "\n",
    "# clust = KMeans(n_clusters=len(segments)).fit(np_features)\n",
    "# cluster_labels = clust.labels_\n",
    "# cluster_centers = clust.cluster_centers_\n",
    "\n",
    "nearest_points = [np.argmin(np.linalg.norm(np_features[cluster_labels==k] - cluster_centers[k][None,:], axis=-1)) \n",
    "                  for k in range(len(segments))]\n",
    "actual_pos = [np.arange(vid_count)[cluster_labels==k][pt] for k,pt in enumerate(nearest_points)]\n",
    "\n",
    "predicted_segment_arr = vid_labels[np.sort(actual_pos)]\n",
    "num_predicted_segments = torch.sum(predicted_segment_arr[1:]!=predicted_segment_arr[:-1]) + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
